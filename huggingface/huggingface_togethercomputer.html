<!doctype html>
<html class="">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
		<meta name="description" content="Weâ€™re on a journey to advance and democratize artificial intelligence through open source and open science." />
		<meta property="fb:app_id" content="1321688464574422" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@huggingface" />
		<meta name="twitter:image" content="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/togethercomputer/RedPajama-Data-1T-Sample.png" />
		<meta property="og:title" content="togethercomputer/RedPajama-Data-1T-Sample Â· Datasets at Hugging Face" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T-Sample" />
		<meta property="og:image" content="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/togethercomputer/RedPajama-Data-1T-Sample.png" />

		<link rel="stylesheet" href="/front/build/kube-68d7aa0/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript>
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" />
		</noscript>

		<script>const guestTheme = document.cookie.match(/theme=(\w+)/)?.[1]; document.documentElement.classList.toggle('dark', guestTheme === 'dark' || ( (!guestTheme || guestTheme === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches));</script>
<link rel="canonical" href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T-Sample"> <script type="application/ld+json">{
  "@context": {
    "@language": "en",
    "@vocab": "https:\/\/schema.org\/",
    "citeAs": "cr:citeAs",
    "column": "cr:column",
    "conformsTo": "dct:conformsTo",
    "cr": "http:\/\/mlcommons.org\/croissant\/",
    "data": {
      "@id": "cr:data",
      "@type": "@json"
    },
    "dataBiases": "cr:dataBiases",
    "dataCollection": "cr:dataCollection",
    "dataType": {
      "@id": "cr:dataType",
      "@type": "@vocab"
    },
    "dct": "http:\/\/purl.org\/dc\/terms\/",
    "extract": "cr:extract",
    "field": "cr:field",
    "fileProperty": "cr:fileProperty",
    "fileObject": "cr:fileObject",
    "fileSet": "cr:fileSet",
    "format": "cr:format",
    "includes": "cr:includes",
    "isLiveDataset": "cr:isLiveDataset",
    "jsonPath": "cr:jsonPath",
    "key": "cr:key",
    "md5": "cr:md5",
    "parentField": "cr:parentField",
    "path": "cr:path",
    "personalSensitiveInformation": "cr:personalSensitiveInformation",
    "recordSet": "cr:recordSet",
    "references": "cr:references",
    "regex": "cr:regex",
    "repeated": "cr:repeated",
    "replace": "cr:replace",
    "sc": "https:\/\/schema.org\/",
    "separator": "cr:separator",
    "source": "cr:source",
    "subField": "cr:subField",
    "transform": "cr:transform"
  },
  "@type": "sc:Dataset",
  "distribution": [
    {
      "@type": "cr:FileObject",
      "@id": "repo",
      "name": "repo",
      "description": "The Hugging Face git repository.",
      "contentUrl": "https:\/\/huggingface.co\/datasets\/togethercomputer\/RedPajama-Data-1T-Sample\/tree\/refs%2Fconvert%2Fparquet",
      "encodingFormat": "git+https",
      "sha256": "https:\/\/github.com\/mlcommons\/croissant\/issues\/80"
    },
    {
      "@type": "cr:FileSet",
      "@id": "parquet-files-for-config-plain_text",
      "name": "parquet-files-for-config-plain_text",
      "description": "The underlying Parquet files as converted by Hugging Face (see: https:\/\/huggingface.co\/docs\/dataset-viewer\/parquet).",
      "containedIn": {
        "@id": "repo"
      },
      "encodingFormat": "application\/x-parquet",
      "includes": "plain_text\/*\/*.parquet"
    }
  ],
  "recordSet": [
    {
      "@type": "cr:RecordSet",
      "dataType": "cr:Split",
      "key": {
        "@id": "plain_text_splits\/split_name"
      },
      "@id": "plain_text_splits",
      "name": "plain_text_splits",
      "description": "Splits for the plain_text config.",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "plain_text_splits\/split_name",
          "name": "split_name",
          "description": "The name of the split.",
          "dataType": "sc:Text"
        }
      ],
      "data": [
        {
          "plain_text_splits\/split_name": "train"
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "@id": "plain_text",
      "name": "plain_text",
      "description": "togethercomputer\/RedPajama-Data-1T-Sample - 'plain_text' subset (first 5GB)",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "plain_text\/split",
          "name": "plain_text\/split",
          "description": "Split to which the example belongs to.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-plain_text"
            },
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "plain_text\/(?:partial-)?(train)\/.+parquet$"
            }
          },
          "references": {
            "field": {
              "@id": "plain_text_splits\/split_name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "plain_text\/text",
          "name": "plain_text\/text",
          "description": "Column 'text' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-plain_text"
            },
            "extract": {
              "column": "text"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "plain_text\/meta",
          "name": "plain_text\/meta",
          "description": "Column 'meta' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-plain_text"
            },
            "extract": {
              "column": "meta"
            }
          }
        }
      ]
    }
  ],
  "conformsTo": "http:\/\/mlcommons.org\/croissant\/1.0",
  "name": "RedPajama-Data-1T-Sample",
  "description": "RedPajama is a clean-room, fully open-source implementation of the LLaMa dataset. This is a 1B-token sample of the full dataset.",
  "alternateName": [
    "togethercomputer\/RedPajama-Data-1T-Sample",
    "Red Pajama 1T Sample"
  ],
  "creator": {
    "@type": "Organization",
    "name": "Together",
    "url": "https:\/\/huggingface.co\/togethercomputer"
  },
  "keywords": [
    "text-generation",
    "English",
    "100K - 1M",
    "Text",
    "Datasets",
    "Croissant",
    "ðŸ‡ºðŸ‡¸ Region: US"
  ],
  "url": "https:\/\/huggingface.co\/datasets\/togethercomputer\/RedPajama-Data-1T-Sample"
}</script> 

		<title>togethercomputer/RedPajama-Data-1T-Sample Â· Datasets at Hugging Face</title>

		<script
			defer
			data-domain="huggingface.co"
			event-loggedIn="false"
			src="/js/script.pageview-props.js"
		></script>
		<script>
			window.plausible =
				window.plausible ||
				function () {
					(window.plausible.q = window.plausible.q || []).push(arguments);
				};
		</script>
		<script>
			window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","captchaDisabledOnSignup":true,"datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}};
		</script>
		<script type="text/javascript" src="https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js" defer></script>
	</head>
	<body class="flex flex-col min-h-dvh bg-white dark:bg-gray-950 text-black DatasetPage">
		<div class="flex min-h-dvh flex-col"><div class="SVELTE_HYDRATER contents" data-target="SystemThemeMonitor" data-props="{&quot;isLoggedIn&quot;:false}"></div>

	<div class="SVELTE_HYDRATER contents" data-target="MainHeader" data-props="{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:false,&quot;isZh&quot;:false,&quot;isPro&quot;:false}"><header class="border-b border-gray-100 "><div class="w-full px-4 container flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl " name="" placeholder="Search models, datasets, users..."   spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-40 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center space-x-1.5 2xl:space-x-2"><li class="hover:text-indigo-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
					Models</a>
			</li><li class="hover:text-red-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					Datasets</a>
			</li><li class="hover:text-blue-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
					Spaces</a>
			</li><li class="hover:text-yellow-700 max-xl:hidden"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/posts"><svg class="mr-1.5 text-gray-400 group-hover:text-yellow-500 text-yellow-500!" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 12 12" preserveAspectRatio="xMidYMid meet"><path fill="currentColor" fill-rule="evenodd" d="M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z" clip-rule="evenodd"></path></svg>
					Posts</a>
			</li><li class="hover:text-yellow-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 16 16"><path d="m2.28 3.7-.3.16a.67.67 0 0 0-.34.58v8.73l.01.04.02.07.01.04.03.06.02.04.02.03.04.06.05.05.04.04.06.04.06.04.08.04.08.02h.05l.07.02h.11l.04-.01.07-.02.03-.01.07-.03.22-.12a5.33 5.33 0 0 1 5.15.1.67.67 0 0 0 .66 0 5.33 5.33 0 0 1 5.33 0 .67.67 0 0 0 1-.58V4.36a.67.67 0 0 0-.34-.5l-.3-.17v7.78a.63.63 0 0 1-.87.59 4.9 4.9 0 0 0-4.35.35l-.65.39a.29.29 0 0 1-.15.04.29.29 0 0 1-.16-.04l-.65-.4a4.9 4.9 0 0 0-4.34-.34.63.63 0 0 1-.87-.59V3.7Z" fill="currentColor" class="dark:opacity-40"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M8 3.1a5.99 5.99 0 0 0-5.3-.43.66.66 0 0 0-.42.62v8.18c0 .45.46.76.87.59a4.9 4.9 0 0 1 4.34.35l.65.39c.05.03.1.04.16.04.05 0 .1-.01.15-.04l.65-.4a4.9 4.9 0 0 1 4.35-.34.63.63 0 0 0 .86-.59V3.3a.67.67 0 0 0-.41-.62 5.99 5.99 0 0 0-5.3.43l-.3.17L8 3.1Zm.73 1.87a.43.43 0 1 0-.86 0v5.48a.43.43 0 0 0 .86 0V4.97Z" fill="currentColor" class="opacity-40 dark:opacity-100"></path><path d="M8.73 4.97a.43.43 0 1 0-.86 0v5.48a.43.43 0 1 0 .86 0V4.96Z" fill="currentColor" class="dark:opacity-40"></path></svg>
					Docs</a>
			</li><li class="hover:text-black dark:hover:text-white"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/enterprise"><svg class="mr-1.5 text-gray-400 group-hover:text-black dark:group-hover:text-white" xmlns="http://www.w3.org/2000/svg" fill="none" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 33 27"><path fill="currentColor" fill-rule="evenodd" d="M13.5.7a8.7 8.7 0 0 0-7.7 5.7L1 20.6c-1 3.1.9 5.7 4.1 5.7h15c3.3 0 6.8-2.6 7.8-5.7l4.6-14.2c1-3.1-.8-5.7-4-5.7h-15Zm1.1 5.7L9.8 20.3h9.8l1-3.1h-5.8l.8-2.5h4.8l1.1-3h-4.8l.8-2.3H23l1-3h-9.5Z" clip-rule="evenodd"></path></svg>
					Enterprise</a>
			</li>

		<li><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class=" text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>
			
		</button>
	
	
	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><a class="block cursor-pointer whitespace-nowrap px-2 py-0.5 hover:text-gray-500 dark:text-gray-300 dark:hover:text-gray-100" href="/login">Log In
				</a></li>
			<li><a class="whitespace-nowrap rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black" href="/join">Sign Up
					</a></li></ul></nav></div></header></div>
	
	
	
	<div class="SVELTE_HYDRATER contents" data-target="SSOBanner" data-props="{}"></div>
	
	

	<main class="flex flex-1 flex-col">
	<div class="SVELTE_HYDRATER contents" data-target="DatasetHeader" data-props="{&quot;activeTab&quot;:&quot;datasetCard&quot;,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1678734258201-6322ad266b1992383fa964ca.png&quot;,&quot;fullname&quot;:&quot;Together&quot;,&quot;name&quot;:&quot;togethercomputer&quot;,&quot;type&quot;:&quot;org&quot;,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isEnterprise&quot;:true,&quot;followerCount&quot;:547},&quot;canReadRepoSettings&quot;:false,&quot;dataset&quot;:{&quot;author&quot;:&quot;togethercomputer&quot;,&quot;cardData&quot;:{&quot;task_categories&quot;:[&quot;text-generation&quot;],&quot;language&quot;:[&quot;en&quot;],&quot;pretty_name&quot;:&quot;Red Pajama 1T Sample&quot;},&quot;cardExists&quot;:true,&quot;createdAt&quot;:&quot;2023-04-16T23:12:30.000Z&quot;,&quot;description&quot;:&quot;RedPajama is a clean-room, fully open-source implementation of the LLaMa dataset. This is a 1B-token sample of the full dataset.&quot;,&quot;downloads&quot;:14211,&quot;downloadsAllTime&quot;:1100055,&quot;id&quot;:&quot;togethercomputer/RedPajama-Data-1T-Sample&quot;,&quot;isLikedByUser&quot;:false,&quot;lastModified&quot;:&quot;2023-07-19T06:59:10.000Z&quot;,&quot;likes&quot;:126,&quot;datasetsServerInfo&quot;:{&quot;viewer&quot;:&quot;viewer-partial&quot;,&quot;numRows&quot;:850000,&quot;libraries&quot;:[&quot;datasets&quot;,&quot;mlcroissant&quot;],&quot;formats&quot;:[],&quot;modalities&quot;:[&quot;text&quot;]},&quot;discussionsDisabled&quot;:false,&quot;repoType&quot;:&quot;dataset&quot;,&quot;private&quot;:false,&quot;gated&quot;:false,&quot;tags&quot;:[&quot;task_categories:text-generation&quot;,&quot;language:en&quot;,&quot;size_categories:100K<n<1M&quot;,&quot;modality:text&quot;,&quot;library:datasets&quot;,&quot;library:mlcroissant&quot;,&quot;region:us&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;task_categories:text-generation&quot;,&quot;label&quot;:&quot;text-generation&quot;,&quot;type&quot;:&quot;task_categories&quot;,&quot;subType&quot;:&quot;nlp&quot;},{&quot;id&quot;:&quot;language:en&quot;,&quot;label&quot;:&quot;English&quot;,&quot;type&quot;:&quot;language&quot;},{&quot;id&quot;:&quot;size_categories:100K<n<1M&quot;,&quot;label&quot;:&quot;100K - 1M&quot;,&quot;type&quot;:&quot;size_categories&quot;},{&quot;id&quot;:&quot;modality:text&quot;,&quot;label&quot;:&quot;Text&quot;,&quot;type&quot;:&quot;modality&quot;},{&quot;id&quot;:&quot;library:datasets&quot;,&quot;label&quot;:&quot;Datasets&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;library:mlcroissant&quot;,&quot;label&quot;:&quot;Croissant&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;type&quot;:&quot;region&quot;,&quot;label&quot;:&quot;ðŸ‡ºðŸ‡¸ Region: US&quot;,&quot;id&quot;:&quot;region:us&quot;}],&quot;hasBlockedOids&quot;:false,&quot;region&quot;:&quot;us&quot;,&quot;xetEnabled&quot;:false},&quot;discussionsStats&quot;:{&quot;closed&quot;:2,&quot;open&quot;:3,&quot;total&quot;:5}}"><header class="bg-linear-to-t border-b border-gray-100 pt-6 sm:pt-9 from-gray-50-to-white via-white dark:via-gray-950"><div class="container relative "><h1 class="flex flex-wrap items-center max-md:leading-tight mb-3 text-lg max-sm:gap-y-1.5 md:text-xl"><a href="/datasets" class="group flex items-center"><svg class="sm:mr-1.5 -mr-1 text-gray-400" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					<span class="mr-2.5 font-semibold text-gray-400 group-hover:text-gray-500 max-sm:hidden">Datasets:</span></a>
				<hr class="mx-1.5 h-2 translate-y-px rounded-sm border-r dark:border-gray-600 sm:hidden">
			<div class="group flex flex-none items-center"><div class="relative mr-1 flex items-center">

			

<span class="inline-block "><span class="contents"><a href="/togethercomputer" class="text-gray-400 hover:text-blue-600"><img alt="" class="w-3.5 h-3.5 rounded-sm  flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1678734258201-6322ad266b1992383fa964ca.png" crossorigin="anonymous"></a></span>
	</span></div>
		

<span class="inline-block "><span class="contents"><a href="/togethercomputer" class="text-gray-400 hover:text-blue-600">togethercomputer</a></span>
	</span>
		<div class="mx-0.5 text-gray-300">/</div></div>

<div class="max-w-full "><a class="break-words font-mono font-semibold hover:text-blue-600 " href="/datasets/togethercomputer/RedPajama-Data-1T-Sample">RedPajama-Data-1T-Sample</a>
	<button class="relative text-sm mr-4 focus:outline-hidden inline-flex cursor-pointer items-center text-sm  mx-0.5   text-gray-600 " title="Copy dataset name to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	</button></div>
			<div class="inline-flex items-center overflow-hidden whitespace-nowrap rounded-md border bg-white text-sm leading-none text-gray-500  mr-2"><button class="relative flex items-center overflow-hidden from-red-50 to-transparent dark:from-red-900 px-1.5 py-1 hover:bg-linear-to-t focus:outline-hidden"  title="Like"><svg class="left-1.5 absolute" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>

		
		<span class="ml-4 pl-0.5 ">like</span></button>
	<button class="focus:outline-hidden flex items-center border-l px-1.5 py-1 text-gray-400 hover:bg-gray-50 focus:bg-gray-100 dark:hover:bg-gray-900 dark:focus:bg-gray-800" title="See users who liked this repository">126</button></div>




			<div class="relative flex items-center gap-1.5  "><div class="mr-2 inline-flex h-6 items-center overflow-hidden whitespace-nowrap rounded-md border text-sm text-gray-500"><button class="focus:outline-hidden relative flex h-full max-w-56 items-center gap-1.5 overflow-hidden px-1.5 hover:bg-gray-50 focus:bg-gray-100 dark:hover:bg-gray-900 dark:focus:bg-gray-800" type="button" ><div class="flex h-full flex-1 items-center justify-center ">Follow</div>
		<img alt="" class="rounded-xs size-3 flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1678734258201-6322ad266b1992383fa964ca.png">
		<span class="truncate">Together</span></button>
	<button class="focus:outline-hidden flex h-full items-center border-l pl-1.5 pr-1.5 text-gray-400 hover:bg-gray-50 focus:bg-gray-100 dark:hover:bg-gray-900 dark:focus:bg-gray-800" title="Show Together's followers" type="button">547</button></div>

		</div>
			
	</h1>
		<div class="mb-3 flex flex-wrap md:mb-4"><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Tasks:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?task_categories=task_categories%3Atext-generation"><div class="tag tag-white   "><div class="tag-ico -ml-2 tag-ico-indigo"><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg></div>

	

	<span>Text Generation</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Modalities:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?modality=modality%3Atext"><div class="tag tag-white   ">
		<svg class="text-red-700 dark:text-red-600" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.619 4.619C2.667 6.573 2.667 9.715 2.667 16s0 9.428 1.952 11.38C6.573 29.333 9.715 29.333 16 29.333s9.428 0 11.38-1.953c1.953-1.95 1.953-5.095 1.953-11.38s0-9.428-1.953-11.381C25.43 2.667 22.285 2.667 16 2.667s-9.428 0-11.381 1.952m8.65 3.714c-.573 0-1.109 0-1.546.066-.495.073-1.003.248-1.41.7-.392.436-.53.956-.59 1.452-.056.464-.056 1.04-.056 1.689V13a1 1 0 1 0 2 0v-.704c0-.724.001-1.176.041-1.505q.015-.15.061-.294a.2.2 0 0 1 .031-.061q0-.003.016-.01a.8.8 0 0 1 .203-.05c.272-.04.654-.043 1.314-.043H15v11.334h-2.333a1 1 0 1 0 0 2H20a1 1 0 0 0 0-2h-3V10.333h1.667c.66 0 1.042.003 1.314.043.123.019.18.04.203.05l.015.009a.2.2 0 0 1 .032.061c.018.05.042.14.061.295.04.329.041.781.041 1.506V13a1 1 0 1 0 2 0v-.76c0-.65 0-1.225-.056-1.69-.06-.495-.198-1.015-.59-1.453-.407-.45-.915-.625-1.41-.698-.437-.067-.973-.067-1.546-.066z" fill="currentColor"></path></svg>

	

	<span>Text</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Languages:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?language=language%3Aen"><div class="tag tag-white   ">
		<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="text-green-600/80" preserveAspectRatio="xMidYMid meet" width="1em" height="1em" viewBox="0 0 10 10"><path fill-rule="evenodd" clip-rule="evenodd" d="M0.625 5C0.625 6.16032 1.08594 7.27312 1.90641 8.09359C2.72688 8.91406 3.83968 9.375 5 9.375C6.16032 9.375 7.27312 8.91406 8.09359 8.09359C8.91406 7.27312 9.375 6.16032 9.375 5C9.375 3.83968 8.91406 2.72688 8.09359 1.90641C7.27312 1.08594 6.16032 0.625 5 0.625C3.83968 0.625 2.72688 1.08594 1.90641 1.90641C1.08594 2.72688 0.625 3.83968 0.625 5ZM7.64365 7.48027C7.61734 7.50832 7.59054 7.53598 7.56326 7.56326C7.13828 7.98824 6.61864 8.2968 6.0539 8.46842C6.29802 8.11949 6.49498 7.64804 6.63475 7.09483C7.00845 7.18834 7.35014 7.3187 7.64365 7.48027ZM8.10076 6.87776C8.37677 6.42196 8.55005 5.90894 8.60556 5.37499H6.86808C6.85542 5.71597 6.82551 6.04557 6.77971 6.35841C7.25309 6.47355 7.68808 6.6414 8.062 6.85549C8.07497 6.86283 8.08789 6.87025 8.10076 6.87776ZM6.03795 6.22536C6.07708 5.95737 6.1044 5.67232 6.11705 5.37499H3.88295C3.89666 5.69742 3.92764 6.00542 3.9722 6.29287C4.37075 6.21726 4.79213 6.17749 5.224 6.17749C5.50054 6.17749 5.77294 6.19376 6.03795 6.22536ZM4.1261 7.02673C4.34894 7.84835 4.68681 8.375 5 8.375C5.32122 8.375 5.66839 7.82101 5.8908 6.963C5.67389 6.93928 5.45082 6.92699 5.224 6.92699C4.84316 6.92699 4.47332 6.96176 4.1261 7.02673ZM3.39783 7.21853C3.53498 7.71842 3.72038 8.14579 3.9461 8.46842C3.42141 8.30898 2.93566 8.03132 2.52857 7.65192C2.77253 7.48017 3.06711 7.33382 3.39783 7.21853ZM3.23916 6.48077C3.18263 6.13193 3.14625 5.76074 3.13192 5.37499H1.39444C1.4585 5.99112 1.67936 6.57938 2.03393 7.08403C2.3706 6.83531 2.78055 6.63162 3.23916 6.48077ZM1.39444 4.62499H3.13192C3.14615 4.24204 3.18211 3.87344 3.23794 3.52681C2.77814 3.37545 2.36731 3.17096 2.03024 2.92123C1.67783 3.42469 1.45828 4.011 1.39444 4.62499ZM2.5237 2.35262C2.76812 2.52552 3.06373 2.67281 3.39584 2.78875C3.53318 2.28573 3.71928 1.85578 3.9461 1.53158C3.41932 1.69166 2.93178 1.97089 2.5237 2.35262ZM3.97101 3.71489C3.92709 4.00012 3.89654 4.30547 3.88295 4.62499H6.11705C6.10453 4.33057 6.07761 4.04818 6.03909 3.78248C5.77372 3.81417 5.50093 3.83049 5.224 3.83049C4.79169 3.83049 4.3699 3.79065 3.97101 3.71489ZM5.8928 3.04476C5.67527 3.06863 5.45151 3.08099 5.224 3.08099C4.84241 3.08099 4.47186 3.04609 4.12405 2.98086C4.34686 2.1549 4.68584 1.625 5 1.625C5.32218 1.625 5.67048 2.18233 5.8928 3.04476ZM6.78083 3.6493C6.826 3.95984 6.85552 4.28682 6.86808 4.62499H8.60556C8.55029 4.09337 8.37827 3.58251 8.10436 3.1282C8.0903 3.1364 8.07618 3.14449 8.062 3.15249C7.68838 3.36641 7.25378 3.53417 6.78083 3.6493ZM7.64858 2.52499C7.35446 2.68754 7.0117 2.81868 6.63664 2.91268C6.49676 2.35623 6.29913 1.88209 6.0539 1.53158C6.61864 1.7032 7.13828 2.01176 7.56326 2.43674C7.59224 2.46572 7.62068 2.49514 7.64858 2.52499Z" fill="currentColor"></path></svg>

	

	<span>English</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Size:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?size_categories=size_categories%3A100K%3Cn%3C1M"><div class="tag tag-white   ">

	

	<span>100K - 1M</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Libraries:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?library=library%3Adatasets"><div class="tag tag-white   "><svg class="text-black inline-block text-sm" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" width="1em" height="1em" viewBox="0 0 95 88"><path fill="#fff" d="M94.25 70.08a8.28 8.28 0 0 1-.43 6.46 10.57 10.57 0 0 1-3 3.6 25.18 25.18 0 0 1-5.7 3.2 65.74 65.74 0 0 1-7.56 2.65 46.67 46.67 0 0 1-11.42 1.68c-5.42.05-10.09-1.23-13.4-4.5a40.4 40.4 0 0 1-10.14.03c-3.34 3.25-7.99 4.52-13.39 4.47a46.82 46.82 0 0 1-11.43-1.68 66.37 66.37 0 0 1-7.55-2.65c-2.28-.98-4.17-2-5.68-3.2a10.5 10.5 0 0 1-3.02-3.6c-.99-2-1.18-4.3-.42-6.46a8.54 8.54 0 0 1-.33-5.63c.25-.95.66-1.83 1.18-2.61a8.67 8.67 0 0 1 2.1-8.47 8.23 8.23 0 0 1 2.82-2.07 41.75 41.75 0 1 1 81.3-.12 8.27 8.27 0 0 1 3.11 2.19 8.7 8.7 0 0 1 2.1 8.47c.52.78.93 1.66 1.18 2.61a8.61 8.61 0 0 1-.32 5.63Z"></path><path fill="#FFD21E" d="M47.21 76.5a34.75 34.75 0 1 0 0-69.5 34.75 34.75 0 0 0 0 69.5Z"></path><path fill="#FF9D0B" d="M81.96 41.75a34.75 34.75 0 1 0-69.5 0 34.75 34.75 0 0 0 69.5 0Zm-73.5 0a38.75 38.75 0 1 1 77.5 0 38.75 38.75 0 0 1-77.5 0Z"></path><path fill="#3A3B45" d="M58.5 32.3c1.28.44 1.78 3.06 3.07 2.38a5 5 0 1 0-6.76-2.07c.61 1.15 2.55-.72 3.7-.32ZM34.95 32.3c-1.28.44-1.79 3.06-3.07 2.38a5 5 0 1 1 6.76-2.07c-.61 1.15-2.56-.72-3.7-.32Z"></path><path fill="#FF323D" d="M46.96 56.29c9.83 0 13-8.76 13-13.26 0-2.34-1.57-1.6-4.09-.36-2.33 1.15-5.46 2.74-8.9 2.74-7.19 0-13-6.88-13-2.38s3.16 13.26 13 13.26Z"></path><path fill="#3A3B45" fill-rule="evenodd" d="M39.43 54a8.7 8.7 0 0 1 5.3-4.49c.4-.12.81.57 1.24 1.28.4.68.82 1.37 1.24 1.37.45 0 .9-.68 1.33-1.35.45-.7.89-1.38 1.32-1.25a8.61 8.61 0 0 1 5 4.17c3.73-2.94 5.1-7.74 5.1-10.7 0-2.34-1.57-1.6-4.09-.36l-.14.07c-2.31 1.15-5.39 2.67-8.77 2.67s-6.45-1.52-8.77-2.67c-2.6-1.29-4.23-2.1-4.23.29 0 3.05 1.46 8.06 5.47 10.97Z" clip-rule="evenodd"></path><path fill="#FF9D0B" d="M70.71 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM24.21 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM17.52 48c-1.62 0-3.06.66-4.07 1.87a5.97 5.97 0 0 0-1.33 3.76 7.1 7.1 0 0 0-1.94-.3c-1.55 0-2.95.59-3.94 1.66a5.8 5.8 0 0 0-.8 7 5.3 5.3 0 0 0-1.79 2.82c-.24.9-.48 2.8.8 4.74a5.22 5.22 0 0 0-.37 5.02c1.02 2.32 3.57 4.14 8.52 6.1 3.07 1.22 5.89 2 5.91 2.01a44.33 44.33 0 0 0 10.93 1.6c5.86 0 10.05-1.8 12.46-5.34 3.88-5.69 3.33-10.9-1.7-15.92-2.77-2.78-4.62-6.87-5-7.77-.78-2.66-2.84-5.62-6.25-5.62a5.7 5.7 0 0 0-4.6 2.46c-1-1.26-1.98-2.25-2.86-2.82A7.4 7.4 0 0 0 17.52 48Zm0 4c.51 0 1.14.22 1.82.65 2.14 1.36 6.25 8.43 7.76 11.18.5.92 1.37 1.31 2.14 1.31 1.55 0 2.75-1.53.15-3.48-3.92-2.93-2.55-7.72-.68-8.01.08-.02.17-.02.24-.02 1.7 0 2.45 2.93 2.45 2.93s2.2 5.52 5.98 9.3c3.77 3.77 3.97 6.8 1.22 10.83-1.88 2.75-5.47 3.58-9.16 3.58-3.81 0-7.73-.9-9.92-1.46-.11-.03-13.45-3.8-11.76-7 .28-.54.75-.76 1.34-.76 2.38 0 6.7 3.54 8.57 3.54.41 0 .7-.17.83-.6.79-2.85-12.06-4.05-10.98-8.17.2-.73.71-1.02 1.44-1.02 3.14 0 10.2 5.53 11.68 5.53.11 0 .2-.03.24-.1.74-1.2.33-2.04-4.9-5.2-5.21-3.16-8.88-5.06-6.8-7.33.24-.26.58-.38 1-.38 3.17 0 10.66 6.82 10.66 6.82s2.02 2.1 3.25 2.1c.28 0 .52-.1.68-.38.86-1.46-8.06-8.22-8.56-11.01-.34-1.9.24-2.85 1.31-2.85Z"></path><path fill="#FFD21E" d="M38.6 76.69c2.75-4.04 2.55-7.07-1.22-10.84-3.78-3.77-5.98-9.3-5.98-9.3s-.82-3.2-2.69-2.9c-1.87.3-3.24 5.08.68 8.01 3.91 2.93-.78 4.92-2.29 2.17-1.5-2.75-5.62-9.82-7.76-11.18-2.13-1.35-3.63-.6-3.13 2.2.5 2.79 9.43 9.55 8.56 11-.87 1.47-3.93-1.71-3.93-1.71s-9.57-8.71-11.66-6.44c-2.08 2.27 1.59 4.17 6.8 7.33 5.23 3.16 5.64 4 4.9 5.2-.75 1.2-12.28-8.53-13.36-4.4-1.08 4.11 11.77 5.3 10.98 8.15-.8 2.85-9.06-5.38-10.74-2.18-1.7 3.21 11.65 6.98 11.76 7.01 4.3 1.12 15.25 3.49 19.08-2.12Z"></path><path fill="#FF9D0B" d="M77.4 48c1.62 0 3.07.66 4.07 1.87a5.97 5.97 0 0 1 1.33 3.76 7.1 7.1 0 0 1 1.95-.3c1.55 0 2.95.59 3.94 1.66a5.8 5.8 0 0 1 .8 7 5.3 5.3 0 0 1 1.78 2.82c.24.9.48 2.8-.8 4.74a5.22 5.22 0 0 1 .37 5.02c-1.02 2.32-3.57 4.14-8.51 6.1-3.08 1.22-5.9 2-5.92 2.01a44.33 44.33 0 0 1-10.93 1.6c-5.86 0-10.05-1.8-12.46-5.34-3.88-5.69-3.33-10.9 1.7-15.92 2.78-2.78 4.63-6.87 5.01-7.77.78-2.66 2.83-5.62 6.24-5.62a5.7 5.7 0 0 1 4.6 2.46c1-1.26 1.98-2.25 2.87-2.82A7.4 7.4 0 0 1 77.4 48Zm0 4c-.51 0-1.13.22-1.82.65-2.13 1.36-6.25 8.43-7.76 11.18a2.43 2.43 0 0 1-2.14 1.31c-1.54 0-2.75-1.53-.14-3.48 3.91-2.93 2.54-7.72.67-8.01a1.54 1.54 0 0 0-.24-.02c-1.7 0-2.45 2.93-2.45 2.93s-2.2 5.52-5.97 9.3c-3.78 3.77-3.98 6.8-1.22 10.83 1.87 2.75 5.47 3.58 9.15 3.58 3.82 0 7.73-.9 9.93-1.46.1-.03 13.45-3.8 11.76-7-.29-.54-.75-.76-1.34-.76-2.38 0-6.71 3.54-8.57 3.54-.42 0-.71-.17-.83-.6-.8-2.85 12.05-4.05 10.97-8.17-.19-.73-.7-1.02-1.44-1.02-3.14 0-10.2 5.53-11.68 5.53-.1 0-.19-.03-.23-.1-.74-1.2-.34-2.04 4.88-5.2 5.23-3.16 8.9-5.06 6.8-7.33-.23-.26-.57-.38-.98-.38-3.18 0-10.67 6.82-10.67 6.82s-2.02 2.1-3.24 2.1a.74.74 0 0 1-.68-.38c-.87-1.46 8.05-8.22 8.55-11.01.34-1.9-.24-2.85-1.31-2.85Z"></path><path fill="#FFD21E" d="M56.33 76.69c-2.75-4.04-2.56-7.07 1.22-10.84 3.77-3.77 5.97-9.3 5.97-9.3s.82-3.2 2.7-2.9c1.86.3 3.23 5.08-.68 8.01-3.92 2.93.78 4.92 2.28 2.17 1.51-2.75 5.63-9.82 7.76-11.18 2.13-1.35 3.64-.6 3.13 2.2-.5 2.79-9.42 9.55-8.55 11 .86 1.47 3.92-1.71 3.92-1.71s9.58-8.71 11.66-6.44c2.08 2.27-1.58 4.17-6.8 7.33-5.23 3.16-5.63 4-4.9 5.2.75 1.2 12.28-8.53 13.36-4.4 1.08 4.11-11.76 5.3-10.97 8.15.8 2.85 9.05-5.38 10.74-2.18 1.69 3.21-11.65 6.98-11.76 7.01-4.31 1.12-15.26 3.49-19.08-2.12Z"></path></svg>

	

	<span>Datasets</span>
	

	</div></a><div class="relative inline-block ">
	<button class="group mr-1 mb-1 md:mr-1.5 md:mb-1.5  rounded-lg rounded-br-none " type="button">
		<div class="tag tag-white   relative rounded-br-none pr-2.5"><svg class="text-black inline-block text-sm" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="none" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M22.2812 12.2656L25.9532 15.7187C26.8932 16.6587 28.0913 17.3931 29.0313 16.4531C29.8594 15.7812 29.9332 14.1 29.9532 13.5C29.9532 11.5625 28.9219 8.375 27.25 6.71875C25.5604 5.04493 23.3782 3.91692 22.7032 3.78125L22.2812 12.2656Z" fill="#F5AB6A"></path><path d="M22.2812 12.2656L25.9532 15.7187C26.8932 16.6587 28.0913 17.3931 29.0313 16.4531C29.8594 15.7812 29.9332 14.1 29.9532 13.5C29.9532 11.5625 28.9219 8.375 27.25 6.71875C25.5604 5.04493 23.3782 3.91692 22.7032 3.78125L22.2812 12.2656Z" fill="url(#paint0_radial_18_31665)"></path><g filter="url(#filter0_f_18_31665)"><path d="M22.2849 12.1817L23.4375 13.2656L24.4375 4.70312C23.5121 4.1242 23.0198 3.96369 22.6563 3.89062L22.2849 12.1817Z" fill="url(#paint1_linear_18_31665)"></path></g><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint2_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint3_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint4_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint5_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint6_linear_18_31665)"></path><g filter="url(#filter1_f_18_31665)"><path d="M13.1016 2.72656C11.862 3.06924 11.5298 3.40016 11.5298 3.40016C10.9102 3.52335 10.936 4.11525 11.2408 4.6799C13.1487 6.95202 15.1361 13.2496 18.007 14.0958C18.2707 14.1633 18.6953 14.2107 19.1797 14.2344L13.1016 2.72656Z" fill="url(#paint7_linear_18_31665)"></path></g><path d="M12.2187 22.7187L15.7656 26.2031C16.7332 27.1171 17.3334 28.2487 16.4219 29.2188C15.7749 30.0687 14.2241 29.9933 13.625 30.0313C11.6883 30.0891 9.09014 29.5622 6.84373 27.5313C5.07737 25.9343 4.09321 23.688 3.93751 23.0156L12.2187 22.7187Z" fill="url(#paint8_radial_18_31665)"></path><path d="M12.2187 22.7187L15.7656 26.2031C16.7332 27.1171 17.3334 28.2487 16.4219 29.2188C15.7749 30.0687 14.2241 29.9933 13.625 30.0313C11.6883 30.0891 9.09014 29.5622 6.84373 27.5313C5.07737 25.9343 4.09321 23.688 3.93751 23.0156L12.2187 22.7187Z" fill="url(#paint9_radial_18_31665)"></path><g filter="url(#filter2_f_18_31665)"><path d="M12.0523 22.7916L13.2187 23.9375L4.81018 24.5721C4.4328 23.8671 4.20835 23.2768 4.14062 22.9844L12.0523 22.7916Z" fill="url(#paint10_linear_18_31665)"></path><path d="M12.0523 22.7916L13.2187 23.9375L4.81018 24.5721C4.4328 23.8671 4.20835 23.2768 4.14062 22.9844L12.0523 22.7916Z" fill="url(#paint11_radial_18_31665)"></path></g><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="#EC9F6A"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint12_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint13_linear_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint14_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint15_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint16_radial_18_31665)"></path><g filter="url(#filter3_f_18_31665)"><path d="M2.70313 13.6719C3.04135 12.4711 3.36224 12.0555 3.36224 12.0555C3.46697 11.4309 3.98746 11.3864 4.56092 11.6749C6.88874 13.5189 13.0809 15.1104 14.0121 17.9622C14.1731 18.5231 14.2766 19.0394 14.3287 19.5128L2.70313 13.6719Z" fill="url(#paint17_linear_18_31665)"></path><path d="M2.70313 13.6719C3.04135 12.4711 3.36224 12.0555 3.36224 12.0555C3.46697 11.4309 3.98746 11.3864 4.56092 11.6749C6.88874 13.5189 13.0809 15.1104 14.0121 17.9622C14.1731 18.5231 14.2766 19.0394 14.3287 19.5128L2.70313 13.6719Z" fill="url(#paint18_linear_18_31665)"></path></g><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="#D79453"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint19_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint20_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint21_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint22_linear_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint23_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint24_radial_18_31665)"></path><defs><filter id="filter0_f_18_31665" x="22.0349" y="3.64062" width="2.65265" height="9.875" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter1_f_18_31665" x="10.7815" y="2.47656" width="8.64819" height="12.0078" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter2_f_18_31665" x="3.89062" y="22.5416" width="9.57812" height="2.2804" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter3_f_18_31665" x="2.45312" y="11.2538" width="12.1255" height="8.50903" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><radialGradient id="paint0_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.8125 12.9375) rotate(42.7741) scale(12.5164 7.08839)"><stop offset="0.0937591" stop-color="#C05159"></stop><stop offset="0.553697" stop-color="#F6AC6A"></stop><stop offset="0.832916" stop-color="#FFD186"></stop><stop offset="0.916927" stop-color="#FFDC87"></stop></radialGradient><linearGradient id="paint1_linear_18_31665" x1="24.7344" y1="4.67187" x2="20.8594" y2="12.8906" gradientUnits="userSpaceOnUse"><stop stop-color="#EBD67C"></stop><stop offset="0.0655686" stop-color="#FFFFA6"></stop><stop offset="0.530552" stop-color="#F8C281"></stop><stop offset="0.937338" stop-color="#E99E6B"></stop></linearGradient><radialGradient id="paint2_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.9009 13.1847) rotate(-127.648) scale(14.3438 11.7966)"><stop stop-color="#FFBE66"></stop><stop offset="1" stop-color="#E2AE5B"></stop></radialGradient><radialGradient id="paint3_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(18 11.4375) rotate(53.9726) scale(11.9013 4.84018)"><stop stop-color="#D67C63"></stop><stop offset="1" stop-color="#D97D67" stop-opacity="0"></stop></radialGradient><radialGradient id="paint4_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(23 4.1875) rotate(45.7639) scale(3.31486 5.75622)"><stop stop-color="#FFE4A6"></stop><stop offset="0.711285" stop-color="#F8B76F"></stop><stop offset="1" stop-color="#F9B870" stop-opacity="0"></stop></radialGradient><radialGradient id="paint5_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.875 12.4375) rotate(88.9391) scale(3.37558 1.29066)"><stop stop-color="#FFBC67"></stop><stop offset="1" stop-color="#FFBC67" stop-opacity="0"></stop></radialGradient><linearGradient id="paint6_linear_18_31665" x1="20.375" y1="15.6875" x2="20.125" y2="12.7813" gradientUnits="userSpaceOnUse"><stop offset="0.461609" stop-color="#B45077"></stop><stop offset="0.855389" stop-color="#B75077" stop-opacity="0"></stop></linearGradient><linearGradient id="paint7_linear_18_31665" x1="12.9375" y1="2.57056" x2="18.5625" y2="14.3891" gradientUnits="userSpaceOnUse"><stop stop-color="#DDC173"></stop><stop offset="0.485173" stop-color="#D59F65"></stop><stop offset="1" stop-color="#E49966"></stop></linearGradient><radialGradient id="paint8_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(13.5625 23.5) rotate(109.113) scale(6.68078 10.2578)"><stop offset="0.165756" stop-color="#FFBF7E"></stop><stop offset="0.827674" stop-color="#DF8C6D"></stop><stop offset="1" stop-color="#B05A66"></stop></radialGradient><radialGradient id="paint9_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.1875 26) rotate(41.0652) scale(8.37243 2.03649)"><stop stop-color="#FFD483"></stop><stop offset="1" stop-color="#FFD688" stop-opacity="0"></stop></radialGradient><linearGradient id="paint10_linear_18_31665" x1="3.96063" y1="23.794" x2="13.3748" y2="23.5143" gradientUnits="userSpaceOnUse"><stop stop-color="#A8716F"></stop><stop offset="0.103615" stop-color="#B37173"></stop><stop offset="0.225484" stop-color="#DB9F84"></stop><stop offset="0.799889" stop-color="#F1BB8A"></stop><stop offset="1" stop-color="#FFD780"></stop></linearGradient><radialGradient id="paint11_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(11.4219 23.1719) rotate(-178.616) scale(3.23532 0.569081)"><stop offset="0.621498" stop-color="#AF5A3E"></stop><stop offset="1" stop-color="#B35445" stop-opacity="0"></stop></radialGradient><radialGradient id="paint12_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(13.625 19.125) rotate(-171.737) scale(15.2205 15.0767)"><stop offset="0.138435" stop-color="#FFB974"></stop><stop offset="0.403618" stop-color="#F2A56D"></stop><stop offset="0.925938" stop-color="#A16948"></stop></radialGradient><linearGradient id="paint13_linear_18_31665" x1="8.22184" y1="13.125" x2="6.81191" y2="15.4996" gradientUnits="userSpaceOnUse"><stop offset="0.610751" stop-color="#984847"></stop><stop offset="0.850075" stop-color="#9A4947" stop-opacity="0"></stop></linearGradient><radialGradient id="paint14_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(7.25 23.7461) scale(11.25 5.68361)"><stop stop-color="#C66364"></stop><stop offset="1" stop-color="#D4766B" stop-opacity="0"></stop></radialGradient><radialGradient id="paint15_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(7.875 23.5313) scale(10.0937 1.29657)"><stop stop-color="#B64B4B"></stop><stop offset="1" stop-color="#C56158" stop-opacity="0"></stop></radialGradient><radialGradient id="paint16_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(11.4375 19.875) rotate(-46.8882) scale(4.02385 7.51767)"><stop stop-color="#FFC083"></stop><stop offset="0.620218" stop-color="#FFBD7D" stop-opacity="0"></stop></radialGradient><linearGradient id="paint17_linear_18_31665" x1="2.8125" y1="13.0312" x2="14.5582" y2="18.9404" gradientUnits="userSpaceOnUse"><stop stop-color="#B89367"></stop><stop offset="1" stop-color="#C5835E"></stop></linearGradient><linearGradient id="paint18_linear_18_31665" x1="8.21875" y1="14.6406" x2="7.59349" y2="15.6717" gradientUnits="userSpaceOnUse"><stop offset="0.351552" stop-color="#A74746"></stop><stop offset="0.845198" stop-color="#A04346" stop-opacity="0"></stop></linearGradient><radialGradient id="paint19_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.5625 14.5625) rotate(140.244) scale(18.3733 13.7403)"><stop stop-color="#FDAE69"></stop><stop offset="0.729021" stop-color="#CE8C4F"></stop><stop offset="0.921546" stop-color="#AD7B45"></stop><stop offset="1" stop-color="#8B6B4A"></stop></radialGradient><radialGradient id="paint20_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.0625 7) rotate(65.3152) scale(11.0745 3.16547)"><stop offset="0.233237" stop-color="#FFD47C"></stop><stop offset="0.853648" stop-color="#FFD98B" stop-opacity="0"></stop></radialGradient><radialGradient id="paint21_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.3125 8.875) rotate(100.886) scale(6.6191 5.57808)"><stop offset="0.128419" stop-color="#FFD88C"></stop><stop offset="0.924134" stop-color="#FFBE7B" stop-opacity="0"></stop></radialGradient><linearGradient id="paint22_linear_18_31665" x1="7.25" y1="15.1875" x2="10.7588" y2="10.3142" gradientUnits="userSpaceOnUse"><stop offset="0.142353" stop-color="#C15F4D"></stop><stop offset="1" stop-color="#D58366" stop-opacity="0"></stop></linearGradient><radialGradient id="paint23_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(8.15625 15.7813) rotate(28.5422) scale(12.5574 1.96589)"><stop offset="0.149989" stop-color="#E4745D"></stop><stop offset="0.453292" stop-color="#C8604C"></stop><stop offset="0.632597" stop-color="#C0605F"></stop><stop offset="1" stop-color="#C0605F" stop-opacity="0"></stop></radialGradient><radialGradient id="paint24_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(1.40625 2.69067) rotate(46.0943) scale(22.3963)"><stop offset="0.935802" stop-color="#C17C61" stop-opacity="0"></stop><stop offset="0.982109" stop-color="#C17C61"></stop></radialGradient></defs></svg>

	

	<span>Croissant</span>
	

	<div class="border-br-gray-200 absolute bottom-0.5 right-0.5 h-1 w-1 border-[3px] border-l-transparent border-t-transparent border-b-gray-200 border-r-gray-200 dark:border-b-gray-700 dark:border-r-gray-700"></div></div>
		
		</button>
	
	
	</div>

	</div></div>

		<div class="flex flex-col-reverse lg:flex-row lg:items-center lg:justify-between"><div class="-mb-px flex h-12 items-center overflow-x-auto overflow-y-hidden ">
	<a class="tab-alternate active" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample"><svg class="mr-1.5 text-gray-400 flex-none" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
	Dataset card
	

	
		</a><a class="tab-alternate" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
	Data Studio
	

	
		</a><a class="tab-alternate" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/tree/main"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-tertiary" d="M21 19h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0-4h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0-8h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0 4h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M9 19a1 1 0 0 1-1-1V6a1 1 0 0 1 2 0v12a1 1 0 0 1-1 1zm-6-4.333a1 1 0 0 1-.64-1.769L3.438 12l-1.078-.898a1 1 0 0 1 1.28-1.538l2 1.667a1 1 0 0 1 0 1.538l-2 1.667a.999.999 0 0 1-.64.231z" fill="currentColor"></path></svg>
	<span class="xl:hidden">Files</span>
		<span class="hidden xl:inline">Files and versions</span>
	

	
		</a><a class="tab-alternate" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/discussions"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M20.6081 3C21.7684 3 22.8053 3.49196 23.5284 4.38415C23.9756 4.93678 24.4428 5.82749 24.4808 7.16133C24.9674 7.01707 25.4353 6.93643 25.8725 6.93643C26.9833 6.93643 27.9865 7.37587 28.696 8.17411C29.6075 9.19872 30.0124 10.4579 29.8361 11.7177C29.7523 12.3177 29.5581 12.8555 29.2678 13.3534C29.8798 13.8646 30.3306 14.5763 30.5485 15.4322C30.719 16.1032 30.8939 17.5006 29.9808 18.9403C30.0389 19.0342 30.0934 19.1319 30.1442 19.2318C30.6932 20.3074 30.7283 21.5229 30.2439 22.6548C29.5093 24.3704 27.6841 25.7219 24.1397 27.1727C21.9347 28.0753 19.9174 28.6523 19.8994 28.6575C16.9842 29.4379 14.3477 29.8345 12.0653 29.8345C7.87017 29.8345 4.8668 28.508 3.13831 25.8921C0.356375 21.6797 0.754104 17.8269 4.35369 14.1131C6.34591 12.058 7.67023 9.02782 7.94613 8.36275C8.50224 6.39343 9.97271 4.20438 12.4172 4.20438H12.4179C12.6236 4.20438 12.8314 4.2214 13.0364 4.25468C14.107 4.42854 15.0428 5.06476 15.7115 6.02205C16.4331 5.09583 17.134 4.359 17.7682 3.94323C18.7242 3.31737 19.6794 3 20.6081 3ZM20.6081 5.95917C20.2427 5.95917 19.7963 6.1197 19.3039 6.44225C17.7754 7.44319 14.8258 12.6772 13.7458 14.7131C13.3839 15.3952 12.7655 15.6837 12.2086 15.6837C11.1036 15.6837 10.2408 14.5497 12.1076 13.1085C14.9146 10.9402 13.9299 7.39584 12.5898 7.1776C12.5311 7.16799 12.4731 7.16355 12.4172 7.16355C11.1989 7.16355 10.6615 9.33114 10.6615 9.33114C10.6615 9.33114 9.0863 13.4148 6.38031 16.206C3.67434 18.998 3.5346 21.2388 5.50675 24.2246C6.85185 26.2606 9.42666 26.8753 12.0653 26.8753C14.8021 26.8753 17.6077 26.2139 19.1799 25.793C19.2574 25.7723 28.8193 22.984 27.6081 20.6107C27.4046 20.212 27.0693 20.0522 26.6471 20.0522C24.9416 20.0522 21.8393 22.6726 20.5057 22.6726C20.2076 22.6726 19.9976 22.5416 19.9116 22.222C19.3433 20.1173 28.552 19.2325 27.7758 16.1839C27.639 15.6445 27.2677 15.4256 26.746 15.4263C24.4923 15.4263 19.4358 19.5181 18.3759 19.5181C18.2949 19.5181 18.2368 19.4937 18.2053 19.4419C17.6743 18.557 17.9653 17.9394 21.7082 15.6009C25.4511 13.2617 28.0783 11.8545 26.5841 10.1752C26.4121 9.98141 26.1684 9.8956 25.8725 9.8956C23.6001 9.89634 18.2311 14.9403 18.2311 14.9403C18.2311 14.9403 16.7821 16.496 15.9057 16.496C15.7043 16.496 15.533 16.4139 15.4169 16.2112C14.7956 15.1296 21.1879 10.1286 21.5484 8.06535C21.7928 6.66715 21.3771 5.95917 20.6081 5.95917Z" fill="#FF9D00"></path><path d="M5.50686 24.2246C3.53472 21.2387 3.67446 18.9979 6.38043 16.206C9.08641 13.4147 10.6615 9.33111 10.6615 9.33111C10.6615 9.33111 11.2499 6.95933 12.59 7.17757C13.93 7.39581 14.9139 10.9401 12.1069 13.1084C9.29997 15.276 12.6659 16.7489 13.7459 14.713C14.8258 12.6772 17.7747 7.44316 19.304 6.44221C20.8326 5.44128 21.9089 6.00204 21.5484 8.06532C21.188 10.1286 14.795 15.1295 15.4171 16.2118C16.0391 17.2934 18.2312 14.9402 18.2312 14.9402C18.2312 14.9402 25.0907 8.49588 26.5842 10.1752C28.0776 11.8545 25.4512 13.2616 21.7082 15.6008C17.9646 17.9393 17.6744 18.557 18.2054 19.4418C18.7372 20.3266 26.9998 13.1351 27.7759 16.1838C28.5513 19.2324 19.3434 20.1173 19.9117 22.2219C20.48 24.3274 26.3979 18.2382 27.6082 20.6107C28.8193 22.9839 19.2574 25.7722 19.18 25.7929C16.0914 26.62 8.24723 28.3726 5.50686 24.2246Z" fill="#FFD21E"></path></svg>
	Community
	<div class="ml-1.5 flex h-4 min-w-[1rem] items-center justify-center rounded px-1 text-xs leading-none shadow-sm bg-black text-white dark:bg-gray-800 dark:text-gray-200">5</div>

	
		</a></div>
	
			</div></div></header>


</div>
	
<div class="container relative flex flex-col md:grid md:space-y-0 w-full md:grid-cols-12 md:flex-1 md:grid-rows-full space-y-4 md:gap-6 ">
		<section class="pt-6 border-gray-100 md:col-span-8 pb-24 relative break-words copiable-code-container">
				<div class="SVELTE_HYDRATER contents" data-target="UnsafeBanner" data-props="{&quot;classNames&quot;:&quot;mb-4&quot;,&quot;repoId&quot;:&quot;togethercomputer/RedPajama-Data-1T-Sample&quot;,&quot;repoType&quot;:&quot;dataset&quot;,&quot;minLevel&quot;:&quot;unsafe&quot;}"></div>
					<div class="SVELTE_HYDRATER contents" data-target="DatasetViewer" data-props="{&quot;data&quot;:{&quot;kind&quot;:&quot;DatasetAndSampleData&quot;,&quot;datasetInfo&quot;:[{&quot;isValid&quot;:true,&quot;href&quot;:&quot;/datasets/togethercomputer/RedPajama-Data-1T-Sample/tree/refs%2Fconvert%2Fparquet/&quot;,&quot;label&quot;:&quot;Size of the auto-converted Parquet files (First 5GB):&quot;,&quot;value&quot;:&quot;2.92 GB&quot;},{&quot;isValid&quot;:true,&quot;href&quot;:&quot;&quot;,&quot;label&quot;:&quot;Number of rows (First 5GB):&quot;,&quot;value&quot;:&quot;850,000&quot;}],&quot;partial&quot;:true,&quot;configsData&quot;:{&quot;configInfos&quot;:[{&quot;name&quot;:&quot;plain_text&quot;,&quot;status&quot;:&quot;ok&quot;,&quot;numRows&quot;:850000}],&quot;selectedConfig&quot;:&quot;plain_text&quot;,&quot;hasSelectedConfigParquet&quot;:true},&quot;splitsData&quot;:{&quot;splitInfos&quot;:[{&quot;name&quot;:&quot;train&quot;,&quot;numRows&quot;:850000}],&quot;selectedSplit&quot;:&quot;train&quot;},&quot;sampleData&quot;:{&quot;dataset&quot;:&quot;togethercomputer/RedPajama-Data-1T-Sample&quot;,&quot;config&quot;:&quot;plain_text&quot;,&quot;split&quot;:&quot;train&quot;,&quot;capabilities&quot;:{&quot;rows&quot;:true,&quot;search&quot;:true,&quot;filter&quot;:true,&quot;statistics&quot;:true},&quot;navigation&quot;:{&quot;p&quot;:0},&quot;jwt&quot;:&quot;eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc0MjkyMzA5MSwic3ViIjoiL2RhdGFzZXRzL3RvZ2V0aGVyY29tcHV0ZXIvUmVkUGFqYW1hLURhdGEtMVQtU2FtcGxlIiwiZXhwIjoxNzQyOTI2NjkxLCJpc3MiOiJodHRwczovL2h1Z2dpbmdmYWNlLmNvIn0.8NYlzxPcFB7oIfKxXeEvkfjDU3rnAdzpFq12xL5vqQ1ueWMkAC4t0uVz-dgFGbTTLWJA4tZArrCu3RBs7FPsCA&quot;,&quot;sampleData&quot;:{&quot;columns&quot;:[{&quot;name&quot;:&quot;text&quot;,&quot;align&quot;:&quot;depends on text direction&quot;,&quot;type&quot;:&quot;string&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;text&quot;,&quot;column_type&quot;:&quot;string_text&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:4,&quot;max&quot;:5483996,&quot;mean&quot;:5675.75176,&quot;median&quot;:2730,&quot;std&quot;:18256.65505,&quot;histogram&quot;:{&quot;hist&quot;:[849852,136,9,0,2,0,0,0,0,1],&quot;bin_edges&quot;:[4,548404,1096804,1645204,2193604,2742004,3290404,3838804,4387204,4935604,5483996]}}}},{&quot;name&quot;:&quot;meta&quot;,&quot;align&quot;:&quot;depends on text direction&quot;,&quot;type&quot;:&quot;string&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;meta&quot;,&quot;column_type&quot;:&quot;string_text&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:14,&quot;max&quot;:6540,&quot;mean&quot;:161.22923,&quot;median&quot;:159,&quot;std&quot;:60.41073,&quot;histogram&quot;:{&quot;hist&quot;:[846980,2788,196,33,1,0,0,0,0,2],&quot;bin_edges&quot;:[14,667,1320,1973,2626,3279,3932,4585,5238,5891,6540]}}}}],&quot;rows&quot;:[{&quot;rowIdx&quot;:0,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;\\section{Introduction}\n\\label{sec:intro}\n\n\\emph{Gender diversity}, or more often its lack thereof, among participants to\nsoftware development activities has been thoroughly studied in recent years. In\nparticular, the presence of, effects of, and countermeasures for \\emph{gender\n  bias} in Free/Open Source Software (FOSS) have received a lot of attention\nover the past decade~\\cite{david2008fossdevs, qiu2010kdewomen,\n  nafus2012patches, kuechler2012genderfoss, vasilescu2014gender,\n  oneil2016debiansurvey, robles2016womeninfoss, terrell2017gender,\n  zacchiroli2021gender}.  \\emph{Geographic diversity} is on the other hand the\nkind of diversity that stems from participants in some global activity coming\nfrom different world regions and cultures.\n\nGeographic diversity in FOSS has received relatively little attention in scholarly\nworks. In particular, while seminal survey-based and\npoint-in-time medium-scale studies of the geographic origins of FOSS\ncontributors exist~\\cite{ghosh2005understanding, david2008fossdevs,\n  barahona2008geodiversity, takhteyev2010ossgeography, robles2014surveydataset,\n  wachs2021ossgeography}, large-scale longitudinal studies of the geographic\norigin of FOSS contributors are still lacking. Such a quantitative\ncharacterization would be useful to inform decisions related to global\ndevelopment teams~\\cite{herbsleb2007globalsweng} and hiring strategies in the\ninformation technology (IT) market, as well as contribute factual information\nto the debates on the economic impact and sociology of FOSS around the world.\n\n\n\\paragraph{Contributions}\n\nWith this work we contribute to close this gap by conducting \\textbf{the first\n  longitudinal study of the geographic origin of contributors to public code\n  over 50 years.} Specifically, we provide a preliminary answer to the\nfollowing research question:\n\\begin{researchquestion}\n  From which world regions do authors of publicly available commits come from\n  and how has it changed over the past 50 years?\n  \\label{rq:geodiversity}\n\\end{researchquestion}\nWe use as dataset the \\SWH/ archive~\\cite{swhipres2017} and analyze from it\n2.2 billion\\xspace commits archived from 160 million\\xspace projects and authored by\n43 million\\xspace authors during the 1971--2021 time period. \nWe geolocate developers to\n\\DATAWorldRegions/ world regions, using as signals email country code top-level domains (ccTLDs) and \nauthor (first/last) names compared with name distributions around the world, and UTC offsets \nmined from commit metadata.\n\nWe find evidence of the early dominance of North America in open source\nsoftware, later joined by Europe. After that period, the geographic diversity \nin public code has been constantly increasing.\nWe also identify relevant historical shifts\nrelated to the end of the UNIX wars and the increase of coding literacy in\nCentral and South Asia, as well as of broader phenomena like colonialism and\npeople movement across countries (immigration/emigration).\n\n\n\n\n\\paragraph{Data availability.}\n\nA replication package for this paper is available from Zenodo at\n\\url{https://doi.org/10.5281/zenodo.6390355}~\\cite{replication-package}.\n\n\n \\section{Related Work}\n\\label{sec:related}\n\nBoth early and recent works~\\cite{ghosh2005understanding, david2008fossdevs,\n  robles2014surveydataset, oneil2016debiansurvey} have characterized the\ngeography of Free/Open Source Software (FOSS) using \\emph{developer surveys},\nwhich provide high-quality answers but are limited in size (2-5\\,K developers)\nand can be biased by participant sampling.\n\nIn 2008 Barahona et al.~\\cite{barahona2008geodiversity} conducted a seminal\nlarge-scale (for the time) study on FOSS \\emph{geography using mining software\n  repositories (MSR) techniques}. They analyzed the origin of 1\\,M contributors\nusing the SourceForge user database and mailing list archives over the\n1999--2005 period, using as signals information similar to ours: email domains\nand UTC offsets. \nThe studied period (7 years) in~\\cite{barahona2008geodiversity} is shorter than \nwhat is studied in the present paper (50 years) and the data sources are \nlargely different; with that in mind, our results show a slightly larger quote of \nEuropean v.~North American contributions.\n\nAnother empirical work from 2010 by Takhteyev and\nHilts~\\cite{takhteyev2010ossgeography} harvested self-declared geographic\nlocations of GitHub accounts recursively following their connections,\ncollecting information for $\\approx$\\,70\\,K GitHub users.  A very recent\nwork~\\cite{wachs2021ossgeography} by Wachs et al.~has geolocated half a million\nGitHub users, having contributed at least 100 commits each, and who\nself-declare locations on their GitHub profiles. While the study is\npoint-in-time as of 2021, the authors compare their findings\nagainst~\\cite{barahona2008geodiversity, takhteyev2010ossgeography} to\ncharacterize the evolution of FOSS geography over the time snapshots taken by\nthe three studies.\n\nCompared with previous empirical works, our study is much larger scale---having\nanalyzed 43 million\\xspace authors of 2.2 billion\\xspace commits from 160 million\\xspace\nprojects---longitudinal over 50 years of public code contributions rather than\npoint in time, and also more fine-grained (with year-by-year granularity over\nthe observed period). Methodologically, our study relies on Version Control\nSystem (VCS) commit data rather than platform-declared location information.\n\n\nOther works---in particular the work by Daniel~\\cite{daniel2013ossdiversity}\nand, more recently, Rastogi et al.~\\cite{rastogi2016geobias,\n  rastogi2018geobias, prana2021geogenderdiversity}---have studied geographic\n\\emph{diversity and bias}, i.e., the extent to which the origin of FOSS\ndevelopers affect their collaborative coding activities.\nIn this work we characterized geographic diversity in public code for the first\ntime at this scale, both in terms of contributors and observation period. We do\nnot tackle the bias angle, but provide empirical data and findings that can be\nleveraged to that end as future work.\n\n\\emph{Global software engineering}~\\cite{herbsleb2007globalsweng} is the\nsub-field of software engineering that has analyzed the challenges of scaling\ndeveloper collaboration globally, including the specific concern of how to deal\nwith geographic diversity~\\cite{holmstrom2006globaldev, fraser2014eastwest}.\nDecades later the present study provides evidence that can be used, in the\nspecific case of public code and at a very large scale, to verify which\npromises of global software engineering have borne fruit.\n\n\n\n\n\n\n \\section{Methodology}\n\\label{sec:method}\n\n\n\\newif\\ifgrowthfig  \\growthfigtrue\n\\ifgrowthfig\n\\begin{figure}\n  \\includegraphics[width=\\columnwidth]{yearly-commits}\n  \\caption{Yearly public commits over time (log scale).\n}\n  \\label{fig:growth}\n\\end{figure}\n\\fi\n\n\\paragraph{Dataset}\n\nWe retrieved from \\SWH/~\\cite{swh-msr2019-dataset} all commits archived until \\DATALastCommitDate/.\nThey amount to \\DATACommitsRaw/ commits, unique by SHA1 identifier, harvested from \\DATATotalCommitsInSH/ public projects coming from major development forges (GitHub, GitLab, etc.) and package repositories (Debian, PyPI, NPM, etc.).\nCommits in the dataset are by \\DATAAuthorsRaw/ authors, unique by $\\langle$name, email$\\rangle$ pairs.\nThe dataset came as two relational tables, one for commits and one for authors, with the former referencing the latter via a foreign key.\n\\iflong\nEach row in the commit table contains the following fields: commit SHA1 identifier, author and committer timestamps, author and committer identifiers (referencing the author table).\nThe distinction between commit authors and committers come from Git, which allows to commit a change authored by someone else.\nFor this study we focused on authors and ignored committers, as the difference between the two is not relevant for our research questions and the amount of commits with a committer other than its author is negligible.\n\\fi\nFor each entry in the author table we have author full name and email as two separate strings of raw bytes.\n\nWe removed implausible or unusable names that: are not decodable as UTF-8 (\\DATAAuthorsRmNondecodable/ author names removed), are email addresses instead of names (\\DATAAuthorsRmEmail/ ``names''), consist of only blank characters (\\DATAAuthorsRmBlank/), contain more than 10\\% non-letters (\\DATAAuthorsRmNonletter/), are longer than 100 characters (\\DATAAuthorsRmToolong/).\nAfter filtering, about \\DATAAuthorsPlausibleApprox/ authors (\\DATAAuthorsPlausiblePct/ of the initial dataset) remained for further analysis.\n\nNote that the amount of public code commits (and authors) contained in the\ninitial dataset grows exponentially over\ntime~\\cite{swh-provenance-emse}\\ifgrowthfig, as shown for commits in\n\\Cref{fig:growth}\\else: from $10^4$ commits in 1971, to $10^6$ in 1998, to\nalmost $10^9$ in 2020\\fi. As a consequence the observed trends tend to be more\nstable in recent decades than in 40+ year-old ones, due to statistics taken on\nexponentially larger populations.\n\n\n\\paragraph{Geolocation}\n\n\\begin{figure}\n  \\centering\n  \\includegraphics[clip,trim=6cm 6cm 0 0,width=\\linewidth]{subregions-ours}\n  \\caption{The \\DATAWorldRegions/ world regions used as geolocation targets.}\n  \\label{fig:worldmap}\n\\end{figure}\n\nAs geolocation targets we use macro world regions derived from the United Nations geoscheme~\\cite{un1999geoscheme}.\nTo avoid domination by large countries (e.g., China or Russia) within macro regions, we merged and split some regions based on geographic proximity and the sharing of preeminent cultural identification features, such as spoken language.\n\\Cref{fig:worldmap} shows the final list of \\DATAWorldRegions/ world regions used as geolocation targets in this study.\n\nGeolocation of commit authors to world regions uses the two complementary techniques introduced in~\\cite{icse-seis-2022-gender}, briefly recalled below.\nThe first one relies on the country code top-level domain (ccTLD) of email addresses extracted from commit metadata, e.g., \\texttt{.fr}, \\texttt{.ru}, \\texttt{.cn}, etc.\nWe started from the IANA list of Latin character ccTLDs~\\cite{wikipedia-cctld} and manually mapped each corresponding territory to a target world region.\n\nThe second geolocation technique uses the UTC offset of commit timestamps (e.g., UTC-05:00) and author names to determine the most likely world region of the commit author.\nFor each UTC offset we determine a list of compatible places (country, state, or dependent territory) in the world that, at the time of that commit, had that UTC offset; commit time is key here, as country UTC offsets vary over time due to timezone changes.\nTo make this determination we use the IANA time zone database~\\cite{tzdata}.\n\nThen we assign to each place a score that captures the likelihood that a given author name is characteristic of it.\nTo this end we use the Forebears dataset of the frequencies of the most common first and family names which, quoting from~\\cite{forebear-names}: {\\itshape ``provides the approximate incidence of forenames and surnames produced from a database of \\num{4 044 546 938} people (55.5\\% of living people in 2014). As of September 2019 it covers \\num{27 662 801} forenames and \\num{27 206 821} surnames in 236 jurisdictions.''}\nAs in our dataset authors are full name strings (rather than split by first/family name), we first tokenize names (by blanks and case changes) and then lookup individual tokens in both first and family names frequency lists.\nFor each element found in name lists we multiply the place population\\footnotemark{} by the name frequency to obtain a measure that is proportional to the number of persons bearing that name (token) in the specific place.\n\\footnotetext{To obtain population totals---as the notion of ``place'' is heterogeneous: full countries v.~slices of large countries spanning multiple timezones---we use a mixture of primary sources (e.g., government websites), and non-primary ones (e.g., Wikipedia articles).}\nWe sum this figure for all elements to obtain a place score, ending up with a list of $\\langle$place, score$\\rangle$ pairs.\nWe then partition this list by the world region that a place belongs to and sum the score for all the places in each region to obtain an overall score, corresponding to the likelihood that the commit belongs to a given world region.\nWe assign the starting commit as coming from the world region with the highest score.\n\nThe email-based technique suffers from the limited and unbalanced use of ccTLDs: most developers use generic TLDs such as \\texttt{.com}, \\texttt{.org}, or \\texttt{.net}.\nMoreover this does not happen uniformly across zones: US-based developers, for example, use the \\texttt{.us} ccTLD much more seldomly than their European counterparts.\nOn the other hand the offset/name-based technique relies on the UTC offset of the commit timestamps.\nDue to tool configurations on developer setups, a large number of commits in the dataset has an UTC offset equal to zero.\nThis affects less recent commits (\\DATACommitsTZZTwoThousandTwenty/ of 2020s commits have a zero offset) than older ones (\\DATACommitsTZZTwoThousand/ in 2000).\nAs a result the offset/name-based technique could end up detecting a large share of older commits as authored by African developers, and to a lesser extent Europeans.\n\nTo counter these issues we combine the two geolocation techniques together by applying the offset/name-based techniques to all commits with a non-zero UTC offset, and the email-based on to all other commits.\n\n\n \\section{Results and Discussion}\n\\label{sec:results}\n\n\\begin{figure*}\n  \\centering\n  \\includegraphics[width=\\linewidth]{stacked.pdf}\n  \\caption{Ratio of commits (above) and active authors (below) by world zone over the 1971--2020 period.}\n  \\Description[Chart]{Stacked bar chart showing the world zone ratios for commits and authors over the 1971--2020 period.}\n  \\label{fig:results}\n\\end{figure*}\n\n\n \nTo answer \\cref{rq:geodiversity} we gathered the number of commits and distinct authors per year and per world zone.\nWe present the obtained results in \\Cref{fig:results} as two stacked bar charts, showing yearly breakdowns for commits and authors respectively.\nEvery bar represents a year and is partitioned in slices showing the commit/author ratio for each of the world regions of \\Cref{fig:worldmap} in that year.\nTo avoid outliers due to sporadic contributors, in the author chart we only consider authors having contributed at least 5 commits in a given year.\n\nWhile observing trends in the charts remember that the total numbers of commits and authors grow exponentially over time.\nHence for the first years in the charts, the number of data points in some world regions can be extremely small, with negative consequences on the stability of trends.\n\n\n\n\n\\paragraph{Geographic diversity over time}\n\nOverall, the general trend appears to be that the \\textbf{geographic diversity in public code is increasing}: North America and Europe alternated their ``dominance'' until the middle of the 90s; from that moment on most other world regions show a slow but steady increment.\nThis trend of increased participation into public code development includes Central and South Asia (comprising India), Russia, Africa, Central and South America,\nNotice that also zones that do not seem to follow this trend, such as Australia and New Zealand, are also increasing their participation, but at a lower speed with respect to other zones.\nFor example, Australia and New Zealand incremented the absolute number of their commits by about 3 orders of magnitude from 2000 to present days.\n\nAnother interesting phenomenon that can be appreciated in both charts is the sudden contraction of contributions from North America in 1995; since the charts depict ratios, this corresponds to other zones, and Europe in particular, increasing their share.\nAn analysis of the main contributions in the years right before the contraction shows that nine out of ten have \\texttt{ucbvax.Berkeley.EDU} as author email domain, and the tenth is Keith Bostic, one of the leading Unix BSD developers, appearing with email \\texttt{bostic}.\nNo developer with the same email domain appears anymore within the first hundred contributors in 1996.\nThis shows the relevance that BSD Unix and the Computer Systems Research Group at the University of California at Berkeley had in the history of open source software.\nThe group was disbanded in 1995, partially as a consequence of the so-called UNIX wars~\\cite{kernighan2019unixhistory}, and this contributes significantly---also because of the relatively low amount of public code circulating at the time---to the sudden drop of contributions from North America in subsequent years.\nDescendant UNIX operating systems based on BSD, such as OpenBSD, FreeBSD, and NetBSD had smaller relevance to world trends due to (i) the increasing amount of open source code coming from elsewhere and (ii) their more geographically diverse developer community.\n\nAnother time frame in which the ratios for Europe and North America are subject to large, sudden changes is 1975--79.\nA preliminary analysis shows that these ratios are erratic due to the very limited number of commits in those time period, but we were unable to detect a specific root cause.\nTrends for those years should be subject to further studies, in collaboration with software historians.\n\n\n\\paragraph{Colonialism}\n\nAnother trend that stands out from the charts is that Africa appears to be well represented.\nTo assess if this results from a methodological bias, we double-checked the commits detected as originating from Africa for timezones included in the $[0, 3]$ range using both the email- the offset/name-based methods.\nThe results show that the offset/name-based approach assigns 22.7\\% of the commits to Africa whereas the email-based one only assigns 2.7\\% of them.\nWhile a deeper investigation is in order, it is our opinion that the phenomenon we are witnessing here is a consequence of colonialism, specifically the adoption of Europeans names in African countries.\nFor example the name Eric, derived from Old Norse, is more popular in Ghana than it is in France or in the UK.\nThis challenges the ability of the offset/name-based method to correctly differentiate between candidate places.\nTogether with the fact that several African countries are largely populated, the offset/name-based method could detect European names as originating from Africa.\nWhile this cuts both way, the likelihood of a random person contributing to public code is very different between European countries, all having a well-developed software industry, and African countries that do not all share this trait.\n\n\n\\paragraph{Immigration/emigration}\n\nAnother area where a similar phenomenon could be at play is the evolution of Central and South America.\nContribution from this macro region appears to be growing steadily.\nTo assess if this is the result of a bias introduced by the name-based detection we analyzed the evolution of offset/name-based assignment over time for authors whose email domain is among the top-ten US-based entities in terms of overall contributions (estimated in turn by analyzing the most frequent email domains and manually selecting those belonging to US-based entities).\nIn 1971 no author with an email from top US-based entities is detected as belonging to Central and South America, whereas in 2019 the ratio is 12\\%.\nNowadays more than one tenth of the people email-associated to top US-based entities have popular Central and South American names, which we posit as a likely consequence of immigration into US (emigration from Central and South America).\nSince immigration has a much longer history than what we are studying here, what we are witnessing probably includes long-term consequences of it, such as second and third generation immigrants employed in white-collar jobs, such as software development.\n\n\n\n\n \\section{Limitations and Future Work}\n\\label{sec:conclusion}\n\nWe have performed an exploratory, yet very large scale, empirical study of the geographic diversity in public code commits over time.\nWe have analyzed 2.2 billion\\xspace public commits covering the \\DATAYearRange/ time period.\nWe have geolocated developers to \\DATAWorldRegions/ world regions using as signals email domains, timezone offsets, and author names.\nOur findings show that the geographic diversity in public code is increasing over time, and markedly so over the past 20--25 years.\nObserved trends also co-occur with historical events and macro phenomena like the end of the UNIX wars, increase of coding literacy around the world, colonialism, and immigration.\n\n\n\\medskip\n\\emph{Limitations.}\nThis study relies on a combination of two geolocation methods: one based on email domains, another based on commit UTC offsets and author names.\nWe discussed some of the limitations of either method in \\Cref{sec:method}, motivating our decision of restricting the use of the email-based method to commits with a zero UTC offset.\nAs a consequence, for most commits in the dataset the offset/name-based method is used.\nWith such method, the frequencies of forenames and surnames are used to rank candidate zones that have a compatible UTC offset at commit time.\n\nA practical consequence of this is that for commits with, say, offset UTC+09:00 the candidate places can be Russia, Japan and Australia, depending on the specific date due to daylight saving time.\nPopular forenames and surnames in these regions tend to be quite different so the likelihood of the method to provide a reliable detection is high.\nFor other offsets the set of popular forenames and surnames from candidate zones can exhibit more substantial overlaps, negatively impacting detection accuracy.\nWe have discussed some of these cases in \\Cref{sec:results}, but other might be lingering in the results impacting observed trends.\n\nThe choice of using the email-based method for commits with zero UTC offset, and the offset/name-based method elsewhere, has allowed us to study all developers not having a country-specific email domain (ccTLD), but comes with the risk of under-representing the world zones that have (in part and in some times of the year) an actual UTC offset of zero.\n\nA potential bias in this study could be introduced by the fact that the name database used for offset/name-based geolocation only contains names formed using Latin alphabet characters.\nWe looked for names containing Chinese, Japanese, and Korean characters in the original dataset, finding only a negligible amount of authors who use non-Latin characters in their VCS names, which leads us to believe that the impact of this issue is minimal.\n\nWe did not apply identity merging (e.g., using state-of-the-art tools like SortingHat~\\cite{moreno2019sortinghat}), but we do not expect this to be a significant issue because: (a) to introduce bias in author trends the distribution of identity merges around the world should be uneven, which seems unlikely; and (b) the observed commit trends (which would be unaffected by identity merging) are very similar to observed author trends.\n\nWe did not systematically remove known bot accounts~\\cite{lebeuf2018swbots} from the author dataset, but we did check for the presence of software bots among the top committers of each year. We only found limited traces of continuous integration (CI) bots, used primarily to automate merge commits. After removing CI bots from the dataset the observed global trends were unchanged, therefore this paper presents unfiltered data.\n\n\n\\medskip\n\\emph{Future work.}\nTo some extent the above limitations are the price to pay to study such a large dataset: there exists a trade-off between large-scale analysis and accuracy.\nWe plan nonetheless to further investigate and mitigate them in future work.\nMulti-method approaches, merging data mining with social science methods, could be applied to address some of the questions raised in this exploratory study.\nWhile they do not scale to the whole dataset, multi-methods can be adopted to dig deeper into specific aspects, specifically those related to social phenomena.\nSoftware is a social artifact, it is no wonder that aspects related to sociocultural evolution emerge when analyzing its evolution at this scale.\n\n\n\n\n \n\\clearpage\n\n\n&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;{'timestamp': '2022-03-30T02:27:00', 'yymm': '2203', 'arxiv_id': '2203.15369', 'language': 'en', 'url': 'https://arxiv.org/abs/2203.15369'}&quot;}}},{&quot;rowIdx&quot;:1,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;\\section{Introduction}\n\nOne of the fundamental ingredients in the theory of non-commutative or\nquantum geometry is the notion of a differential calculus.\nIn the framework of quantum groups the natural notion\nis that of a\nbicovariant differential calculus as introduced by Woronowicz\n\\cite{Wor_calculi}. Due to the allowance of non-commutativity\nthe uniqueness of a canonical calculus is lost.\nIt is therefore desirable to classify the possible choices.\nThe most important piece is the space of one-forms or ``first\norder differential calculus'' to which we will restrict our attention\nin the following. (From this point on we will use the term\n``differential calculus'' to denote a\nbicovariant first order differential calculus).\n\nMuch attention has been devoted to the investigation of differential\ncalculi on quantum groups $C_q(G)$ of function algebra type for\n$G$ a simple Lie group.\nNatural differential calculi on matrix quantum groups were obtained by\nJurco \\cite{Jur} and\nCarow-Watamura et al.\\\n\\cite{CaScWaWe}. A partial classification of calculi of the same\ndimension as the natural ones\nwas obtained by\nSchm\\\&quot;udgen and Sch\\\&quot;uler \\cite{ScSc2}.\nMore recently, a classification theorem for factorisable\ncosemisimple quantum groups was obtained by Majid \\cite{Majid_calculi},\ncovering the general $C_q(G)$ case. A similar result was\nobtained later by Baumann and Schmitt \\cite{BaSc}.\nAlso, Heckenberger and Schm\\\&quot;udgen \\cite{HeSc} gave a\ncomplete classification on $C_q(SL(N))$ and $C_q(Sp(N))$. \n\n\nIn contrast, for $G$ not simple or semisimple the differential calculi\non $C_q(G)$\nare largely unknown. A particularly basic case is the Lie group $B_+$\nassociated with the Lie algebra $\\lalg{b_+}$ generated by two elements\n$X,H$ with the relation $[H,X]=X$. The quantum enveloping algebra\n\\ensuremath{U_q(\\lalg{b_+})}{}\nis self-dual, i.e.\\ is non-degenerately paired with itself \\cite{Drinfeld}.\nThis has an interesting consequence: \\ensuremath{U_q(\\lalg{b_+})}{} may be identified with (a\ncertain algebraic model of) \\ensuremath{C_q(B_+)}. The differential calculi on this\nquantum group and on its ``classical limits'' \\ensuremath{C(B_+)}{} and \\ensuremath{U(\\lalg{b_+})}{}\nwill be the main concern of this paper. We pay hereby equal attention\nto the dual notion of ``quantum tangent space''.\n\nIn section \\ref{sec:q} we obtain the complete classification of differential\ncalculi on \\ensuremath{C_q(B_+)}{}. It turns out that (finite\ndimensional) differential\ncalculi are characterised by finite subsets $I\\subset\\mathbb{N}$.\nThese\nsets determine the decomposition into coirreducible (i.e.\\ not\nadmitting quotients) differential calculi\ncharacterised by single integers. For the coirreducible calculi the\nexplicit formulas for the commutation relations and braided\nderivations are given.\n\nIn section \\ref{sec:class} we give the complete classification for the\nclassical function algebra \\ensuremath{C(B_+)}{}. It is essentially the same as in the\n$q$-deformed setting and we stress this by giving an almost\none-to-one correspondence of differential calculi to those obtained in\nthe previous section. In contrast, however, the decomposition and\ncoirreducibility properties do not hold at all. (One may even say that\nthey are maximally violated). We give the explicit formulas for those\ncalculi corresponding to coirreducible ones.\n\nMore interesting perhaps is the ``dual'' classical limit. I.e.\\ we\nview \\ensuremath{U(\\lalg{b_+})}{} as a quantum function algebra with quantum enveloping\nalgebra \\ensuremath{C(B_+)}{}. This is investigated in section \\ref{sec:dual}. It\nturns out that in this setting we have considerably more freedom in\nchoosing a\ndifferential calculus since the bicovariance condition becomes much\nweaker. This shows that this dual classical limit is in a sense\n``unnatural'' as compared to the ordinary classical limit of section\n\\ref{sec:class}. \nHowever, we can still establish a correspondence of certain\ndifferential calculi to those of section \\ref{sec:q}. The\ndecomposition properties are conserved while the coirreducibility\nproperties are not.\nWe give the\nformulas for the calculi corresponding to coirreducible ones.\n\nAnother interesting aspect of viewing \\ensuremath{U(\\lalg{b_+})}{} as a quantum function\nalgebra is the connection to quantum deformed models of space-time and\nits symmetries. In particular, the $\\kappa$-deformed Minkowski space\ncoming from the $\\kappa$-deformed Poincar\\'e algebra\n\\cite{LuNoRu}\\cite{MaRu} is just a simple generalisation of \\ensuremath{U(\\lalg{b_+})}.\nWe use this in section \\ref{sec:kappa} to give\na natural $4$-dimensional differential calculus. Then we show (in a\nformal context) that integration is given by\nthe usual Lesbegue integral on $\\mathbb{R}^n$ after normal ordering.\nThis is obtained in an intrinsic context different from the standard\n$\\kappa$-Poincar\\'e approach.\n\nA further important motivation for the investigation of differential\ncalculi on\n\\ensuremath{U(\\lalg{b_+})}{} and \\ensuremath{C(B_+)}{} is the relation of those objects to the Planck-scale\nHopf algebra \\cite{Majid_Planck}\\cite{Majid_book}. This shall be\ndeveloped elsewhere.\n\nIn the remaining parts of this introduction we will specify our\nconventions and provide preliminaries on the quantum group \\ensuremath{U_q(\\lalg{b_+})}, its\ndeformations, and differential calculi.\n\n\n\\subsection{Conventions}\n\nThroughout, $\\k$ denotes a field of characteristic 0 and\n$\\k(q)$ denotes the field of rational\nfunctions in one parameter $q$ over $\\k$.\n$\\k(q)$ is our ground field in\nthe $q$-deformed setting, while $\\k$ is the\nground field in the ``classical'' settings.\nWithin section \\ref{sec:q} one could equally well view $\\k$ as the ground\nfield with $q\\in\\k^*$ not a root of unity. This point of view is\nproblematic, however, when obtaining ``classical limits'' as\nin sections \\ref{sec:class} and \\ref{sec:dual}.\n\nThe positive integers are denoted by $\\mathbb{N}$ while the non-negative\nintegers are denoted by $\\mathbb{N}_0$.\nWe define $q$-integers, $q$-factorials and\n$q$-binomials as follows:\n\\begin{gather*}\n[n]_q=\\sum_{i=0}^{n-1} q^i\\qquad\n[n]_q!=[1]_q [2]_q\\cdots [n]_q\\qquad\n\\binomq{n}{m}=\\frac{[n]_q!}{[m]_q! [n-m]_q!}\n\\end{gather*}\nFor a function of several variables (among\nthem $x$) over $\\k$ we define\n\\begin{gather*}\n(T_{a,x} f)(x) = f(x+a)\\\\\n(\\fdiff_{a,x} f)(x) = \\frac{f(x+a)-f(x)}{a}\n\\end{gather*}\nwith $a\\in\\k$ and similarly over $\\k(q)$\n\\begin{gather*}\n(Q_{m,x} f)(x) = f(q^m x)\\\\\n(\\partial_{q,x} f)(x) = \\frac{f(x)-f(qx)}{x(1-q)}\\\\\n\\end{gather*}\nwith  $m\\in\\mathbb{Z}$.\n\nWe frequently use the notion of a polynomial in an extended\nsense. Namely, if we have an algebra with an element $g$ and its\ninverse $g^{-1}$ (as\nin \\ensuremath{U_q(\\lalg{b_+})}{}) we will mean by a polynomial in $g,g^{-1}$ a finite power\nseries in $g$ with exponents in $\\mathbb{Z}$. The length of such a polynomial\nis the difference between highest and lowest degree.\n\nIf $H$ is a Hopf algebra, then $H^{op}$ will denote the Hopf algebra\nwith the opposite product.\n\n\\subsection{\\ensuremath{U_q(\\lalg{b_+})}{} and its Classical Limits}\n\\label{sec:intro_limits}\n\nWe recall that,\nin the framework of quantum groups, the duality between enveloping algebra\n$U(\\lalg{g})$ of the Lie algebra and algebra of functions $C(G)$ on the Lie\ngroup carries over to $q$-deformations.\nIn the case of\n$\\lalg{b_+}$, the\n$q$-deformed enveloping algebra \\ensuremath{U_q(\\lalg{b_+})}{} defined over $\\k(q)$ as\n\\begin{gather*}\nU_q(\\lalg{b_+})=\\k(q)\\langle X,g,g^{-1}\\rangle \\qquad\n\\text{with relations} \\\\\ng g^{-1}=1 \\qquad Xg=qgX \\\\\n\\cop X=X\\otimes 1 + g\\otimes X \\qquad\n\\cop g=g\\otimes g \\\\\n\\cou (X)=0 \\qquad \\cou (g)=1 \\qquad\n\\antip X=-g^{-1}X \\qquad \\antip g=g^{-1}\n\\end{gather*}\nis self-dual. Consequently, it\nmay alternatively be viewed as the quantum algebra \\ensuremath{C_q(B_+)}{} of\nfunctions on the Lie group $B_+$ associated with $\\lalg{b_+}$.\nIt has two classical limits, the enveloping algebra \\ensuremath{U(\\lalg{b_+})}{}\nand the function algebra $C(B_+)$.\nThe transition to the classical enveloping algebra is achieved by\nreplacing $q$\nby $e^{-t}$ and $g$ by $e^{tH}$ in a formal power series setting in\n$t$, introducing a new generator $H$. Now, all expressions are written in\nthe form $\\sum_j a_j t^j$ and only the lowest order in $t$ is kept.\nThe transition to the classical function algebra on the other hand is\nachieved by setting $q=1$.\nThis may be depicted as follows:\n\\[\\begin{array}{c @{} c @{} c @{} c}\n&amp; \\ensuremath{U_q(\\lalg{b_+})} \\cong \\ensuremath{C_q(B_+)} &amp;&amp; \\\\\n&amp; \\diagup \\hspace{\\stretch{1}} \\diagdown &amp;&amp; \\\\\n \\begin{array}{l} q=e^{-t} \\\\ g=e^{tH} \\end{array} \\Big| _{t\\to 0} \n &amp;&amp; q=1 &amp;\\\\\n \\swarrow &amp;&amp;&amp; \\searrow \\\\\n \\ensuremath{U(\\lalg{b_+})} &amp; <\\cdots\\textrm{dual}\\cdots> &amp;&amp; \\ensuremath{C(B_+)}\n\\end{array}\\]\nThe self-duality of \\ensuremath{U_q(\\lalg{b_+})}{} is expressed as a pairing\n$\\ensuremath{U_q(\\lalg{b_+})}\\times\\ensuremath{U_q(\\lalg{b_+})}\\to\\k$\nwith\nitself:\n\\[\\langle X^n g^m, X^r g^s\\rangle =\n \\delta_{n,r} [n]_q!\\, q^{-n(n-1)/2} q^{-ms}\n \\qquad\\forall n,r\\in\\mathbb{N}_0\\: m,s\\in\\mathbb{Z}\\]\nIn the classical limit this becomes the pairing $\\ensuremath{U(\\lalg{b_+})}\\times\\ensuremath{C(B_+)}\\to\\k$\n\\begin{equation}\n\\langle X^n H^m, X^r g^s\\rangle =\n \\delta_{n,r} n!\\, s^m\\qquad \\forall n,m,r\\in\\mathbb{N}_0\\: s\\in\\mathbb{Z}\n\\label{eq:pair_class}\n\\end{equation} \n\n\n\n\\subsection{Differential Calculi and Quantum Tangent Spaces}\n\nIn this section we recall some facts about differential calculi\nalong the lines of Majid's treatment in \\cite{Majid_calculi}.\n\nFollowing Woronowicz \\cite{Wor_calculi}, first order bicovariant differential\ncalculi on a quantum group $A$ (of\nfunction algebra type) are in one-to-one correspondence to submodules\n$M$ of $\\ker\\cou\\subset A$ in the category $^A_A\\cal{M}$ of (say) left\ncrossed modules of $A$ via left multiplication and left adjoint\ncoaction:\n\\[\na\\triangleright v = av \\qquad \\mathrm{Ad_L}(v)\n =v_{(1)}\\antip v_{(3)}\\otimes v_{(2)}\n\\qquad \\forall a\\in A, v\\in A\n\\]\nMore precisely, given a crossed submodule $M$, the corresponding\ncalculus is given by $\\Gamma=\\ker\\cou/M\\otimes A$ with $\\diff a =\n\\pi(\\cop a - 1\\otimes a)$ ($\\pi$ the canonical projection).\nThe right action and coaction on $\\Gamma$ are given by\nthe right multiplication and coproduct on $A$, the left action and\ncoaction by the tensor product ones with $\\ker\\cou/M$ as a left\ncrossed module. In all of what follows, ``differential calculus'' will\nmean ``bicovariant first order differential calculus''.\n\nAlternatively \\cite{Majid_calculi}, given in addition a quantum group $H$\ndually paired with $A$\n(which we might think of as being of enveloping algebra type), we can\nexpress the coaction of $A$ on\nitself as an action of $H^{op}$ using the pairing:\n\\[\nh\\triangleright v = \\langle h, v_{(1)} \\antip v_{(3)}\\rangle v_{(2)}\n\\qquad \\forall h\\in H^{op}, v\\in A\n\\]\nThereby we change from the category of (left) crossed $A$-modules to\nthe category of left modules of the quantum double $A\\!\\bowtie\\! H^{op}$.\n\nIn this picture the pairing between $A$ and $H$ descends to a pairing\nbetween $A/\\k 1$ (which we may identify with $\\ker\\cou\\subset A$) and\n$\\ker\\cou\\subset H$. Further quotienting $A/\\k 1$ by $M$ (viewed in\n$A/\\k 1$) leads to a pairing with the subspace $L\\subset\\ker\\cou H$\nthat annihilates $M$. $L$ is called a ``quantum tangent space''\nand is dual to the differential calculus $\\Gamma$ generated by $M$ in\nthe sense that $\\Gamma\\cong \\Lin(L,A)$ via\n\\begin{equation}\nA/(\\k 1+M)\\otimes A \\to \\Lin(L,A)\\qquad\nv\\otimes a \\mapsto \\langle \\cdot, v\\rangle a\n\\label{eq:eval}\n\\end{equation}\nif the pairing between $A/(\\k 1+M)$ and $L$ is non-degenerate.\n\nThe quantum tangent spaces are obtained directly by dualising the\n(left) action of the quantum double on $A$ to a (right) action on\n$H$. Explicitly, this is the adjoint action and the coregular action\n\\[\nh \\triangleright x = h_{(1)} x \\antip h_{(2)} \\qquad\na \\triangleright x = \\langle x_{(1)}, a \\rangle x_{(2)}\\qquad\n \\forall h\\in H, a\\in A^{op},x\\in A\n\\]\nwhere we have converted the right action to a left action by going\nfrom \\mbox{$A\\!\\bowtie\\! H^{op}$}-modules to \\mbox{$H\\!\\bowtie\\! A^{op}$}-modules.\nQuantum tangent spaces are subspaces of $\\ker\\cou\\subset H$ invariant\nunder the projection of this action to $\\ker\\cou$ via \\mbox{$x\\mapsto\nx-\\cou(x) 1$}. Alternatively, the left action of $A^{op}$ can be\nconverted to a left coaction of $H$ being the comultiplication (with\nsubsequent projection onto $H\\otimes\\ker\\cou$).\n\nWe can use the evaluation map (\\ref{eq:eval})\nto define a ``braided derivation'' on elements of the quantum tangent\nspace via\n\\[\\partial_x:A\\to A\\qquad \\partial_x(a)={\\diff a}(x)=\\langle\nx,a_{(1)}\\rangle a_{(2)}\\qquad\\forall x\\in L, a\\in A\\]\nThis obeys the braided derivation rule\n\\[\\partial_x(a b)=(\\partial_x a) b\n + a_{(2)} \\partial_{a_{(1)}\\triangleright x}b\\qquad\\forall x\\in L, a\\in A\\]\n\nGiven a right invariant basis $\\{\\eta_i\\}_{i\\in I}$ of $\\Gamma$ with a\ndual basis $\\{\\phi_i\\}_{i\\in I}$ of $L$ we have\n\\[{\\diff a}=\\sum_{i\\in I} \\eta_i\\cdot \\partial_i(a)\\qquad\\forall a\\in A\\]\nwhere we denote $\\partial_i=\\partial_{\\phi_i}$. (This can be easily\nseen to hold by evaluation against $\\phi_i\\ \\forall i$.)\n\n\n\\section{Classification on \\ensuremath{C_q(B_+)}{} and \\ensuremath{U_q(\\lalg{b_+})}{}}\n\\label{sec:q}\n\nIn this section we completely classify differential calculi on \\ensuremath{C_q(B_+)}{}\nand, dually, quantum tangent spaces on \\ensuremath{U_q(\\lalg{b_+})}{}. We start by\nclassifying the relevant crossed modules and then proceed to a\ndetailed description of the calculi.\n\n\\begin{lem}\n\\label{lem:cqbp_class}\n(a) Left crossed \\ensuremath{C_q(B_+)}-submodules $M\\subseteq\\ensuremath{C_q(B_+)}$ by left\nmultiplication and left\nadjoint coaction are in one-to-one correspondence to\npairs $(P,I)$\nwhere $P\\in\\k(q)[g]$ is a polynomial with $P(0)=1$ and $I\\subset\\mathbb{N}$ is\nfinite.\n$\\codim M<\\infty$ iff $P=1$. In particular $\\codim M=\\sum_{n\\in I}n$\nif $P=1$.\n\n(b) The finite codimensional maximal $M$\ncorrespond to the pairs $(1,\\{n\\})$ with $n$ the\ncodimension. The infinite codimensional maximal $M$ are characterised by\n$(P,\\emptyset)$ with $P$ irreducible and $P(g)\\neq 1-q^{-k}g$ for any\n$k\\in\\mathbb{N}_0$.\n\n(c) Crossed submodules $M$ of finite\ncodimension are intersections of maximal ones.\nIn particular $M=\\bigcap_{n\\in I} M^n$, with $M^n$ corresponding to\n$(1,\\{n\\})$.\n\\end{lem}\n\\begin{proof}\n(a) Let $M\\subseteq\\ensuremath{C_q(B_+)}$ be a crossed \\ensuremath{C_q(B_+)}-submodule by left\nmultiplication and left adjoint coaction and let\n$\\sum_n X^n P_n(g) \\in M$, where $P_n$ are polynomials in $g,g^{-1}$\n(every element of \\ensuremath{C_q(B_+)}{} can be expressed in\nthis form). From the formula for the coaction ((\\ref{eq:adl}), see appendix)\nwe observe that for all $n$ and for all $t\\le n$ the element\n\\[X^t P_n(g) \\prod_{s=1}^{n-t} (1-q^{s-n}g)\\]\nlies in $M$.\nIn particular\nthis is true for $t=n$, meaning that elements of constant degree in $X$\nlie separately in $M$. It is therefore enough to consider such\nelements.\n\nLet now $X^n P(g) \\in M$.\nBy left multiplication $X^n P(g)$ generates any element of the form\n$X^k P(g) Q(g)$, where $k\\ge n$ and $Q$ is any polynomial in\n$g,g^{-1}$. (Note that $Q(q^kg) X^k=X^k Q(g)$.)\nWe see that $M$ contains the following elements:\n\\[\\begin{array}{ll}\n\\vdots &amp; \\\\\nX^{n+2} &amp; P(g) \\\\\nX^{n+1} &amp; P(g) \\\\\nX^n &amp; P(g) \\\\\nX^{n-1} &amp; P(g) (1-q^{1-n}g) \\\\\nX^{n-2} &amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \\\\\n\\vdots &amp; \\\\\nX &amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \\ldots (1-q^{-1}g) \\\\\n&amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \\ldots (1-q^{-1}g)(1-g) \n\\end{array}\n\\]\nMoreover, if $M$ is generated by $X^n P(g)$ as a module\nthen these elements generate a basis for $M$ as a vector\nspace by left\nmultiplication with polynomials in $g,g^{-1}$. (Observe that the\napplication of the coaction to any of the elements shown does not\ngenerate elements of new type.)\n\nNow, let $M$ be a given crossed submodule. We pick, among the\nelements in $M$ of the form $X^n P(g)$ with $P$ of minimal\nlength,\none\nwith lowest degree in $X$. Then certainly the elements listed above are\nin $M$. Furthermore for any element of the form $X^k Q(g)$, $Q$ must\ncontain $P$ as a factor and for $k<n$, $Q$ must contain $P(g) (1-q^{1-n}g)$\nas a factor. We continue by picking the smallest $n_2$, so that\n$X^{n_2} P(g) (1-q^{1-n}g) \\in M$. Certainly $n_2<n$. Again, for any\nelement of $X^l Q(g)$ in $M$ with $l<n_2$, we have that\n$P(g) (1-q^{1-n}g) (1-q^{1-n_2}g)$ divides Q(g). We proceed by\ninduction, until we arrive at degree zero in $X$.\n\nWe obtain the following elements generating a basis for $M$ by left\nmultiplication with polynomials in $g,g^{-1}$ (rename $n_1=n$):\n\n\\[ \\begin{array}{ll}\n\\vdots &amp; \\\\\nX^{n_1+1} &amp; P(g) \\\\\nX^{n_1} &amp; P(g) \\\\\nX^{n_1-1} &amp; P(g) (1-q^{1-{n_1}}g) \\\\\n\\vdots &amp; \\\\\nX^{n_2} &amp; P(g) (1-q^{1-{n_1}}g) \\\\\nX^{n_2-1} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-n_2})\\\\\n\\vdots &amp; \\\\\nX^{n_3} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-{n_2}}g) \\\\\nX^{n_3-1} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-{n_2}}g) (1-q^{1-n_3})\\\\\n\\vdots &amp; \\\\\n&amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-n_2}g) (1-q^{1-n_3}g) \\ldots (1-q^{1-n_m}g) \n\\end{array}\n\\]\nWe see that the integers $n_1,\\ldots,n_m$ uniquely determine the shape\nof this picture. The polynomial $P(g)$ on the other hand can be\nshifted (by $g$ and $g^{-1}$) or renormalised. To determine $M$\nuniquely we shift and normalise $P$ in such a way that it contains no\nnegative powers\nand has unit constant coefficient. $P$ can then be viewed as a\npolynomial $\\in\\k(q)[g]$.\n\nWe see that the codimension of $M$ is the sum of the lengths of the\npolynomials in $g$ over all degrees in $X$ in the above\npicture. Finite codimension corresponds to $P=1$. In this\ncase the codimension is the sum\n$n_1+\\ldots +n_m$.\n\n(b) We observe that polynomials of the form $1-q^{j}g$\nhave no common divisors for distinct $j$. Therefore,\nfinite codimensional crossed\nsubmodules are maximal if and only if\nthere is just one integer ($m=1$). Thus, the maximal left\ncrossed submodule of\ncodimension $k$ is generated by $X^k$ and $1-q^{1-k}g$.\nFor an infinite codimensional crossed submodule we certainly need\n$m=0$. Then, the maximality corresponds to irreducibility of\n$P$.\n\n(c) This is again due to the distinctness of factors $1-q^j g$.\n\\end{proof}\n\n\n\\begin{cor}\n\\label{cor:cqbp_eclass}\n(a) Left crossed \\ensuremath{C_q(B_+)}-submodules $M\\subseteq\\ker\\cou\\subset\\ensuremath{C_q(B_+)}$\nare in one-to-one correspondence to pairs\n$(P,I)$ as in lemma \\ref{lem:cqbp_class}\nwith the additional constraint $(1-g)$ divides $P(g)$ or $1\\in I$.\n$\\codim M<\\infty$ iff $P=1$. In particular $\\codim M=(\\sum_{n\\in I}n)-1$\nif $P=1$.\n\n(b) The finite codimensional maximal $M$\ncorrespond to the pairs\n$(1,\\{1,n\\})$ with $n\\ge 2$ the\ncodimension. The infinite codimensional maximal $M$ correspond to pairs\n$(P,\\{1\\})$ with $P$ irreducible and $P(g)\\neq 1-q^{-k}g$ for any\n$k\\in\\mathbb{N}_0$.\n\n(c) Crossed submodules $M$ of finite\ncodimension are intersections of maximal ones.\nIn particular $M=\\bigcap_{n\\in I} M^n$, with $M^n$ corresponding to\n$(1,\\{1,n\\})$.\n\\end{cor}\n\\begin{proof}\nFirst observe that $\\sum_n X^n P_n(g)\\in \\ker\\cou$ if and only if\n$(1-g)$ divides $P_0(g)$. This is to say that that $\\ker\\cou$\nis the crossed submodule corresponding to the pair $(1,\\{1\\})$ in\nlemma \\ref{lem:cqbp_class}. We obtain the classification\nfrom the one of lemmas \\ref{lem:cqbp_class} by intersecting\neverything with this crossed submodule. In particular, this reduces\nthe codimension by one in the finite codimensional case.\n\\end{proof}\n\n\n\n\\begin{lem}\n\\label{lem:uqbp_class}\n(a) Left crossed \\ensuremath{U_q(\\lalg{b_+})}-submodules $L\\subseteq\\ensuremath{U_q(\\lalg{b_+})}$ via the left adjoint\naction and left\nregular coaction are in one-to-one correspondence to the set\n$3^{\\mathbb{N}_0}\\times2^{\\mathbb{N}}$.\nFinite dimensional $L$ are in one-to-one correspondence to\nfinite sets $I\\subset\\mathbb{N}$ and $\\dim L=\\sum_{n\\in I}n$.\n\n(b) Finite dimensional irreducible $L$ correspond to $\\{n\\}$\nwith $n$ the dimension.\n\n(c) Finite dimensional $L$ are direct sums of irreducible ones. In\nparticular $L=\\oplus_{n\\in I} L^n$ with $L^n$ corresponding to $\\{n\\}$.\n\\end{lem}\n\\begin{proof}\n(a) The action takes the explicit form\n\\[g\\triangleright X^n g^k = q^{-n} X^n g^k\\qquad\nX\\triangleright X^n g^k = X^{n+1}g^k(1-q^{-(n+k)})\\]\nwhile the coproduct is\n\\[\\cop(X^n g^k)=\\sum_{r=0}^{n} \\binomq{n}{r}\n q^{-r(n-r)} X^{n-r} g^{k+r}\\otimes X^r g^k\\]\nwhich we view as a left coaction here.\nLet now $L\\subseteq\\ensuremath{U_q(\\lalg{b_+})}$ be a crossed \\ensuremath{U_q(\\lalg{b_+})}-submodule via this action\nand coaction. For $\\sum_n X^n P_n(g)\\in L$ invariance under\nthe action by\n$g$ clearly means that \\mbox{$X^n P_n(g)\\in L\\ \\forall n$}. Then from\ninvariance under the coaction we can conclude that\nif $X^n \\sum_j a_j g^j\\in L$ we must have\n$X^n g^j\\in L\\ \\forall j$.\nI.e.\\ elements of the form $X^n g^j$ lie separately in $L$ and it is\nsufficient to consider such elements. From the coaction we learn that\nif $X^n g^j\\in L$ we have $X^m g^j\\in L\\ \\forall m\\le n$.\nThe action\nby $X$ leads to $X^n g^j\\in L \\Rightarrow X^{n+1} g^j\\in\nL$ except if\n$n+j=0$. The classification is given by the possible choices we have\nfor each power in $g$. For every positive integer $j$ we can\nchoose wether or not to include the span of\n$\\{ X^n g^j|\\forall n\\}$ in $L$ and for\nevery non-positive\ninteger we can choose to include either the span of $\\{ X^n\ng^j|\\forall n\\}$\nor just\n$\\{ X^n g^j|\\forall n\\le -j\\}$ or neither. I.e.\\ for positive\nintegers ($\\mathbb{N}$) we have two choices while for non-positive (identified\nwith $\\mathbb{N}_0$) ones we have three choices.\n\nClearly, the finite dimensional $L$ are those where we choose only to\ninclude finitely many powers of $g$ and also only finitely many powers\nof $X$. The latter is only possible for the non-positive powers\nof $g$.\nBy identifying positive integers $n$ with powers $1-n$ of $g$, we\nobtain a classification by finite subsets of $\\mathbb{N}$.\n\n(b) Irreducibility clearly corresponds to just including one power of $g$\nin the finite dimensional case.\n\n(c) The decomposition property is obvious from the discussion.\n\\end{proof}\n\n\n\\begin{cor}\n\\label{cor:uqbp_eclass}\n(a) Left crossed \\ensuremath{U_q(\\lalg{b_+})}-submodules $L\\subseteq\\ker\\cou\\subset\\ensuremath{U_q(\\lalg{b_+})}$ via\nthe left adjoint\naction and left regular coaction (with subsequent projection to\n$\\ker\\cou$ via $x\\mapsto x-\\cou(x)1$) are in one-to-one correspondence to\nthe set $3^{\\mathbb{N}}\\times2^{\\mathbb{N}_0}$.\nFinite dimensional $L$ are in one-to-one correspondence to\nfinite sets\n$I\\subset\\mathbb{N}\\setminus\\{1\\}$ and $\\dim L=\\sum_{n\\in I}n$.\n\n(b) Finite dimensional irreducible $L$ correspond to $\\{n\\}$\nwith $n\\ge 2$ the dimension.\n\n(c) Finite dimensional $L$ are direct sums of irreducible ones. In\nparticular $L=\\oplus_{n\\in I} L^n$ with $L^n$ corresponding to $\\{n\\}$.\n\\end{cor}\n\\begin{proof}\nOnly a small modification of lemma \\ref{lem:uqbp_class} is\nnecessary. Elements of\nthe form $P(g)$ are replaced by elements of the form\n$P(g)-P(1)$. Monomials with non-vanishing degree in $X$ are unchanged.\nThe choices for elements of degree $0$ in $g$ are reduced to either\nincluding the span of\n$\\{ X^k |\\forall k>0 \\}$ in the crossed submodule or not. In\nparticular, the crossed submodule characterised by \\{1\\} in lemma\n\\ref{lem:uqbp_class} is projected out.\n\\end{proof}\n\nDifferential calculi in the original sense of Woronowicz are\nclassified by corollary \\ref{cor:cqbp_eclass} while from the quantum\ntangent space\npoint of view the\nclassification is given by corollary \\ref{cor:uqbp_eclass}.\nIn the finite dimensional case the duality is strict in the sense of a\none-to-one correspondence.\nThe infinite dimensional case on the other hand depends strongly on\nthe algebraic models we use for the function or enveloping\nalgebras. It is therefore not surprising that in the present purely\nalgebraic context the classifications are quite different in this\ncase. We will restrict ourselves to the finite dimensional\ncase in the following description of the differential calculi.\n\n\n\\begin{thm}\n\\label{thm:q_calc}\n(a) Finite dimensional differential calculi $\\Gamma$ on \\ensuremath{C_q(B_+)}{} and\ncorresponding quantum tangent spaces $L$ on \\ensuremath{U_q(\\lalg{b_+})}{} are\nin one-to-one correspondence to\nfinite sets $I\\subset\\mathbb{N}\\setminus\\{1\\}$. In particular\n$\\dim\\Gamma=\\dim L=\\sum_{n\\in I}n$.\n\n(b) Coirreducible $\\Gamma$ and irreducible $L$ correspond to\n$\\{n\\}$ with $n\\ge 2$ the dimension.\nSuch a $\\Gamma$ has a\nright invariant basis $\\eta_0,\\dots,\\eta_{n-1}$ so that the relations\n\\begin{gather*}\n\\diff X=\\eta_1+(q^{n-1}-1)\\eta_0 X \\qquad\n \\diff g=(q^{n-1}-1)\\eta_0 g\\\\\n[a,\\eta_0]=\\diff a\\quad \\forall a\\in\\ensuremath{C_q(B_+)}\\\\\n[g,\\eta_i]_{q^{n-1-i}}=0\\quad \\forall i\\qquad\n[X,\\eta_i]_{q^{n-1-i}}=\\begin{cases}\n \\eta_{i+1} &amp; \\text{if}\\ i<n-1 \\\\\n 0 &amp; \\text{if}\\ i=n-1\n \\end{cases}\n\\end{gather*}\nhold, where $[a,b]_p := a b - p b a$. By choosing the dual basis on\nthe corresponding irreducible $L$ we obtain\nthe braided derivations\n\\begin{gather*}\n\\partial_i\\no{f}=\n \\no{Q_{n-1-i,g} Q_{n-1-i,X} \\frac{1}{[i]_q!} (\\partial_{q,X})^i f}\n \\qquad\\forall i\\ge 1\\\\\n\\partial_0\\no{f}=\n \\no{Q_{n-1,g} Q_{n-1,X} f - f}\n\\end{gather*}\nfor $f\\in \\k(q)[X,g,g^{-1}]$ with normal ordering\n$\\k(q)[X,g,g^{-1}]\\to \\ensuremath{C_q(B_+)}$ given by \\mbox{$g^n X^m\\mapsto g^n X^m$}.\n\n(c) Finite dimensional $\\Gamma$ and $L$ decompose into direct sums of\ncoirreducible respectively irreducible ones.\nIn particular $\\Gamma=\\oplus_{n\\in I}\\Gamma^n$ and\n$L=\\oplus_{n\\in I}L^n$ with $\\Gamma^n$ and $L^n$ corresponding to $\\{n\\}$.\n\\end{thm}\n\\begin{proof}\n(a) We observe that the classifications of lemma\n\\ref{lem:cqbp_class} and lemma \\ref{lem:uqbp_class} or\ncorollary \\ref{cor:cqbp_eclass} and corollary \\ref{cor:uqbp_eclass}\nare dual to each other in the finite (co){}dimensional case. More\nprecisely, for $I\\subset\\mathbb{N}$ finite the crossed submodule $M$\ncorresponding to $(1,I)$ in lemma \\ref{lem:cqbp_class} is the\nannihilator of the crossed\nsubmodule $L$ corresponding to $I$ in lemma \\ref{lem:uqbp_class} \nand vice versa.\n$\\ensuremath{C_q(B_+)}/M$ and $L$ are dual spaces with the induced pairing.\nFor $I\\subset\\mathbb{N}\\setminus\\{1\\}$ finite this descends to \n$M$ corresponding to $(1,I\\cup\\{1\\})$ in corollary\n\\ref{cor:cqbp_eclass} and $L$ corresponding to $I$ in corollary\n\\ref{cor:uqbp_eclass}.\nFor the dimension of $\\Gamma$ observe\n$\\dim\\Gamma=\\dim{\\ker\\cou/M}=\\codim M$.\n\n(b) Coirreducibility (having no proper quotient) of $\\Gamma$\nclearly corresponds to maximality of $M$. The statement then follows\nfrom parts (b) of corollaries\n\\ref{cor:cqbp_eclass} and \\ref{cor:uqbp_eclass}. The formulas are\nobtained by choosing the basis $\\eta_0,\\dots,\\eta_{n-1}$ of\n$\\ker\\cou/M$ as the equivalence classes of \n\\[(g-1)/(q^{n-1}-1),X,\\dots,X^{n-1}\\]\nThe dual basis of $L$ is then given by\n\\[g^{1-n}-1, X g^{1-n},\\dots, q^{k(k-1)} \\frac{1}{[k]_q!} X^k g^{1-n},\n\\dots,q^{(n-1)(n-2)} \\frac{1}{[n-1]_q!} X^{n-1} g^{1-n}\\]\n\n(c) The statement follows from corollaries \\ref{cor:cqbp_eclass} and \n\\ref{cor:uqbp_eclass} parts (c) with the observation\n\\[\\ker\\cou/M=\\ker\\cou/{\\bigcap_{n\\in I}}M^n\n=\\oplus_{n\\in I}\\ker\\cou/M^n\\]\n\\end{proof}\n\n\\begin{cor}\nThere is precisely one differential calculus on \\ensuremath{C_q(B_+)}{} which is\nnatural in the sense that it\nhas dimension $2$.\nIt is coirreducible and obeys the relations\n\\begin{gather*}\n[g,\\diff X]=0\\qquad [g,\\diff g]_q=0\\qquad\n[X,\\diff X]_q=0\\qquad [X,\\diff g]_q=(q-1)({\\diff X}) g\n\\end{gather*}\nwith $[a,b]_q:=ab-qba$. In particular we have\n\\begin{gather*}\n\\diff\\no{f} = {\\diff g} \\no{\\partial_{q,g} f} + {\\diff X}\n\\no{\\partial_{q,X} f}\\qquad\\forall f\\in \\k(q)[X,g,g^{-1}]\n\\end{gather*}\n\\end{cor}\n\\begin{proof}\nThis is a special case of theorem \\ref{thm:q_calc}.\nThe formulas follow from (b) with $n=2$.\n\\end{proof}\n\n\n\n\\section{Classification in the Classical Limit}\n\\label{sec:class}\n\nIn this section we give the complete classification of differential\ncalculi and quantum tangent spaces in the classical case of \\ensuremath{C(B_+)}{}\nalong the lines of the previous section.\nWe pay particular\nattention to the relation to the $q$-deformed setting.\n\n\nThe classical limit \\ensuremath{C(B_+)}{} of the quantum group \\ensuremath{C_q(B_+)}{} is\nsimply obtained by substituting the parameter $q$ with $1$.\nThe\nclassification of left crossed submodules in part (a) of lemma\n\\ref{lem:cqbp_class} remains\nunchanged, as one may check by going through the proof.\nIn particular, we get a correspondence of crossed modules in the\n$q$-deformed setting with crossed modules in the\nclassical setting\nas a map of \npairs $(P,I)\\mapsto (P,I)$\nthat converts polynomials $\\k(q)[g]$ to polynomials $\\k[g]$ (if\ndefined) and leaves\nsets $I$ unchanged. This is one-to-one in the finite\ndimensional case.\nHowever, we did use the distinctness of powers of $q$ in part (b) and\n(c) of lemma\n$\\ref{lem:cqbp_class}$ and have to account for changing this. The\nonly place where we used it, was in observing that\nfactors $1-q^j g $ have no common divisors for distinct $j$. This was\ncrucial to conclude the maximality (b) of certain finite codimensional\ncrossed submodules and the intersection property (c).\nNow, all those factors become $1-g$.\n\n\\begin{cor}\n\\label{cor:cbp_class}\n(a) Left crossed \\ensuremath{C(B_+)}-submodules $M\\subseteq\\ensuremath{C(B_+)}$ by left\nmultiplication and left\nadjoint coaction are in one-to-one correspondence to\npairs $(P,I)$\nwhere $P\\in\\k[g]$ is a polynomial with $P(0)=1$ and $I\\subset\\mathbb{N}$ is\nfinite.\n$\\codim M<\\infty$ iff $P=1$. In particular $\\codim M=\\sum_{n\\in I}n$\nif $P=1$.\n\n(b) The infinite codimensional maximal $M$ are characterised by\n$(P,\\emptyset)$ with $P$ irreducible and $P(g)\\neq 1-g$ for any\n$k\\in\\mathbb{N}_0$.\n\\end{cor}\n\nIn the restriction to $\\ker\\cou\\subset\\ensuremath{C(B_+)}$ corresponding to corollary\n\\ref{cor:cqbp_eclass} we observe another difference to the\n$q$-deformed setting.\nSince the condition for a crossed submodule to lie in $\\ker\\cou$ is exactly\nto have factors $1-g$ in the $X$-free monomials this condition may now\nbe satisfied more easily. If the characterising polynomial does not\ncontain this factor it is now sufficient to have just any non-empty\ncharacterising integer set $I$ and it need not contain $1$. Consequently,\nthe map $(P,I)\\mapsto (P,I)$ does not reach all crossed submodules now.\n\n\\begin{cor}\n\\label{cor:cbp_eclass}\n(a) Left crossed \\ensuremath{C(B_+)}-submodules $M\\subseteq\\ker\\cou\\subset\\ensuremath{C(B_+)}$\nare in one-to-one correspondence to pairs\n$(P,I)$ as in corollary \\ref{cor:cbp_class}\nwith the additional constraint $(1-g)$ divides $P(g)$ or $I$ non-empty.\n$\\codim M<\\infty$ iff $P=1$. In particular $\\codim M=(\\sum_{n\\in I}n)-1$\nif $P=1$.\n\n(b) The infinite codimensional maximal $M$ correspond to pairs\n$(P,\\{1\\})$ with $P$ irreducible and $P(g)\\neq 1-g$.\n\\end{cor}\n\n\nLet us now turn to quantum tangent spaces on \\ensuremath{U(\\lalg{b_+})}{}. Here, the process\nto go from the $q$-deformed setting to the classical one is not quite\nso straightforward.\n\n\\begin{lem}\n\\label{lem:ubp_class}\nProper left crossed \\ensuremath{U(\\lalg{b_+})}-submodules $L\\subset\\ensuremath{U(\\lalg{b_+})}$ via the left\nadjoint action\nand left regular coaction are\nin one-to-one correspondence to pairs $(l,I)$ with $l\\in\\mathbb{N}_0$ and\n$I\\subset\\mathbb{N}$ finite. $\\dim L<\\infty$ iff $l=0$. In particular $\\dim\nL=\\sum_{n\\in I}n$ if $l=0$.\n\\end{lem}\n\\begin{proof}\nThe left adjoint action takes the form\n\\[\nX\\triangleright X^n H^m = X^{n+1}(H^m-(H+1)^m) \\qquad\nH\\triangleright X^n H^m = n X^n H^m\n\\]\nwhile the coaction is\n\\[\n\\cop(X^n H^m) = \\sum_{i=1}^n \\sum_{j=1}^m \\binom{n}{i} \\binom{m}{j}\nX^i H^j\\otimes X^{n-1} H^{m-j}\n\\]\nLet $L$ be a crossed submodule invariant under the action and coaction.\nThe (repeated) action of $H$ separates elements by degree in $X$. It is\ntherefore sufficient to consider elements of the form $X^n P(H)$, where\n$P$ is a polynomial.\nBy acting with $X$ on an element $X^n P(H)$ we obtain\n$X^{n+1}(P(H)-P(H+1))$. Subsequently applying the coaction and\nprojecting on the left hand side of the tensor product onto $X$ (in\nthe basis $X^i H^j$ of \\ensuremath{U(\\lalg{b_+})})\nleads to the element $X^n (P(H)-P(H+1))$. Now the degree of\n$P(H)-P(H+1)$ is exactly the degree of $P(H)$ minus $1$. Thus we have\npolynomials $X^n P_i(H)$ of any degree $i=\\deg(P_i)\\le \\deg(P)$ in $L$\nby induction. In particular, $X^n H^m\\in L$ for all\n$m\\le\\deg(P)$. It is thus sufficient to consider elements of\nthe form $X^n H^m$. Given such an element, the coaction generates all\nelements of the form $X^i H^j$ with $i\\le n, j\\le m$.\n\nFor given $n$, the characterising datum is the maximal $m$ so\nthat $X^n H^m\\in L$. Due to the coaction this cannot decrease\nwith decreasing $n$ and due to the action of $X$ this can decrease at\nmost by $1$ when increasing $n$ by $1$. This leads to the\nclassification given. For $l\\in N_0$ and $I\\subset\\mathbb{N}$ finite, the\ncorresponding crossed submodule\nis generated by\n\\begin{gather*}\nX^{n_m-1} H^{l+m-1}, X^{n_m+n_{m-1}-1} H^{l+m-2},\\dots,\nX^{(\\sum_i n_i)-1} H^{l}\\\\\n\\text{and}\\qquad\nX^{(\\sum_i n_i)+k} H^{l-1}\\quad \\forall k\\ge 0\\quad\\text{if}\\quad l>0\n\\end{gather*}\nas a crossed module.\n\\end{proof}\n\nFor the transition from the $q$-deformed (lemma\n\\ref{lem:uqbp_class}) to the classical case we\nobserve that the space spanned by $g^{s_1},\\dots,g^{s_m}$ with $m$\ndifferent integers $s_i\\in\\mathbb{Z}$ maps to the space spanned by\n$1, H, \\dots, H^{m-1}$ in the\nprescription of the classical limit (as described in section\n\\ref{sec:intro_limits}). I.e.\\ the classical crossed submodule\ncharacterised by an integer $l$ and a finite set $I\\subset\\mathbb{N}$ comes\nfrom a crossed submodule characterised by this same $I$ and additionally $l$\nother integers $j\\in\\mathbb{Z}$ for which $X^k g^{1-j}$ is included. In\nparticular, we have a one-to-one correspondence in the finite\ndimensional case.\n\nTo formulate the analogue of corollary \\ref{cor:uqbp_eclass} for the\nclassical case is essentially straightforward now. However, as for\n\\ensuremath{C(B_+)}{}, we obtain more crossed submodules than those from the $q$-deformed\nsetting. This is due to the degeneracy introduced by forgetting the\npowers of $g$ and just retaining the number of different powers. \n\n\\begin{cor}\n\\label{cor:ubp_eclass}\n(a) Proper left crossed \\ensuremath{U(\\lalg{b_+})}-submodules\n$L\\subset\\ker\\cou\\subset\\ensuremath{U(\\lalg{b_+})}$ via the\nleft adjoint\naction and left regular coaction (with subsequent projection to\n$\\ker\\cou$ via $x\\mapsto x-\\cou(x)1$) are in one-to-one correspondence to\npairs $(l,I)$ with $l\\in\\mathbb{N}_0$ and $I\\subset\\mathbb{N}$ finite where $l\\neq 0$\nor $I\\neq\\emptyset$.\n$\\dim L<\\infty$ iff $l=0$. In particular $\\dim\nL=(\\sum_{n\\in I}n)-1$ if $l=0$.\n\\end{cor}\n\n\nAs in the $q$-deformed setting, we give a description of the finite\ndimensional differential calculi where we have a strict duality to\nquantum tangent spaces.\n\n\\begin{prop}\n(a) Finite dimensional differential calculi $\\Gamma$ on \\ensuremath{C(B_+)}{} and\nfinite dimensional quantum tangent spaces $L$ on \\ensuremath{U(\\lalg{b_+})}{} are\nin one-to-one correspondence to non-empty finite sets $I\\subset\\mathbb{N}$.\nIn particular $\\dim\\Gamma=\\dim L=(\\sum_{n\\in I}) n)-1$.\n\nThe $\\Gamma$ with $1\\in\\mathbb{N}$ are in\none-to-one correspondence to the finite dimensional\ncalculi and quantum tangent spaces of the $q$-deformed setting\n(theorem \\ref{thm:q_calc}(a)).\n\n(b) The differential calculus $\\Gamma$ of dimension $n\\ge 2$\ncorresponding to the\ncoirreducible one of \\ensuremath{C_q(B_+)}{} (theorem \\ref{thm:q_calc}(b)) has a right\ninvariant\nbasis $\\eta_0,\\dots,\\eta_{n-1}$ so that\n\\begin{gather*}\n\\diff X=\\eta_1+\\eta_0 X \\qquad\n \\diff g=\\eta_0 g\\\\\n[g, \\eta_i]=0\\ \\forall i \\qquad\n[X, \\eta_i]=\\begin{cases}\n 0 &amp; \\text{if}\\ i=0\\ \\text{or}\\ i=n-1\\\\\n \\eta_{i+1} &amp; \\text{if}\\ 0<i<n-1\n \\end{cases}\n\\end{gather*}\nhold. The braided derivations obtained from the dual basis of the\ncorresponding $L$ are\ngiven by\n\\begin{gather*}\n\\partial_i f=\\frac{1}{i!}\n \\left(\\frac{\\partial}{\\partial X}\\right)^i f\\qquad\n \\forall i\\ge 1\\\\\n\\partial_0 f=\\left(X \\frac{\\partial}{X}+\n g \\frac{\\partial}{g}\\right) f\n\\end{gather*}\nfor $f\\in\\ensuremath{C(B_+)}$.\n\n(c) The differential calculus of dimension $n-1$ \ncorresponding to the\none in (b) with $1$ removed from the characterising set is\nthe same as the one above, except that we set $\\eta_0=0$ and\n$\\partial_0=0$.\n\\end{prop}\n\\begin{proof}\n(a) We observe that the classifications of corollary\n\\ref{cor:cbp_class} and lemma \\ref{lem:ubp_class} or\ncorollary \\ref{cor:cbp_eclass} and corollary \\ref{cor:ubp_eclass}\nare dual to each other in the finite (co)dimensional case.\nMore\nprecisely, for $I\\subset\\mathbb{N}$ finite the crossed submodule $M$\ncorresponding to $(1,I)$ in corollary \\ref{cor:cbp_class} is the\nannihilator of the crossed\nsubmodule $L$ corresponding to $(0,I)$ in lemma \\ref{lem:ubp_class} \nand vice versa.\n$\\ensuremath{C(B_+)}/M$ and $L$ are dual spaces with the induced pairing.\nFor non-empty $I$ this descends to \n$M$ corresponding to $(1,I)$ in corollary\n\\ref{cor:cbp_eclass} and $L$ corresponding to $(0,I)$ in corollary\n\\ref{cor:ubp_eclass}.\nFor the dimension of $\\Gamma$ note\n$\\dim\\Gamma=\\dim{\\ker\\cou/M}=\\codim M$.\n\n(b) For $I=\\{1,n\\}$ we choose in\n$\\ker\\cou\\subset\\ensuremath{C(B_+)}$ the basis $\\eta_0,\\dots,\\eta_{n-1}$ as the\nequivalence classes of\n$g-1,X,\\dots,X^{n-1}$. The dual basis in $L$\nis then $H,X,\\dots,\\frac{1}{k!}X^k,\\dots,\\frac{1}{(n-1)!}X^{n-1}$.\nThis leads to the\nformulas given.\n\n(c) For $I=\\{n\\}$ we get the same as in (b) except that $\\eta_0$ and\n$\\partial_0$ disappear.\n\\end{proof}\n\nThe classical commutative calculus is the special case of (b) with\n$n=2$. It is the only calculus of dimension $2$ with\n$\\diff g\\neq 0$. Note that it is not coirreducible.\n\n\n\n\n\\section{The Dual Classical Limit}\n\\label{sec:dual}\n\nWe proceed in this section to the more interesting point of view where\nwe consider the classical algebras, but with their roles\ninterchanged. I.e.\\ we view \\ensuremath{U(\\lalg{b_+})}{} as the ``function algebra''\nand \\ensuremath{C(B_+)}{} as the ``enveloping algebra''. Due to the self-duality of\n\\ensuremath{U_q(\\lalg{b_+})}{}, we can again view the differential calculi and quantum tangent\nspaces as classical limits of the $q$-deformed setting investigated in\nsection \\ref{sec:q}.\n\nIn this dual setting the bicovariance constraint for differential\ncalculi becomes much\nweaker. In particular, the adjoint action on a classical function\nalgebra is trivial due to commutativity and the adjoint coaction on a\nclassical enveloping algebra is trivial due to cocommutativity.\nIn effect, the correspondence with the\n$q$-deformed setting is much weaker than in the ordinary case of\nsection \\ref{sec:class}.\nThere are much more differential\ncalculi and quantum tangent spaces than in the $q$-deformed setting.\n\nWe will not attempt to classify all of them in the following but\nessentially \ncontend ourselves with those objects coming from the $q$-deformed setting.\n\n\\begin{lem}\n\\label{lem:cbp_dual}\nLeft \\ensuremath{C(B_+)}-subcomodules $\\subseteq\\ensuremath{C(B_+)}$ via the left regular coaction are\n$\\mathbb{Z}$-graded subspaces of \\ensuremath{C(B_+)}{} with $|X^n g^m|=n+m$,\nstable under formal derivation in $X$.\n\nBy choosing any ordering in \\ensuremath{C_q(B_+)}{}, left crossed submodules via left\nregular action and adjoint coaction are in one-to-one correspondence\nto certain subcomodules of \\ensuremath{C(B_+)}{} by setting $q=1$. Direct sums\ncorrespond to direct sums.\n\nThis descends to $\\ker\\cou\\subset\\ensuremath{C(B_+)}$ by the projection $x\\mapsto\nx-\\cou(x) 1$.\n\\end{lem}\n\\begin{proof}\nThe coproduct on \\ensuremath{C(B_+)}{} is\n\\[\\cop(X^n g^k)=\\sum_{r=0}^{n} \\binom{n}{r}\n X^{n-r} g^{k+r}\\otimes X^r g^k\\]\nwhich we view as a left coaction.\nProjecting on the left hand side of the tensor product onto $g^l$ in a\nbasis $X^n g^k$, we\nobserve that coacting on an element\n$\\sum_{n,k} a_{n,k} X^n g^k$ we obtain elements\n$\\sum_n a_{n,l-n} X^n g^{l-n}$ for all $l$.\nI.e.\\ elements of the form\n$\\sum_n b_n X^n g^{l-n}$ lie\nseparately in a subcomodule and it is\nsufficient to consider such elements. Writing the coaction\non such an element as\n\\[\\sum_t \\frac{1}{t!} X^t g^{l-t}\\otimes \\sum_n b_n\n \\frac{n!}{(n-t)!} X^{n-t} g^{l-n}\\]\nwe see that the coaction generates all formal derivatives in $X$\nof this element. This gives us the classification: \\ensuremath{C(B_+)}-subcomodules\n$\\subseteq\\ensuremath{C(B_+)}$ under the left regular coaction are $\\mathbb{Z}$-graded\nsubspaces with $|X^n g^m|=n+m$, stable under formal derivation in\n$X$ given by $X^n\ng^m \\mapsto n X^{n-1} g^m$.\n\nThe correspondence with the \\ensuremath{C_q(B_+)} case follows from\nthe trivial observation\nthat the coproduct of \\ensuremath{C(B_+)}{} is the same as that of \\ensuremath{C_q(B_+)}{} with $q=1$.\n\nThe restriction to $\\ker\\cou$ is straightforward.\n\\end{proof}\n\n\n\n\\begin{lem}\n\\label{lem:ubp_dual}\nThe process of obtaining the classical limit \\ensuremath{U(\\lalg{b_+})}{} from \\ensuremath{U_q(\\lalg{b_+})}{} is\nwell defined for subspaces and sends crossed \\ensuremath{U_q(\\lalg{b_+})}-submodules\n$\\subset\\ensuremath{U_q(\\lalg{b_+})}$ by\nregular action and adjoint coaction to \\ensuremath{U(\\lalg{b_+})}-submodules $\\subset\\ensuremath{U(\\lalg{b_+})}$\nby regular\naction. This map is injective in the finite codimensional\ncase. Intersections and codimensions are preserved in this case.\n\nThis descends to $\\ker\\cou$.\n\\end{lem}\n\\begin{proof}\nTo obtain the classical limit of a left ideal it is enough to\napply the limiting process (as described in section\n\\ref{sec:intro_limits}) to the\nmodule generators (We can forget the additional comodule\nstructure). On the one hand,\nany element generated by left multiplication with polynomials in\n$g$ corresponds to some element generated by left multiplication with a\npolynomial in $H$, that is, there will be no more generators in the\nclassical setting. On the other hand, left multiplication by a\npolynomial in $H$ comes\nfrom left multiplication by the same polynomial in $g-1$, that is,\nthere will be no fewer generators.\n\nThe maximal left crossed \\ensuremath{U_q(\\lalg{b_+})}-submodule $\\subseteq\\ensuremath{U_q(\\lalg{b_+})}$\nby left multiplication and adjoint coaction of\ncodimension $n$ ($n\\ge 1$) is generated as a left ideal by\n$\\{1-q^{1-n}g,X^n\\}$ (see lemma\n\\ref{lem:cqbp_class}). Applying the limiting process to this\nleads to the\nleft ideal of \\ensuremath{U(\\lalg{b_+})}{} (which is not maximal for $n\\neq 1$) generated by\n$\\{H+n-1,X^n\\}$ having also codimension $n$.\n\nMore generally, the picture given for arbitrary finite codimensional left\ncrossed modules of \\ensuremath{U_q(\\lalg{b_+})}{} in terms of generators with respect to\npolynomials in $g,g^{-1}$ in lemma \\ref{lem:cqbp_class} carries over\nby replacing factors\n$1-q^{1-n}g$ with factors $H+n-1$ leading to generators with\nrespect to polynomials in $H$. In particular,\nintersections go to intersections since the distinctness of\nthe factors for different $n$ is conserved.\n\nThe restriction to $\\ker\\cou$ is straightforward.\n\\end{proof}\n\n\nWe are now in a position to give a detailed description of the\ndifferential calculi induced from the $q$-deformed setting by the\nlimiting process.\n\n\\begin{prop}\n(a) Certain finite dimensional\ndifferential calculi $\\Gamma$ on \\ensuremath{U(\\lalg{b_+})}{} and quantum tangent spaces $L$\non \\ensuremath{C(B_+)}{}\nare in one-to-one correspondence to finite dimensional differential\ncalculi on \\ensuremath{U_q(\\lalg{b_+})}{} and quantum\ntangent spaces on \\ensuremath{C_q(B_+)}{}. Intersections correspond to intersections.\n\n(b) In particular,\n$\\Gamma$ and $L$ corresponding to coirreducible differential calculi\non \\ensuremath{U_q(\\lalg{b_+})}{} and\nirreducible quantum tangent spaces on \\ensuremath{C_q(B_+)}{} via the limiting process\nare given as follows:\n$\\Gamma$ has a right invariant basis\n$\\eta_0,\\dots,\\eta_{n-1}$ so that\n\\begin{gather*}\n\\diff X=\\eta_1 \\qquad \\diff H=(1-n)\\eta_0 \\\\\n[H, \\eta_i]=(1-n+i)\\eta_i\\quad\\forall i\\qquad\n[X, \\eta_i]=\\begin{cases}\n \\eta_{i+1} &amp; \\text{if}\\ \\ i<n-1\\\\\n 0 &amp; \\text{if}\\ \\ i=n-1\n\\end{cases}\n\\end{gather*}\nholds. The braided derivations corresponding to the dual basis of\n$L$ are given by\n\\begin{gather*}\n\\partial_i\\no{f}=\\no{T_{1-n+i,H}\n \\frac{1}{i!}\\left(\\frac{\\partial}{\\partial X}\\right)^i f}\n \\qquad\\forall i\\ge 1\\\\\n\\partial_0\\no{f}=\\no{T_{1-n,H} f - f}\n\\end{gather*}\nfor $f\\in\\k[X,H]$\nwith the normal ordering $\\k[X,H]\\to \\ensuremath{U(\\lalg{b_+})}$ via $H^n X^m\\mapsto H^n X^m$.\n\\end{prop}\n\\begin{proof}\n(a) The strict duality between \\ensuremath{C(B_+)}-subcomodules $L\\subseteq\\ker\\cou$\ngiven by lemma \\ref{lem:cbp_dual} and corollary \\ref{cor:uqbp_eclass}\nand \\ensuremath{U(\\lalg{b_+})}-modules $\\ensuremath{U(\\lalg{b_+})}/(\\k 1+M)$ with $M$ given by lemma\n\\ref{lem:ubp_dual} and\ncorollary \\ref{cor:cqbp_eclass} can be checked explicitly.\nIt is essentially due to mutual annihilation of factors $H+k$ in\n\\ensuremath{U(\\lalg{b_+})}{} with elements $g^k$ in \\ensuremath{C(B_+)}{}.\n\n(b) $L$ is generated by\n$\\{g^{1-n}-1,Xg^{1-n},\\dots,\nX^{n-1}g^{1-n}\\}$ and\n$M$ is generated by $\\{H(H+n-1),X(H+n-1),X^n \\}$.\nThe formulas are obtained by denoting with\n$\\eta_0,\\dots,\\eta_{n-1}$ the equivalence classes of\n$H/(1-n),X,\\dots,X^{n-1}$ in $\\ensuremath{U(\\lalg{b_+})}/(\\k 1+M)$.\nThe dual basis of $L$ is then\n\\[g^{1-n}-1,X g^{1-n},\n\\dots,\\frac{1}{(n-1)!}X^{n-1}\ng^{1-n}\\]\n\\end{proof}\n\n\nIn contrast to the $q$-deformed setting and to the usual classical\nsetting the many freedoms in choosing a calculus leave us with many\n$2$-dimensional calculi. It is not obvious which one we should\nconsider to be the ``natural'' one. Let us first look at the\n$2$-dimensional calculus coming from the $q$-deformed\nsetting as described in (b). The relations become\n\\begin{gather*}\n[\\diff H, a]=\\diff a\\qquad [\\diff X, a]=0\\qquad\\forall a\\in\\ensuremath{U(\\lalg{b_+})}\\\\\n\\diff\\no{f} =\\diff H \\no{\\fdiff_{1,H} f} \n + \\diff X \\no{\\frac{\\partial}{\\partial X} f}\n\\end{gather*}\nfor $f\\in\\k[X,H]$.\n\nWe might want to consider calculi which are closer to the classical\ntheory in the sense that derivatives are not finite differences but\nusual derivatives. Let us therefore demand\n\\[\\diff P(H)=\\diff H \\frac{\\partial}{\\partial H} P(H)\\qquad\n\\text{and}\\qquad\n\\diff P(X)=\\diff X \\frac{\\partial}{\\partial X} P(X)\\]\nfor polynomials $P$ and ${\\diff X}\\neq 0$ and ${\\diff H}\\neq 0$.\n\n\\begin{prop}\n\\label{prop:nat_bp}\nThere is precisely one differential calculus of dimension $2$ meeting\nthese conditions. It obeys the relations\n\\begin{gather*}\n[a,\\diff H]=0\\qquad [X,\\diff X]=0\\qquad [H,\\diff X]=\\diff X\\\\\n\\diff \\no{f} =\\diff H \\no{\\frac{\\partial}{\\partial H} f}\n +\\diff X \\no{\\frac{\\partial}{\\partial X} f}\n\\end{gather*}\nwhere the normal ordering $\\k[X,H]\\to \\ensuremath{U(\\lalg{b_+})}$ is given by\n$X^n H^m\\mapsto X^n H^m$.\n\\end{prop}\n\\begin{proof}\nLet $M$ be the left ideal corresponding to the calculus. It is easy to\nsee that for a primitive element $a$ the classical derivation condition\ncorresponds to $a^2\\in M$ and $a\\notin M$. In our case $X^2,H^2\\in\nM$. If we take the\nideal generated from these two elements we obtain an ideal of\n$\\ker\\cou$ of codimension $3$. Now, it is sufficient without loss of\ngenerality to add a generator of the form $\\alpha H+\\beta X+\\gamma\nXH$. $\\alpha$ and $\\beta$ must then be zero in order not\nto generate $X$ or $H$ in $M$.\nI.e.\\ $M$ is generated by $H^2,\nXH, X^2$. The relations stated follow.\n\\end{proof}\n\n\n\n\\section{Remarks on $\\kappa$-Minkowski Space and Integration}\n\\label{sec:kappa}\n\nThere is a straightforward generalisation of \\ensuremath{U(\\lalg{b_+})}.\nLet us define the Lie algebra $\\lalg b_{n+}$ as generated by\n$x_0,\\dots, x_{n-1}$ with relations\n\\[ [x_0,x_i]=x_i\\qquad [x_i,x_j]=0\\qquad\\forall i,j\\ge 1\\]\nIts enveloping algebra \\ensuremath{U(\\lalg{b}_{n+})}{} is nothing but (rescaled) $\\kappa$-Minkowski\nspace as introduced in \\cite{MaRu}. In this section we make some\nremarks about its intrinsic geometry.\n\nWe have an injective Lie algebra\nhomomorphism $b_{n+}\\to b_+$ given by\n$x_0\\mapsto H$ and $x_i\\mapsto X$.\nThis is an isomorphism for $n=2$. The injective Lie algebra\nhomomorphism extends to an injective homomorphism of enveloping\nalgebras $\\ensuremath{U(\\lalg{b_+})}\\to \\ensuremath{U(\\lalg{b}_{n+})}$ in the obvious way. This gives rise\nto an injective map from the set of submodules of \\ensuremath{U(\\lalg{b_+})}{} to the set of\nsubmodules of \\ensuremath{U(\\lalg{b}_{n+})}{} by taking the pre-image. In\nparticular this induces an injective\nmap from the set of differential calculi on \\ensuremath{U(\\lalg{b_+})}{} to the set of\ndifferential calculi on \\ensuremath{U(\\lalg{b}_{n+})}{} which are invariant under permutations\nof the $x_i\\ i\\ge 1$.\n\n\\begin{cor}\n\\label{cor:nat_bnp}\nThere is a natural $n$-dimensional differential calculus on \\ensuremath{U(\\lalg{b}_{n+})}{}\ninduced from the one considered in proposition\n\\ref{prop:nat_bp}.\nIt obeys the relations\n\\begin{gather*}\n[a,\\diff x_0]=0\\quad\\forall a\\in \\ensuremath{U(\\lalg{b}_{n+})}\\qquad [x_i,\\diff x_j]=0\n \\quad [x_0,\\diff x_i]=\\diff x_i\\qquad\\forall i,j\\ge 1\\\\\n\\diff \\no{f} =\\sum_{\\mu=0}^{n-1}\\diff x_{\\mu}\n \\no{\\frac{\\partial}{\\partial x_{\\mu}} f}\n\\end{gather*}\nwhere the normal ordering is given by\n\\[\\k[x_0,\\dots,x_{n-1}]\\to \\ensuremath{U(\\lalg{b}_{n+})}\\quad\\text{via}\\quad\nx_{n-1}^{m_{n-1}}\\cdots\nx_0^{m_0}\\mapsto x_{n-1}^{m_{n-1}}\\cdots x_0^{m_0}\\]\n\\end{cor}\n\\begin{proof}\nThe calculus is obtained from the ideal generated by\n\\[x_0^2,x_i x_j, x_i x_0\\qquad\\forall i,j\\ge 1\\]\nbeing the pre-image of\n$X^2,XH,X^2$ in \\ensuremath{U(\\lalg{b_+})}{}.\n\\end{proof}\n\nLet us try to push the analogy with the commutative case further and\ntake a look at the notion of integration. The natural way to encode\nthe condition of translation invariance from the classical context\nin the quantum group context\nis given by the condition\n\\[(\\int\\otimes\\id)\\circ\\cop a=1 \\int a\\qquad\\forall a\\in A\\]\nwhich defines a right integral on a quantum group $A$\n\\cite{Sweedler}.\n(Correspondingly, we have the notion of a left integral.)\nLet us\nformulate a slightly\nweaker version of this equation\nin the context of a Hopf algebra $H$ dually paired with\n$A$. We write\n\\[\\int (h-\\cou(h))\\triangleright a = 0\\qquad \\forall h\\in H, a\\in A\\]\nwhere the action of $H$ on $A$ is the coregular action\n$h\\triangleright a = a_{(1)}\\langle a_{(2)}, h\\rangle$\ngiven by the pairing.\n\nIn the present context we set $A=\\ensuremath{U(\\lalg{b}_{n+})}$ and $H=\\ensuremath{C(B_{n+})}$. We define the\nlatter as a generalisation of \\ensuremath{C(B_+)}{} with commuting\ngenerators $g,p_1,\\dots,p_{n-1}$ and coproducts\n\\[\\cop p_i=p_i\\otimes 1+g\\otimes p_i\\qquad \\cop g=g\\otimes g\\]\nThis can be identified (upon rescaling) as the momentum sector of the\nfull $\\kappa$-Poincar\\'e algebra (with $g=e^{p_0}$).\nThe pairing is the natural extension of (\\ref{eq:pair_class}):\n\\[\\langle x_{n-1}^{m_{n-1}}\\cdots x_1^{m_1} x_0^{k},\n  p_{n-1}^{r_{n-1}}\\cdots p_1^{r_1} g^s\\rangle\n  = \\delta_{m_{n-1},r_{n-1}}\\cdots\\delta_{m_1,r_1} m_{n-1}!\\cdots m_1!\n  s^k\\]\nThe resulting coregular\naction is conveniently expressed as (see also \\cite{MaRu})\n\\[p_i\\triangleright\\no{f}=\\no{\\frac{\\partial}{\\partial x_i} f}\\qquad\n  g\\triangleright\\no{f}=\\no{T_{1,x_0} f}\\]\n  with $f\\in\\k[x_0,\\dots,x_{n-1}]$.\nDue to cocommutativity, the notions of left and right integral\ncoincide. The invariance conditions for integration become\n\\[\\int \\no{\\frac{\\partial}{\\partial x_i} f}=0\\quad\n\\forall i\\in\\{1,\\dots,n-1\\} \n\\qquad\\text{and}\\qquad \\int \\no{\\fdiff_{1,x_0} f}=0\\]\nThe condition on the left is familiar and states the invariance under\ninfinitesimal translations in the $x_i$. The condition on the right states the\ninvariance under integer translations in $x_0$. However, we should\nremember that we use a certain algebraic model of \\ensuremath{C(B_{n+})}{}. We might add,\nfor example, a generator $p_0$\nto \\ensuremath{C(B_{n+})}{}\nthat is dual to $x_0$ and behaves\nas the ``logarithm'' of $g$, i.e.\\ acts as an infinitesimal\ntranslation in $x_0$. We then have the condition of infinitesimal\ntranslation invariance\n\\[\\int \\no{\\frac{\\partial}{\\partial x_{\\mu}} f}=0\\]\nfor all $\\mu\\in\\{0,1,\\dots,{n-1}\\}$.\n\nIn the present purely algebraic context these conditions do not make\nmuch sense. In fact they would force the integral to be zero on the\nwhole algebra. This is not surprising, since we are dealing only with\npolynomial functions which would not be integrable in the classical\ncase either.\nIn contrast, if we had for example the algebra of smooth functions\nin two real variables, the conditions just characterise the usual\nLesbegue integral (up to normalisation).\nLet us assume $\\k=\\mathbb{R}$ and suppose that we have extended the normal\nordering vector\nspace isomorphism $\\mathbb{R}[x_0,\\dots,x_{n-1}]\\cong \\ensuremath{U(\\lalg{b}_{n+})}$ to a vector space\nisomorphism of some sufficiently large class of functions on $\\mathbb{R}^n$ with a\nsuitable completion $\\hat{U}(\\lalg{b_{n+}})$ in a functional\nanalytic framework (embedding \\ensuremath{U(\\lalg{b}_{n+})}{} in some operator algebra on a\nHilbert space). It is then natural to define the integration on\n$\\hat{U}(\\lalg{b_{n+}})$ by\n\\[\\int \\no{f}=\\int_{\\mathbb{R}^n} f\\ dx_0\\cdots dx_{n-1}\\]\nwhere the right hand side is just the usual Lesbegue integral in $n$\nreal variables $x_0,\\dots,x_{n-1}$. This\nintegral is unique (up to normalisation) in\nsatisfying the covariance condition since, as we have seen,\nthese correspond\njust to the usual translation invariance in the classical case via normal\nordering, for which the Lesbegue integral is the unique solution.\nIt is also the $q\\to 1$ limit of the translation invariant integral on\n\\ensuremath{U_q(\\lalg{b_+})}{} obtained in \\cite{Majid_qreg}.\n\nWe see that the natural differential calculus in corollary\n\\ref{cor:nat_bnp} is\ncompatible with this integration in that the appearing braided\nderivations are exactly the actions of the translation generators\n$p_{\\mu}$. However, we should stress that this calculus is not\ncovariant under the full $\\kappa$-Poincar\\'e algebra, since it was\nshown in \\cite{GoKoMa} that in $n=4$ there is no such\ncalculus of dimension $4$. Our results therefore indicate a new\nintrinsic approach to $\\kappa$-Minkowski space that allows a\nbicovariant\ndifferential calculus of dimension $4$ and a unique translation\ninvariant integral by normal ordering and Lesbegue integration.\n\n\n\n\\section*{Acknowledgements}\nI would like to thank S.~Majid for proposing this project,\nand for fruitful discussions during the preparation of this paper.\n\n\n&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;{'timestamp': '1998-07-19T14:33:52', 'yymm': '9807', 'arxiv_id': 'math/9807097', 'language': 'en', 'url': 'https://arxiv.org/abs/math/9807097'}&quot;}}},{&quot;rowIdx&quot;:2,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;\\section{Introduction}\n\nContinuous Engineering (CE) practices, \nsuch as Continuous Integration (CI) and Continuous Deployment (CD), \nare gaining prominence in software engineering, \nas they help streamline and optimize the way software is built, tested and shipped. \nThe most salient advantage of CE is the tighter feedback loops: \nCE practices help developers test and build their software more, \nand makes software releases less brittle by enabling more incremental releases.\n\nNevertheless, a frequently reported barrier for success is the need to effectively analyze\nthe data that results from the numerous build and test\nruns~\\cite{Laukkanen2017,Hilton2017,Shahin2017,Debbiche2014,Olsson2012}.\nOne evident example of this is the handling and\nanalysis of results from complex end-to-end integration tests \nwhich we focus on in this paper: \nCE practices make it easier to run such end-to-end tests, \nwhich include system integration and deployment to production hardware, \nand they are critical for ensuring the quality of the end product. \nHowever, since these end-to-end tests by their nature can fail for multiple\nreasons, not least in the sense that new product code can make the tests\nfail in new ways, it is critical to rapidly diagnose these failures.\n\nIn this paper we concern ourselves with how to rapidly analyze a set\nof logs resulting from complex CE tasks\\footnote{~For simplicity, and without loss of generality, \nwe will refer to these CE tasks as ``integration tests'' or ``tests'' throughout the paper, \nthough we acknowledge that they include more than just testing, \nsuch as building the system and deploying it on hardware in a test or staging environment, \nand failures can occur in any of these phases. \nThe proposed approach aims to cover all these situations, \nand is evaluated on real-life logs capturing everything from building the system, \nto deploying it on production hardware, \nand running complex integration and interaction scenarios.} \nwhere the overall outcome of the task (i.e. 'fail' or 'pass') is known, \nbut where analysts must consult the resulting logs to fully diagnose why the failures occurred. \nSince these logs can get large and unwieldy, we\ndevelop a tool that automatically suggests which segments in the logs\nare most likely relevant for troubleshooting purposes. \nOur method gives each event in the log an interestingness score based\non the overall event frequencies in the test result set: The log\nevents are in turn clustered based on these scores, and the event\nclusters are presented to the user in decreasing order of overall\ninterestingness. The goal is to enable users to find all relevant\ndiagnostic information in the first presented event cluster, while having the\noption of retrieving additional clusters if needed. An\nadditional benefit of our method is that the extracted events can help\nidentify commonly occurring patterns that are symptomatic for specific\nerrors. Future logs that exhibit the same characteristics can then be\nautomatically classified as having symptoms of that error.\n\n\\head{Contributions} We present Spectrum-Based Log Diagnosis (SBLD), a method for helping developers quickly find the\nmost relevant segments of a log. Using data from \\CiscoNorway{an\nindustrial partner}, we empirically evaluate SBLD by investigating the following\nthree questions:\n(i) How well does SBLD reduce the \\emph{effort needed} to identify all \\emph{failure-relevant events} in the log for a failing run?\n(ii) How is the \\emph{performance} of SBLD affected by \\emph{available data}?\n(iii) How does SBLD compare to searching for \\emph{simple textual patterns} that often occur in failure-relevant events?\n\n\\head{Overview} \nThe rest of the paper is structured as follows: Section~\\ref{sec:approach}\nexplains SBLD and the methodology underlying its event ranking\nprocedures. Sections~\\ref{sec:rqs} and~\\ref{sec:expdesign} motivates our research questions \nand empirical design. We report and discuss our results in\nSection~\\ref{sec:resdiscuss}. Section~\\ref{sec:relwork} surveys related work,\nand we discuss threats to validity in Section~\\ref{sec:ttv} before concluding \nin Section~\\ref{sec:conclusion}.\n %\n\n\\section{Approach}\n\\label{sec:approach}\n\n\\begin{figure}[b]\n        \\includegraphics[width=0.99\\columnwidth]{overview.pdf}\n        \t\\vspace*{-2ex}\n        \\caption{A visual overview of our approach.}\n        \\label{fig:approach}\n\\end{figure}\n\nSBLD takes a set of log files from test failures, a set of log files from test successes, and a singular log file from a test failure called the \\emph{target log} that the user wants analyzed and produces a list of segments  from the target log file that are likely relevant for understanding why the corresponding test run failed.\n\nIn the following we explain the workings of SBLD in a stepwise\nmanner. At each step, we present the technical background needed to\nunderstand how SBLD accomplishes its task. A visual overview of SBLD is\nshown in Figure \\ref{fig:approach}.\n\n\\head{Prerequisites}\nFirst of all, SBLD requires access to a set of log files from failing test runs and a set of log files from successful test runs.\nFor brevity, we will refer to log files from failing test runs as 'failing logs', \nand log files from successful test runs as 'passing logs'.%\n\\footnote{~Note that we explicitly assume that the outcome of each run is known; \n  This work is not concerned with determining whether the run was a failure or a success, \n  but rather with helping identify why the failing runs failed.} \nWe also require a programmatic way of segmenting each log file\ninto individually meaningful components. For the dataset used in this\npaper these components are \\emph{events} in the form of blocks of text\npreceded by a date and a time-stamp in a predictable format. Lastly,\nwe require that run-time specific information such as timestamps,\ndynamically generated IP addresses, check-sums and so on are removed\nfrom the logs and replaced with standardized text. We refer to the process of\nenforcing these requirements and delineating the log into events as\nthe \\emph{abstraction} step. This enables SBLD to treat events\nlike ``2019-04-05 19:19:22.441 CEST: Alice calls Bob'' and ``2019-04-07\n13:12:11.337 CEST: Alice calls Bob'' as two instances of the same\ngeneric event \&quot;Alice calls Bob\&quot;. The appropriate degree of abstraction\nand how to meaningfully delineate a log will be context-dependent\nand thus we require the user to perform these steps before using SBLD. \nIn the current paper we use an abstraction mechanism\nand dataset generously provided by \\CiscoNorway{our industrial partner}.\n\n\\renewcommand{\\Ncf}{\\ensuremath{\\text{N}_\\text{FI}}} %\n\\renewcommand{\\Nuf}{\\ensuremath{\\text{N}_\\text{FE}}} %\n\\renewcommand{\\Ncs}{\\ensuremath{\\text{N}_\\text{PI}}} %\n\\renewcommand{\\Nus}{\\ensuremath{\\text{N}_\\text{PE}}} %\n\n\\head{Computing coverage and event relevance} SBLD requires an assumption about what makes an event \\emph{relevant}\nand a method for computing this relevance. Our method takes inspiration\nfrom Spectrum-Based Fault Localization (SBFL) in which the suspiciousness \nor fault-proneness of a program statement is treated as a function of \nthe number of times the statement was activated in a failing test case, \ncombined with the number of times it is skipped in a passing test case~\\cite{Jones2002,Abreu2007,Abreu2009}. \nThe four primitives that need to be computed are shown on the right-hand side in Table~\\ref{table:measures}. \nWe treat each abstracted event as a statement and study their occurrences\nin the logs like Fault Localization tracks the activation of statements in test cases. \nWe compute the analysis primitives by devising a binary\n\\emph{coverage matrix} whose columns represent every unique event\nobserved in the set of failing and successful logs while each row $r$\nrepresents a log and tracks whether the event at column $c$ occurred in\nlog $r$ (1), or not (0), as shown in Figure~\\ref{fig:approach}.\n\nBy computing these primitives, we can rank each event by using an\n\\emph{interestingness measure} (also referred to as ranking\nmetric, heuristic, or similarity coefficient~\\cite{Wong2016}). \nThe choice of interestingness measure\nis ultimately left to the user, as these are context dependent and \nthere is no generally optimal choice of interestingness measure~\\cite{Yoo2014}. \nIn this paper we consider a\nselection of nine interestingness measures prominent in the literature\nand a simple metric that emphasizes the events that exclusively occur\nin failing logs in the spirit of the \\emph{union model} discussed\nby Renieres et al.~\\cite{renieres2003:fault}. We\nreport on the median performance of these interestingness measures with the intention of providing a\nrepresentative, yet unbiased, result. The ten measures considered are\nprecisely defined in Table~\\ref{table:measures}.\n\n\\begin{table*}\n\\centering\n\\begin{tabular}{c@{\\hspace{10mm}}c}\n{\\renewcommand{\\arraystretch}{1.7} %\n\\begin{tabular}{lc}\n\\toprule\nmeasure\t &amp; formula \\\\\\midrule\n\nTarantula \\cite{Jones2001,Jones2002} &amp; %\n\n\\( \\frac{ \\frac{ \\cef{} }{ \\cef{} + \\cnf{} } }{ \\frac{ \\cef{} }{ \\cef{} + \\cnf{} } + \\frac{ \\cep{} }{ \\cep{} + \\cnp{} } } \\) \n\n\\\\\n\nJaccard \\cite{Jaccard1912,Chen2002} &amp; %\n\n\\( \\frac{ \\Ncf }{ \\Ncf + \\Nuf + \\Ncs } \\)\n\n\\\\\n\nOchiai \\cite{Ochiai1957,Abreu2006} &amp; %\n\n\\( \\frac{ \\Ncf }{ \\sqrt{ ( \\cef + \\cnf ) \\times ( \\cef + \\cep ) } } \\)\n\n\\\\\n\nOchiai2 \\cite{Ochiai1957, Naish2011} &amp; %\n\n\\( \\frac{ \\Aef \\times \\Anp }{ \\sqrt{ ( \\Aef + \\Aep ) \\times ( \\Anf + \\Anp ) \\times ( \\Aef + \\Anf) \\times ( \\Aep + \\Anp ) } } \\)\n\n\\\\\n\nZoltar \\cite{Gonzalez2007} &amp; %\n\n\\( \\frac{ \\Ncf }{ \\Ncf + \\Nuf + \\Ncs + \\frac { 10000 \\times \\Nuf \\times \\Ncs }{ \\Ncf } } \\)\n\n\\\\\n\nD$^\\star$ \\cite{Wong2014} (we use $\\star = 2$) &amp; %\n\n\\( \\frac{ (\\cef)^\\star }{ \\cnf + \\cep } \\)\n\n\\\\\n\nO$^p$ \\cite{Naish2011} &amp; %\n\n\\( \\Aef - \\frac{ \\Aep }{ \\Aep + \\Anp + 1} \\)\n\n\\\\\n\nWong3 \\cite{Wong2007,Wong2010} &amp;\n\n\\( \\Aef - h, \\text{where~} h = \\left\\{ \n\\scalebox{.8}{\\(\\renewcommand{\\arraystretch}{1} %\n\\begin{array}{@{}ll@{}}\n\\Aep &amp; \\text{if~} \\Aep \\leq 2 \\\\\n2 + 0.1(\\Aep - 2) &amp; \\text{if~} 2 < \\Aep \\leq 10 \\\\\n2.8 + 0.001(\\Aep - 10) &amp; \\text{if~} \\Aep > 10 \\\\\n\\end{array}\\)}\n\\right. \\)\n\n\\\\\n\nKulczynski2 \\cite{Kulczynski1927,Naish2011} &amp; %\n\n\\( \\frac{ 1 }{ 2 } \\times ( \\frac{ \\Aef }{ \\Aef + \\Anf } + \\frac{ \\Aef }{ \\Aef + \\Aep } ) \\)\n\n\\\\\n\nFailed only &amp; %\n\n\\( \\left\\{\\scalebox{.8}{\\(\\renewcommand{\\arraystretch}{1} %\n\\begin{array}{@{}ll@{}}\n1 &amp; \\text{if~} \\Ncs = 0 \\\\\n0 &amp; \\text{otherwise~}  \\\\\n\\end{array}\\)}\n\\right. \\)\n\n\\\\\n\\bottomrule\n\n\\end{tabular}} &amp;\n\\begin{tabular}{lp{2.99cm}}\n\\toprule\n\\multicolumn{2}{l}{notation used} \\\\\\midrule\n\\Ncf &amp; number of \\emph{failing} logs \\\\ &amp; that \\emph{include} the event \\\\\n\\Nuf &amp; number of \\emph{failing} logs \\\\ &amp; that \\emph{exclude} the event \\\\\n\\Ncs &amp; number of \\emph{passing} logs \\\\ &amp; that \\emph{include} the event \\\\\n\\Nus &amp; number of \\emph{passing} logs \\\\ &amp; that \\emph{exclude} the event \\\\\n\\bottomrule\n\\end{tabular}\n\\end{tabular}\\vspace*{1ex}\n\\caption{\\label{table:measures}The 10 interestingness measures under consideration in this paper.}\n\\vspace*{-3ex}\n\\end{table*}\n\n\\head{Analyzing a target log file} Using our database of event scores,\nwe first identify the events occurring in the target log file and the\ninterestingness scores associated with these events. Then, we group\nsimilarly scored events together using a clustering algorithm. Finally,\nwe present the best performing cluster of events to the end user. The\nclustering step helps us make a meaningful selection of events rather\nthan setting an often arbitrary window selection size. Among other\nthings, it prevents two identically scored events from falling at\nopposite sides of the selection threshold. If the user suspects that\nthe best performing cluster did not report all relevant events, she can\ninspect additional event clusters in order of decreasing\naggregate interestingness score.  To perform the clustering step we use Hierarchical Agglomerative\nClustering (HAC) with Complete linkage~\\cite{manning2008introduction}, where\nsub-clusters are merged until the maximal distance between members of\neach candidate cluster exceeds some specified threshold. In SBLD,\nthis threshold is the uncorrected sample standard deviation of the event\nscores for the events being clustered.\\footnote{~Specifically, \nwe use the \\texttt{numpy.std} procedure from the SciPy framework~\\cite{2020SciPy-NMeth},\nin which the uncorrected sample standard deviation is given by\n$ \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N}\\lvert x_{i} - \\bar{x} \\rvert^2} $ where\n$\\bar{x}$ is the sample mean of the interestingness scores obtained for the\nevents in the log being analyzed and $N$ is the number of events in the log.}  \nThis ensures that the ``interestingness-distance'' between two events \nin a cluster never exceeds the uncorrected sample standard deviation observed in the set.\n\n %\n\n\\section{Research Questions}\n\\label{sec:rqs}\n\nThe goal of this paper is to present SBLD and help practitioners make\nan informed decision whether SBLD meets their needs. To this end, we have identified\nthree research questions that encompass several concerns practitioners\nare likely to have and that also are of interested to the research community at\nlarge:\n\\begin{enumerate}[\\bfseries RQ1]\n\n\\item How well does SBLD reduce the effort needed to identify all\n        known-to-be relevant events (\&quot;does it work?\&quot;) ?\n\n\\item How is the efficacy of SBLD impacted by increased evidence in the form of\n        additional failing and passing logs (\&quot;how much data do we need before\n                running the analysis?\&quot;) ?\n\n\\item How does SBLD perform compared to a strategy based on searching for\n        common textual patterns with a tool like \\texttt{grep} (\&quot;is it better than doing the obvious thing?\&quot;) ?\n\\end{enumerate}\nRQ1 looks at the aggregated performance of SBLD to assess its viability.\nWith RQ2 we assess how sensitive the performance is to the amount of\navailable data: How many logs should you have before you can expect the\nanalysis to yield good results? Is more data unequivocally a good thing?\nWhat type of log is more informative: A passing log or a failing log?\nFinally, we compare SBLD's performance to a more traditional method for\nfinding relevant segments in logs: Using a textual search for strings \none expects to occur near informative segments, like\n\&quot;failure\&quot; and \&quot;error\&quot;. The next section details the dataset used, our\nchosen quality measures for assessment and our methodology for answering\neach research question.\n\n %\n\n\\section{Experimental Design}\n\\label{sec:expdesign}\n\n\\begin{table}\n\\centering\n\\caption{The key per-test attributes of our dataset. Two events are considered\n        distinct if they are treated as separate events after the abstraction\n        step. A \&quot;mixed\&quot; event is an event that occurs in logs of both failing and\n        passing runs.}\n\\vspace*{-1ex}\n\\label{table:descriptive}\n\\renewcommand{\\tabcolsep}{0.11cm}\\small\n\\begin{tabular}{rcrrrrrr}\n\\toprule\n     &amp;           &amp; \\# fail   &amp; \\# pass   &amp; distinct &amp; fail-only  &amp; mixed   &amp; pass-only  \\\\\ntest &amp; signature &amp; logs      &amp; logs      &amp;  events  &amp; events     &amp; events  &amp; events \\\\\n\\midrule\n   1 &amp; C  &amp;     24 &amp;     100 &amp;           36391 &amp;            21870 &amp;          207 &amp;               14314 \\\\\n   2 &amp; E  &amp;     11 &amp;      25 &amp;             380 &amp;               79 &amp;          100 &amp;                 201 \\\\\n   3 &amp; E  &amp;     11 &amp;      25 &amp;             679 &amp;              174 &amp;           43 &amp;                 462 \\\\\n   4 &amp; E  &amp;      4 &amp;      25 &amp;             227 &amp;               49 &amp;           39 &amp;                 139 \\\\\n   5 &amp; C  &amp;      2 &amp;     100 &amp;           33420 &amp;             2034 &amp;           82 &amp;               31304 \\\\\n   6 &amp; C  &amp;     19 &amp;     100 &amp;           49155 &amp;            15684 &amp;          893 &amp;               32578 \\\\\n   7 &amp; C  &amp;     21 &amp;     100 &amp;           37316 &amp;            17881 &amp;          154 &amp;               19281 \\\\\n   8 &amp; C  &amp;      4 &amp;     100 &amp;           26614 &amp;             3976 &amp;           67 &amp;               22571 \\\\\n   9 &amp; C  &amp;     21 &amp;     100 &amp;           36828 &amp;            19240 &amp;          228 &amp;               17360 \\\\\n  10 &amp; C  &amp;     22 &amp;     100 &amp;          110479 &amp;            19134 &amp;         1135 &amp;               90210 \\\\\n  11 &amp; E  &amp;      5 &amp;      25 &amp;             586 &amp;               95 &amp;           47 &amp;                 444 \\\\\n  12 &amp; E  &amp;      7 &amp;      25 &amp;             532 &amp;               66 &amp;           18 &amp;                 448 \\\\\n  13 &amp; C  &amp;      2 &amp;     100 &amp;           15351 &amp;             2048 &amp;          232 &amp;               13071 \\\\\n  14 &amp; C  &amp;      3 &amp;     100 &amp;           16318 &amp;             2991 &amp;          237 &amp;               13090 \\\\\n  15 &amp; C  &amp;     26 &amp;     100 &amp;           60362 &amp;            20964 &amp;         1395 &amp;               38003 \\\\\n  16 &amp; C  &amp;     12 &amp;     100 &amp;            2206 &amp;              159 &amp;          112 &amp;                1935 \\\\\n  17 &amp; E  &amp;      8 &amp;      25 &amp;             271 &amp;               58 &amp;           98 &amp;                 115 \\\\\n  18 &amp; A  &amp;     23 &amp;      75 &amp;            3209 &amp;              570 &amp;          156 &amp;                2483 \\\\\n  19 &amp; C  &amp;     13 &amp;     100 &amp;           36268 &amp;            13544 &amp;          411 &amp;               22313 \\\\\n  20 &amp; B  &amp;      3 &amp;      19 &amp;             688 &amp;               69 &amp;           31 &amp;                 588 \\\\\n  21 &amp; B  &amp;     22 &amp;      25 &amp;             540 &amp;              187 &amp;           94 &amp;                 259 \\\\\n  22 &amp; E  &amp;      1 &amp;      25 &amp;             276 &amp;               11 &amp;           13 &amp;                 252 \\\\\n  23 &amp; C  &amp;     13 &amp;     100 &amp;           28395 &amp;            13629 &amp;          114 &amp;               14652 \\\\\n  24 &amp; E  &amp;      7 &amp;      26 &amp;             655 &amp;              117 &amp;           56 &amp;                 482 \\\\\n  25 &amp; C  &amp;     21 &amp;     100 &amp;           44693 &amp;            18461 &amp;          543 &amp;               25689 \\\\\n  26 &amp; C  &amp;     21 &amp;     100 &amp;           42259 &amp;            19434 &amp;          408 &amp;               22417 \\\\\n  27 &amp; C  &amp;     21 &amp;     100 &amp;           44229 &amp;            18115 &amp;          396 &amp;               25718 \\\\\n  28 &amp; C  &amp;     20 &amp;     100 &amp;           43862 &amp;            16922 &amp;          642 &amp;               26298 \\\\\n  29 &amp; C  &amp;     28 &amp;     100 &amp;           54003 &amp;            24216 &amp;         1226 &amp;               28561 \\\\\n  30 &amp; C  &amp;     31 &amp;     100 &amp;           53482 &amp;            26997 &amp;         1063 &amp;               25422 \\\\\n  31 &amp; C  &amp;     27 &amp;     100 &amp;           53092 &amp;            23283 &amp;          463 &amp;               29346 \\\\\n  32 &amp; C  &amp;     21 &amp;     100 &amp;           55195 &amp;            19817 &amp;          768 &amp;               34610 \\\\\n  33 &amp; E  &amp;      9 &amp;      25 &amp;             291 &amp;               70 &amp;           30 &amp;                 191 \\\\\n  34 &amp; D  &amp;      2 &amp;      13 &amp;             697 &amp;               76 &amp;           92 &amp;                 529 \\\\\n  35 &amp; E  &amp;      9 &amp;      25 &amp;             479 &amp;              141 &amp;           47 &amp;                 291 \\\\\n  36 &amp; E  &amp;     10 &amp;      75 &amp;            1026 &amp;              137 &amp;           68 &amp;                 821 \\\\\n  37 &amp; E  &amp;      7 &amp;      25 &amp;            7165 &amp;             1804 &amp;           94 &amp;                5267 \\\\\n  38 &amp; E  &amp;      4 &amp;      25 &amp;             647 &amp;               67 &amp;           49 &amp;                 531 \\\\\n  39 &amp; G  &amp;     47 &amp;     333 &amp;            3350 &amp;              428 &amp;          144 &amp;                2778 \\\\\n  40 &amp; G  &amp;     26 &amp;     333 &amp;            3599 &amp;              240 &amp;          157 &amp;                3202 \\\\\n  41 &amp; G  &amp;     26 &amp;     332 &amp;            4918 &amp;              239 &amp;          145 &amp;                4534 \\\\\n  42 &amp; C  &amp;     17 &amp;     100 &amp;           30411 &amp;            14844 &amp;          348 &amp;               15219 \\\\\n  43 &amp; F  &amp;    267 &amp;     477 &amp;           10002 &amp;             3204 &amp;         1519 &amp;                5279 \\\\\n  44 &amp; C  &amp;      9 &amp;     100 &amp;           29906 &amp;             8260 &amp;          274 &amp;               21372 \\\\\n  45 &amp; E  &amp;      3 &amp;      25 &amp;             380 &amp;               44 &amp;           43 &amp;                 293 \\\\\n\\bottomrule\n\\end{tabular}\n\\vspace*{-2ex}\n\\end{table}\n %\n\n\\begin{table}\n\\centering\n\\caption{Ground-truth signatures and their occurrences in distinct events.}\n\\label{table:signature}\n\\vspace*{-1ex}\n\\small\n\\begin{tabular}{ccrrrc}\n\\toprule\n          &amp;   sub-  &amp; fail-only &amp; pass-only &amp; fail \\&amp; &amp; failure \\\\\nsignature &amp; pattern &amp; events    &amp; events    &amp; pass    &amp; strings* \\\\\n\\midrule\n        A &amp;       1 &amp;                1 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        A &amp;       2 &amp;                2 &amp;                0 &amp;            0 &amp;                                   no \\\\\n        B &amp;       1 &amp;                2 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        C &amp;       1 &amp;               21 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        C &amp;       2 &amp;               21 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        D &amp;       1 &amp;                4 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n \\textbf{D$^{\\#}$} &amp; \\textbf{2} &amp;               69 &amp;              267 &amp;          115 &amp;                                   no \\\\\n \\textbf{D$^{\\#}$} &amp; \\textbf{3} &amp;                2 &amp;               10 &amp;           13 &amp;                                   no \\\\\n \\textbf{E$^{\\#}$} &amp; \\textbf{1} &amp;               24 &amp;              239 &amp;          171 &amp;                                   no \\\\\n        E &amp;       1 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\\\\n        E &amp;       2 &amp;                9 &amp;                0 &amp;            0 &amp;                                   no \\\\\n        E &amp;       3 &amp;                9 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        E &amp;       4 &amp;               23 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        F &amp;       1 &amp;               19 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        F &amp;       2 &amp;               19 &amp;                0 &amp;            0 &amp;                                   no \\\\\n        F &amp;       3 &amp;               19 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        F &amp;       4 &amp;               14 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        G &amp;       1 &amp;                2 &amp;                0 &amp;            0 &amp;                                  yes \\\\\n        G &amp;       2 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\\\\n        G &amp;       3 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\\\\n\\bottomrule\n\\multicolumn{6}{l}{* signature contains the lexical patterns 'error', 'fault' or 'fail*'}\\\\\n\\multicolumn{6}{l}{$^{\\#}$ sub-patterns that were removed to ensure a clean ground truth}\n\\end{tabular}\n\\vspace*{-3ex}\n\\end{table}\n \n\\subsection{Dataset and ground truth}\n\\label{sec:dataset}\n\nOur dataset provided by \\CiscoNorway{our industrial partner} consists\nof failing and passing log files from 45 different end-to-end integration\ntests. In addition to the log text we also have data on when a given\nlog file was produced. Most test-sets span a time-period of 38 days, while\nthe largest set (test 43 in Table~\\ref{table:descriptive}) spans 112\ndays. Each failing log is known to exemplify symptoms of one of seven\nknown errors, and \\CiscoNorway{our industrial partner} has given us a\nset of regular expressions that help determine which events are relevant\nfor a given known error. We refer to the set of regular expressions\nthat identify a known error as a \\emph{signature} for that error. These\nsignatures help us construct a ground truth for our investigation.\nMoreover, an important motivation for developing SBLD is to help create\nsignatures for novel problems: The events highlighted by SBLD should be\ncharacteristic of the observed failure, and the textual contents of the\nevents can be used in new signature expressions.\n\nDescriptive facts about our dataset is listed in\nTable~\\ref{table:descriptive} while Table~\\ref{table:signature}\nsummarizes key insights about the signatures used.\n\nIdeally, our ground truth should highlight exactly and \\emph{only} the\nlog events that an end user would find relevant for troubleshooting\nan error. However, the signatures used in this investigation were\ndesigned to find sufficient evidence that the \\emph{entire log} in\nquestion belongs to a certain error class: the log might contain other\nevents that a human user would find equally relevant for diagnosing\na problem, but the signature in question might not encompass these\nevents. Nevertheless, the events that constitute sufficient evidence\nfor assigning the log to a given error class are presumably relevant\nand should be presented as soon as possible to the end user. However,\nif our method cannot differentiate between these signature events and\nother events we cannot say anything certain about the relevance of\nthose other events. This fact is reflected in our choice of quality\nmeasures, specifically in how we assess the precision of the approach. This\nis explained in detail in the next section.\n\nWhen producing the ground truth, we first ensured that a log would only be\nassociated with a signature if the entire log taken as a whole satisfied all\nthe sub-patterns of that signature. If so, we then determined which events\nthe patterns were matching on. These events constitute the known-to-be relevant\nset of events for a given log.  However, we identified some problems with two of the provided\nsignatures that made them unsuitable for assessing SBLD. Signature \\emph{E}\n(see Table~\\ref{table:signature}) had a sub-pattern that searched for a \&quot;starting test\&quot;-prefix that necessarily\nmatches on the first event in all logs due to the structure of the logs.\nSimilarly, signature \\emph{D} contained two sub-patterns that necessarily\nmatch all logs in the set--in this case by searching for whether the test\nwas run on a given machine, which was true for all logs for the corresponding\ntest. We therefore elected to remove these sub-patterns from the signatures\nbefore conducting the analysis.\n\n\\subsection{Quality Measures}\n\nAs a measure of how well SBLD reports all known-to-be relevant log\nevents, we measure \\emph{recall in best cluster}, which we for brevity refer to\nas simply \\emph{recall}. \nThis is an adaption of the classic recall measure used in information retrieval,\nwhich tracks the proportion of all relevant events that were retrieved\nby the system~\\cite{manning2008introduction}. \nAs our method presents events to the user in a series of ranked clusters, \nwe ideally want all known-to-be relevant events to appear in the highest ranked cluster. \nWe therefore track the overall recall obtained as if the first cluster were the only events retrieved.\nNote, however, that SBLD ranks all clusters, and a user can retrieve additional clusters if desired. \nWe explore whether this could improve SBLD's performance on a\nspecific problematic test-set in Section~\\ref{sec:testfourtythree}.\n\nIt is trivial to obtain a perfect recall by simply retrieving all events\nin the log, but such a method would obviously be of little help to a user\nwho wants to reduce the effort needed to diagnose failures.\nWe therefore also track the \\emph{effort reduction} (ER), defined as\n\\[ \\text{ER} = 1 - \\frac{\\text{number of events in first cluster}}{\\text{number of events in log}} \\]\n\nMuch like effective information retrieval systems aim for high recall and\nprecision, we want our method to score a perfect recall while obtaining the\nhighest effort reduction possible. \n\n\\subsection{Recording the impact of added data}\n\nTo study the impact of added data on SBLD's performance, we need to measure how\nSBLD's performance on a target log $t$ is affected by adding an extra\nfailing log $f$ or a passing log $p$. There are several strategies\nfor accomplishing this. One way is to try all combinations in the\ndataset i.e.\\ compute the performance on any $t$ using any choice of\nfailing and passing logs to produce the interestingness scores. This\napproach does not account for the fact that the logs in the data are\nproduced at different points in time and is also extremely expensive\ncomputationally. We opted instead to order the logs chronologically and\nsimulate a step-wise increase in data as time progresses, as shown in\nAlgorithm~\\ref{alg:time}.\n\n\\begin{algorithm}[b]\n\\caption{Pseudo-code illustrating how we simulate a step-wise increase in data\n        as time progresses and account for variability in choice of\n        interestingness measure.}\n\\label{alg:time}\n\\begin{algorithmic}\\small\n\\STATE $F$ is the set of failing logs for a given test\n\\STATE $P$ is the set of passing logs for a given test\n\\STATE $M$ is the set of interestingness measures considered\n\\STATE sort $F$ chronologically\n\\STATE sort $P$ chronologically\n\\FOR{$i=0$ to $i=\\lvert F \\rvert$}\n        \\FOR{$j=0$ to $j=\\lvert P \\rvert$}\n                \\STATE $f = F[:i]$ \\COMMENT{get all elements in F up to and including position i}\n                \\STATE $p = P[:j]$\n                \\FORALL{$l$ in $f$}\n                        \\STATE initialize $er\\_scores$ as an empty list\n                        \\STATE initialize $recall\\_scores$ as an empty list\n                        \\FORALL{$m$ in $M$}\n                                \\STATE perform SBLD on $l$ using $m$ as measure \\\\ \\hspace*{1.75cm} and $f$ and $p$ as spectrum data\n                                \\STATE append recorded effort reduction score to $er\\_scores$\n                                \\STATE append recorded recall score to $recall\\_scores$\n                        \\ENDFOR\n                        \\STATE record median of $er\\_scores$\n                        \\STATE record median of $recall\\_scores$\n                \\ENDFOR\n        \\ENDFOR\n\\ENDFOR\n\\end{algorithmic}\n\\end{algorithm}\n\n\\subsection{Variability in interestingness measures}\n\\label{sec:imvars}\n\nAs mentioned in Section~\\ref{sec:approach}, SBLD requires a\nchoice of interestingness measure for scoring the events, \nwhich can have a considerable impact on SBLD's performance. \nConsidering that the best choice of interestingness measure is context-dependent, \nthere is no global optimum, \nit is up to the user to decide which interestingness metric best reflects their\nnotion of event relevance. \n\nConsequently, we want to empirically study SBLD in way\nthat captures the variability introduced by this decision. \nTo this end, we record the median score obtained by performing SBLD for every possible choice of\ninterestingness measure from those listed in Table~\\ref{table:measures}.\nAlgorithm~\\ref{alg:time} demonstrates the procedure in pseudo-code.\n\n\\subsection{Comparing alternatives}\n\\label{sec:comps}\n\nTo answer RQ2 and RQ3, we use pairwise comparisons of\ndifferent configurations of SBLD with a method that searches for regular expressions. \nThe alternatives are compared\non each individual failing log in the set in a paired fashion. An\nimportant consequence of this is that the statistical comparisons have\nno concept of which test the failing log belongs to, and thus the test\nfor which there is most data has the highest impact on the result of the\ncomparison.\n\nThe pairwise comparisons are conducted using paired Wilcoxon signed-rank\ntests~\\cite{wilcoxon1945} where the Pratt correction~\\cite{Pratt1959}\nis used to handle ties. We apply Holm's correction~\\cite{Holm1979}\nto the obtained p-values to account for the family-wise error\nrate arising from multiple comparisons. We declare a comparison\n\\emph{statistically significant} if the Holm-adjusted p-value is below\n$\\alpha=0.05$. The Wilcoxon tests check the two-sided null hypothesis of\nno difference between the alternatives. We report the Vargha-Delaney $A_{12}$ and\n$A_{21}$~\\cite{Vargha2000} measures of stochastic superiority to\nindicate which alternative is the strongest. Conventionally, $A_{12}=0.56$ is\nconsidered a small difference, $A_{12}=.64$ is considered a medium difference\nand $A_{12}=.71$ or greater is considered large~\\cite{Vargha2000}. Observe\nalso that $A_{21} = 1 - A_{12}$.\n\n\\begin{figure*}\n        \\includegraphics[width=0.8\\textwidth]{rq1_boxplot.png}\n        %\n        \\caption{The overall performance of SBLD in terms of effort reduction\n        and recall. On many tests, SBLD exhibited perfect recall for\n        all observations in the inter-quartile range and thus the box collapses to a single line on the $1.0$ mark.\\label{fig:rq1boxplot}}\n\\end{figure*}\n\n\\subsection{Analysis procedures}\n\nWe implement the SBLD approach in a prototype tool \nDAIM (Diagnosis and Analysis using Interestingness Measures), \nand use DAIM to empirically evaluate the idea.\n\n\\head{RQ1 - overall performance} We investigate the overall performance\nof SBLD by analyzing a boxplot for each test in our dataset. Every individual\ndatum that forms the basis of the plot is the median performance of SBLD over\nall choices of interestingness measures for a given set of failing and passing\nlogs subject to the chronological ordering scheme outlined above.\n\n\\head{RQ2 - impact of data} We analyze the impact of added data by\nproducing and evaluating heatmaps that show the obtained performance\nas a function of the number of failing logs (y-axis) and number of\npassing logs (x-axis). The color intensity of each tile in the heatmaps\nis calculated by taking the median of the scores obtained for each\nfailing log analyzed with the given number of failing and passing logs\nas data for the spectrum inference, wherein the score for each log is\nthe median over all the interestingness measures considered as outlined in\nSection~\\ref{sec:imvars}.\n\nFurthermore, we compare three variant configurations\nof SBLD that give an overall impression of the influence of added\ndata. The three configurations considered are \\emph{minimal evidence},\n\\emph{median evidence} and \\emph{maximal evidence}, where minimal\nevidence uses only events from the log being analyzed and one additional\npassing log, median evidence uses the median amount of respectively failing and\nand passing logs available while maximal evidence uses\nall available data for a given test. The comparisons are conducted with the\nstatistical scheme described above in Section~\\ref{sec:comps}.\n\n\\head{RQ3 - SBLD versus pattern-based search} To compare SBLD\nagainst a pattern-based search, we record the effort reduction and\nrecall obtained when only selecting events in the log that match on the\ncase-insensitive regular expression \\texttt{\&quot;error|fault|fail*\&quot;}, where\nthe $*$ denotes a wildcard-operator and the $\\lvert$ denotes logical\n$OR$. This simulates the results that a user would obtain by using\na tool like \\texttt{grep} to search for words like 'error' and 'failure'.\nSometimes the ground-truth signature expressions contain words from this\npattern, and we indicate this in Table~\\ref{table:signature}. If so, the\nregular expression-based method is guaranteed to retrieve the event.\nSimilarly to RQ2, we compare the three configurations of SBLD described\nabove (minimum, median and maximal evidence) against the pattern-based\nsearch using the statistical described in Section~\\ref{sec:comps}.\n\n %\n\n\\section{Results and Discussion}\n\\label{sec:resdiscuss}\n\nThis section gradually dissects Figure~\\ref{fig:rq1boxplot}, showing a breakdown of SBLD's performance per test for both recall\nand effort reduction, Figures \\ref{fig:erheat} and \\ref{fig:recallheat}, \nshowing SBLD's performance as a function of the number of failing and passing\nlogs used, as well as Table~\\ref{table:comparisons}, which shows the results\nof the statistical comparisons we have performed.\n\n\\begin{figure*}\n\\includegraphics[width=\\textwidth]{er_heatmap.pdf}\n        \\caption{Effort reduction score obtained when SBLD is run on a given number of failing and passing logs. The tests not listed in this figure all obtained a lowest median effort reduction score of 90\\% or greater and are thus not shown for space considerations. \\label{fig:erheat}}\n\\vspace*{-2ex}\n\\end{figure*}\n\n\\begin{table*}\n\\caption{Statistical comparisons performed in this investigation. The\nbold p-values are those for which no statistically significant difference under $\\alpha=0.05$\n        could be established.}\n\\label{table:comparisons}\n{\\small%\n\\begin{tabular}{lllrrrr}\n\\toprule\n variant 1 &amp; variant 2 &amp;            quality measure &amp;  Wilcoxon statistic &amp;   $A_{12}$ &amp;  $A_{21}$   &amp; Holm-adjusted p-value\\\\\n\\midrule\n pattern-based search &amp;  minimal  evidence &amp;  effort reduction &amp; 29568.5 &amp; 0.777 &amp; 0.223 &amp;    $\\ll$ 0.001 \\\\\n pattern-based search &amp;  maximal  evidence &amp;  effort reduction &amp; 202413.0 &amp; 0.506 &amp; 0.494 &amp;       \\textbf{1.000} \\\\\n pattern-based search &amp;   median evidence &amp;  effort reduction &amp; 170870.5 &amp; 0.496 &amp; 0.504 &amp;    $\\ll$ 0.001 \\\\\n     minimal evidence &amp;  maximal evidence &amp;  effort reduction &amp; 832.0 &amp; 0.145 &amp; 0.855 &amp;    $\\ll$ 0.001 \\\\\n     minimal evidence &amp;   median evidence &amp;  effort reduction &amp; 2666.0 &amp; 0.125 &amp; 0.875 &amp;    $\\ll$ 0.001 \\\\\n     maximal evidence &amp;   median evidence &amp;  effort reduction &amp; 164674.0 &amp; 0.521 &amp; 0.479 &amp;       \\textbf{1.000} \\\\\n pattern-based search &amp;  minimal evidence &amp;            recall &amp; 57707.0 &amp; 0.610 &amp; 0.390 &amp;    $\\ll$ 0.001 \\\\\n pattern-based search &amp;  maximal evidence &amp;            recall &amp; 67296.0 &amp; 0.599 &amp; 0.401 &amp;    $\\ll$ 0.001 \\\\\n pattern-based search &amp;   median evidence &amp;            recall &amp; 58663.5 &amp; 0.609 &amp; 0.391 &amp;    $\\ll$ 0.001 \\\\\n     minimal evidence &amp;  maximal evidence &amp;            recall &amp; 867.5 &amp; 0.481 &amp; 0.519 &amp;    $\\ll$ 0.001 \\\\\n     minimal evidence &amp;   median evidence &amp;            recall &amp;             909.0 &amp; 0.498 &amp; 0.502 &amp;       0.020 \\\\\n     maximal evidence &amp;   median evidence &amp;            recall &amp; 0.0 &amp; 0.518 &amp; 0.482 &amp;    $\\ll$ 0.001 \\\\\n\\bottomrule\n\\end{tabular}\n %\n}\n\\end{table*}\n\n\\begin{figure}\n\\includegraphics[width=\\columnwidth]{recall_heatmap.pdf}\n        \\caption{Recall score obtained when SBLD is run on a given number of failing and passing logs. For space\n        considerations, we only show tests for which the minimum observed\n        median recall was smaller than 1 (SBLD attained perfect median recall for all configurations in the other tests). \\label{fig:recallheat}}\n\\vspace*{-3ex}\n\\end{figure}\n\n\\subsection{RQ1: The overall performance of SBLD}\n\nFigure~\\ref{fig:rq1boxplot} suggests that SBLD's overall performance is strong,\nsince it obtains near-perfect recall while retaining a high degree of effort\nreduction.  In terms of recall, SBLD obtains a perfect performance on all except\nfour tests: 18, 34, 42 and 43, with the lower quartile stationed at perfect recall for all tests\nexcept 43 (which we discuss in detail in Section~\\ref{sec:testfourtythree}).\nFor test 18, only 75 out of 20700 observations ($0.036\\%$) obtained a recall score\nof $0.5$ while the rest obtained a perfect score. On test 34 (the smallest in our\ndataset), 4 out of 39 observations obtained a score of zero recall while the\nothers obtained perfect recall. \nFor test 42, 700 out of 15300 ($0.4\\%$) observations obtained a score of zero recall while the rest obtained perfect recall.\nHence with the exception of test 43 which is discussed later, \nSBLD obtains very strong recall scores overall with only a few outliers.\n\nThe performance is also strong in terms of effort reduction, albeit\nmore varied. To a certain extent this is expected since the attainable\neffort reduction on any log will vary with the length of the log and\nthe number of ground-truth relevant events in the log. As can be seen\nin Figure~\\ref{fig:rq1boxplot}, most of the observations fall well\nover the 75\\% mark, with the exceptions being tests 4 and 22. For test\n4, Figure~\\ref{fig:erheat} suggests that one or more of the latest\npassing logs helped SBLD refine the interestingness scores. A similar\nbut less pronounced effect seems to have happened for test 22. However,\nas reported in Table~\\ref{table:descriptive}, test 22 consists only of\n\\emph{one} failing log. Manual inspection reveals that the log consists\nof 30 events, of which 11 are fail-only events. Without additional\nfailing logs, most interestingness measures will give a high score to\nall events that are unique to that singular failing log, which is likely\nto include many events that are not ground-truth relevant. Reporting 11\nout of 30 events to the user yields a meager effort reduction of around\n63\\%. Nevertheless, the general trend is that SBLD retrieves a compact\nset of events to the user which yields a high effort reduction score.\n\nIn summary, the overall performance shows that SBLD\nretrieves the majority of all known-to-be-relevant events\nin compact clusters, which dramatically reduces the analysis burden for the\nend user. The major exception is Test 43, which we return to in\nSection~\\ref{sec:testfourtythree}.\n\n\\subsection{RQ2: On the impact of evidence}\n\nThe heatmaps suggest that the effort reduction is generally not\nadversely affected by adding more \\emph{passing logs}. If the\nassumptions underlying our interestingness measures are correct,\nthis is to be expected: Each additional passing log either gives us\nreason to devalue certain events that co-occur in failing and passing\nlogs or contain passing-only events that are deemed uninteresting.\nMost interestingness measures highly value events that\nexclusively occur in failing logs, and additional passing logs help\nreduce the number of events that satisfy this criteria. However, since\nour method bases itself on clustering similarly scored events it is\nweak to \\emph{ties} in interestingness scores. It is possible that\nan additional passing log introduces ties where there previously was\nnone. This is likely to have an exaggerated effect in situations with\nlittle data, where each additional log can have a dramatic impact on the\ninterestingness scores. This might explain the gradual dip in effort\nreduction seen in Test 34, for which there are only two failing logs.\n\nAdding more failing logs, on the other hand, draws a more nuanced\npicture: When the number of failing logs (y-axis) is high relative\nto the number of passing logs (x-axis), effort reduction seems to suffer.\nAgain, while most interestingness measures will prioritize events that\nonly occur in failing logs, this strategy only works if there is a\nsufficient corpus of passing logs to weed out false positives. When\nthere are far fewer passing than failing logs, many events will be\nunique to the failing logs even though they merely reflect a different\nvalid execution path that the test can take. This is especially true for\ncomplex integration tests like the ones in our dataset, which might test\na system's ability to recover from an error, or in other ways have many\nvalid execution paths.\n\nThe statistical comparisons summarized in Table~\\ref{table:comparisons}\nsuggest that the minimal evidence strategy performs poorly compared to the\nmedian and maximal evidence strategies. This is especially\npronounced for effort reduction, where the Vargha-Delaney\nmetric scores well over 80\\% in favor of the maximal and median\nstrategy. For recall, the difference between the minimum strategy and\nthe other variants is small, albeit statistically significant. Furthermore,\nthe jump from minimal evidence to median evidence is much more\npronounced than the jump from median evidence to maximal evidence.\nFor effort reduction, there is in fact no statistically discernible\ndifference between the median and maximal strategies. For recall, the maximal\nstrategies seems a tiny bit better, but the $A_{12}$ measure suggests the\nmagnitude of the difference to be small.\n\nOverall, SBLD seems to benefit from extra data, especially additional passing\nlogs. Failing logs also help, but depend on a proportional amount of passing\nlogs for SBLD to fully benefit. \nThe performance increase from going from minimal data to some data is more pronounced than going from some data to\nmaximal data. This suggests that there may be diminishing returns to\ncollecting extra logs, but our investigation cannot prove or disprove this.\n\n\\subsection{RQ3: SBLD versus simple pattern-search}\n\nIn terms of effort reduction, Table~\\ref{table:comparisons} shows that\nthe pattern-based search clearly beats the minimal evidence variant of\nSBLD. It does not, however, beat the median and maximal variants: The\ncomparison to median evidence suggests a statistically significant win\nin favor of median evidence, but the effect reported by $A_{12}$ is\nso small that it is unlikely to matter in practice. No statistically\nsignificant difference could be established between the pattern-based\nsearch and SBLD with maximal evidence.\n\nIn one sense, it is to be expected that the pattern-based search does\nwell on effort reduction assuming that events containing words like\n\&quot;fault\&quot; and \&quot;error\&quot; are rare. The fact that the pattern-based search\nworks so well could indicate that \\CiscoNorway{our industrial partner}\nhas a well-designed logging infrastructure where such words are\nrare and occur at relevant positions in the logs. On the other\nhand, it is then notable that the median and maximum variants of SBLD perform\ncomparably on effort reduction without having any concept of the textual\ncontent in the events.\n\nIn terms of recall, however, pattern-based search beats all variants of\nSBLD in a statistically significant manner, where the effect size of the\ndifferences is small to medium.  One likely explanation for this better performance is that the\npattern-based search performs very well on Test 43, which SBLD generally\nperforms less well on. Since the comparisons are run per failing log and test\n43 constitutes 29\\% of the failing logs (specifically, 267 out of 910 logs), the\nperformance of test 43 has a massive impact. We return to test 43 and its\nimpact on our results in Section~\\ref{sec:testfourtythree}.\n\nOn the whole, SBLD performs similarly to pattern-based search, obtaining\nslightly poorer results on recall for reasons that are likely due\nto a particular test we discuss below. At any rate, there is no\ncontradiction in combining SBLD with a traditional pattern-based search.\nAnalysts could start by issuing a set of pattern-based searches and\nrun SBLD afterward if the pattern search returned unhelpful results.\nIndeed, an excellent and intended use of SBLD is to suggest candidate\nsignature patterns that, once proven reliable, can be incorporated in a\nregular-expression based search to automatically identify known issues\nin future runs.\n\n\\subsection{What happens in Test 43?}\n\\label{sec:testfourtythree}\n\nSBLD's performance is much worse on Test 43 than the other tests, which\nwarrants a dedicated investigation. The first thing we observed in the\nresults for Test 43 is that all of the ground-truth-relevant events\noccurred \\emph{exclusively} in failing logs and were often singular\n(11 out of the 33) or infrequent (30 out of 33 events occurred in 10\\%\nof the failing logs or fewer). Consequently, we observed a strong\nperformance from the \\emph{Tarantula} and \\emph{Failed only}-measures\nthat put a high premium on failure-exclusive events. Most of the\ninterestingness measures, on the other hand, will prefer an event that\nis very frequent in the failing logs and sometimes occur in passing logs\nover a very rare event that only occurs in failing logs. This goes a\nlong way in explaining the poor performance on recall. The abundance of\nsingular events might also suggest that there is an error in the event\nabstraction framework, where several events that should be treated as\ninstances of the same abstract event are treated as separate events. We\ndiscuss this further in Section~\\ref{sec:ttv}.\n\n\\begin{sloppypar}%\nAnother observation we made is that the failing logs contained only \\emph{two}\nground-truth relevant events, which means that the recorded recall can quickly\nfluctuate between $0$, $0.5$ and $1$.\n\\end{sloppypar}\n\nWould the overall performance improve by retrieving an additional\ncluster? A priori, retrieving an extra cluster would strictly improve\nor not change recall since more events are retrieved without removing\nthe previously retrieved events. Furthermore, retrieving an additional\ncluster necessarily decreases the effort reduction. We re-ran the\nanalysis on Test 43 and collected effort reduction and recall scores\nfor SBLD when retrieving \\emph{two} clusters, and found that the added\ncluster increased median recall from $0$ to $0.5$ while the median\neffort reduction decreased from $0.97$ to $0.72$. While the proportional\nincrease in recall is larger than the decrease in effort reduction,\nthis should in our view not be seen as an improvement: As previously\nmentioned, the failing logs in this set contain only two ground-truth\nrelevant events and thus recall is expected to fluctuate greatly.\nSecondly, an effort reduction of $0.72$ implies that you still have to\nmanually inspect 28\\% of the data, which in most information retrieval\ncontexts is unacceptable. An unfortunate aspect of our analysis in this\nregard is that we do not account for event \\emph{lengths}: An abstracted\nevent is treated as one atomic entity, but could in reality vary from a\nsingle line to a stack trace that spans several pages. A better measure\nof effort reduction should incorporate a notion of event length to\nbetter reflect the real-world effect of retrieving more events.\n\nAll in all, Test 43 exhibits a challenge that SBLD is not suited for:\nIt asks SBLD to prioritize rare events that are exclusive to failing\nlogs over events that frequently occur in failing logs but might\noccasionally occur in passing logs. The majority of interestingness\nmeasures supported by SBLD would prioritize the latter category of\nevents. In a way, this might suggest that SBLD is not suited for finding\n\\emph{outliers} and rare events: Rather, it is useful for finding\nevents that are \\emph{characteristic} for failures that have occurred\nseveral times - a \&quot;recurring suspect\&quot;, if you will. An avenue for future\nresearch is to explore ways of letting the user combine a search for\n\&quot;recurring suspects\&quot; with the search for outliers.\n\n %\n\n\\section{Related Work}\n\\label{sec:relwork}\n\nWe distinguish two main lines of related work: \nFirst, there is other work aimed at automated analysis of log files, \ni.e., our problem domain,\nand second, there is other work that shares similarities with our technical approach, \ni.e., our solution domain.\n\n\\head{Automated log analysis}\nAutomated log analysis originates in \\emph{system and network monitoring} for security and administration~\\cite{lin1990:error,Oliner2007}, \nand saw a revival in recent years due to the needs of \\emph{modern software development}, \\emph{CE} and \\emph{DevOps}~\\cite{Hilton2017,Laukkanen2017,Debbiche2014,Olsson2012,Shahin2017,candido2019:contemporary}.\n\nA considerable amount of research has focused on automated \\emph{log parsing} or \\emph{log abstraction}, \nwhich aims to reduce and organize log data by recognizing latent structures or templates in the events in a log~\\cite{zhu2019:tools,el-masri2020:systematic}.\nHe et al. analyze the quality of these log parsers and conclude that many of them are not accurate or efficient enough for parsing the logs of modern software systems~\\cite{he2018:automated}.\nIn contrast to these automated approaches, \nour study uses a handcrafted log abstracter developed by \\CiscoNorway{our industrial collaborator}.\n\n\\emph{Anomaly detection} has traditionally been used for intrusion detection and computer security~\\cite{liao2013:intrusion,ramaki2016:survey,ramaki2018:systematic}.\nApplication-level anomaly detection has been investigated for troubleshooting~\\cite{chen2004:failure,zhang2019:robust},\nand to assess compliance with service-level agreements~\\cite{banerjee2010:logbased,He2018,sauvanaud2018:anomaly}.\nGunter et al. present an infrastructure for troubleshooting of large distributed systems, %\nby first (distributively) summarizing high volume event streams before submitting those summaries to a centralized anomaly detector. \nThis helps them achieve the fidelity needed for detailed troubleshooting, \nwithout suffering from the overhead that such detailed instrumentation would bring~\\cite{Gunter2007}.\nDeeplog by Du et al. enables execution-path and performance anomaly detection in system logs by training a Long Short-Term Memory neural network of the system's expected behavior from the logs, and using that model to flag events and parameter values in the logs that deviate from the model's expectations~\\cite{Du2017}.\nSimilarly, LogRobust by Zhang et al. performs anomaly detection using a bi-LSTM neural network but also detects events that are likely evolved versions of previously seen events, making the learned model more robust to updates in the target logging infrastructure~\\cite{zhang2019:robust}.\n\nIn earlier work, we use \\emph{log clustering} to reduce the effort needed to process a backlog of failing CE logs \nby grouping those logs that failed for similar reasons~\\cite{rosenberg2018:use,rosenberg:2018:improving}. \nThey build on earlier research that uses log clustering to identify problems in system logs~\\cite{Lin2016,Shang2013}.\nCommon to these approaches is how the contrast between passing and failing logs is used to improve accuracy, \nwhich is closely related to how SBLD highlights failure-relevant events.\n\nNagarash et al.~\\cite{nagaraj:2012} explore the use of dependency networks to exploit the contrast between two sets of logs, \none with good and one with bad performance, \nto help developers understand which component(s) likely contain the root cause of performance issues.\n\nAn often-occurring challenge is the need to (re)construct an interpretable model of a system's execution.\nTo this end, several authors investigate the combination of log analysis with (static) source code analysis, \nwhere they try to (partially) match events in logs to log statements in the code, \nand then use these statements to reconstruct a path through the source code to help determine \nwhat happened in a failed execution~\\cite{Xu2009,yuan:2010:sherlog,zhao2014:lprof,schipper2019:tracing}.\nGadler et al. employ Hidden Markov Models to create a model of a system's usage patterns from logged events~\\cite{gadler2017:mining}, while\nPettinato et al. model and analyze the behavior of a complex telescope system using Latent Dirichlet Allocation~\\cite{pettinato2019:log}.\n\nOther researchers have analyzed the logs for successful and failing builds, \nto warn for anti-patterns and decay~\\cite{vassallo2019:automated}, \ngive build repair hints~\\cite{Vassallo2018}, \nand automatically repair build scripts~\\cite{hassan2018:hirebuild, tarlow2019:learning}. \nOpposite to our work,\nthese techniques exploit the \\emph{overlap} in build systems used by many projects to mine patterns that hint at decay or help repair a failing build, \nwhereas we exploit the \\emph{contrast} with passing runs for the same project to highlight failure-relevant events.\n\n\\begin{sloppypar}\n\\head{Fault Localization} \nAs mentioned, our approach was inspired by Spectrum-Based Fault Localization (SBFL), \nwhere the fault-proneness of a statement is computed as a function of \nthe number of times that the statement was executed in a failing test case, combined with \nthe number of times that the statement was skipped in a passing test case~\\cite{Jones2002,Chen2002,Abreu2007,Abreu2009,Naish2011}.\nThis more or less directly translates to the inclusion or exclusion of events in failing, resp. passing logs, \nwhere the difference is that SBLD adds clustering of the results to enable step-wise presentation of results to the user. \n\\end{sloppypar}\n\nA recent survey of Software Fault Localization includes the SBFL literature up to 2014~\\cite{Wong2016}.\nDe Souza et. all extend this with SBFL work up to to 2017, and add an overview of seminal work on automated debugging from 1950 to 1977~\\cite{deSouza2017}.\nBy reflecting on the information-theoretic foundations of fault localization, Perez proposes the DDU metric, \nwhich can be used to evaluate test suites and predict their diagnostic performance when used in SBFL~\\cite{Perez2018}. \nOne avenue for future work is exploring how a metric like this can be adapted to our context, \nand see if helps to explain what happened with test 43.\n\nA recent evaluation of \\emph{pure} SBFL on large-scale software systems found that it under-performs in these situations \n(only 33-40\\% of the bugs are identified with the top 10 of ranked results~\\cite{heiden2019:evaluation}. \nThe authors discuss several directions beyond pure SBFL, such as combining it with dynamic program analysis techniques, \nincluding additional text analysis/IR techniques~\\cite{Wang2015a}, mutation based fault localization, \nand using SBFL in an interactive feedback-based process, such as whyline-debugging~\\cite{ko2008:debugging}.\nPure SBFL is closely related to the Spectrum-Based Log Diagnosis proposed here, \nso we may see similar challenges (in fact, test 43 may already show some of this). \nOf the proposed directions to go beyond pure SBFL, \nboth the inclusion of additional text analysis/IR techniques, \nand the application of Spectrum-Based Log Diagnosis in an interactive feedback-based process\nare plausible avenues to extend our approach. \nClosely related to the latter option, \nde Souza et al.~\\cite{deSouza2018b} assess guidance and filtering strategies to \\emph{contextualize} the fault localization process.\nTheir results suggest that contextualization by guidance and filtering can improve the effectiveness of SBFL,\nby classifying more actual bugs in the top ranked results.\n\n\\begin{comment}\n\nDirect comparison~\\cite{He2018, jiang2017:what, Jones:2007:DP:1273463.1273468,\nXu2009, Hwa-YouHsu:2008:RIB:1642931.1642994}.  \n\nHsu et\nal~\\cite{Hwa-YouHsu:2008:RIB:1642931.1642994} discuss methods for extracting\nfailure signatures as sequences of code executions, which in spirit is rather\nsimilar to what we are trying to accomplish.\n\nAn interesting data-structure, the event correlation\ngraph, is explores in~\\cite{Fu2012a}. An FL metric that takes frequencies into\naccount~\\cite{Shu2016}.\n\\end{comment}\n\n %\n\\section{Threats to Validity}\n\\label{sec:ttv}\n\n\\head{Construct Validity} %\nThe signatures that provide our ground truth were devised to determine whether a given log \\emph{in its entirety} showed symptoms of a known error.\nAs discussed in Section~\\ref{sec:dataset}, we have used these signatures to detect events that give sufficient evidence for a symptom, \nbut there may be other events that could be useful to the user that are not part of our ground truth.\nWe also assume that the logs exhibit exactly the failures described by the signature expression.\nIn reality, the logs could contain symptoms of multiple failures beyond the ones described by the signature.\n\nFurthermore, we currently do not distinguish between events that consist of single line of text, \nor events that contain a multi-line stack-trace, although these clearly represent different comprehension efforts.\nThis threat could be addressed by tracking the \\emph{length} of the event contents, \nand using it to further improve the accuracy of our effort reduction measure.\n\nThe choice of clustering algorithm and parameters affects the events retrieved, \nbut our investigation currently only considers HAC with complete linkage.\nWhile we chose complete linkage to favor compact clusters, \noutliers in the dataset could cause unfavorable clustering outcomes.\nFurthermore, using the uncorrected sample standard deviation as threshold criterion \nmay be too lenient if the variance in the scores is high.\nThis threat could be addressed by investigate alternative cluster algorithm and parameter choices.\n\nMoreover, as for the majority of log analysis frameworks, the performance of SBLD strongly depends on the quality of log abstraction. \nAn error in the abstraction will directly propagate to SBLD: \nFor example, if abstraction fails to identify two concrete events as being instances of the same generic event, \ntheir aggregated frequencies will be smaller and consequently treated as less interesting by SBLD.\nSimilarly, the accuracy will suffer if two events that represent distinct generic events are treated as instances of the same generic event.\nFuture work could investigate alternative log abstraction approaches.\n\n\\head{Internal Validity} %\nWhile our heatmaps illustrate the interaction between additional data and SBLD performance, \nthey are not sufficient to prove a causal relationship between performance and added data.\nOur statistical comparisons suggests that a strategy of maximizing data is generally preferable, \nbut they are not sufficient for discussing the respective contribution of failing or passing logs.\n\n\\head{External Validity} %\nThis investigation is concerned with a single dataset from one industrial partner.\nStudies using additional datasets from other contexts is needed to assess the generalizability of SBLD to other domains.\nMoreover, while SBLD is made to help users diagnose problems that are not already well understood,\nwe are assessing it on a dataset of \\emph{known} problems.\nIt could be that these errors, being known, are of a kind that are generally easier to identify than most errors.\nStudying SBLD in-situ over time and directly assessing whether end users found it helpful\nin diagnosis would better indicate the generalizability of our approach.\n\n %\n\n\\section{Concluding Remarks}\n\\label{sec:conclusion}\n\n\\head{Contributions}\nThis paper presents and evaluates Spectrum-Based Log Diagnosis (SBLD), \na method for automatically identifying segments of failing logs \nthat are likely to help users diagnose failures. \nOur empirical investigation of SBLD addresses the following questions: \n(i) How well does SBLD reduce the \\emph{effort needed} to identify all \\emph{failure-relevant events} in the log for a failing run? \n(ii) How is the \\emph{performance} of SBLD affected by \\emph{available data}? \n(iii) How does SBLD compare to searching for \\emph{simple textual patterns} that often occur in failure-relevant events? \n\n\\head{Results}\nIn response to (i), \nwe find that SBLD generally retrieves the failure-relevant events in a compact manner \nthat effectively reduces the effort needed to identify failure-relevant events. \nIn response to (ii), \nwe find that SBLD benefits from addition data, especially more logs from successful runs. \nSBLD also benefits from additional logs from failing runs if there is a proportional amount of successful runs in the set. \nWe also find that the effect of added data is most pronounced when going from little data to \\emph{some} data rather than from \\emph{some} data to maximal data. \nIn response to (iii), \nwe find that SBLD achieves roughly the same effort reduction as traditional search-based methods but obtains slightly lower recall. \nWe trace the likely cause of this discrepancy on recall to a prominent part of our dataset, whose ground truth emphasizes rare events. \nA lesson learned in this regard is that SBLD is not suited for finding statistical outliers but rather \\emph{recurring suspects} \nthat characterize the observed failures. \nFurthermore, the investigation highlights that traditional pattern-based search and SBLD can complement each other nicely: \nUsers can resort to SBLD if they are unhappy with what the pattern-based searches turn\nup, and SBLD is an excellent method for finding characteristic textual patterns\nthat can form the basis of automated failure identification methods.\n\n\\head{Conclusions}\nWe conclude that SBLD shows promise as a method diagnosing failing runs, \nthat its performance is positively affected by additional data, \nbut that it does not outperform textual search on the dataset considered. \n\n\\head{Future work}\nWe see the following directions for future work: \n(a) investigate SBLD's performance on other datasets, to better assess generalizability, \n(b) explore the impact of alternative log abstraction mechanisms,\n(c) explore ways of combining SBLD with outlier detection, to accommodate different user needs, \n(d) adapt the Perez' DDU metric to our context and see if it can help predict diagnostic efficiency,\n(e) experiment with extensions of \\emph{pure SBLD} that include additional text analysis/IR techniques, \n    or apply it in an interactive feedback-based process\n(f) rigorously assess (extensions of) SBLD in in-situ experiments.\n\n\\begin{acks}\nWe thank Marius Liaaen and Thomas Nornes of Cisco Systems Norway for help with obtaining and understanding the dataset, for developing the log abstraction\nmechanisms and for extensive discussions.\nThis work is supported by the \\grantsponsor{RCN}{Research Council of Norway}{https://www.rcn.no} through the\nCertus SFI (\\grantnum{RCN}{\\#203461/030)}.\nThe empirical evaluation was performed on resources provided by \\textsc{uninett s}igma2,\nthe national infrastructure for high performance computing and data\nstorage in Norway.\n\\end{acks}\n\n \\printbibliography\n\n\\end{document}\n&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;{'timestamp': '2020-08-18T02:18:33', 'yymm': '2008', 'arxiv_id': '2008.06948', 'language': 'en', 'url': 'https://arxiv.org/abs/2008.06948'}&quot;}}},{&quot;rowIdx&quot;:3,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;\\section{Introduction}\nWhen granular material in a cubic container is shaken\nhorizontally one observes experimentally different types of\ninstabilities, i.e. spontaneous formation of ripples in shallow\nbeds~\\cite{StrassburgerBetatSchererRehberg:1996},\nliquefaction~\\cite{RistowStrassburgerRehberg:1997,Ristow:1997}, convective\nmotion~\\cite{TennakoonBehringer:1997,Jaeger} and recurrent swelling of\nshaken material where the period of swelling decouples from the\nforcing period~\\cite{RosenkranzPoeschel:1996}. Other interesting experimental results concerning simultaneously vertically and horizontally vibrated granular systems~\\cite{TennakoonBehringer:1998} and enhanced packing of spheres due to horizontal vibrations~\\cite{PouliquenNicolasWeidman:1997} have been reported recently. Horizontally shaken\ngranular systems have been simulated numerically using cellular\nautomata~\\cite{StrassburgerBetatSchererRehberg:1996} as well as\nmolecular dynamics\ntechniques~\\cite{RistowStrassburgerRehberg:1997,Ristow:1997,IwashitaEtAl:1988,LiffmanMetcalfeCleary:1997,SaluenaEsipovPoeschel:1997,SPEpre99}.\nTheoretical work on horizontal shaking can be found\nin~\\cite{SaluenaEsipovPoeschel:1997} and the dynamics of a single\nparticle in a horizontally shaken box has been discussed\nin~\\cite{DrosselPrellberg:1997}.\n\n\\begin{figure}[htbp]\n \\centerline{\\psfig{file=sketch.eps,width=7cm,clip=}}  \n  \\caption{Sketch of the simulated system.}\n  \\label{fig:sketch}\n\\end{figure}\n\nRecently the effect of convection in a horizontally shaken box filled with \ngranular material attracted much attention and presently the effect is studied\nexperimentally by different\ngroups~\\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996}.\nUnlike the effect of convective motion in vertically shaken granular\nmaterial which has been studied intensively experimentally,\nanalytically and by means of computer simulations\n(s.~e.g.~\\cite{vertikalEX,JaegerVert,vertikalANA,vertikalMD}), there\nexist only a few references on horizontal shaking. Different from the\nvertical case, where the ``architecture'' of the convection pattern is\nvery simple~\\cite{BizonEtAl:1998}, in horizontally shaken containers one observes a variety\nof different patterns, convecting in different directions, in parallel\nas well as perpendicular to the direction of\nforcing~\\cite{TennakoonBehringer:1997}. Under certain conditions one\nobserves several convection rolls on top of each other~\\cite{Jaeger}.\nAn impression of the complicated convection can be found in the\ninternet~\\cite{movies}.\n\nWhereas the properties of convection in vertically sha\\-ken systems\ncan be reproduced by two dimensional molecular dynamics simulations\nwith good reliability, for the case of horizontal motion the results\nof simulations are inconsistent with the experimental results: in {\\em\n  all} experimental investigations it was reported that the material\nflows downwards close to the vertical\nwalls~\\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996,movies},\nbut reported numerical simulations systematically show surface rolls\nin opposite direction accompanying the more realistic deeper rolls, or\neven replacing them completely~\\cite{LiffmanMetcalfeCleary:1997}.\n\nOur investigation is thus concerned with the convection pattern, i.e. the\nnumber and direction of the convection rolls in a two dimensional\nmolecular dynamics simulation. We will show that the choice of the\ndissipative material parameters has crucial influence on the convection pattern\nand, in particular, that the type of convection rolls observed experimentally\ncan be \nreproduced by using sufficiently high dissipation constants.\n\n\\section{Numerical Model}\nThe system under consideration is sketched in Fig.~\\ref{fig:sketch}:\nwe simulate a two-dimensional vertical cross section of a three-dimensional\ncontainer.\nThis rectangular section of width $L=100$ (all units in cgs system), and\ninfinite height, contains $N=1000$ spherical particles. The system is\nperiodically driven by an external oscillator $x(t) = A \\sin (2\\pi f\nt)$ along a horizontal plane. For the effect we want to show, a\nworking frequency $f=10$ and amplitude $A=4$ is\nselected. \nThese values give an acceleration amplitude of approximately $16 g$.\nLower accelerations affect the intensity of the\nconvection but do not change the basic features of the convection \npattern which we want to discuss. \nAs has been shown in~\\cite{SPEpre99},\npast the fluidization point, a much better indicator of the convective\nstate is the dimensionless velocity $A 2\\pi f/ \\sqrt{Lg}$. This means\nthat in small containers motion saturates earlier, hence,  results for\ndifferent container lengths at the same values of the acceleration amplitude \ncannot be compared directly. Our acceleration amplitude $\\approx 16g$ corresponds to\n$\\approx 3g$ in a 10 cm container (provided that the frequency is the same\nand particle sizes have been \nscaled by the same amount).\n\n\nThe radii of the particles of density $2$ are homogeneously\ndistributed in the interval $[0.6, 1.4]$. The rough inner walls of the\ncontainer are simulated by attaching additional particles of the same\nradii and material properties (this simulation technique is similar to ``real''\nexperiments, e.g.~\\cite{JaegerVert}). \n\nFor the molecular dynamics simulations, we apply a modified\nsoft-particle model by Cundall and Strack~\\cite{CundallStrack:1979}:\nTwo particles $i$ and $j$, with radii $R_i$ and $R_j$ and at positions\n$\\vec{r}_i$ and $\\vec{r}_j$, interact if their compression $\\xi_{ij}=\nR_i+R_j-\\left|\\vec{r}_i -\\vec{r}_j\\right|$ is positive. In this case\nthe colliding spheres feel the force\n $F_{ij}^{N} \\vec{n}^N + F_{ij}^{S} \\vec{n}^S$, \nwith $\\vec{n}^N$ and $\\vec{n}^S$ being the unit vectors in normal and shear\ndirection. The normal force acting between colliding spheres reads\n\\begin{equation}\n F_{ij}^N = \\frac{Y\\sqrt{R^{\\,\\mbox{\\it\\footnotesize\\it eff}}_{ij}}}{1-\\nu^2} \n~\\left(\\frac{2}{3}\\xi_{ij}^{3/2} + B \\sqrt{\\xi_{ij}}\\, \n\\frac{d {\\xi_{ij}}}{dt} \\right)\n\\label{normal}\n\\end{equation}\nwhere $Y$ is the Young modulus, $\\nu$ is the Poisson ratio and $B$ \nis a material constant which characterizes the dissipative\ncharacter of the material~\\cite{BSHP}. \n\\begin{equation}\nR^{\\,\\mbox{\\it\\footnotesize\\it\n    eff}}_{ij} = \\left(R_i R_j\\right)/\\left(R_i + R_j\\right)  \n\\end{equation}\n is the\neffective radius. For a strict derivation of (\\ref{normal})\nsee~\\cite{BSHP,KuwabaraKono}.\n\nFor the shear force we apply the model by Haff and Werner~\\cite{HaffWerner}\n\\begin{equation}\nF_{ij}^S = \\mbox{sign}\\left({v}_{ij}^{\\,\\mbox{\\it\\footnotesize\\it rel}}\\right) \n\\min \\left\\{\\gamma_s m_{ij}^{\\,\\mbox{\\it\\footnotesize\\it eff}} \n\\left|{v}_{ij}^{\\,\\mbox{\\it\\footnotesize\\it rel}}\\right|~,~\\mu \n\\left|F_{ij}^N\\right| \\right\\} \n\\label{shear}      \n\\end{equation}\nwith the effective mass $m_{ij}^{\\,\\mbox{\\it\\footnotesize\\it eff}} =\n\\left(m_i m_j\\right)/\\left(m_i + m_j\\right)$ and the relative velocity\nat the point of contact\n\\begin{equation}\n{v}_{ij}^{\\,\\mbox{\\it\\footnotesize\\it rel}} = \\left(\\dot{\\vec{r}}_i - \n\\dot{\\vec{r}}_j\\right)\\cdot \\vec{n}^S + R_i {\\Omega}_i + R_j  {\\Omega}_j ~.\n\\end{equation}\n$\\Omega_i$ and $\\Omega_j$ are the angular velocities of the particles.\n \nThe resulting momenta $M_i$ and $M_j$ acting upon the particles are\n$M_i = F_{ij}^S R_i$ and $M_j = - F_{ij}^S R_j$. Eq.~(\\ref{shear})\ntakes into account that the particles slide upon each other for the\ncase that the Coulomb condition $\\mu \\mid F_{ij}^N \\mid~<~\\left| \nF_{ij}^S \\right|$ holds, otherwise they feel some viscous friction.\nBy means of $\\gamma _{n} \\equiv BY/(1-\\nu ^2)$ and $\\gamma _{s}$,\nnormal and shear damping coefficients, energy loss during particle\ncontact is taken into account~\\cite{restitution}.\n\nThe equations of motion for translation and rotation have been solved\nusing a Gear predictor-corrector scheme of sixth order\n(e.g.~\\cite{AllenTildesley:1987}).\n\nThe values of the coefficients used in simulations are $Y/(1-\\nu\n^2)=1\\times 10^{8}$, $\\gamma _{s}=1\\times 10^{3}$, $ \\mu =0.5$. For\nthe effect we want to show, the coefficient $\\gamma _{n}$ takes values within the range\n$\\left[10^2,10^4\\right]$.\n\n\\section{Results}\nThe mechanisms for convection under horizontal shaking have been\ndiscussed in \\cite{LiffmanMetcalfeCleary:1997}. Now we can show that\nthese mechanisms can be better understood by taking into account the\nparticular role of dissipation in this problem. The most striking\nconsequence of varying the normal damping coefficient is the change\nin organization of the convective pattern, i.e. the direction and\nnumber of rolls in the stationary regime. This is shown in\nFig.~\\ref{fig1}, which has been obtained after averaging particle\ndisplacements over 200 cycles \n(2 snapshots per cycle).\nThe asymmetry of compression and expansion of particles close to\nthe walls (where the material results highly compressible) explains \nthe large transverse velocities shown in the figure.\nNote, however, that the upward and downward motion at the walls cannot be altered \nby this particular averaging procedure. \n\nThe first frame shows a convection pattern with only two rolls, where\nthe arrows indicate that the grains slide down the walls, with at most\na slight expansion of the material at the surface. \nThere are no surface rolls.\nThis is very\nsimilar to what has been observed in\nexperiments\\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996}.\nIn this case, dissipation is high enough to damp most of the sloshing\ninduced by the vertical walls, and not even the grains just below the\nsurface can overcome the pressure gradient directed downwards.\n\nFor lower damping, we see the developing of surface rolls, \nwhich\ncoexist with the inner rolls circulating in the opposite way. Some\nenergy is now available for upward motion when the walls compress the\nmaterial fluidized during the opening of the wall ``gap'' (empty space\nwhich is created alternatively during the shaking motion). This is the\ncase reported in \\cite{LiffmanMetcalfeCleary:1997}. The last frames\ndemonstrate how the original rolls vanish at the same time that the\nsurface rolls grow occupying a significant part of the system.\nAnother feature shown in the figure is the thin layer of material involving\n3 particle rows close to the bottom, which perform a different kind\nof motion. This effect, which can be seen in all frames,\nis due to the presence of the constraining boundaries\nbut has not been analyzed separately.\n\\onecolumn\n\\begin{figure}\n\\centerline{\\psfig{file=fric1nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric2nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric3nn.eps,width=5.7cm,clip=}}\n\\centerline{\\psfig{file=fric4nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric5nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric6nn.eps,width=5.7cm,clip=}}\n\\centerline{\\psfig{file=fric7nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric8nn.eps,width=5.7cm,clip=}\n\\hspace{0.3cm}\\psfig{file=fric9nn.eps,width=5.7cm,clip=}}\n\\vspace{0.3cm}\n\\caption{Velocity field obtained after cycle averaging of \n  particle displacements, for different values of the normal damping\n  coefficient, $\\gamma_n$. The first one is $1\\times 10^4$, and for\n  obtaining each subsequent frame the coefficient has been divided by\n  two. The frames are ordered from left to right and from top to\n  bottom. The cell size for averaging is approximately one particle diameter.}\n\\label{fig1}\n\\vspace*{-0.2cm}\n\\end{figure}\n\\twocolumn\n\nWith decreasing normal damping $\\gamma_n$ there are two transitions \nobservable in Fig.~\\ref{fig1}, meaning that the convection pattern changes\nqualitatively at these two particular values of $\\gamma_n$:\nThe first transition leads to the appearance of two surface rolls\nlaying on top of the bulk cells and circulating in opposite direction.\nThe second transition eliminates the bulk rolls. A more detailed analysis of \nthe displacement fields  (Fig.~\\ref{fig2})\nallows us to locate the transitions much more precisely.\nIn Fig.~\\ref{fig2} we have represented in  grey-scale the horizontal and\nvertical components of the displacement vectors pictured in\nFig.~\\ref{fig1} but in a denser sampling, analyzing data from 30 simulations \ncorresponding to \nvalues of the normal damping coefficient within the interval [50,10000]. \nFor horizontal displacements, we have chosen vertical sections \nat some representative position in horizontal direction\n($x=30$). For the vertical displacements, vertical sections of the\nleftmost part of the container were selected ($x=10$), s.\nFig.~\\ref{fig2}, lower part.\n\\begin{figure}\n  \\centerline{\\psfig{file=vx.eps,width=4.5cm,clip=}\\hspace{-0.5cm}\n    \\psfig{file=vy.eps,width=4.5cm,clip=}\n\n\\centerline{\\psfig{file=sectionn.eps,height=4.2cm,bbllx=7pt,bblly=16pt,bburx=507pt,bbury=544pt,clip=}}\n\\vspace*{0.2cm}\n\\caption{Horizontal (left) and vertical (right) displacements at \n  selected positions of the frames in Fig.~\\ref{fig1} (see the text\n  for details), for decreasing normal damping and as a function of\n  depth. White indicates strongest flow along positive axis directions\n  (up,right), and black the corresponding negative ones. The black region \n  at the bottom of the left picture corresponds to the complex boundary\n  effect observed in Fig.~\\ref{fig1}, involving only two particle layers.\n  The \n  figure below shows a typical convection pattern together with the sections\n  at $x=10$ and $x=30$ at which the displacements were recorded.}\n\\label{fig2}\n\\vspace*{-0.1cm}\n\\end{figure}\n\nThe horizontal axis shows the values of the normal damping\ncoefficient scaled logarithmically in decreasing sequence. The\nvertical axis represents the position in vertical direction, with the\nfree surface of the system located at $y \\approx 60$.  One observes first\nthat white surface shades, complemented by subsurface black ones,\nappear quite clearly at about $\\gamma =$2000 in Fig.~\\ref{fig2}\n(left), indicating the appearance of surface rolls. On the other\nhand, Fig.~\\ref{fig2} (right) shows a black area (indicative of\ndownward flow along the vertical wall) that vanishes at\n$\\gamma_n \\approx 200$ (at this point the grey shade represents vanishing vertical velocity). \nThe dashed lines in Fig.~\\ref{fig2} lead the eye to identify the transition values.\nIn the interval $ 200 \\lesssim \\gamma_n\n\\lesssim 2000$ surface and inner rolls coexist, rotating in opposite\ndirections.\n\nOne can analyze the situation in terms of the restitution coefficient.\n\\ From Eq. (\\ref{normal}), the equation of motion for the displacement\n$\\xi_{ij}$ can be integrated and the relative energy loss in a\ncollision $\\eta=(E_0-E)/E_0$ (with $E$ and $E_0$ being the energy of\nthe relative motion of the particles) can be evaluated approximately.\nUp to the lowest order in the expansion parameter, one\nfinds~\\cite{Thomas-Thorsten}\n\\begin{equation}\n\\eta = 1.78 \\left( \\frac{\\tau}{\\ell} v_0\\right)^{1/5}\\;,\n\\label{energyloss}\n\\end{equation}\nwhere $v_0$ is the relative initial velocity in normal direction, and\n$\\tau$, $\\ell$, time and length scales associated with the problem\n(see~\\cite{Thomas-Thorsten} for details),\n\n\\begin{equation}\n\\tau = \\frac{3}{2} B\\; ,~~~~~~~~~\n\\ell = \\left(\\frac{1}{3} \\frac{m_{ij}^{\\,\\mbox{\\it\\footnotesize\\it eff}} \n}{\\sqrt{R^{\\,\\mbox{\\it\\footnotesize\\it eff}}_{ij}} \nB \\gamma_{n}}\\right)^{2}.\n\\end{equation}\nFor $\\gamma_n = 10^4$ (the highest value analyzed) and the values of\nthe parameters specified above ($v_0 \\approx A 2\\pi f$ for collisions\nwith the incoming wall), $B= 10^{-4}$ and $\\eta$ is typically\n50\\%. This means that after three more collisions the particle leaves\nwith an energy not enough to overcome the height of one single\nparticle in the gravity field. For $\\gamma_n = 10^3$ and the other\nparameters kept constant, $B=10^{-5}$ and $\\eta$ has been\nreduced to 5\\%, resulting in that the number of collisions needed for\nthe particle to have its kinetic energy reduced to the same residual\nfraction, has increased roughly by an order of magnitude. On the other\nhand, given the weak dependence of Eq. (\\ref{energyloss}) on the\nvelocity, one expects that the transitions shown in Fig.~\\ref{fig2}\nwill depend also weakly on the amplitude of the shaking velocity. The reduction of the\ninelasticity $\\eta$ by an order of magnitude seems enough for\nparticles to ``climb'' the walls and develop the characteristic\nsurface rolls observed in numerical simulations.\n\n\\section{Discussion}\nWe have shown that the value of the normal damping coefficient\ninfluences the convective pattern of horizontally shaken granular\nmaterials. By means of molecular dynamics simulations in two\ndimensions we can reproduce the pattern observed in real experiments,\nwhich corresponds to a situation of comparatively high damping,\ncharacterized by inelasticity parameters $\\eta$ larger than 5\\%. For\nlower damping, the upper layers of the material develop additional\nsurface rolls as has been reported previously. As normal damping\ndecreases, the lower rolls descend and finally disappear completely at\ninelasticities of the order of 1\\%.\n\n\\begin{acknowledgement}\nThe authors want to thank R. P. Behringer, H. M. Jaeger, M. Medved,\nand D. Rosenkranz for providing experimental results prior to\npublication and V. Buchholtz, S. E. Esipov, and L. Schimansky-Geier\nfor discussion. The calculations have been done on the parallel\nmachine {\\it KATJA} (http://summa.physik.hu-berlin.de/KATJA/) of the\nmedical department {\\em Charit\\'e} of the Humboldt University Berlin.\nThe work was supported by Deut\\-sche Forschungsgemeinschaft through\ngrant Po 472/3-2.\n\\end{acknowledgement}\n\n&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;{'timestamp': '2002-03-19T12:47:20', 'yymm': '9807', 'arxiv_id': 'cond-mat/9807071', 'language': 'en', 'url': 'https://arxiv.org/abs/cond-mat/9807071'}&quot;}}},{&quot;rowIdx&quot;:4,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\\\section{\\\\label{sec:intro}Introduction}\\n \\nDemonstration of non-abelian exchange statistics is o&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '2022-10-20T02:16:28', 'yymm': '2210', 'arxiv_id': '2210.10650', 'language': 'en', 'u&quot;}}},{&quot;rowIdx&quot;:5,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\\\section{Introduction}\\n\\nOver the last decade, imaging atmospheric Cherenkov telescopes\\n(IACTs) &quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '1998-07-13T09:54:01', 'yymm': '9807', 'arxiv_id': 'astro-ph/9807119', 'language': 'e&quot;}}},{&quot;rowIdx&quot;:6,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\\\section{Introduction}\\n\\\\label{sec:introduction}\\nA plethora of observations have led to confirm &quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '2021-11-08T02:04:43', 'yymm': '2111', 'arxiv_id': '2111.03152', 'language': 'en', 'u&quot;}}},{&quot;rowIdx&quot;:7,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\n\\n\\\\section{Introduction} \\\\label{sec:introduction}  \\\\input{introduction}\\n\\\\section{Related Wor&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '2016-06-17T02:01:41', 'yymm': '1606', 'arxiv_id': '1606.04992', 'language': 'en', 'u&quot;}}},{&quot;rowIdx&quot;:8,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\\\section{introduction}\\nRecent discovery of Weyl semimetals (WSMs)~\\\\cite{Lv2015TaAs,Xu2015TaAs,Ya&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '2016-08-18T02:05:38', 'yymm': '1608', 'arxiv_id': '1608.03404', 'language': 'en', 'u&quot;}}},{&quot;rowIdx&quot;:9,&quot;cells&quot;:{&quot;text&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;\\\\section{Introduction}\\n\\nConformal invariance was first recognised to be of physical interest whe&quot;},&quot;meta&quot;:{&quot;kind&quot;:&quot;truncated&quot;,&quot;value&quot;:&quot;\&quot;{'timestamp': '2019-04-24T02:04:30', 'yymm': '1904', 'arxiv_id': '1904.10101', 'language': 'en', 'u&quot;}}}],&quot;truncated&quot;:true},&quot;paginationData&quot;:{&quot;pageIndex&quot;:0,&quot;numItemsPerPage&quot;:100,&quot;numTotalItems&quot;:850000,&quot;offset&quot;:0,&quot;length&quot;:100}},&quot;jwt&quot;:&quot;eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc0MjkyMzA5MSwic3ViIjoiL2RhdGFzZXRzL3RvZ2V0aGVyY29tcHV0ZXIvUmVkUGFqYW1hLURhdGEtMVQtU2FtcGxlIiwiZXhwIjoxNzQyOTI2NjkxLCJpc3MiOiJodHRwczovL2h1Z2dpbmdmYWNlLmNvIn0.8NYlzxPcFB7oIfKxXeEvkfjDU3rnAdzpFq12xL5vqQ1ueWMkAC4t0uVz-dgFGbTTLWJA4tZArrCu3RBs7FPsCA&quot;,&quot;displayUrls&quot;:true},&quot;dataset&quot;:&quot;togethercomputer/RedPajama-Data-1T-Sample&quot;,&quot;isGated&quot;:false,&quot;isPrivate&quot;:false,&quot;hasParquetFormat&quot;:false,&quot;author&quot;:{&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/1678734258201-6322ad266b1992383fa964ca.png&quot;,&quot;fullname&quot;:&quot;Together&quot;,&quot;name&quot;:&quot;togethercomputer&quot;,&quot;type&quot;:&quot;org&quot;,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false,&quot;isEnterprise&quot;:true,&quot;followerCount&quot;:547},&quot;compact&quot;:true}"><div class="flex flex-col overflow-hidden shadow-xs mx-auto mb-10 rounded-lg border pt-2  px-2.5"><div class="mb-2 flex flex-wrap items-center gap-2"><div class="mr-auto flex items-center"><svg class="mr-1 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
	<div class="whitespace-nowrap font-semibold">Dataset Viewer (First 5GB)</div>
	<div class="translate-y-px z-10"><svg class="mx-1.5 text-sm text-gray-400 hover:text-black dark:hover:text-white" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M17 22v-8h-4v2h2v6h-3v2h8v-2h-3z" fill="currentColor"></path><path d="M16 8a1.5 1.5 0 1 0 1.5 1.5A1.5 1.5 0 0 0 16 8z" fill="currentColor"></path><path d="M16 30a14 14 0 1 1 14-14a14 14 0 0 1-14 14zm0-26a12 12 0 1 0 12 12A12 12 0 0 0 16 4z" fill="currentColor"></path></svg>
	</div></div>
				<a href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/tree/refs%2Fconvert%2Fparquet/plain_text" class="group mr-1 text-xs text-gray-400 max-sm:hidden"><svg class="text-[.6rem] mr-1 inline -translate-y-px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path fill="currentColor" d="M12 10H6.78A11 11 0 0 1 27 16h2A13 13 0 0 0 6 7.68V4H4v8h8zm8 12h5.22A11 11 0 0 1 5 16H3a13 13 0 0 0 23 8.32V28h2v-8h-8z"></path></svg>
						<span class="underline decoration-gray-300 group-hover:decoration-gray-400 dark:decoration-gray-500 dark:group-hover:decoration-gray-300">Auto-converted</span> to Parquet
					</a>
				<button class="btn shadow-xs flex cursor-pointer items-center rounded-sm border px-1 py-0.5 text-xs font-normal text-gray-700 hover:text-gray-800 hover:shadow-inner dark:hover:text-gray-200"><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" style="transform: rotate(360deg);"><path d="M31 16l-7 7l-1.41-1.41L28.17 16l-5.58-5.59L24 9l7 7z" fill="currentColor"></path><path d="M1 16l7-7l1.41 1.41L3.83 16l5.58 5.59L8 23l-7-7z" fill="currentColor"></path><path d="M12.419 25.484L17.639 6l1.932.518L14.35 26z" fill="currentColor"></path></svg>API</button>
					<button class="btn shadow-xs flex cursor-pointer items-center rounded-sm border px-1 py-0.5 text-xs font-normal text-gray-700 hover:text-gray-800 hover:shadow-inner dark:hover:text-gray-200"><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path d="M9.80603 2.86737H3.56107C3.37704 2.86737 3.20055 2.94048 3.07042 3.0706C2.94029 3.20073 2.86719 3.37723 2.86719 3.56126V9.80622C2.86719 9.99025 2.94029 10.1667 3.07042 10.2969C3.20055 10.427 3.37704 10.5001 3.56107 10.5001H9.80603C9.99006 10.5001 10.1666 10.427 10.2967 10.2969C10.4268 10.1667 10.4999 9.99025 10.4999 9.80622V3.56126C10.4999 3.37723 10.4268 3.20073 10.2967 3.0706C10.1666 2.94048 9.99006 2.86737 9.80603 2.86737Z" fill="currentColor" fill-opacity="0.3"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M2.40942 1.66191C2.05175 1.66191 1.7618 1.95186 1.7618 2.30953V6.76191H1.43799V2.30953C1.43799 1.77303 1.87291 1.3381 2.40942 1.3381H6.45704V1.66191H2.40942Z" fill="currentColor"></path></svg>Embed</button>

					<button class="bg-linear-to-b shadow-xs flex items-center gap-1.5 rounded-full border from-white to-red-100/90 px-2 py-0.5 text-xs font-medium text-[#2D3648] transition-shadow hover:shadow-inner dark:from-gray-900 dark:to-red-800/30 dark:text-gray-100 dark:hover:shadow-inner dark:hover:shadow-red-800/30" ><svg class="h-3.5 w-3.5 text-red-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
						<span>Data Studio</span></button></div>
		<div class="flex flex-1 flex-col overflow-hidden -mx-2.5"><div class="flex flex-1 flex-col overflow-hidden"><div class="flex min-h-0 flex-1"><div class="flex flex-1 flex-col overflow-hidden"><div class="md:-mx-2.5 flex min-w-0 flex-wrap border-t"><div class="flex min-w-0 flex-1 flex-wrap"><div class="grid flex-1 grid-cols-1 overflow-hidden text-sm md:grid-cols-2 md:place-content-center sm:mx-2.5"><label class="relative block flex-1 px-3 py-2 hover:bg-gray-50 dark:border-gray-850 dark:hover:bg-gray-950 md:border-r md:border-r-0 hidden" title="plain_text"><span class="text-gray-500">Subset (1)</span>
			<div class="flex items-center whitespace-nowrap"><span class="truncate">plain_text</span>
				<span class="mx-2 text-gray-500">Â·</span>
					<span class="text-gray-500">850k rows</span>
				<svg class="ml-auto min-w-6 pl-2" width="1em" height="1em" viewBox="0 0 12 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1 1L6 6L11 1" stroke="currentColor"></path></svg></div>
			<select class="absolute inset-0 z-10 w-full cursor-pointer border-0 bg-white text-base opacity-0"><optgroup label="Subset (1)"><option value="plain_text" selected>plain_text (850k rows)</option></optgroup></select></label>
		<label class="relative block flex-1 px-3 py-2 hover:bg-gray-50 dark:border-gray-850 dark:hover:bg-gray-900 md:border-r md:border-r" title="train"><div class="text-gray-500">Split (1)</div>
				<div class="flex items-center overflow-hidden whitespace-nowrap"><span class="truncate">train</span>
					<span class="mx-2 text-gray-500">Â·</span>
						<span class="text-gray-500">850k rows</span>
					<svg class="ml-auto min-w-6 pl-2" width="1em" height="1em" viewBox="0 0 12 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1 1L6 6L11 1" stroke="currentColor"></path></svg></div>
				<select class="absolute inset-0 z-10 w-full cursor-pointer border-0 bg-white text-base opacity-0"><optgroup label="Split (1)"><option value="train" selected>train (850k rows)</option></optgroup></select></label></div></div>
								</div>

							<div class="flex min-h-0 flex-1 flex-col ">
	<div class="bg-linear-to-r text-smd relative flex items-center dark:border-gray-900 dark:bg-gray-950 false border-t [&amp;:has(:focus)]:from-gray-50 [&amp;:has(:focus)]:to-transparent [&amp;:has(:focus)]:to-20% dark:[&amp;:has(:focus)]:from-gray-900"><form class="flex-1"><svg class="absolute left-3 top-1/2 transform -translate-y-1/2 pointer-events-none text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
				<input disabled class="outline-hidden h-9 w-full border-none bg-transparent px-1 pl-9 pr-3 placeholder:text-gray-400 " placeholder="Search this dataset" dir="auto"></form>
			<div class="flex items-center gap-2 px-2 py-1"><button type="button" class="hover:bg-yellow-200/70 flex items-center gap-1 rounded-md border border-yellow-200 bg-yellow-100 pl-0.5 pr-1 text-[.8rem] leading-normal text-gray-700 dark:border-orange-500/25 dark:bg-orange-500/20 dark:text-gray-300 dark:hover:brightness-110 hidden"><div class="rounded-sm bg-yellow-300 px-1 font-mono text-[.7rem] font-bold text-black dark:bg-yellow-700 dark:text-gray-200">SQL
	</div>
	Console
</button></div></div>


<div class="flex flex-1 flex-col overflow-hidden min-h-64 border-t">
		

<div class="max-h-96 relative overflow-auto"><table class="w-full table-auto rounded-lg font-mono text-xs text-gray-900"><thead class="shadow-xs sticky left-0 right-0 top-0 z-1 bg-white align-top"><tr class="space-y-54 h-full min-w-fit divide-x border-b text-left"><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">text
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>string</span><span class="italic text-gray-400 before:mx-1 before:content-['Â·']">lengths</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="0" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="13.2" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="26.4" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="39.599999999999994" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="52.8" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="66" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="79.19999999999999" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="92.39999999999999" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="105.6" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="118.8" y="25" width="11.2" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">4</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">5.48M</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">meta
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>string</span><span class="italic text-gray-400 before:mx-1 before:content-['Â·']">lengths</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="0" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="13.2" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="26.4" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="39.599999999999994" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="52.8" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="66" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="79.19999999999999" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="92.39999999999999" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="105.6" y="26" width="11.2" height="4" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="118.8" y="25" width="11.2" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">14</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">6.54k</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th></tr></thead>
			<tbody class="h-16 overflow-scroll"><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="0"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">\section{Introduction}
\label{sec:intro}

\emph{Gender diversity}, or more often its lack thereof, among participants to
software development activities has been thoroughly studied in recent years. In
particular, the presence of, effects of, and countermeasures for \emph{gender
  bias} in Free/Open Source Software (FOSS) have received a lot of attention
over the past decade~\cite{david2008fossdevs, qiu2010kdewomen,
  nafus2012patches, kuechler2012genderfoss, vasilescu2014gender,
  oneil2016debiansurvey, robles2016womeninfoss, terrell2017gender,
  zacchiroli2021gender}.  \emph{Geographic diversity} is on the other hand the
kind of diversity that stems from participants in some global activity coming
from different world regions and cultures.

Geographic diversity in FOSS has received relatively little attention in scholarly
works. In particular, while seminal survey-based and
point-in-time medium-scale studies of the geographic origins of FOSS
contributors exist~\cite{ghosh2005understanding, david2008fossdevs,
  barahona2008geodiversity, takhteyev2010ossgeography, robles2014surveydataset,
  wachs2021ossgeography}, large-scale longitudinal studies of the geographic
origin of FOSS contributors are still lacking. Such a quantitative
characterization would be useful to inform decisions related to global
development teams~\cite{herbsleb2007globalsweng} and hiring strategies in the
information technology (IT) market, as well as contribute factual information
to the debates on the economic impact and sociology of FOSS around the world.


\paragraph{Contributions}

With this work we contribute to close this gap by conducting \textbf{the first
  longitudinal study of the geographic origin of contributors to public code
  over 50 years.} Specifically, we provide a preliminary answer to the
following research question:
\begin{researchquestion}
  From which world regions do authors of publicly available commits come from
  and how has it changed over the past 50 years?
  \label{rq:geodiversity}
\end{researchquestion}
We use as dataset the \SWH/ archive~\cite{swhipres2017} and analyze from it
2.2 billion\xspace commits archived from 160 million\xspace projects and authored by
43 million\xspace authors during the 1971--2021 time period. 
We geolocate developers to
\DATAWorldRegions/ world regions, using as signals email country code top-level domains (ccTLDs) and 
author (first/last) names compared with name distributions around the world, and UTC offsets 
mined from commit metadata.

We find evidence of the early dominance of North America in open source
software, later joined by Europe. After that period, the geographic diversity 
in public code has been constantly increasing.
We also identify relevant historical shifts
related to the end of the UNIX wars and the increase of coding literacy in
Central and South Asia, as well as of broader phenomena like colonialism and
people movement across countries (immigration/emigration).




\paragraph{Data availability.}

A replication package for this paper is available from Zenodo at
\url{https://doi.org/10.5281/zenodo.6390355}~\cite{replication-package}.


 \section{Related Work}
\label{sec:related}

Both early and recent works~\cite{ghosh2005understanding, david2008fossdevs,
  robles2014surveydataset, oneil2016debiansurvey} have characterized the
geography of Free/Open Source Software (FOSS) using \emph{developer surveys},
which provide high-quality answers but are limited in size (2-5\,K developers)
and can be biased by participant sampling.

In 2008 Barahona et al.~\cite{barahona2008geodiversity} conducted a seminal
large-scale (for the time) study on FOSS \emph{geography using mining software
  repositories (MSR) techniques}. They analyzed the origin of 1\,M contributors
using the SourceForge user database and mailing list archives over the
1999--2005 period, using as signals information similar to ours: email domains
and UTC offsets. 
The studied period (7 years) in~\cite{barahona2008geodiversity} is shorter than 
what is studied in the present paper (50 years) and the data sources are 
largely different; with that in mind, our results show a slightly larger quote of 
European v.~North American contributions.

Another empirical work from 2010 by Takhteyev and
Hilts~\cite{takhteyev2010ossgeography} harvested self-declared geographic
locations of GitHub accounts recursively following their connections,
collecting information for $\approx$\,70\,K GitHub users.  A very recent
work~\cite{wachs2021ossgeography} by Wachs et al.~has geolocated half a million
GitHub users, having contributed at least 100 commits each, and who
self-declare locations on their GitHub profiles. While the study is
point-in-time as of 2021, the authors compare their findings
against~\cite{barahona2008geodiversity, takhteyev2010ossgeography} to
characterize the evolution of FOSS geography over the time snapshots taken by
the three studies.

Compared with previous empirical works, our study is much larger scale---having
analyzed 43 million\xspace authors of 2.2 billion\xspace commits from 160 million\xspace
projects---longitudinal over 50 years of public code contributions rather than
point in time, and also more fine-grained (with year-by-year granularity over
the observed period). Methodologically, our study relies on Version Control
System (VCS) commit data rather than platform-declared location information.


Other works---in particular the work by Daniel~\cite{daniel2013ossdiversity}
and, more recently, Rastogi et al.~\cite{rastogi2016geobias,
  rastogi2018geobias, prana2021geogenderdiversity}---have studied geographic
\emph{diversity and bias}, i.e., the extent to which the origin of FOSS
developers affect their collaborative coding activities.
In this work we characterized geographic diversity in public code for the first
time at this scale, both in terms of contributors and observation period. We do
not tackle the bias angle, but provide empirical data and findings that can be
leveraged to that end as future work.

\emph{Global software engineering}~\cite{herbsleb2007globalsweng} is the
sub-field of software engineering that has analyzed the challenges of scaling
developer collaboration globally, including the specific concern of how to deal
with geographic diversity~\cite{holmstrom2006globaldev, fraser2014eastwest}.
Decades later the present study provides evidence that can be used, in the
specific case of public code and at a very large scale, to verify which
promises of global software engineering have borne fruit.






 \section{Methodology}
\label{sec:method}


\newif\ifgrowthfig  \growthfigtrue
\ifgrowthfig
\begin{figure}
  \includegraphics[width=\columnwidth]{yearly-commits}
  \caption{Yearly public commits over time (log scale).
}
  \label{fig:growth}
\end{figure}
\fi

\paragraph{Dataset}

We retrieved from \SWH/~\cite{swh-msr2019-dataset} all commits archived until \DATALastCommitDate/.
They amount to \DATACommitsRaw/ commits, unique by SHA1 identifier, harvested from \DATATotalCommitsInSH/ public projects coming from major development forges (GitHub, GitLab, etc.) and package repositories (Debian, PyPI, NPM, etc.).
Commits in the dataset are by \DATAAuthorsRaw/ authors, unique by $\langle$name, email$\rangle$ pairs.
The dataset came as two relational tables, one for commits and one for authors, with the former referencing the latter via a foreign key.
\iflong
Each row in the commit table contains the following fields: commit SHA1 identifier, author and committer timestamps, author and committer identifiers (referencing the author table).
The distinction between commit authors and committers come from Git, which allows to commit a change authored by someone else.
For this study we focused on authors and ignored committers, as the difference between the two is not relevant for our research questions and the amount of commits with a committer other than its author is negligible.
\fi
For each entry in the author table we have author full name and email as two separate strings of raw bytes.

We removed implausible or unusable names that: are not decodable as UTF-8 (\DATAAuthorsRmNondecodable/ author names removed), are email addresses instead of names (\DATAAuthorsRmEmail/ ``names''), consist of only blank characters (\DATAAuthorsRmBlank/), contain more than 10\% non-letters (\DATAAuthorsRmNonletter/), are longer than 100 characters (\DATAAuthorsRmToolong/).
After filtering, about \DATAAuthorsPlausibleApprox/ authors (\DATAAuthorsPlausiblePct/ of the initial dataset) remained for further analysis.

Note that the amount of public code commits (and authors) contained in the
initial dataset grows exponentially over
time~\cite{swh-provenance-emse}\ifgrowthfig, as shown for commits in
\Cref{fig:growth}\else: from $10^4$ commits in 1971, to $10^6$ in 1998, to
almost $10^9$ in 2020\fi. As a consequence the observed trends tend to be more
stable in recent decades than in 40+ year-old ones, due to statistics taken on
exponentially larger populations.


\paragraph{Geolocation}

\begin{figure}
  \centering
  \includegraphics[clip,trim=6cm 6cm 0 0,width=\linewidth]{subregions-ours}
  \caption{The \DATAWorldRegions/ world regions used as geolocation targets.}
  \label{fig:worldmap}
\end{figure}

As geolocation targets we use macro world regions derived from the United Nations geoscheme~\cite{un1999geoscheme}.
To avoid domination by large countries (e.g., China or Russia) within macro regions, we merged and split some regions based on geographic proximity and the sharing of preeminent cultural identification features, such as spoken language.
\Cref{fig:worldmap} shows the final list of \DATAWorldRegions/ world regions used as geolocation targets in this study.

Geolocation of commit authors to world regions uses the two complementary techniques introduced in~\cite{icse-seis-2022-gender}, briefly recalled below.
The first one relies on the country code top-level domain (ccTLD) of email addresses extracted from commit metadata, e.g., \texttt{.fr}, \texttt{.ru}, \texttt{.cn}, etc.
We started from the IANA list of Latin character ccTLDs~\cite{wikipedia-cctld} and manually mapped each corresponding territory to a target world region.

The second geolocation technique uses the UTC offset of commit timestamps (e.g., UTC-05:00) and author names to determine the most likely world region of the commit author.
For each UTC offset we determine a list of compatible places (country, state, or dependent territory) in the world that, at the time of that commit, had that UTC offset; commit time is key here, as country UTC offsets vary over time due to timezone changes.
To make this determination we use the IANA time zone database~\cite{tzdata}.

Then we assign to each place a score that captures the likelihood that a given author name is characteristic of it.
To this end we use the Forebears dataset of the frequencies of the most common first and family names which, quoting from~\cite{forebear-names}: {\itshape ``provides the approximate incidence of forenames and surnames produced from a database of \num{4 044 546 938} people (55.5\% of living people in 2014). As of September 2019 it covers \num{27 662 801} forenames and \num{27 206 821} surnames in 236 jurisdictions.''}
As in our dataset authors are full name strings (rather than split by first/family name), we first tokenize names (by blanks and case changes) and then lookup individual tokens in both first and family names frequency lists.
For each element found in name lists we multiply the place population\footnotemark{} by the name frequency to obtain a measure that is proportional to the number of persons bearing that name (token) in the specific place.
\footnotetext{To obtain population totals---as the notion of ``place'' is heterogeneous: full countries v.~slices of large countries spanning multiple timezones---we use a mixture of primary sources (e.g., government websites), and non-primary ones (e.g., Wikipedia articles).}
We sum this figure for all elements to obtain a place score, ending up with a list of $\langle$place, score$\rangle$ pairs.
We then partition this list by the world region that a place belongs to and sum the score for all the places in each region to obtain an overall score, corresponding to the likelihood that the commit belongs to a given world region.
We assign the starting commit as coming from the world region with the highest score.

The email-based technique suffers from the limited and unbalanced use of ccTLDs: most developers use generic TLDs such as \texttt{.com}, \texttt{.org}, or \texttt{.net}.
Moreover this does not happen uniformly across zones: US-based developers, for example, use the \texttt{.us} ccTLD much more seldomly than their European counterparts.
On the other hand the offset/name-based technique relies on the UTC offset of the commit timestamps.
Due to tool configurations on developer setups, a large number of commits in the dataset has an UTC offset equal to zero.
This affects less recent commits (\DATACommitsTZZTwoThousandTwenty/ of 2020s commits have a zero offset) than older ones (\DATACommitsTZZTwoThousand/ in 2000).
As a result the offset/name-based technique could end up detecting a large share of older commits as authored by African developers, and to a lesser extent Europeans.

To counter these issues we combine the two geolocation techniques together by applying the offset/name-based techniques to all commits with a non-zero UTC offset, and the email-based on to all other commits.


 \section{Results and Discussion}
\label{sec:results}

\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{stacked.pdf}
  \caption{Ratio of commits (above) and active authors (below) by world zone over the 1971--2020 period.}
  \Description[Chart]{Stacked bar chart showing the world zone ratios for commits and authors over the 1971--2020 period.}
  \label{fig:results}
\end{figure*}


 
To answer \cref{rq:geodiversity} we gathered the number of commits and distinct authors per year and per world zone.
We present the obtained results in \Cref{fig:results} as two stacked bar charts, showing yearly breakdowns for commits and authors respectively.
Every bar represents a year and is partitioned in slices showing the commit/author ratio for each of the world regions of \Cref{fig:worldmap} in that year.
To avoid outliers due to sporadic contributors, in the author chart we only consider authors having contributed at least 5 commits in a given year.

While observing trends in the charts remember that the total numbers of commits and authors grow exponentially over time.
Hence for the first years in the charts, the number of data points in some world regions can be extremely small, with negative consequences on the stability of trends.




\paragraph{Geographic diversity over time}

Overall, the general trend appears to be that the \textbf{geographic diversity in public code is increasing}: North America and Europe alternated their ``dominance'' until the middle of the 90s; from that moment on most other world regions show a slow but steady increment.
This trend of increased participation into public code development includes Central and South Asia (comprising India), Russia, Africa, Central and South America,
Notice that also zones that do not seem to follow this trend, such as Australia and New Zealand, are also increasing their participation, but at a lower speed with respect to other zones.
For example, Australia and New Zealand incremented the absolute number of their commits by about 3 orders of magnitude from 2000 to present days.

Another interesting phenomenon that can be appreciated in both charts is the sudden contraction of contributions from North America in 1995; since the charts depict ratios, this corresponds to other zones, and Europe in particular, increasing their share.
An analysis of the main contributions in the years right before the contraction shows that nine out of ten have \texttt{ucbvax.Berkeley.EDU} as author email domain, and the tenth is Keith Bostic, one of the leading Unix BSD developers, appearing with email \texttt{bostic}.
No developer with the same email domain appears anymore within the first hundred contributors in 1996.
This shows the relevance that BSD Unix and the Computer Systems Research Group at the University of California at Berkeley had in the history of open source software.
The group was disbanded in 1995, partially as a consequence of the so-called UNIX wars~\cite{kernighan2019unixhistory}, and this contributes significantly---also because of the relatively low amount of public code circulating at the time---to the sudden drop of contributions from North America in subsequent years.
Descendant UNIX operating systems based on BSD, such as OpenBSD, FreeBSD, and NetBSD had smaller relevance to world trends due to (i) the increasing amount of open source code coming from elsewhere and (ii) their more geographically diverse developer community.

Another time frame in which the ratios for Europe and North America are subject to large, sudden changes is 1975--79.
A preliminary analysis shows that these ratios are erratic due to the very limited number of commits in those time period, but we were unable to detect a specific root cause.
Trends for those years should be subject to further studies, in collaboration with software historians.


\paragraph{Colonialism}

Another trend that stands out from the charts is that Africa appears to be well represented.
To assess if this results from a methodological bias, we double-checked the commits detected as originating from Africa for timezones included in the $[0, 3]$ range using both the email- the offset/name-based methods.
The results show that the offset/name-based approach assigns 22.7\% of the commits to Africa whereas the email-based one only assigns 2.7\% of them.
While a deeper investigation is in order, it is our opinion that the phenomenon we are witnessing here is a consequence of colonialism, specifically the adoption of Europeans names in African countries.
For example the name Eric, derived from Old Norse, is more popular in Ghana than it is in France or in the UK.
This challenges the ability of the offset/name-based method to correctly differentiate between candidate places.
Together with the fact that several African countries are largely populated, the offset/name-based method could detect European names as originating from Africa.
While this cuts both way, the likelihood of a random person contributing to public code is very different between European countries, all having a well-developed software industry, and African countries that do not all share this trait.


\paragraph{Immigration/emigration}

Another area where a similar phenomenon could be at play is the evolution of Central and South America.
Contribution from this macro region appears to be growing steadily.
To assess if this is the result of a bias introduced by the name-based detection we analyzed the evolution of offset/name-based assignment over time for authors whose email domain is among the top-ten US-based entities in terms of overall contributions (estimated in turn by analyzing the most frequent email domains and manually selecting those belonging to US-based entities).
In 1971 no author with an email from top US-based entities is detected as belonging to Central and South America, whereas in 2019 the ratio is 12\%.
Nowadays more than one tenth of the people email-associated to top US-based entities have popular Central and South American names, which we posit as a likely consequence of immigration into US (emigration from Central and South America).
Since immigration has a much longer history than what we are studying here, what we are witnessing probably includes long-term consequences of it, such as second and third generation immigrants employed in white-collar jobs, such as software development.




 \section{Limitations and Future Work}
\label{sec:conclusion}

We have performed an exploratory, yet very large scale, empirical study of the geographic diversity in public code commits over time.
We have analyzed 2.2 billion\xspace public commits covering the \DATAYearRange/ time period.
We have geolocated developers to \DATAWorldRegions/ world regions using as signals email domains, timezone offsets, and author names.
Our findings show that the geographic diversity in public code is increasing over time, and markedly so over the past 20--25 years.
Observed trends also co-occur with historical events and macro phenomena like the end of the UNIX wars, increase of coding literacy around the world, colonialism, and immigration.


\medskip
\emph{Limitations.}
This study relies on a combination of two geolocation methods: one based on email domains, another based on commit UTC offsets and author names.
We discussed some of the limitations of either method in \Cref{sec:method}, motivating our decision of restricting the use of the email-based method to commits with a zero UTC offset.
As a consequence, for most commits in the dataset the offset/name-based method is used.
With such method, the frequencies of forenames and surnames are used to rank candidate zones that have a compatible UTC offset at commit time.

A practical consequence of this is that for commits with, say, offset UTC+09:00 the candidate places can be Russia, Japan and Australia, depending on the specific date due to daylight saving time.
Popular forenames and surnames in these regions tend to be quite different so the likelihood of the method to provide a reliable detection is high.
For other offsets the set of popular forenames and surnames from candidate zones can exhibit more substantial overlaps, negatively impacting detection accuracy.
We have discussed some of these cases in \Cref{sec:results}, but other might be lingering in the results impacting observed trends.

The choice of using the email-based method for commits with zero UTC offset, and the offset/name-based method elsewhere, has allowed us to study all developers not having a country-specific email domain (ccTLD), but comes with the risk of under-representing the world zones that have (in part and in some times of the year) an actual UTC offset of zero.

A potential bias in this study could be introduced by the fact that the name database used for offset/name-based geolocation only contains names formed using Latin alphabet characters.
We looked for names containing Chinese, Japanese, and Korean characters in the original dataset, finding only a negligible amount of authors who use non-Latin characters in their VCS names, which leads us to believe that the impact of this issue is minimal.

We did not apply identity merging (e.g., using state-of-the-art tools like SortingHat~\cite{moreno2019sortinghat}), but we do not expect this to be a significant issue because: (a) to introduce bias in author trends the distribution of identity merges around the world should be uneven, which seems unlikely; and (b) the observed commit trends (which would be unaffected by identity merging) are very similar to observed author trends.

We did not systematically remove known bot accounts~\cite{lebeuf2018swbots} from the author dataset, but we did check for the presence of software bots among the top committers of each year. We only found limited traces of continuous integration (CI) bots, used primarily to automate merge commits. After removing CI bots from the dataset the observed global trends were unchanged, therefore this paper presents unfiltered data.


\medskip
\emph{Future work.}
To some extent the above limitations are the price to pay to study such a large dataset: there exists a trade-off between large-scale analysis and accuracy.
We plan nonetheless to further investigate and mitigate them in future work.
Multi-method approaches, merging data mining with social science methods, could be applied to address some of the questions raised in this exploratory study.
While they do not scale to the whole dataset, multi-methods can be adopted to dig deeper into specific aspects, specifically those related to social phenomena.
Software is a social artifact, it is no wonder that aspects related to sociocultural evolution emerge when analyzing its evolution at this scale.




 
\clearpage


</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">{'timestamp': '2022-03-30T02:27:00', 'yymm': '2203', 'arxiv_id': '2203.15369', 'language': 'en', 'url': 'https://arxiv.org/abs/2203.15369'}</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="1"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">\section{Introduction}

One of the fundamental ingredients in the theory of non-commutative or
quantum geometry is the notion of a differential calculus.
In the framework of quantum groups the natural notion
is that of a
bicovariant differential calculus as introduced by Woronowicz
\cite{Wor_calculi}. Due to the allowance of non-commutativity
the uniqueness of a canonical calculus is lost.
It is therefore desirable to classify the possible choices.
The most important piece is the space of one-forms or ``first
order differential calculus'' to which we will restrict our attention
in the following. (From this point on we will use the term
``differential calculus'' to denote a
bicovariant first order differential calculus).

Much attention has been devoted to the investigation of differential
calculi on quantum groups $C_q(G)$ of function algebra type for
$G$ a simple Lie group.
Natural differential calculi on matrix quantum groups were obtained by
Jurco \cite{Jur} and
Carow-Watamura et al.\
\cite{CaScWaWe}. A partial classification of calculi of the same
dimension as the natural ones
was obtained by
Schm\"udgen and Sch\"uler \cite{ScSc2}.
More recently, a classification theorem for factorisable
cosemisimple quantum groups was obtained by Majid \cite{Majid_calculi},
covering the general $C_q(G)$ case. A similar result was
obtained later by Baumann and Schmitt \cite{BaSc}.
Also, Heckenberger and Schm\"udgen \cite{HeSc} gave a
complete classification on $C_q(SL(N))$ and $C_q(Sp(N))$. 


In contrast, for $G$ not simple or semisimple the differential calculi
on $C_q(G)$
are largely unknown. A particularly basic case is the Lie group $B_+$
associated with the Lie algebra $\lalg{b_+}$ generated by two elements
$X,H$ with the relation $[H,X]=X$. The quantum enveloping algebra
\ensuremath{U_q(\lalg{b_+})}{}
is self-dual, i.e.\ is non-degenerately paired with itself \cite{Drinfeld}.
This has an interesting consequence: \ensuremath{U_q(\lalg{b_+})}{} may be identified with (a
certain algebraic model of) \ensuremath{C_q(B_+)}. The differential calculi on this
quantum group and on its ``classical limits'' \ensuremath{C(B_+)}{} and \ensuremath{U(\lalg{b_+})}{}
will be the main concern of this paper. We pay hereby equal attention
to the dual notion of ``quantum tangent space''.

In section \ref{sec:q} we obtain the complete classification of differential
calculi on \ensuremath{C_q(B_+)}{}. It turns out that (finite
dimensional) differential
calculi are characterised by finite subsets $I\subset\mathbb{N}$.
These
sets determine the decomposition into coirreducible (i.e.\ not
admitting quotients) differential calculi
characterised by single integers. For the coirreducible calculi the
explicit formulas for the commutation relations and braided
derivations are given.

In section \ref{sec:class} we give the complete classification for the
classical function algebra \ensuremath{C(B_+)}{}. It is essentially the same as in the
$q$-deformed setting and we stress this by giving an almost
one-to-one correspondence of differential calculi to those obtained in
the previous section. In contrast, however, the decomposition and
coirreducibility properties do not hold at all. (One may even say that
they are maximally violated). We give the explicit formulas for those
calculi corresponding to coirreducible ones.

More interesting perhaps is the ``dual'' classical limit. I.e.\ we
view \ensuremath{U(\lalg{b_+})}{} as a quantum function algebra with quantum enveloping
algebra \ensuremath{C(B_+)}{}. This is investigated in section \ref{sec:dual}. It
turns out that in this setting we have considerably more freedom in
choosing a
differential calculus since the bicovariance condition becomes much
weaker. This shows that this dual classical limit is in a sense
``unnatural'' as compared to the ordinary classical limit of section
\ref{sec:class}. 
However, we can still establish a correspondence of certain
differential calculi to those of section \ref{sec:q}. The
decomposition properties are conserved while the coirreducibility
properties are not.
We give the
formulas for the calculi corresponding to coirreducible ones.

Another interesting aspect of viewing \ensuremath{U(\lalg{b_+})}{} as a quantum function
algebra is the connection to quantum deformed models of space-time and
its symmetries. In particular, the $\kappa$-deformed Minkowski space
coming from the $\kappa$-deformed Poincar\'e algebra
\cite{LuNoRu}\cite{MaRu} is just a simple generalisation of \ensuremath{U(\lalg{b_+})}.
We use this in section \ref{sec:kappa} to give
a natural $4$-dimensional differential calculus. Then we show (in a
formal context) that integration is given by
the usual Lesbegue integral on $\mathbb{R}^n$ after normal ordering.
This is obtained in an intrinsic context different from the standard
$\kappa$-Poincar\'e approach.

A further important motivation for the investigation of differential
calculi on
\ensuremath{U(\lalg{b_+})}{} and \ensuremath{C(B_+)}{} is the relation of those objects to the Planck-scale
Hopf algebra \cite{Majid_Planck}\cite{Majid_book}. This shall be
developed elsewhere.

In the remaining parts of this introduction we will specify our
conventions and provide preliminaries on the quantum group \ensuremath{U_q(\lalg{b_+})}, its
deformations, and differential calculi.


\subsection{Conventions}

Throughout, $\k$ denotes a field of characteristic 0 and
$\k(q)$ denotes the field of rational
functions in one parameter $q$ over $\k$.
$\k(q)$ is our ground field in
the $q$-deformed setting, while $\k$ is the
ground field in the ``classical'' settings.
Within section \ref{sec:q} one could equally well view $\k$ as the ground
field with $q\in\k^*$ not a root of unity. This point of view is
problematic, however, when obtaining ``classical limits'' as
in sections \ref{sec:class} and \ref{sec:dual}.

The positive integers are denoted by $\mathbb{N}$ while the non-negative
integers are denoted by $\mathbb{N}_0$.
We define $q$-integers, $q$-factorials and
$q$-binomials as follows:
\begin{gather*}
[n]_q=\sum_{i=0}^{n-1} q^i\qquad
[n]_q!=[1]_q [2]_q\cdots [n]_q\qquad
\binomq{n}{m}=\frac{[n]_q!}{[m]_q! [n-m]_q!}
\end{gather*}
For a function of several variables (among
them $x$) over $\k$ we define
\begin{gather*}
(T_{a,x} f)(x) = f(x+a)\\
(\fdiff_{a,x} f)(x) = \frac{f(x+a)-f(x)}{a}
\end{gather*}
with $a\in\k$ and similarly over $\k(q)$
\begin{gather*}
(Q_{m,x} f)(x) = f(q^m x)\\
(\partial_{q,x} f)(x) = \frac{f(x)-f(qx)}{x(1-q)}\\
\end{gather*}
with  $m\in\mathbb{Z}$.

We frequently use the notion of a polynomial in an extended
sense. Namely, if we have an algebra with an element $g$ and its
inverse $g^{-1}$ (as
in \ensuremath{U_q(\lalg{b_+})}{}) we will mean by a polynomial in $g,g^{-1}$ a finite power
series in $g$ with exponents in $\mathbb{Z}$. The length of such a polynomial
is the difference between highest and lowest degree.

If $H$ is a Hopf algebra, then $H^{op}$ will denote the Hopf algebra
with the opposite product.

\subsection{\ensuremath{U_q(\lalg{b_+})}{} and its Classical Limits}
\label{sec:intro_limits}

We recall that,
in the framework of quantum groups, the duality between enveloping algebra
$U(\lalg{g})$ of the Lie algebra and algebra of functions $C(G)$ on the Lie
group carries over to $q$-deformations.
In the case of
$\lalg{b_+}$, the
$q$-deformed enveloping algebra \ensuremath{U_q(\lalg{b_+})}{} defined over $\k(q)$ as
\begin{gather*}
U_q(\lalg{b_+})=\k(q)\langle X,g,g^{-1}\rangle \qquad
\text{with relations} \\
g g^{-1}=1 \qquad Xg=qgX \\
\cop X=X\otimes 1 + g\otimes X \qquad
\cop g=g\otimes g \\
\cou (X)=0 \qquad \cou (g)=1 \qquad
\antip X=-g^{-1}X \qquad \antip g=g^{-1}
\end{gather*}
is self-dual. Consequently, it
may alternatively be viewed as the quantum algebra \ensuremath{C_q(B_+)}{} of
functions on the Lie group $B_+$ associated with $\lalg{b_+}$.
It has two classical limits, the enveloping algebra \ensuremath{U(\lalg{b_+})}{}
and the function algebra $C(B_+)$.
The transition to the classical enveloping algebra is achieved by
replacing $q$
by $e^{-t}$ and $g$ by $e^{tH}$ in a formal power series setting in
$t$, introducing a new generator $H$. Now, all expressions are written in
the form $\sum_j a_j t^j$ and only the lowest order in $t$ is kept.
The transition to the classical function algebra on the other hand is
achieved by setting $q=1$.
This may be depicted as follows:
\[\begin{array}{c @{} c @{} c @{} c}
&amp; \ensuremath{U_q(\lalg{b_+})} \cong \ensuremath{C_q(B_+)} &amp;&amp; \\
&amp; \diagup \hspace{\stretch{1}} \diagdown &amp;&amp; \\
 \begin{array}{l} q=e^{-t} \\ g=e^{tH} \end{array} \Big| _{t\to 0} 
 &amp;&amp; q=1 &amp;\\
 \swarrow &amp;&amp;&amp; \searrow \\
 \ensuremath{U(\lalg{b_+})} &amp; &lt;\cdots\textrm{dual}\cdots> &amp;&amp; \ensuremath{C(B_+)}
\end{array}\]
The self-duality of \ensuremath{U_q(\lalg{b_+})}{} is expressed as a pairing
$\ensuremath{U_q(\lalg{b_+})}\times\ensuremath{U_q(\lalg{b_+})}\to\k$
with
itself:
\[\langle X^n g^m, X^r g^s\rangle =
 \delta_{n,r} [n]_q!\, q^{-n(n-1)/2} q^{-ms}
 \qquad\forall n,r\in\mathbb{N}_0\: m,s\in\mathbb{Z}\]
In the classical limit this becomes the pairing $\ensuremath{U(\lalg{b_+})}\times\ensuremath{C(B_+)}\to\k$
\begin{equation}
\langle X^n H^m, X^r g^s\rangle =
 \delta_{n,r} n!\, s^m\qquad \forall n,m,r\in\mathbb{N}_0\: s\in\mathbb{Z}
\label{eq:pair_class}
\end{equation} 



\subsection{Differential Calculi and Quantum Tangent Spaces}

In this section we recall some facts about differential calculi
along the lines of Majid's treatment in \cite{Majid_calculi}.

Following Woronowicz \cite{Wor_calculi}, first order bicovariant differential
calculi on a quantum group $A$ (of
function algebra type) are in one-to-one correspondence to submodules
$M$ of $\ker\cou\subset A$ in the category $^A_A\cal{M}$ of (say) left
crossed modules of $A$ via left multiplication and left adjoint
coaction:
\[
a\triangleright v = av \qquad \mathrm{Ad_L}(v)
 =v_{(1)}\antip v_{(3)}\otimes v_{(2)}
\qquad \forall a\in A, v\in A
\]
More precisely, given a crossed submodule $M$, the corresponding
calculus is given by $\Gamma=\ker\cou/M\otimes A$ with $\diff a =
\pi(\cop a - 1\otimes a)$ ($\pi$ the canonical projection).
The right action and coaction on $\Gamma$ are given by
the right multiplication and coproduct on $A$, the left action and
coaction by the tensor product ones with $\ker\cou/M$ as a left
crossed module. In all of what follows, ``differential calculus'' will
mean ``bicovariant first order differential calculus''.

Alternatively \cite{Majid_calculi}, given in addition a quantum group $H$
dually paired with $A$
(which we might think of as being of enveloping algebra type), we can
express the coaction of $A$ on
itself as an action of $H^{op}$ using the pairing:
\[
h\triangleright v = \langle h, v_{(1)} \antip v_{(3)}\rangle v_{(2)}
\qquad \forall h\in H^{op}, v\in A
\]
Thereby we change from the category of (left) crossed $A$-modules to
the category of left modules of the quantum double $A\!\bowtie\! H^{op}$.

In this picture the pairing between $A$ and $H$ descends to a pairing
between $A/\k 1$ (which we may identify with $\ker\cou\subset A$) and
$\ker\cou\subset H$. Further quotienting $A/\k 1$ by $M$ (viewed in
$A/\k 1$) leads to a pairing with the subspace $L\subset\ker\cou H$
that annihilates $M$. $L$ is called a ``quantum tangent space''
and is dual to the differential calculus $\Gamma$ generated by $M$ in
the sense that $\Gamma\cong \Lin(L,A)$ via
\begin{equation}
A/(\k 1+M)\otimes A \to \Lin(L,A)\qquad
v\otimes a \mapsto \langle \cdot, v\rangle a
\label{eq:eval}
\end{equation}
if the pairing between $A/(\k 1+M)$ and $L$ is non-degenerate.

The quantum tangent spaces are obtained directly by dualising the
(left) action of the quantum double on $A$ to a (right) action on
$H$. Explicitly, this is the adjoint action and the coregular action
\[
h \triangleright x = h_{(1)} x \antip h_{(2)} \qquad
a \triangleright x = \langle x_{(1)}, a \rangle x_{(2)}\qquad
 \forall h\in H, a\in A^{op},x\in A
\]
where we have converted the right action to a left action by going
from \mbox{$A\!\bowtie\! H^{op}$}-modules to \mbox{$H\!\bowtie\! A^{op}$}-modules.
Quantum tangent spaces are subspaces of $\ker\cou\subset H$ invariant
under the projection of this action to $\ker\cou$ via \mbox{$x\mapsto
x-\cou(x) 1$}. Alternatively, the left action of $A^{op}$ can be
converted to a left coaction of $H$ being the comultiplication (with
subsequent projection onto $H\otimes\ker\cou$).

We can use the evaluation map (\ref{eq:eval})
to define a ``braided derivation'' on elements of the quantum tangent
space via
\[\partial_x:A\to A\qquad \partial_x(a)={\diff a}(x)=\langle
x,a_{(1)}\rangle a_{(2)}\qquad\forall x\in L, a\in A\]
This obeys the braided derivation rule
\[\partial_x(a b)=(\partial_x a) b
 + a_{(2)} \partial_{a_{(1)}\triangleright x}b\qquad\forall x\in L, a\in A\]

Given a right invariant basis $\{\eta_i\}_{i\in I}$ of $\Gamma$ with a
dual basis $\{\phi_i\}_{i\in I}$ of $L$ we have
\[{\diff a}=\sum_{i\in I} \eta_i\cdot \partial_i(a)\qquad\forall a\in A\]
where we denote $\partial_i=\partial_{\phi_i}$. (This can be easily
seen to hold by evaluation against $\phi_i\ \forall i$.)


\section{Classification on \ensuremath{C_q(B_+)}{} and \ensuremath{U_q(\lalg{b_+})}{}}
\label{sec:q}

In this section we completely classify differential calculi on \ensuremath{C_q(B_+)}{}
and, dually, quantum tangent spaces on \ensuremath{U_q(\lalg{b_+})}{}. We start by
classifying the relevant crossed modules and then proceed to a
detailed description of the calculi.

\begin{lem}
\label{lem:cqbp_class}
(a) Left crossed \ensuremath{C_q(B_+)}-submodules $M\subseteq\ensuremath{C_q(B_+)}$ by left
multiplication and left
adjoint coaction are in one-to-one correspondence to
pairs $(P,I)$
where $P\in\k(q)[g]$ is a polynomial with $P(0)=1$ and $I\subset\mathbb{N}$ is
finite.
$\codim M&lt;\infty$ iff $P=1$. In particular $\codim M=\sum_{n\in I}n$
if $P=1$.

(b) The finite codimensional maximal $M$
correspond to the pairs $(1,\{n\})$ with $n$ the
codimension. The infinite codimensional maximal $M$ are characterised by
$(P,\emptyset)$ with $P$ irreducible and $P(g)\neq 1-q^{-k}g$ for any
$k\in\mathbb{N}_0$.

(c) Crossed submodules $M$ of finite
codimension are intersections of maximal ones.
In particular $M=\bigcap_{n\in I} M^n$, with $M^n$ corresponding to
$(1,\{n\})$.
\end{lem}
\begin{proof}
(a) Let $M\subseteq\ensuremath{C_q(B_+)}$ be a crossed \ensuremath{C_q(B_+)}-submodule by left
multiplication and left adjoint coaction and let
$\sum_n X^n P_n(g) \in M$, where $P_n$ are polynomials in $g,g^{-1}$
(every element of \ensuremath{C_q(B_+)}{} can be expressed in
this form). From the formula for the coaction ((\ref{eq:adl}), see appendix)
we observe that for all $n$ and for all $t\le n$ the element
\[X^t P_n(g) \prod_{s=1}^{n-t} (1-q^{s-n}g)\]
lies in $M$.
In particular
this is true for $t=n$, meaning that elements of constant degree in $X$
lie separately in $M$. It is therefore enough to consider such
elements.

Let now $X^n P(g) \in M$.
By left multiplication $X^n P(g)$ generates any element of the form
$X^k P(g) Q(g)$, where $k\ge n$ and $Q$ is any polynomial in
$g,g^{-1}$. (Note that $Q(q^kg) X^k=X^k Q(g)$.)
We see that $M$ contains the following elements:
\[\begin{array}{ll}
\vdots &amp; \\
X^{n+2} &amp; P(g) \\
X^{n+1} &amp; P(g) \\
X^n &amp; P(g) \\
X^{n-1} &amp; P(g) (1-q^{1-n}g) \\
X^{n-2} &amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \\
\vdots &amp; \\
X &amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \ldots (1-q^{-1}g) \\
&amp; P(g) (1-q^{1-n}g) (1-q^{2-n}g) \ldots (1-q^{-1}g)(1-g) 
\end{array}
\]
Moreover, if $M$ is generated by $X^n P(g)$ as a module
then these elements generate a basis for $M$ as a vector
space by left
multiplication with polynomials in $g,g^{-1}$. (Observe that the
application of the coaction to any of the elements shown does not
generate elements of new type.)

Now, let $M$ be a given crossed submodule. We pick, among the
elements in $M$ of the form $X^n P(g)$ with $P$ of minimal
length,
one
with lowest degree in $X$. Then certainly the elements listed above are
in $M$. Furthermore for any element of the form $X^k Q(g)$, $Q$ must
contain $P$ as a factor and for $k&lt;n$, $Q$ must contain $P(g) (1-q^{1-n}g)$
as a factor. We continue by picking the smallest $n_2$, so that
$X^{n_2} P(g) (1-q^{1-n}g) \in M$. Certainly $n_2&lt;n$. Again, for any
element of $X^l Q(g)$ in $M$ with $l&lt;n_2$, we have that
$P(g) (1-q^{1-n}g) (1-q^{1-n_2}g)$ divides Q(g). We proceed by
induction, until we arrive at degree zero in $X$.

We obtain the following elements generating a basis for $M$ by left
multiplication with polynomials in $g,g^{-1}$ (rename $n_1=n$):

\[ \begin{array}{ll}
\vdots &amp; \\
X^{n_1+1} &amp; P(g) \\
X^{n_1} &amp; P(g) \\
X^{n_1-1} &amp; P(g) (1-q^{1-{n_1}}g) \\
\vdots &amp; \\
X^{n_2} &amp; P(g) (1-q^{1-{n_1}}g) \\
X^{n_2-1} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-n_2})\\
\vdots &amp; \\
X^{n_3} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-{n_2}}g) \\
X^{n_3-1} &amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-{n_2}}g) (1-q^{1-n_3})\\
\vdots &amp; \\
&amp; P(g) (1-q^{1-{n_1}}g) (1-q^{1-n_2}g) (1-q^{1-n_3}g) \ldots (1-q^{1-n_m}g) 
\end{array}
\]
We see that the integers $n_1,\ldots,n_m$ uniquely determine the shape
of this picture. The polynomial $P(g)$ on the other hand can be
shifted (by $g$ and $g^{-1}$) or renormalised. To determine $M$
uniquely we shift and normalise $P$ in such a way that it contains no
negative powers
and has unit constant coefficient. $P$ can then be viewed as a
polynomial $\in\k(q)[g]$.

We see that the codimension of $M$ is the sum of the lengths of the
polynomials in $g$ over all degrees in $X$ in the above
picture. Finite codimension corresponds to $P=1$. In this
case the codimension is the sum
$n_1+\ldots +n_m$.

(b) We observe that polynomials of the form $1-q^{j}g$
have no common divisors for distinct $j$. Therefore,
finite codimensional crossed
submodules are maximal if and only if
there is just one integer ($m=1$). Thus, the maximal left
crossed submodule of
codimension $k$ is generated by $X^k$ and $1-q^{1-k}g$.
For an infinite codimensional crossed submodule we certainly need
$m=0$. Then, the maximality corresponds to irreducibility of
$P$.

(c) This is again due to the distinctness of factors $1-q^j g$.
\end{proof}


\begin{cor}
\label{cor:cqbp_eclass}
(a) Left crossed \ensuremath{C_q(B_+)}-submodules $M\subseteq\ker\cou\subset\ensuremath{C_q(B_+)}$
are in one-to-one correspondence to pairs
$(P,I)$ as in lemma \ref{lem:cqbp_class}
with the additional constraint $(1-g)$ divides $P(g)$ or $1\in I$.
$\codim M&lt;\infty$ iff $P=1$. In particular $\codim M=(\sum_{n\in I}n)-1$
if $P=1$.

(b) The finite codimensional maximal $M$
correspond to the pairs
$(1,\{1,n\})$ with $n\ge 2$ the
codimension. The infinite codimensional maximal $M$ correspond to pairs
$(P,\{1\})$ with $P$ irreducible and $P(g)\neq 1-q^{-k}g$ for any
$k\in\mathbb{N}_0$.

(c) Crossed submodules $M$ of finite
codimension are intersections of maximal ones.
In particular $M=\bigcap_{n\in I} M^n$, with $M^n$ corresponding to
$(1,\{1,n\})$.
\end{cor}
\begin{proof}
First observe that $\sum_n X^n P_n(g)\in \ker\cou$ if and only if
$(1-g)$ divides $P_0(g)$. This is to say that that $\ker\cou$
is the crossed submodule corresponding to the pair $(1,\{1\})$ in
lemma \ref{lem:cqbp_class}. We obtain the classification
from the one of lemmas \ref{lem:cqbp_class} by intersecting
everything with this crossed submodule. In particular, this reduces
the codimension by one in the finite codimensional case.
\end{proof}



\begin{lem}
\label{lem:uqbp_class}
(a) Left crossed \ensuremath{U_q(\lalg{b_+})}-submodules $L\subseteq\ensuremath{U_q(\lalg{b_+})}$ via the left adjoint
action and left
regular coaction are in one-to-one correspondence to the set
$3^{\mathbb{N}_0}\times2^{\mathbb{N}}$.
Finite dimensional $L$ are in one-to-one correspondence to
finite sets $I\subset\mathbb{N}$ and $\dim L=\sum_{n\in I}n$.

(b) Finite dimensional irreducible $L$ correspond to $\{n\}$
with $n$ the dimension.

(c) Finite dimensional $L$ are direct sums of irreducible ones. In
particular $L=\oplus_{n\in I} L^n$ with $L^n$ corresponding to $\{n\}$.
\end{lem}
\begin{proof}
(a) The action takes the explicit form
\[g\triangleright X^n g^k = q^{-n} X^n g^k\qquad
X\triangleright X^n g^k = X^{n+1}g^k(1-q^{-(n+k)})\]
while the coproduct is
\[\cop(X^n g^k)=\sum_{r=0}^{n} \binomq{n}{r}
 q^{-r(n-r)} X^{n-r} g^{k+r}\otimes X^r g^k\]
which we view as a left coaction here.
Let now $L\subseteq\ensuremath{U_q(\lalg{b_+})}$ be a crossed \ensuremath{U_q(\lalg{b_+})}-submodule via this action
and coaction. For $\sum_n X^n P_n(g)\in L$ invariance under
the action by
$g$ clearly means that \mbox{$X^n P_n(g)\in L\ \forall n$}. Then from
invariance under the coaction we can conclude that
if $X^n \sum_j a_j g^j\in L$ we must have
$X^n g^j\in L\ \forall j$.
I.e.\ elements of the form $X^n g^j$ lie separately in $L$ and it is
sufficient to consider such elements. From the coaction we learn that
if $X^n g^j\in L$ we have $X^m g^j\in L\ \forall m\le n$.
The action
by $X$ leads to $X^n g^j\in L \Rightarrow X^{n+1} g^j\in
L$ except if
$n+j=0$. The classification is given by the possible choices we have
for each power in $g$. For every positive integer $j$ we can
choose wether or not to include the span of
$\{ X^n g^j|\forall n\}$ in $L$ and for
every non-positive
integer we can choose to include either the span of $\{ X^n
g^j|\forall n\}$
or just
$\{ X^n g^j|\forall n\le -j\}$ or neither. I.e.\ for positive
integers ($\mathbb{N}$) we have two choices while for non-positive (identified
with $\mathbb{N}_0$) ones we have three choices.

Clearly, the finite dimensional $L$ are those where we choose only to
include finitely many powers of $g$ and also only finitely many powers
of $X$. The latter is only possible for the non-positive powers
of $g$.
By identifying positive integers $n$ with powers $1-n$ of $g$, we
obtain a classification by finite subsets of $\mathbb{N}$.

(b) Irreducibility clearly corresponds to just including one power of $g$
in the finite dimensional case.

(c) The decomposition property is obvious from the discussion.
\end{proof}


\begin{cor}
\label{cor:uqbp_eclass}
(a) Left crossed \ensuremath{U_q(\lalg{b_+})}-submodules $L\subseteq\ker\cou\subset\ensuremath{U_q(\lalg{b_+})}$ via
the left adjoint
action and left regular coaction (with subsequent projection to
$\ker\cou$ via $x\mapsto x-\cou(x)1$) are in one-to-one correspondence to
the set $3^{\mathbb{N}}\times2^{\mathbb{N}_0}$.
Finite dimensional $L$ are in one-to-one correspondence to
finite sets
$I\subset\mathbb{N}\setminus\{1\}$ and $\dim L=\sum_{n\in I}n$.

(b) Finite dimensional irreducible $L$ correspond to $\{n\}$
with $n\ge 2$ the dimension.

(c) Finite dimensional $L$ are direct sums of irreducible ones. In
particular $L=\oplus_{n\in I} L^n$ with $L^n$ corresponding to $\{n\}$.
\end{cor}
\begin{proof}
Only a small modification of lemma \ref{lem:uqbp_class} is
necessary. Elements of
the form $P(g)$ are replaced by elements of the form
$P(g)-P(1)$. Monomials with non-vanishing degree in $X$ are unchanged.
The choices for elements of degree $0$ in $g$ are reduced to either
including the span of
$\{ X^k |\forall k>0 \}$ in the crossed submodule or not. In
particular, the crossed submodule characterised by \{1\} in lemma
\ref{lem:uqbp_class} is projected out.
\end{proof}

Differential calculi in the original sense of Woronowicz are
classified by corollary \ref{cor:cqbp_eclass} while from the quantum
tangent space
point of view the
classification is given by corollary \ref{cor:uqbp_eclass}.
In the finite dimensional case the duality is strict in the sense of a
one-to-one correspondence.
The infinite dimensional case on the other hand depends strongly on
the algebraic models we use for the function or enveloping
algebras. It is therefore not surprising that in the present purely
algebraic context the classifications are quite different in this
case. We will restrict ourselves to the finite dimensional
case in the following description of the differential calculi.


\begin{thm}
\label{thm:q_calc}
(a) Finite dimensional differential calculi $\Gamma$ on \ensuremath{C_q(B_+)}{} and
corresponding quantum tangent spaces $L$ on \ensuremath{U_q(\lalg{b_+})}{} are
in one-to-one correspondence to
finite sets $I\subset\mathbb{N}\setminus\{1\}$. In particular
$\dim\Gamma=\dim L=\sum_{n\in I}n$.

(b) Coirreducible $\Gamma$ and irreducible $L$ correspond to
$\{n\}$ with $n\ge 2$ the dimension.
Such a $\Gamma$ has a
right invariant basis $\eta_0,\dots,\eta_{n-1}$ so that the relations
\begin{gather*}
\diff X=\eta_1+(q^{n-1}-1)\eta_0 X \qquad
 \diff g=(q^{n-1}-1)\eta_0 g\\
[a,\eta_0]=\diff a\quad \forall a\in\ensuremath{C_q(B_+)}\\
[g,\eta_i]_{q^{n-1-i}}=0\quad \forall i\qquad
[X,\eta_i]_{q^{n-1-i}}=\begin{cases}
 \eta_{i+1} &amp; \text{if}\ i&lt;n-1 \\
 0 &amp; \text{if}\ i=n-1
 \end{cases}
\end{gather*}
hold, where $[a,b]_p := a b - p b a$. By choosing the dual basis on
the corresponding irreducible $L$ we obtain
the braided derivations
\begin{gather*}
\partial_i\no{f}=
 \no{Q_{n-1-i,g} Q_{n-1-i,X} \frac{1}{[i]_q!} (\partial_{q,X})^i f}
 \qquad\forall i\ge 1\\
\partial_0\no{f}=
 \no{Q_{n-1,g} Q_{n-1,X} f - f}
\end{gather*}
for $f\in \k(q)[X,g,g^{-1}]$ with normal ordering
$\k(q)[X,g,g^{-1}]\to \ensuremath{C_q(B_+)}$ given by \mbox{$g^n X^m\mapsto g^n X^m$}.

(c) Finite dimensional $\Gamma$ and $L$ decompose into direct sums of
coirreducible respectively irreducible ones.
In particular $\Gamma=\oplus_{n\in I}\Gamma^n$ and
$L=\oplus_{n\in I}L^n$ with $\Gamma^n$ and $L^n$ corresponding to $\{n\}$.
\end{thm}
\begin{proof}
(a) We observe that the classifications of lemma
\ref{lem:cqbp_class} and lemma \ref{lem:uqbp_class} or
corollary \ref{cor:cqbp_eclass} and corollary \ref{cor:uqbp_eclass}
are dual to each other in the finite (co){}dimensional case. More
precisely, for $I\subset\mathbb{N}$ finite the crossed submodule $M$
corresponding to $(1,I)$ in lemma \ref{lem:cqbp_class} is the
annihilator of the crossed
submodule $L$ corresponding to $I$ in lemma \ref{lem:uqbp_class} 
and vice versa.
$\ensuremath{C_q(B_+)}/M$ and $L$ are dual spaces with the induced pairing.
For $I\subset\mathbb{N}\setminus\{1\}$ finite this descends to 
$M$ corresponding to $(1,I\cup\{1\})$ in corollary
\ref{cor:cqbp_eclass} and $L$ corresponding to $I$ in corollary
\ref{cor:uqbp_eclass}.
For the dimension of $\Gamma$ observe
$\dim\Gamma=\dim{\ker\cou/M}=\codim M$.

(b) Coirreducibility (having no proper quotient) of $\Gamma$
clearly corresponds to maximality of $M$. The statement then follows
from parts (b) of corollaries
\ref{cor:cqbp_eclass} and \ref{cor:uqbp_eclass}. The formulas are
obtained by choosing the basis $\eta_0,\dots,\eta_{n-1}$ of
$\ker\cou/M$ as the equivalence classes of 
\[(g-1)/(q^{n-1}-1),X,\dots,X^{n-1}\]
The dual basis of $L$ is then given by
\[g^{1-n}-1, X g^{1-n},\dots, q^{k(k-1)} \frac{1}{[k]_q!} X^k g^{1-n},
\dots,q^{(n-1)(n-2)} \frac{1}{[n-1]_q!} X^{n-1} g^{1-n}\]

(c) The statement follows from corollaries \ref{cor:cqbp_eclass} and 
\ref{cor:uqbp_eclass} parts (c) with the observation
\[\ker\cou/M=\ker\cou/{\bigcap_{n\in I}}M^n
=\oplus_{n\in I}\ker\cou/M^n\]
\end{proof}

\begin{cor}
There is precisely one differential calculus on \ensuremath{C_q(B_+)}{} which is
natural in the sense that it
has dimension $2$.
It is coirreducible and obeys the relations
\begin{gather*}
[g,\diff X]=0\qquad [g,\diff g]_q=0\qquad
[X,\diff X]_q=0\qquad [X,\diff g]_q=(q-1)({\diff X}) g
\end{gather*}
with $[a,b]_q:=ab-qba$. In particular we have
\begin{gather*}
\diff\no{f} = {\diff g} \no{\partial_{q,g} f} + {\diff X}
\no{\partial_{q,X} f}\qquad\forall f\in \k(q)[X,g,g^{-1}]
\end{gather*}
\end{cor}
\begin{proof}
This is a special case of theorem \ref{thm:q_calc}.
The formulas follow from (b) with $n=2$.
\end{proof}



\section{Classification in the Classical Limit}
\label{sec:class}

In this section we give the complete classification of differential
calculi and quantum tangent spaces in the classical case of \ensuremath{C(B_+)}{}
along the lines of the previous section.
We pay particular
attention to the relation to the $q$-deformed setting.


The classical limit \ensuremath{C(B_+)}{} of the quantum group \ensuremath{C_q(B_+)}{} is
simply obtained by substituting the parameter $q$ with $1$.
The
classification of left crossed submodules in part (a) of lemma
\ref{lem:cqbp_class} remains
unchanged, as one may check by going through the proof.
In particular, we get a correspondence of crossed modules in the
$q$-deformed setting with crossed modules in the
classical setting
as a map of 
pairs $(P,I)\mapsto (P,I)$
that converts polynomials $\k(q)[g]$ to polynomials $\k[g]$ (if
defined) and leaves
sets $I$ unchanged. This is one-to-one in the finite
dimensional case.
However, we did use the distinctness of powers of $q$ in part (b) and
(c) of lemma
$\ref{lem:cqbp_class}$ and have to account for changing this. The
only place where we used it, was in observing that
factors $1-q^j g $ have no common divisors for distinct $j$. This was
crucial to conclude the maximality (b) of certain finite codimensional
crossed submodules and the intersection property (c).
Now, all those factors become $1-g$.

\begin{cor}
\label{cor:cbp_class}
(a) Left crossed \ensuremath{C(B_+)}-submodules $M\subseteq\ensuremath{C(B_+)}$ by left
multiplication and left
adjoint coaction are in one-to-one correspondence to
pairs $(P,I)$
where $P\in\k[g]$ is a polynomial with $P(0)=1$ and $I\subset\mathbb{N}$ is
finite.
$\codim M&lt;\infty$ iff $P=1$. In particular $\codim M=\sum_{n\in I}n$
if $P=1$.

(b) The infinite codimensional maximal $M$ are characterised by
$(P,\emptyset)$ with $P$ irreducible and $P(g)\neq 1-g$ for any
$k\in\mathbb{N}_0$.
\end{cor}

In the restriction to $\ker\cou\subset\ensuremath{C(B_+)}$ corresponding to corollary
\ref{cor:cqbp_eclass} we observe another difference to the
$q$-deformed setting.
Since the condition for a crossed submodule to lie in $\ker\cou$ is exactly
to have factors $1-g$ in the $X$-free monomials this condition may now
be satisfied more easily. If the characterising polynomial does not
contain this factor it is now sufficient to have just any non-empty
characterising integer set $I$ and it need not contain $1$. Consequently,
the map $(P,I)\mapsto (P,I)$ does not reach all crossed submodules now.

\begin{cor}
\label{cor:cbp_eclass}
(a) Left crossed \ensuremath{C(B_+)}-submodules $M\subseteq\ker\cou\subset\ensuremath{C(B_+)}$
are in one-to-one correspondence to pairs
$(P,I)$ as in corollary \ref{cor:cbp_class}
with the additional constraint $(1-g)$ divides $P(g)$ or $I$ non-empty.
$\codim M&lt;\infty$ iff $P=1$. In particular $\codim M=(\sum_{n\in I}n)-1$
if $P=1$.

(b) The infinite codimensional maximal $M$ correspond to pairs
$(P,\{1\})$ with $P$ irreducible and $P(g)\neq 1-g$.
\end{cor}


Let us now turn to quantum tangent spaces on \ensuremath{U(\lalg{b_+})}{}. Here, the process
to go from the $q$-deformed setting to the classical one is not quite
so straightforward.

\begin{lem}
\label{lem:ubp_class}
Proper left crossed \ensuremath{U(\lalg{b_+})}-submodules $L\subset\ensuremath{U(\lalg{b_+})}$ via the left
adjoint action
and left regular coaction are
in one-to-one correspondence to pairs $(l,I)$ with $l\in\mathbb{N}_0$ and
$I\subset\mathbb{N}$ finite. $\dim L&lt;\infty$ iff $l=0$. In particular $\dim
L=\sum_{n\in I}n$ if $l=0$.
\end{lem}
\begin{proof}
The left adjoint action takes the form
\[
X\triangleright X^n H^m = X^{n+1}(H^m-(H+1)^m) \qquad
H\triangleright X^n H^m = n X^n H^m
\]
while the coaction is
\[
\cop(X^n H^m) = \sum_{i=1}^n \sum_{j=1}^m \binom{n}{i} \binom{m}{j}
X^i H^j\otimes X^{n-1} H^{m-j}
\]
Let $L$ be a crossed submodule invariant under the action and coaction.
The (repeated) action of $H$ separates elements by degree in $X$. It is
therefore sufficient to consider elements of the form $X^n P(H)$, where
$P$ is a polynomial.
By acting with $X$ on an element $X^n P(H)$ we obtain
$X^{n+1}(P(H)-P(H+1))$. Subsequently applying the coaction and
projecting on the left hand side of the tensor product onto $X$ (in
the basis $X^i H^j$ of \ensuremath{U(\lalg{b_+})})
leads to the element $X^n (P(H)-P(H+1))$. Now the degree of
$P(H)-P(H+1)$ is exactly the degree of $P(H)$ minus $1$. Thus we have
polynomials $X^n P_i(H)$ of any degree $i=\deg(P_i)\le \deg(P)$ in $L$
by induction. In particular, $X^n H^m\in L$ for all
$m\le\deg(P)$. It is thus sufficient to consider elements of
the form $X^n H^m$. Given such an element, the coaction generates all
elements of the form $X^i H^j$ with $i\le n, j\le m$.

For given $n$, the characterising datum is the maximal $m$ so
that $X^n H^m\in L$. Due to the coaction this cannot decrease
with decreasing $n$ and due to the action of $X$ this can decrease at
most by $1$ when increasing $n$ by $1$. This leads to the
classification given. For $l\in N_0$ and $I\subset\mathbb{N}$ finite, the
corresponding crossed submodule
is generated by
\begin{gather*}
X^{n_m-1} H^{l+m-1}, X^{n_m+n_{m-1}-1} H^{l+m-2},\dots,
X^{(\sum_i n_i)-1} H^{l}\\
\text{and}\qquad
X^{(\sum_i n_i)+k} H^{l-1}\quad \forall k\ge 0\quad\text{if}\quad l>0
\end{gather*}
as a crossed module.
\end{proof}

For the transition from the $q$-deformed (lemma
\ref{lem:uqbp_class}) to the classical case we
observe that the space spanned by $g^{s_1},\dots,g^{s_m}$ with $m$
different integers $s_i\in\mathbb{Z}$ maps to the space spanned by
$1, H, \dots, H^{m-1}$ in the
prescription of the classical limit (as described in section
\ref{sec:intro_limits}). I.e.\ the classical crossed submodule
characterised by an integer $l$ and a finite set $I\subset\mathbb{N}$ comes
from a crossed submodule characterised by this same $I$ and additionally $l$
other integers $j\in\mathbb{Z}$ for which $X^k g^{1-j}$ is included. In
particular, we have a one-to-one correspondence in the finite
dimensional case.

To formulate the analogue of corollary \ref{cor:uqbp_eclass} for the
classical case is essentially straightforward now. However, as for
\ensuremath{C(B_+)}{}, we obtain more crossed submodules than those from the $q$-deformed
setting. This is due to the degeneracy introduced by forgetting the
powers of $g$ and just retaining the number of different powers. 

\begin{cor}
\label{cor:ubp_eclass}
(a) Proper left crossed \ensuremath{U(\lalg{b_+})}-submodules
$L\subset\ker\cou\subset\ensuremath{U(\lalg{b_+})}$ via the
left adjoint
action and left regular coaction (with subsequent projection to
$\ker\cou$ via $x\mapsto x-\cou(x)1$) are in one-to-one correspondence to
pairs $(l,I)$ with $l\in\mathbb{N}_0$ and $I\subset\mathbb{N}$ finite where $l\neq 0$
or $I\neq\emptyset$.
$\dim L&lt;\infty$ iff $l=0$. In particular $\dim
L=(\sum_{n\in I}n)-1$ if $l=0$.
\end{cor}


As in the $q$-deformed setting, we give a description of the finite
dimensional differential calculi where we have a strict duality to
quantum tangent spaces.

\begin{prop}
(a) Finite dimensional differential calculi $\Gamma$ on \ensuremath{C(B_+)}{} and
finite dimensional quantum tangent spaces $L$ on \ensuremath{U(\lalg{b_+})}{} are
in one-to-one correspondence to non-empty finite sets $I\subset\mathbb{N}$.
In particular $\dim\Gamma=\dim L=(\sum_{n\in I}) n)-1$.

The $\Gamma$ with $1\in\mathbb{N}$ are in
one-to-one correspondence to the finite dimensional
calculi and quantum tangent spaces of the $q$-deformed setting
(theorem \ref{thm:q_calc}(a)).

(b) The differential calculus $\Gamma$ of dimension $n\ge 2$
corresponding to the
coirreducible one of \ensuremath{C_q(B_+)}{} (theorem \ref{thm:q_calc}(b)) has a right
invariant
basis $\eta_0,\dots,\eta_{n-1}$ so that
\begin{gather*}
\diff X=\eta_1+\eta_0 X \qquad
 \diff g=\eta_0 g\\
[g, \eta_i]=0\ \forall i \qquad
[X, \eta_i]=\begin{cases}
 0 &amp; \text{if}\ i=0\ \text{or}\ i=n-1\\
 \eta_{i+1} &amp; \text{if}\ 0&lt;i&lt;n-1
 \end{cases}
\end{gather*}
hold. The braided derivations obtained from the dual basis of the
corresponding $L$ are
given by
\begin{gather*}
\partial_i f=\frac{1}{i!}
 \left(\frac{\partial}{\partial X}\right)^i f\qquad
 \forall i\ge 1\\
\partial_0 f=\left(X \frac{\partial}{X}+
 g \frac{\partial}{g}\right) f
\end{gather*}
for $f\in\ensuremath{C(B_+)}$.

(c) The differential calculus of dimension $n-1$ 
corresponding to the
one in (b) with $1$ removed from the characterising set is
the same as the one above, except that we set $\eta_0=0$ and
$\partial_0=0$.
\end{prop}
\begin{proof}
(a) We observe that the classifications of corollary
\ref{cor:cbp_class} and lemma \ref{lem:ubp_class} or
corollary \ref{cor:cbp_eclass} and corollary \ref{cor:ubp_eclass}
are dual to each other in the finite (co)dimensional case.
More
precisely, for $I\subset\mathbb{N}$ finite the crossed submodule $M$
corresponding to $(1,I)$ in corollary \ref{cor:cbp_class} is the
annihilator of the crossed
submodule $L$ corresponding to $(0,I)$ in lemma \ref{lem:ubp_class} 
and vice versa.
$\ensuremath{C(B_+)}/M$ and $L$ are dual spaces with the induced pairing.
For non-empty $I$ this descends to 
$M$ corresponding to $(1,I)$ in corollary
\ref{cor:cbp_eclass} and $L$ corresponding to $(0,I)$ in corollary
\ref{cor:ubp_eclass}.
For the dimension of $\Gamma$ note
$\dim\Gamma=\dim{\ker\cou/M}=\codim M$.

(b) For $I=\{1,n\}$ we choose in
$\ker\cou\subset\ensuremath{C(B_+)}$ the basis $\eta_0,\dots,\eta_{n-1}$ as the
equivalence classes of
$g-1,X,\dots,X^{n-1}$. The dual basis in $L$
is then $H,X,\dots,\frac{1}{k!}X^k,\dots,\frac{1}{(n-1)!}X^{n-1}$.
This leads to the
formulas given.

(c) For $I=\{n\}$ we get the same as in (b) except that $\eta_0$ and
$\partial_0$ disappear.
\end{proof}

The classical commutative calculus is the special case of (b) with
$n=2$. It is the only calculus of dimension $2$ with
$\diff g\neq 0$. Note that it is not coirreducible.




\section{The Dual Classical Limit}
\label{sec:dual}

We proceed in this section to the more interesting point of view where
we consider the classical algebras, but with their roles
interchanged. I.e.\ we view \ensuremath{U(\lalg{b_+})}{} as the ``function algebra''
and \ensuremath{C(B_+)}{} as the ``enveloping algebra''. Due to the self-duality of
\ensuremath{U_q(\lalg{b_+})}{}, we can again view the differential calculi and quantum tangent
spaces as classical limits of the $q$-deformed setting investigated in
section \ref{sec:q}.

In this dual setting the bicovariance constraint for differential
calculi becomes much
weaker. In particular, the adjoint action on a classical function
algebra is trivial due to commutativity and the adjoint coaction on a
classical enveloping algebra is trivial due to cocommutativity.
In effect, the correspondence with the
$q$-deformed setting is much weaker than in the ordinary case of
section \ref{sec:class}.
There are much more differential
calculi and quantum tangent spaces than in the $q$-deformed setting.

We will not attempt to classify all of them in the following but
essentially 
contend ourselves with those objects coming from the $q$-deformed setting.

\begin{lem}
\label{lem:cbp_dual}
Left \ensuremath{C(B_+)}-subcomodules $\subseteq\ensuremath{C(B_+)}$ via the left regular coaction are
$\mathbb{Z}$-graded subspaces of \ensuremath{C(B_+)}{} with $|X^n g^m|=n+m$,
stable under formal derivation in $X$.

By choosing any ordering in \ensuremath{C_q(B_+)}{}, left crossed submodules via left
regular action and adjoint coaction are in one-to-one correspondence
to certain subcomodules of \ensuremath{C(B_+)}{} by setting $q=1$. Direct sums
correspond to direct sums.

This descends to $\ker\cou\subset\ensuremath{C(B_+)}$ by the projection $x\mapsto
x-\cou(x) 1$.
\end{lem}
\begin{proof}
The coproduct on \ensuremath{C(B_+)}{} is
\[\cop(X^n g^k)=\sum_{r=0}^{n} \binom{n}{r}
 X^{n-r} g^{k+r}\otimes X^r g^k\]
which we view as a left coaction.
Projecting on the left hand side of the tensor product onto $g^l$ in a
basis $X^n g^k$, we
observe that coacting on an element
$\sum_{n,k} a_{n,k} X^n g^k$ we obtain elements
$\sum_n a_{n,l-n} X^n g^{l-n}$ for all $l$.
I.e.\ elements of the form
$\sum_n b_n X^n g^{l-n}$ lie
separately in a subcomodule and it is
sufficient to consider such elements. Writing the coaction
on such an element as
\[\sum_t \frac{1}{t!} X^t g^{l-t}\otimes \sum_n b_n
 \frac{n!}{(n-t)!} X^{n-t} g^{l-n}\]
we see that the coaction generates all formal derivatives in $X$
of this element. This gives us the classification: \ensuremath{C(B_+)}-subcomodules
$\subseteq\ensuremath{C(B_+)}$ under the left regular coaction are $\mathbb{Z}$-graded
subspaces with $|X^n g^m|=n+m$, stable under formal derivation in
$X$ given by $X^n
g^m \mapsto n X^{n-1} g^m$.

The correspondence with the \ensuremath{C_q(B_+)} case follows from
the trivial observation
that the coproduct of \ensuremath{C(B_+)}{} is the same as that of \ensuremath{C_q(B_+)}{} with $q=1$.

The restriction to $\ker\cou$ is straightforward.
\end{proof}



\begin{lem}
\label{lem:ubp_dual}
The process of obtaining the classical limit \ensuremath{U(\lalg{b_+})}{} from \ensuremath{U_q(\lalg{b_+})}{} is
well defined for subspaces and sends crossed \ensuremath{U_q(\lalg{b_+})}-submodules
$\subset\ensuremath{U_q(\lalg{b_+})}$ by
regular action and adjoint coaction to \ensuremath{U(\lalg{b_+})}-submodules $\subset\ensuremath{U(\lalg{b_+})}$
by regular
action. This map is injective in the finite codimensional
case. Intersections and codimensions are preserved in this case.

This descends to $\ker\cou$.
\end{lem}
\begin{proof}
To obtain the classical limit of a left ideal it is enough to
apply the limiting process (as described in section
\ref{sec:intro_limits}) to the
module generators (We can forget the additional comodule
structure). On the one hand,
any element generated by left multiplication with polynomials in
$g$ corresponds to some element generated by left multiplication with a
polynomial in $H$, that is, there will be no more generators in the
classical setting. On the other hand, left multiplication by a
polynomial in $H$ comes
from left multiplication by the same polynomial in $g-1$, that is,
there will be no fewer generators.

The maximal left crossed \ensuremath{U_q(\lalg{b_+})}-submodule $\subseteq\ensuremath{U_q(\lalg{b_+})}$
by left multiplication and adjoint coaction of
codimension $n$ ($n\ge 1$) is generated as a left ideal by
$\{1-q^{1-n}g,X^n\}$ (see lemma
\ref{lem:cqbp_class}). Applying the limiting process to this
leads to the
left ideal of \ensuremath{U(\lalg{b_+})}{} (which is not maximal for $n\neq 1$) generated by
$\{H+n-1,X^n\}$ having also codimension $n$.

More generally, the picture given for arbitrary finite codimensional left
crossed modules of \ensuremath{U_q(\lalg{b_+})}{} in terms of generators with respect to
polynomials in $g,g^{-1}$ in lemma \ref{lem:cqbp_class} carries over
by replacing factors
$1-q^{1-n}g$ with factors $H+n-1$ leading to generators with
respect to polynomials in $H$. In particular,
intersections go to intersections since the distinctness of
the factors for different $n$ is conserved.

The restriction to $\ker\cou$ is straightforward.
\end{proof}


We are now in a position to give a detailed description of the
differential calculi induced from the $q$-deformed setting by the
limiting process.

\begin{prop}
(a) Certain finite dimensional
differential calculi $\Gamma$ on \ensuremath{U(\lalg{b_+})}{} and quantum tangent spaces $L$
on \ensuremath{C(B_+)}{}
are in one-to-one correspondence to finite dimensional differential
calculi on \ensuremath{U_q(\lalg{b_+})}{} and quantum
tangent spaces on \ensuremath{C_q(B_+)}{}. Intersections correspond to intersections.

(b) In particular,
$\Gamma$ and $L$ corresponding to coirreducible differential calculi
on \ensuremath{U_q(\lalg{b_+})}{} and
irreducible quantum tangent spaces on \ensuremath{C_q(B_+)}{} via the limiting process
are given as follows:
$\Gamma$ has a right invariant basis
$\eta_0,\dots,\eta_{n-1}$ so that
\begin{gather*}
\diff X=\eta_1 \qquad \diff H=(1-n)\eta_0 \\
[H, \eta_i]=(1-n+i)\eta_i\quad\forall i\qquad
[X, \eta_i]=\begin{cases}
 \eta_{i+1} &amp; \text{if}\ \ i&lt;n-1\\
 0 &amp; \text{if}\ \ i=n-1
\end{cases}
\end{gather*}
holds. The braided derivations corresponding to the dual basis of
$L$ are given by
\begin{gather*}
\partial_i\no{f}=\no{T_{1-n+i,H}
 \frac{1}{i!}\left(\frac{\partial}{\partial X}\right)^i f}
 \qquad\forall i\ge 1\\
\partial_0\no{f}=\no{T_{1-n,H} f - f}
\end{gather*}
for $f\in\k[X,H]$
with the normal ordering $\k[X,H]\to \ensuremath{U(\lalg{b_+})}$ via $H^n X^m\mapsto H^n X^m$.
\end{prop}
\begin{proof}
(a) The strict duality between \ensuremath{C(B_+)}-subcomodules $L\subseteq\ker\cou$
given by lemma \ref{lem:cbp_dual} and corollary \ref{cor:uqbp_eclass}
and \ensuremath{U(\lalg{b_+})}-modules $\ensuremath{U(\lalg{b_+})}/(\k 1+M)$ with $M$ given by lemma
\ref{lem:ubp_dual} and
corollary \ref{cor:cqbp_eclass} can be checked explicitly.
It is essentially due to mutual annihilation of factors $H+k$ in
\ensuremath{U(\lalg{b_+})}{} with elements $g^k$ in \ensuremath{C(B_+)}{}.

(b) $L$ is generated by
$\{g^{1-n}-1,Xg^{1-n},\dots,
X^{n-1}g^{1-n}\}$ and
$M$ is generated by $\{H(H+n-1),X(H+n-1),X^n \}$.
The formulas are obtained by denoting with
$\eta_0,\dots,\eta_{n-1}$ the equivalence classes of
$H/(1-n),X,\dots,X^{n-1}$ in $\ensuremath{U(\lalg{b_+})}/(\k 1+M)$.
The dual basis of $L$ is then
\[g^{1-n}-1,X g^{1-n},
\dots,\frac{1}{(n-1)!}X^{n-1}
g^{1-n}\]
\end{proof}


In contrast to the $q$-deformed setting and to the usual classical
setting the many freedoms in choosing a calculus leave us with many
$2$-dimensional calculi. It is not obvious which one we should
consider to be the ``natural'' one. Let us first look at the
$2$-dimensional calculus coming from the $q$-deformed
setting as described in (b). The relations become
\begin{gather*}
[\diff H, a]=\diff a\qquad [\diff X, a]=0\qquad\forall a\in\ensuremath{U(\lalg{b_+})}\\
\diff\no{f} =\diff H \no{\fdiff_{1,H} f} 
 + \diff X \no{\frac{\partial}{\partial X} f}
\end{gather*}
for $f\in\k[X,H]$.

We might want to consider calculi which are closer to the classical
theory in the sense that derivatives are not finite differences but
usual derivatives. Let us therefore demand
\[\diff P(H)=\diff H \frac{\partial}{\partial H} P(H)\qquad
\text{and}\qquad
\diff P(X)=\diff X \frac{\partial}{\partial X} P(X)\]
for polynomials $P$ and ${\diff X}\neq 0$ and ${\diff H}\neq 0$.

\begin{prop}
\label{prop:nat_bp}
There is precisely one differential calculus of dimension $2$ meeting
these conditions. It obeys the relations
\begin{gather*}
[a,\diff H]=0\qquad [X,\diff X]=0\qquad [H,\diff X]=\diff X\\
\diff \no{f} =\diff H \no{\frac{\partial}{\partial H} f}
 +\diff X \no{\frac{\partial}{\partial X} f}
\end{gather*}
where the normal ordering $\k[X,H]\to \ensuremath{U(\lalg{b_+})}$ is given by
$X^n H^m\mapsto X^n H^m$.
\end{prop}
\begin{proof}
Let $M$ be the left ideal corresponding to the calculus. It is easy to
see that for a primitive element $a$ the classical derivation condition
corresponds to $a^2\in M$ and $a\notin M$. In our case $X^2,H^2\in
M$. If we take the
ideal generated from these two elements we obtain an ideal of
$\ker\cou$ of codimension $3$. Now, it is sufficient without loss of
generality to add a generator of the form $\alpha H+\beta X+\gamma
XH$. $\alpha$ and $\beta$ must then be zero in order not
to generate $X$ or $H$ in $M$.
I.e.\ $M$ is generated by $H^2,
XH, X^2$. The relations stated follow.
\end{proof}



\section{Remarks on $\kappa$-Minkowski Space and Integration}
\label{sec:kappa}

There is a straightforward generalisation of \ensuremath{U(\lalg{b_+})}.
Let us define the Lie algebra $\lalg b_{n+}$ as generated by
$x_0,\dots, x_{n-1}$ with relations
\[ [x_0,x_i]=x_i\qquad [x_i,x_j]=0\qquad\forall i,j\ge 1\]
Its enveloping algebra \ensuremath{U(\lalg{b}_{n+})}{} is nothing but (rescaled) $\kappa$-Minkowski
space as introduced in \cite{MaRu}. In this section we make some
remarks about its intrinsic geometry.

We have an injective Lie algebra
homomorphism $b_{n+}\to b_+$ given by
$x_0\mapsto H$ and $x_i\mapsto X$.
This is an isomorphism for $n=2$. The injective Lie algebra
homomorphism extends to an injective homomorphism of enveloping
algebras $\ensuremath{U(\lalg{b_+})}\to \ensuremath{U(\lalg{b}_{n+})}$ in the obvious way. This gives rise
to an injective map from the set of submodules of \ensuremath{U(\lalg{b_+})}{} to the set of
submodules of \ensuremath{U(\lalg{b}_{n+})}{} by taking the pre-image. In
particular this induces an injective
map from the set of differential calculi on \ensuremath{U(\lalg{b_+})}{} to the set of
differential calculi on \ensuremath{U(\lalg{b}_{n+})}{} which are invariant under permutations
of the $x_i\ i\ge 1$.

\begin{cor}
\label{cor:nat_bnp}
There is a natural $n$-dimensional differential calculus on \ensuremath{U(\lalg{b}_{n+})}{}
induced from the one considered in proposition
\ref{prop:nat_bp}.
It obeys the relations
\begin{gather*}
[a,\diff x_0]=0\quad\forall a\in \ensuremath{U(\lalg{b}_{n+})}\qquad [x_i,\diff x_j]=0
 \quad [x_0,\diff x_i]=\diff x_i\qquad\forall i,j\ge 1\\
\diff \no{f} =\sum_{\mu=0}^{n-1}\diff x_{\mu}
 \no{\frac{\partial}{\partial x_{\mu}} f}
\end{gather*}
where the normal ordering is given by
\[\k[x_0,\dots,x_{n-1}]\to \ensuremath{U(\lalg{b}_{n+})}\quad\text{via}\quad
x_{n-1}^{m_{n-1}}\cdots
x_0^{m_0}\mapsto x_{n-1}^{m_{n-1}}\cdots x_0^{m_0}\]
\end{cor}
\begin{proof}
The calculus is obtained from the ideal generated by
\[x_0^2,x_i x_j, x_i x_0\qquad\forall i,j\ge 1\]
being the pre-image of
$X^2,XH,X^2$ in \ensuremath{U(\lalg{b_+})}{}.
\end{proof}

Let us try to push the analogy with the commutative case further and
take a look at the notion of integration. The natural way to encode
the condition of translation invariance from the classical context
in the quantum group context
is given by the condition
\[(\int\otimes\id)\circ\cop a=1 \int a\qquad\forall a\in A\]
which defines a right integral on a quantum group $A$
\cite{Sweedler}.
(Correspondingly, we have the notion of a left integral.)
Let us
formulate a slightly
weaker version of this equation
in the context of a Hopf algebra $H$ dually paired with
$A$. We write
\[\int (h-\cou(h))\triangleright a = 0\qquad \forall h\in H, a\in A\]
where the action of $H$ on $A$ is the coregular action
$h\triangleright a = a_{(1)}\langle a_{(2)}, h\rangle$
given by the pairing.

In the present context we set $A=\ensuremath{U(\lalg{b}_{n+})}$ and $H=\ensuremath{C(B_{n+})}$. We define the
latter as a generalisation of \ensuremath{C(B_+)}{} with commuting
generators $g,p_1,\dots,p_{n-1}$ and coproducts
\[\cop p_i=p_i\otimes 1+g\otimes p_i\qquad \cop g=g\otimes g\]
This can be identified (upon rescaling) as the momentum sector of the
full $\kappa$-Poincar\'e algebra (with $g=e^{p_0}$).
The pairing is the natural extension of (\ref{eq:pair_class}):
\[\langle x_{n-1}^{m_{n-1}}\cdots x_1^{m_1} x_0^{k},
  p_{n-1}^{r_{n-1}}\cdots p_1^{r_1} g^s\rangle
  = \delta_{m_{n-1},r_{n-1}}\cdots\delta_{m_1,r_1} m_{n-1}!\cdots m_1!
  s^k\]
The resulting coregular
action is conveniently expressed as (see also \cite{MaRu})
\[p_i\triangleright\no{f}=\no{\frac{\partial}{\partial x_i} f}\qquad
  g\triangleright\no{f}=\no{T_{1,x_0} f}\]
  with $f\in\k[x_0,\dots,x_{n-1}]$.
Due to cocommutativity, the notions of left and right integral
coincide. The invariance conditions for integration become
\[\int \no{\frac{\partial}{\partial x_i} f}=0\quad
\forall i\in\{1,\dots,n-1\} 
\qquad\text{and}\qquad \int \no{\fdiff_{1,x_0} f}=0\]
The condition on the left is familiar and states the invariance under
infinitesimal translations in the $x_i$. The condition on the right states the
invariance under integer translations in $x_0$. However, we should
remember that we use a certain algebraic model of \ensuremath{C(B_{n+})}{}. We might add,
for example, a generator $p_0$
to \ensuremath{C(B_{n+})}{}
that is dual to $x_0$ and behaves
as the ``logarithm'' of $g$, i.e.\ acts as an infinitesimal
translation in $x_0$. We then have the condition of infinitesimal
translation invariance
\[\int \no{\frac{\partial}{\partial x_{\mu}} f}=0\]
for all $\mu\in\{0,1,\dots,{n-1}\}$.

In the present purely algebraic context these conditions do not make
much sense. In fact they would force the integral to be zero on the
whole algebra. This is not surprising, since we are dealing only with
polynomial functions which would not be integrable in the classical
case either.
In contrast, if we had for example the algebra of smooth functions
in two real variables, the conditions just characterise the usual
Lesbegue integral (up to normalisation).
Let us assume $\k=\mathbb{R}$ and suppose that we have extended the normal
ordering vector
space isomorphism $\mathbb{R}[x_0,\dots,x_{n-1}]\cong \ensuremath{U(\lalg{b}_{n+})}$ to a vector space
isomorphism of some sufficiently large class of functions on $\mathbb{R}^n$ with a
suitable completion $\hat{U}(\lalg{b_{n+}})$ in a functional
analytic framework (embedding \ensuremath{U(\lalg{b}_{n+})}{} in some operator algebra on a
Hilbert space). It is then natural to define the integration on
$\hat{U}(\lalg{b_{n+}})$ by
\[\int \no{f}=\int_{\mathbb{R}^n} f\ dx_0\cdots dx_{n-1}\]
where the right hand side is just the usual Lesbegue integral in $n$
real variables $x_0,\dots,x_{n-1}$. This
integral is unique (up to normalisation) in
satisfying the covariance condition since, as we have seen,
these correspond
just to the usual translation invariance in the classical case via normal
ordering, for which the Lesbegue integral is the unique solution.
It is also the $q\to 1$ limit of the translation invariant integral on
\ensuremath{U_q(\lalg{b_+})}{} obtained in \cite{Majid_qreg}.

We see that the natural differential calculus in corollary
\ref{cor:nat_bnp} is
compatible with this integration in that the appearing braided
derivations are exactly the actions of the translation generators
$p_{\mu}$. However, we should stress that this calculus is not
covariant under the full $\kappa$-Poincar\'e algebra, since it was
shown in \cite{GoKoMa} that in $n=4$ there is no such
calculus of dimension $4$. Our results therefore indicate a new
intrinsic approach to $\kappa$-Minkowski space that allows a
bicovariant
differential calculus of dimension $4$ and a unique translation
invariant integral by normal ordering and Lesbegue integration.



\section*{Acknowledgements}
I would like to thank S.~Majid for proposing this project,
and for fruitful discussions during the preparation of this paper.


</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">{'timestamp': '1998-07-19T14:33:52', 'yymm': '9807', 'arxiv_id': 'math/9807097', 'language': 'en', 'url': 'https://arxiv.org/abs/math/9807097'}</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="2"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">\section{Introduction}

Continuous Engineering (CE) practices, 
such as Continuous Integration (CI) and Continuous Deployment (CD), 
are gaining prominence in software engineering, 
as they help streamline and optimize the way software is built, tested and shipped. 
The most salient advantage of CE is the tighter feedback loops: 
CE practices help developers test and build their software more, 
and makes software releases less brittle by enabling more incremental releases.

Nevertheless, a frequently reported barrier for success is the need to effectively analyze
the data that results from the numerous build and test
runs~\cite{Laukkanen2017,Hilton2017,Shahin2017,Debbiche2014,Olsson2012}.
One evident example of this is the handling and
analysis of results from complex end-to-end integration tests 
which we focus on in this paper: 
CE practices make it easier to run such end-to-end tests, 
which include system integration and deployment to production hardware, 
and they are critical for ensuring the quality of the end product. 
However, since these end-to-end tests by their nature can fail for multiple
reasons, not least in the sense that new product code can make the tests
fail in new ways, it is critical to rapidly diagnose these failures.

In this paper we concern ourselves with how to rapidly analyze a set
of logs resulting from complex CE tasks\footnote{~For simplicity, and without loss of generality, 
we will refer to these CE tasks as ``integration tests'' or ``tests'' throughout the paper, 
though we acknowledge that they include more than just testing, 
such as building the system and deploying it on hardware in a test or staging environment, 
and failures can occur in any of these phases. 
The proposed approach aims to cover all these situations, 
and is evaluated on real-life logs capturing everything from building the system, 
to deploying it on production hardware, 
and running complex integration and interaction scenarios.} 
where the overall outcome of the task (i.e. 'fail' or 'pass') is known, 
but where analysts must consult the resulting logs to fully diagnose why the failures occurred. 
Since these logs can get large and unwieldy, we
develop a tool that automatically suggests which segments in the logs
are most likely relevant for troubleshooting purposes. 
Our method gives each event in the log an interestingness score based
on the overall event frequencies in the test result set: The log
events are in turn clustered based on these scores, and the event
clusters are presented to the user in decreasing order of overall
interestingness. The goal is to enable users to find all relevant
diagnostic information in the first presented event cluster, while having the
option of retrieving additional clusters if needed. An
additional benefit of our method is that the extracted events can help
identify commonly occurring patterns that are symptomatic for specific
errors. Future logs that exhibit the same characteristics can then be
automatically classified as having symptoms of that error.

\head{Contributions} We present Spectrum-Based Log Diagnosis (SBLD), a method for helping developers quickly find the
most relevant segments of a log. Using data from \CiscoNorway{an
industrial partner}, we empirically evaluate SBLD by investigating the following
three questions:
(i) How well does SBLD reduce the \emph{effort needed} to identify all \emph{failure-relevant events} in the log for a failing run?
(ii) How is the \emph{performance} of SBLD affected by \emph{available data}?
(iii) How does SBLD compare to searching for \emph{simple textual patterns} that often occur in failure-relevant events?

\head{Overview} 
The rest of the paper is structured as follows: Section~\ref{sec:approach}
explains SBLD and the methodology underlying its event ranking
procedures. Sections~\ref{sec:rqs} and~\ref{sec:expdesign} motivates our research questions 
and empirical design. We report and discuss our results in
Section~\ref{sec:resdiscuss}. Section~\ref{sec:relwork} surveys related work,
and we discuss threats to validity in Section~\ref{sec:ttv} before concluding 
in Section~\ref{sec:conclusion}.
 %

\section{Approach}
\label{sec:approach}

\begin{figure}[b]
        \includegraphics[width=0.99\columnwidth]{overview.pdf}
        	\vspace*{-2ex}
        \caption{A visual overview of our approach.}
        \label{fig:approach}
\end{figure}

SBLD takes a set of log files from test failures, a set of log files from test successes, and a singular log file from a test failure called the \emph{target log} that the user wants analyzed and produces a list of segments  from the target log file that are likely relevant for understanding why the corresponding test run failed.

In the following we explain the workings of SBLD in a stepwise
manner. At each step, we present the technical background needed to
understand how SBLD accomplishes its task. A visual overview of SBLD is
shown in Figure \ref{fig:approach}.

\head{Prerequisites}
First of all, SBLD requires access to a set of log files from failing test runs and a set of log files from successful test runs.
For brevity, we will refer to log files from failing test runs as 'failing logs', 
and log files from successful test runs as 'passing logs'.%
\footnote{~Note that we explicitly assume that the outcome of each run is known; 
  This work is not concerned with determining whether the run was a failure or a success, 
  but rather with helping identify why the failing runs failed.} 
We also require a programmatic way of segmenting each log file
into individually meaningful components. For the dataset used in this
paper these components are \emph{events} in the form of blocks of text
preceded by a date and a time-stamp in a predictable format. Lastly,
we require that run-time specific information such as timestamps,
dynamically generated IP addresses, check-sums and so on are removed
from the logs and replaced with standardized text. We refer to the process of
enforcing these requirements and delineating the log into events as
the \emph{abstraction} step. This enables SBLD to treat events
like ``2019-04-05 19:19:22.441 CEST: Alice calls Bob'' and ``2019-04-07
13:12:11.337 CEST: Alice calls Bob'' as two instances of the same
generic event "Alice calls Bob". The appropriate degree of abstraction
and how to meaningfully delineate a log will be context-dependent
and thus we require the user to perform these steps before using SBLD. 
In the current paper we use an abstraction mechanism
and dataset generously provided by \CiscoNorway{our industrial partner}.

\renewcommand{\Ncf}{\ensuremath{\text{N}_\text{FI}}} %
\renewcommand{\Nuf}{\ensuremath{\text{N}_\text{FE}}} %
\renewcommand{\Ncs}{\ensuremath{\text{N}_\text{PI}}} %
\renewcommand{\Nus}{\ensuremath{\text{N}_\text{PE}}} %

\head{Computing coverage and event relevance} SBLD requires an assumption about what makes an event \emph{relevant}
and a method for computing this relevance. Our method takes inspiration
from Spectrum-Based Fault Localization (SBFL) in which the suspiciousness 
or fault-proneness of a program statement is treated as a function of 
the number of times the statement was activated in a failing test case, 
combined with the number of times it is skipped in a passing test case~\cite{Jones2002,Abreu2007,Abreu2009}. 
The four primitives that need to be computed are shown on the right-hand side in Table~\ref{table:measures}. 
We treat each abstracted event as a statement and study their occurrences
in the logs like Fault Localization tracks the activation of statements in test cases. 
We compute the analysis primitives by devising a binary
\emph{coverage matrix} whose columns represent every unique event
observed in the set of failing and successful logs while each row $r$
represents a log and tracks whether the event at column $c$ occurred in
log $r$ (1), or not (0), as shown in Figure~\ref{fig:approach}.

By computing these primitives, we can rank each event by using an
\emph{interestingness measure} (also referred to as ranking
metric, heuristic, or similarity coefficient~\cite{Wong2016}). 
The choice of interestingness measure
is ultimately left to the user, as these are context dependent and 
there is no generally optimal choice of interestingness measure~\cite{Yoo2014}. 
In this paper we consider a
selection of nine interestingness measures prominent in the literature
and a simple metric that emphasizes the events that exclusively occur
in failing logs in the spirit of the \emph{union model} discussed
by Renieres et al.~\cite{renieres2003:fault}. We
report on the median performance of these interestingness measures with the intention of providing a
representative, yet unbiased, result. The ten measures considered are
precisely defined in Table~\ref{table:measures}.

\begin{table*}
\centering
\begin{tabular}{c@{\hspace{10mm}}c}
{\renewcommand{\arraystretch}{1.7} %
\begin{tabular}{lc}
\toprule
measure	 &amp; formula \\\midrule

Tarantula \cite{Jones2001,Jones2002} &amp; %

\( \frac{ \frac{ \cef{} }{ \cef{} + \cnf{} } }{ \frac{ \cef{} }{ \cef{} + \cnf{} } + \frac{ \cep{} }{ \cep{} + \cnp{} } } \) 

\\

Jaccard \cite{Jaccard1912,Chen2002} &amp; %

\( \frac{ \Ncf }{ \Ncf + \Nuf + \Ncs } \)

\\

Ochiai \cite{Ochiai1957,Abreu2006} &amp; %

\( \frac{ \Ncf }{ \sqrt{ ( \cef + \cnf ) \times ( \cef + \cep ) } } \)

\\

Ochiai2 \cite{Ochiai1957, Naish2011} &amp; %

\( \frac{ \Aef \times \Anp }{ \sqrt{ ( \Aef + \Aep ) \times ( \Anf + \Anp ) \times ( \Aef + \Anf) \times ( \Aep + \Anp ) } } \)

\\

Zoltar \cite{Gonzalez2007} &amp; %

\( \frac{ \Ncf }{ \Ncf + \Nuf + \Ncs + \frac { 10000 \times \Nuf \times \Ncs }{ \Ncf } } \)

\\

D$^\star$ \cite{Wong2014} (we use $\star = 2$) &amp; %

\( \frac{ (\cef)^\star }{ \cnf + \cep } \)

\\

O$^p$ \cite{Naish2011} &amp; %

\( \Aef - \frac{ \Aep }{ \Aep + \Anp + 1} \)

\\

Wong3 \cite{Wong2007,Wong2010} &amp;

\( \Aef - h, \text{where~} h = \left\{ 
\scalebox{.8}{\(\renewcommand{\arraystretch}{1} %
\begin{array}{@{}ll@{}}
\Aep &amp; \text{if~} \Aep \leq 2 \\
2 + 0.1(\Aep - 2) &amp; \text{if~} 2 &lt; \Aep \leq 10 \\
2.8 + 0.001(\Aep - 10) &amp; \text{if~} \Aep > 10 \\
\end{array}\)}
\right. \)

\\

Kulczynski2 \cite{Kulczynski1927,Naish2011} &amp; %

\( \frac{ 1 }{ 2 } \times ( \frac{ \Aef }{ \Aef + \Anf } + \frac{ \Aef }{ \Aef + \Aep } ) \)

\\

Failed only &amp; %

\( \left\{\scalebox{.8}{\(\renewcommand{\arraystretch}{1} %
\begin{array}{@{}ll@{}}
1 &amp; \text{if~} \Ncs = 0 \\
0 &amp; \text{otherwise~}  \\
\end{array}\)}
\right. \)

\\
\bottomrule

\end{tabular}} &amp;
\begin{tabular}{lp{2.99cm}}
\toprule
\multicolumn{2}{l}{notation used} \\\midrule
\Ncf &amp; number of \emph{failing} logs \\ &amp; that \emph{include} the event \\
\Nuf &amp; number of \emph{failing} logs \\ &amp; that \emph{exclude} the event \\
\Ncs &amp; number of \emph{passing} logs \\ &amp; that \emph{include} the event \\
\Nus &amp; number of \emph{passing} logs \\ &amp; that \emph{exclude} the event \\
\bottomrule
\end{tabular}
\end{tabular}\vspace*{1ex}
\caption{\label{table:measures}The 10 interestingness measures under consideration in this paper.}
\vspace*{-3ex}
\end{table*}

\head{Analyzing a target log file} Using our database of event scores,
we first identify the events occurring in the target log file and the
interestingness scores associated with these events. Then, we group
similarly scored events together using a clustering algorithm. Finally,
we present the best performing cluster of events to the end user. The
clustering step helps us make a meaningful selection of events rather
than setting an often arbitrary window selection size. Among other
things, it prevents two identically scored events from falling at
opposite sides of the selection threshold. If the user suspects that
the best performing cluster did not report all relevant events, she can
inspect additional event clusters in order of decreasing
aggregate interestingness score.  To perform the clustering step we use Hierarchical Agglomerative
Clustering (HAC) with Complete linkage~\cite{manning2008introduction}, where
sub-clusters are merged until the maximal distance between members of
each candidate cluster exceeds some specified threshold. In SBLD,
this threshold is the uncorrected sample standard deviation of the event
scores for the events being clustered.\footnote{~Specifically, 
we use the \texttt{numpy.std} procedure from the SciPy framework~\cite{2020SciPy-NMeth},
in which the uncorrected sample standard deviation is given by
$ \sqrt{\frac{1}{N} \sum_{i=1}^{N}\lvert x_{i} - \bar{x} \rvert^2} $ where
$\bar{x}$ is the sample mean of the interestingness scores obtained for the
events in the log being analyzed and $N$ is the number of events in the log.}  
This ensures that the ``interestingness-distance'' between two events 
in a cluster never exceeds the uncorrected sample standard deviation observed in the set.

 %

\section{Research Questions}
\label{sec:rqs}

The goal of this paper is to present SBLD and help practitioners make
an informed decision whether SBLD meets their needs. To this end, we have identified
three research questions that encompass several concerns practitioners
are likely to have and that also are of interested to the research community at
large:
\begin{enumerate}[\bfseries RQ1]

\item How well does SBLD reduce the effort needed to identify all
        known-to-be relevant events ("does it work?") ?

\item How is the efficacy of SBLD impacted by increased evidence in the form of
        additional failing and passing logs ("how much data do we need before
                running the analysis?") ?

\item How does SBLD perform compared to a strategy based on searching for
        common textual patterns with a tool like \texttt{grep} ("is it better than doing the obvious thing?") ?
\end{enumerate}
RQ1 looks at the aggregated performance of SBLD to assess its viability.
With RQ2 we assess how sensitive the performance is to the amount of
available data: How many logs should you have before you can expect the
analysis to yield good results? Is more data unequivocally a good thing?
What type of log is more informative: A passing log or a failing log?
Finally, we compare SBLD's performance to a more traditional method for
finding relevant segments in logs: Using a textual search for strings 
one expects to occur near informative segments, like
"failure" and "error". The next section details the dataset used, our
chosen quality measures for assessment and our methodology for answering
each research question.

 %

\section{Experimental Design}
\label{sec:expdesign}

\begin{table}
\centering
\caption{The key per-test attributes of our dataset. Two events are considered
        distinct if they are treated as separate events after the abstraction
        step. A "mixed" event is an event that occurs in logs of both failing and
        passing runs.}
\vspace*{-1ex}
\label{table:descriptive}
\renewcommand{\tabcolsep}{0.11cm}\small
\begin{tabular}{rcrrrrrr}
\toprule
     &amp;           &amp; \# fail   &amp; \# pass   &amp; distinct &amp; fail-only  &amp; mixed   &amp; pass-only  \\
test &amp; signature &amp; logs      &amp; logs      &amp;  events  &amp; events     &amp; events  &amp; events \\
\midrule
   1 &amp; C  &amp;     24 &amp;     100 &amp;           36391 &amp;            21870 &amp;          207 &amp;               14314 \\
   2 &amp; E  &amp;     11 &amp;      25 &amp;             380 &amp;               79 &amp;          100 &amp;                 201 \\
   3 &amp; E  &amp;     11 &amp;      25 &amp;             679 &amp;              174 &amp;           43 &amp;                 462 \\
   4 &amp; E  &amp;      4 &amp;      25 &amp;             227 &amp;               49 &amp;           39 &amp;                 139 \\
   5 &amp; C  &amp;      2 &amp;     100 &amp;           33420 &amp;             2034 &amp;           82 &amp;               31304 \\
   6 &amp; C  &amp;     19 &amp;     100 &amp;           49155 &amp;            15684 &amp;          893 &amp;               32578 \\
   7 &amp; C  &amp;     21 &amp;     100 &amp;           37316 &amp;            17881 &amp;          154 &amp;               19281 \\
   8 &amp; C  &amp;      4 &amp;     100 &amp;           26614 &amp;             3976 &amp;           67 &amp;               22571 \\
   9 &amp; C  &amp;     21 &amp;     100 &amp;           36828 &amp;            19240 &amp;          228 &amp;               17360 \\
  10 &amp; C  &amp;     22 &amp;     100 &amp;          110479 &amp;            19134 &amp;         1135 &amp;               90210 \\
  11 &amp; E  &amp;      5 &amp;      25 &amp;             586 &amp;               95 &amp;           47 &amp;                 444 \\
  12 &amp; E  &amp;      7 &amp;      25 &amp;             532 &amp;               66 &amp;           18 &amp;                 448 \\
  13 &amp; C  &amp;      2 &amp;     100 &amp;           15351 &amp;             2048 &amp;          232 &amp;               13071 \\
  14 &amp; C  &amp;      3 &amp;     100 &amp;           16318 &amp;             2991 &amp;          237 &amp;               13090 \\
  15 &amp; C  &amp;     26 &amp;     100 &amp;           60362 &amp;            20964 &amp;         1395 &amp;               38003 \\
  16 &amp; C  &amp;     12 &amp;     100 &amp;            2206 &amp;              159 &amp;          112 &amp;                1935 \\
  17 &amp; E  &amp;      8 &amp;      25 &amp;             271 &amp;               58 &amp;           98 &amp;                 115 \\
  18 &amp; A  &amp;     23 &amp;      75 &amp;            3209 &amp;              570 &amp;          156 &amp;                2483 \\
  19 &amp; C  &amp;     13 &amp;     100 &amp;           36268 &amp;            13544 &amp;          411 &amp;               22313 \\
  20 &amp; B  &amp;      3 &amp;      19 &amp;             688 &amp;               69 &amp;           31 &amp;                 588 \\
  21 &amp; B  &amp;     22 &amp;      25 &amp;             540 &amp;              187 &amp;           94 &amp;                 259 \\
  22 &amp; E  &amp;      1 &amp;      25 &amp;             276 &amp;               11 &amp;           13 &amp;                 252 \\
  23 &amp; C  &amp;     13 &amp;     100 &amp;           28395 &amp;            13629 &amp;          114 &amp;               14652 \\
  24 &amp; E  &amp;      7 &amp;      26 &amp;             655 &amp;              117 &amp;           56 &amp;                 482 \\
  25 &amp; C  &amp;     21 &amp;     100 &amp;           44693 &amp;            18461 &amp;          543 &amp;               25689 \\
  26 &amp; C  &amp;     21 &amp;     100 &amp;           42259 &amp;            19434 &amp;          408 &amp;               22417 \\
  27 &amp; C  &amp;     21 &amp;     100 &amp;           44229 &amp;            18115 &amp;          396 &amp;               25718 \\
  28 &amp; C  &amp;     20 &amp;     100 &amp;           43862 &amp;            16922 &amp;          642 &amp;               26298 \\
  29 &amp; C  &amp;     28 &amp;     100 &amp;           54003 &amp;            24216 &amp;         1226 &amp;               28561 \\
  30 &amp; C  &amp;     31 &amp;     100 &amp;           53482 &amp;            26997 &amp;         1063 &amp;               25422 \\
  31 &amp; C  &amp;     27 &amp;     100 &amp;           53092 &amp;            23283 &amp;          463 &amp;               29346 \\
  32 &amp; C  &amp;     21 &amp;     100 &amp;           55195 &amp;            19817 &amp;          768 &amp;               34610 \\
  33 &amp; E  &amp;      9 &amp;      25 &amp;             291 &amp;               70 &amp;           30 &amp;                 191 \\
  34 &amp; D  &amp;      2 &amp;      13 &amp;             697 &amp;               76 &amp;           92 &amp;                 529 \\
  35 &amp; E  &amp;      9 &amp;      25 &amp;             479 &amp;              141 &amp;           47 &amp;                 291 \\
  36 &amp; E  &amp;     10 &amp;      75 &amp;            1026 &amp;              137 &amp;           68 &amp;                 821 \\
  37 &amp; E  &amp;      7 &amp;      25 &amp;            7165 &amp;             1804 &amp;           94 &amp;                5267 \\
  38 &amp; E  &amp;      4 &amp;      25 &amp;             647 &amp;               67 &amp;           49 &amp;                 531 \\
  39 &amp; G  &amp;     47 &amp;     333 &amp;            3350 &amp;              428 &amp;          144 &amp;                2778 \\
  40 &amp; G  &amp;     26 &amp;     333 &amp;            3599 &amp;              240 &amp;          157 &amp;                3202 \\
  41 &amp; G  &amp;     26 &amp;     332 &amp;            4918 &amp;              239 &amp;          145 &amp;                4534 \\
  42 &amp; C  &amp;     17 &amp;     100 &amp;           30411 &amp;            14844 &amp;          348 &amp;               15219 \\
  43 &amp; F  &amp;    267 &amp;     477 &amp;           10002 &amp;             3204 &amp;         1519 &amp;                5279 \\
  44 &amp; C  &amp;      9 &amp;     100 &amp;           29906 &amp;             8260 &amp;          274 &amp;               21372 \\
  45 &amp; E  &amp;      3 &amp;      25 &amp;             380 &amp;               44 &amp;           43 &amp;                 293 \\
\bottomrule
\end{tabular}
\vspace*{-2ex}
\end{table}
 %

\begin{table}
\centering
\caption{Ground-truth signatures and their occurrences in distinct events.}
\label{table:signature}
\vspace*{-1ex}
\small
\begin{tabular}{ccrrrc}
\toprule
          &amp;   sub-  &amp; fail-only &amp; pass-only &amp; fail \&amp; &amp; failure \\
signature &amp; pattern &amp; events    &amp; events    &amp; pass    &amp; strings* \\
\midrule
        A &amp;       1 &amp;                1 &amp;                0 &amp;            0 &amp;                                  yes \\
        A &amp;       2 &amp;                2 &amp;                0 &amp;            0 &amp;                                   no \\
        B &amp;       1 &amp;                2 &amp;                0 &amp;            0 &amp;                                  yes \\
        C &amp;       1 &amp;               21 &amp;                0 &amp;            0 &amp;                                  yes \\
        C &amp;       2 &amp;               21 &amp;                0 &amp;            0 &amp;                                  yes \\
        D &amp;       1 &amp;                4 &amp;                0 &amp;            0 &amp;                                  yes \\
 \textbf{D$^{\#}$} &amp; \textbf{2} &amp;               69 &amp;              267 &amp;          115 &amp;                                   no \\
 \textbf{D$^{\#}$} &amp; \textbf{3} &amp;                2 &amp;               10 &amp;           13 &amp;                                   no \\
 \textbf{E$^{\#}$} &amp; \textbf{1} &amp;               24 &amp;              239 &amp;          171 &amp;                                   no \\
        E &amp;       1 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\
        E &amp;       2 &amp;                9 &amp;                0 &amp;            0 &amp;                                   no \\
        E &amp;       3 &amp;                9 &amp;                0 &amp;            0 &amp;                                  yes \\
        E &amp;       4 &amp;               23 &amp;                0 &amp;            0 &amp;                                  yes \\
        F &amp;       1 &amp;               19 &amp;                0 &amp;            0 &amp;                                  yes \\
        F &amp;       2 &amp;               19 &amp;                0 &amp;            0 &amp;                                   no \\
        F &amp;       3 &amp;               19 &amp;                0 &amp;            0 &amp;                                  yes \\
        F &amp;       4 &amp;               14 &amp;                0 &amp;            0 &amp;                                  yes \\
        G &amp;       1 &amp;                2 &amp;                0 &amp;            0 &amp;                                  yes \\
        G &amp;       2 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\
        G &amp;       3 &amp;                1 &amp;                0 &amp;            0 &amp;                                   no \\
\bottomrule
\multicolumn{6}{l}{* signature contains the lexical patterns 'error', 'fault' or 'fail*'}\\
\multicolumn{6}{l}{$^{\#}$ sub-patterns that were removed to ensure a clean ground truth}
\end{tabular}
\vspace*{-3ex}
\end{table}
 
\subsection{Dataset and ground truth}
\label{sec:dataset}

Our dataset provided by \CiscoNorway{our industrial partner} consists
of failing and passing log files from 45 different end-to-end integration
tests. In addition to the log text we also have data on when a given
log file was produced. Most test-sets span a time-period of 38 days, while
the largest set (test 43 in Table~\ref{table:descriptive}) spans 112
days. Each failing log is known to exemplify symptoms of one of seven
known errors, and \CiscoNorway{our industrial partner} has given us a
set of regular expressions that help determine which events are relevant
for a given known error. We refer to the set of regular expressions
that identify a known error as a \emph{signature} for that error. These
signatures help us construct a ground truth for our investigation.
Moreover, an important motivation for developing SBLD is to help create
signatures for novel problems: The events highlighted by SBLD should be
characteristic of the observed failure, and the textual contents of the
events can be used in new signature expressions.

Descriptive facts about our dataset is listed in
Table~\ref{table:descriptive} while Table~\ref{table:signature}
summarizes key insights about the signatures used.

Ideally, our ground truth should highlight exactly and \emph{only} the
log events that an end user would find relevant for troubleshooting
an error. However, the signatures used in this investigation were
designed to find sufficient evidence that the \emph{entire log} in
question belongs to a certain error class: the log might contain other
events that a human user would find equally relevant for diagnosing
a problem, but the signature in question might not encompass these
events. Nevertheless, the events that constitute sufficient evidence
for assigning the log to a given error class are presumably relevant
and should be presented as soon as possible to the end user. However,
if our method cannot differentiate between these signature events and
other events we cannot say anything certain about the relevance of
those other events. This fact is reflected in our choice of quality
measures, specifically in how we assess the precision of the approach. This
is explained in detail in the next section.

When producing the ground truth, we first ensured that a log would only be
associated with a signature if the entire log taken as a whole satisfied all
the sub-patterns of that signature. If so, we then determined which events
the patterns were matching on. These events constitute the known-to-be relevant
set of events for a given log.  However, we identified some problems with two of the provided
signatures that made them unsuitable for assessing SBLD. Signature \emph{E}
(see Table~\ref{table:signature}) had a sub-pattern that searched for a "starting test"-prefix that necessarily
matches on the first event in all logs due to the structure of the logs.
Similarly, signature \emph{D} contained two sub-patterns that necessarily
match all logs in the set--in this case by searching for whether the test
was run on a given machine, which was true for all logs for the corresponding
test. We therefore elected to remove these sub-patterns from the signatures
before conducting the analysis.

\subsection{Quality Measures}

As a measure of how well SBLD reports all known-to-be relevant log
events, we measure \emph{recall in best cluster}, which we for brevity refer to
as simply \emph{recall}. 
This is an adaption of the classic recall measure used in information retrieval,
which tracks the proportion of all relevant events that were retrieved
by the system~\cite{manning2008introduction}. 
As our method presents events to the user in a series of ranked clusters, 
we ideally want all known-to-be relevant events to appear in the highest ranked cluster. 
We therefore track the overall recall obtained as if the first cluster were the only events retrieved.
Note, however, that SBLD ranks all clusters, and a user can retrieve additional clusters if desired. 
We explore whether this could improve SBLD's performance on a
specific problematic test-set in Section~\ref{sec:testfourtythree}.

It is trivial to obtain a perfect recall by simply retrieving all events
in the log, but such a method would obviously be of little help to a user
who wants to reduce the effort needed to diagnose failures.
We therefore also track the \emph{effort reduction} (ER), defined as
\[ \text{ER} = 1 - \frac{\text{number of events in first cluster}}{\text{number of events in log}} \]

Much like effective information retrieval systems aim for high recall and
precision, we want our method to score a perfect recall while obtaining the
highest effort reduction possible. 

\subsection{Recording the impact of added data}

To study the impact of added data on SBLD's performance, we need to measure how
SBLD's performance on a target log $t$ is affected by adding an extra
failing log $f$ or a passing log $p$. There are several strategies
for accomplishing this. One way is to try all combinations in the
dataset i.e.\ compute the performance on any $t$ using any choice of
failing and passing logs to produce the interestingness scores. This
approach does not account for the fact that the logs in the data are
produced at different points in time and is also extremely expensive
computationally. We opted instead to order the logs chronologically and
simulate a step-wise increase in data as time progresses, as shown in
Algorithm~\ref{alg:time}.

\begin{algorithm}[b]
\caption{Pseudo-code illustrating how we simulate a step-wise increase in data
        as time progresses and account for variability in choice of
        interestingness measure.}
\label{alg:time}
\begin{algorithmic}\small
\STATE $F$ is the set of failing logs for a given test
\STATE $P$ is the set of passing logs for a given test
\STATE $M$ is the set of interestingness measures considered
\STATE sort $F$ chronologically
\STATE sort $P$ chronologically
\FOR{$i=0$ to $i=\lvert F \rvert$}
        \FOR{$j=0$ to $j=\lvert P \rvert$}
                \STATE $f = F[:i]$ \COMMENT{get all elements in F up to and including position i}
                \STATE $p = P[:j]$
                \FORALL{$l$ in $f$}
                        \STATE initialize $er\_scores$ as an empty list
                        \STATE initialize $recall\_scores$ as an empty list
                        \FORALL{$m$ in $M$}
                                \STATE perform SBLD on $l$ using $m$ as measure \\ \hspace*{1.75cm} and $f$ and $p$ as spectrum data
                                \STATE append recorded effort reduction score to $er\_scores$
                                \STATE append recorded recall score to $recall\_scores$
                        \ENDFOR
                        \STATE record median of $er\_scores$
                        \STATE record median of $recall\_scores$
                \ENDFOR
        \ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Variability in interestingness measures}
\label{sec:imvars}

As mentioned in Section~\ref{sec:approach}, SBLD requires a
choice of interestingness measure for scoring the events, 
which can have a considerable impact on SBLD's performance. 
Considering that the best choice of interestingness measure is context-dependent, 
there is no global optimum, 
it is up to the user to decide which interestingness metric best reflects their
notion of event relevance. 

Consequently, we want to empirically study SBLD in way
that captures the variability introduced by this decision. 
To this end, we record the median score obtained by performing SBLD for every possible choice of
interestingness measure from those listed in Table~\ref{table:measures}.
Algorithm~\ref{alg:time} demonstrates the procedure in pseudo-code.

\subsection{Comparing alternatives}
\label{sec:comps}

To answer RQ2 and RQ3, we use pairwise comparisons of
different configurations of SBLD with a method that searches for regular expressions. 
The alternatives are compared
on each individual failing log in the set in a paired fashion. An
important consequence of this is that the statistical comparisons have
no concept of which test the failing log belongs to, and thus the test
for which there is most data has the highest impact on the result of the
comparison.

The pairwise comparisons are conducted using paired Wilcoxon signed-rank
tests~\cite{wilcoxon1945} where the Pratt correction~\cite{Pratt1959}
is used to handle ties. We apply Holm's correction~\cite{Holm1979}
to the obtained p-values to account for the family-wise error
rate arising from multiple comparisons. We declare a comparison
\emph{statistically significant} if the Holm-adjusted p-value is below
$\alpha=0.05$. The Wilcoxon tests check the two-sided null hypothesis of
no difference between the alternatives. We report the Vargha-Delaney $A_{12}$ and
$A_{21}$~\cite{Vargha2000} measures of stochastic superiority to
indicate which alternative is the strongest. Conventionally, $A_{12}=0.56$ is
considered a small difference, $A_{12}=.64$ is considered a medium difference
and $A_{12}=.71$ or greater is considered large~\cite{Vargha2000}. Observe
also that $A_{21} = 1 - A_{12}$.

\begin{figure*}
        \includegraphics[width=0.8\textwidth]{rq1_boxplot.png}
        %
        \caption{The overall performance of SBLD in terms of effort reduction
        and recall. On many tests, SBLD exhibited perfect recall for
        all observations in the inter-quartile range and thus the box collapses to a single line on the $1.0$ mark.\label{fig:rq1boxplot}}
\end{figure*}

\subsection{Analysis procedures}

We implement the SBLD approach in a prototype tool 
DAIM (Diagnosis and Analysis using Interestingness Measures), 
and use DAIM to empirically evaluate the idea.

\head{RQ1 - overall performance} We investigate the overall performance
of SBLD by analyzing a boxplot for each test in our dataset. Every individual
datum that forms the basis of the plot is the median performance of SBLD over
all choices of interestingness measures for a given set of failing and passing
logs subject to the chronological ordering scheme outlined above.

\head{RQ2 - impact of data} We analyze the impact of added data by
producing and evaluating heatmaps that show the obtained performance
as a function of the number of failing logs (y-axis) and number of
passing logs (x-axis). The color intensity of each tile in the heatmaps
is calculated by taking the median of the scores obtained for each
failing log analyzed with the given number of failing and passing logs
as data for the spectrum inference, wherein the score for each log is
the median over all the interestingness measures considered as outlined in
Section~\ref{sec:imvars}.

Furthermore, we compare three variant configurations
of SBLD that give an overall impression of the influence of added
data. The three configurations considered are \emph{minimal evidence},
\emph{median evidence} and \emph{maximal evidence}, where minimal
evidence uses only events from the log being analyzed and one additional
passing log, median evidence uses the median amount of respectively failing and
and passing logs available while maximal evidence uses
all available data for a given test. The comparisons are conducted with the
statistical scheme described above in Section~\ref{sec:comps}.

\head{RQ3 - SBLD versus pattern-based search} To compare SBLD
against a pattern-based search, we record the effort reduction and
recall obtained when only selecting events in the log that match on the
case-insensitive regular expression \texttt{"error|fault|fail*"}, where
the $*$ denotes a wildcard-operator and the $\lvert$ denotes logical
$OR$. This simulates the results that a user would obtain by using
a tool like \texttt{grep} to search for words like 'error' and 'failure'.
Sometimes the ground-truth signature expressions contain words from this
pattern, and we indicate this in Table~\ref{table:signature}. If so, the
regular expression-based method is guaranteed to retrieve the event.
Similarly to RQ2, we compare the three configurations of SBLD described
above (minimum, median and maximal evidence) against the pattern-based
search using the statistical described in Section~\ref{sec:comps}.

 %

\section{Results and Discussion}
\label{sec:resdiscuss}

This section gradually dissects Figure~\ref{fig:rq1boxplot}, showing a breakdown of SBLD's performance per test for both recall
and effort reduction, Figures \ref{fig:erheat} and \ref{fig:recallheat}, 
showing SBLD's performance as a function of the number of failing and passing
logs used, as well as Table~\ref{table:comparisons}, which shows the results
of the statistical comparisons we have performed.

\begin{figure*}
\includegraphics[width=\textwidth]{er_heatmap.pdf}
        \caption{Effort reduction score obtained when SBLD is run on a given number of failing and passing logs. The tests not listed in this figure all obtained a lowest median effort reduction score of 90\% or greater and are thus not shown for space considerations. \label{fig:erheat}}
\vspace*{-2ex}
\end{figure*}

\begin{table*}
\caption{Statistical comparisons performed in this investigation. The
bold p-values are those for which no statistically significant difference under $\alpha=0.05$
        could be established.}
\label{table:comparisons}
{\small%
\begin{tabular}{lllrrrr}
\toprule
 variant 1 &amp; variant 2 &amp;            quality measure &amp;  Wilcoxon statistic &amp;   $A_{12}$ &amp;  $A_{21}$   &amp; Holm-adjusted p-value\\
\midrule
 pattern-based search &amp;  minimal  evidence &amp;  effort reduction &amp; 29568.5 &amp; 0.777 &amp; 0.223 &amp;    $\ll$ 0.001 \\
 pattern-based search &amp;  maximal  evidence &amp;  effort reduction &amp; 202413.0 &amp; 0.506 &amp; 0.494 &amp;       \textbf{1.000} \\
 pattern-based search &amp;   median evidence &amp;  effort reduction &amp; 170870.5 &amp; 0.496 &amp; 0.504 &amp;    $\ll$ 0.001 \\
     minimal evidence &amp;  maximal evidence &amp;  effort reduction &amp; 832.0 &amp; 0.145 &amp; 0.855 &amp;    $\ll$ 0.001 \\
     minimal evidence &amp;   median evidence &amp;  effort reduction &amp; 2666.0 &amp; 0.125 &amp; 0.875 &amp;    $\ll$ 0.001 \\
     maximal evidence &amp;   median evidence &amp;  effort reduction &amp; 164674.0 &amp; 0.521 &amp; 0.479 &amp;       \textbf{1.000} \\
 pattern-based search &amp;  minimal evidence &amp;            recall &amp; 57707.0 &amp; 0.610 &amp; 0.390 &amp;    $\ll$ 0.001 \\
 pattern-based search &amp;  maximal evidence &amp;            recall &amp; 67296.0 &amp; 0.599 &amp; 0.401 &amp;    $\ll$ 0.001 \\
 pattern-based search &amp;   median evidence &amp;            recall &amp; 58663.5 &amp; 0.609 &amp; 0.391 &amp;    $\ll$ 0.001 \\
     minimal evidence &amp;  maximal evidence &amp;            recall &amp; 867.5 &amp; 0.481 &amp; 0.519 &amp;    $\ll$ 0.001 \\
     minimal evidence &amp;   median evidence &amp;            recall &amp;             909.0 &amp; 0.498 &amp; 0.502 &amp;       0.020 \\
     maximal evidence &amp;   median evidence &amp;            recall &amp; 0.0 &amp; 0.518 &amp; 0.482 &amp;    $\ll$ 0.001 \\
\bottomrule
\end{tabular}
 %
}
\end{table*}

\begin{figure}
\includegraphics[width=\columnwidth]{recall_heatmap.pdf}
        \caption{Recall score obtained when SBLD is run on a given number of failing and passing logs. For space
        considerations, we only show tests for which the minimum observed
        median recall was smaller than 1 (SBLD attained perfect median recall for all configurations in the other tests). \label{fig:recallheat}}
\vspace*{-3ex}
\end{figure}

\subsection{RQ1: The overall performance of SBLD}

Figure~\ref{fig:rq1boxplot} suggests that SBLD's overall performance is strong,
since it obtains near-perfect recall while retaining a high degree of effort
reduction.  In terms of recall, SBLD obtains a perfect performance on all except
four tests: 18, 34, 42 and 43, with the lower quartile stationed at perfect recall for all tests
except 43 (which we discuss in detail in Section~\ref{sec:testfourtythree}).
For test 18, only 75 out of 20700 observations ($0.036\%$) obtained a recall score
of $0.5$ while the rest obtained a perfect score. On test 34 (the smallest in our
dataset), 4 out of 39 observations obtained a score of zero recall while the
others obtained perfect recall. 
For test 42, 700 out of 15300 ($0.4\%$) observations obtained a score of zero recall while the rest obtained perfect recall.
Hence with the exception of test 43 which is discussed later, 
SBLD obtains very strong recall scores overall with only a few outliers.

The performance is also strong in terms of effort reduction, albeit
more varied. To a certain extent this is expected since the attainable
effort reduction on any log will vary with the length of the log and
the number of ground-truth relevant events in the log. As can be seen
in Figure~\ref{fig:rq1boxplot}, most of the observations fall well
over the 75\% mark, with the exceptions being tests 4 and 22. For test
4, Figure~\ref{fig:erheat} suggests that one or more of the latest
passing logs helped SBLD refine the interestingness scores. A similar
but less pronounced effect seems to have happened for test 22. However,
as reported in Table~\ref{table:descriptive}, test 22 consists only of
\emph{one} failing log. Manual inspection reveals that the log consists
of 30 events, of which 11 are fail-only events. Without additional
failing logs, most interestingness measures will give a high score to
all events that are unique to that singular failing log, which is likely
to include many events that are not ground-truth relevant. Reporting 11
out of 30 events to the user yields a meager effort reduction of around
63\%. Nevertheless, the general trend is that SBLD retrieves a compact
set of events to the user which yields a high effort reduction score.

In summary, the overall performance shows that SBLD
retrieves the majority of all known-to-be-relevant events
in compact clusters, which dramatically reduces the analysis burden for the
end user. The major exception is Test 43, which we return to in
Section~\ref{sec:testfourtythree}.

\subsection{RQ2: On the impact of evidence}

The heatmaps suggest that the effort reduction is generally not
adversely affected by adding more \emph{passing logs}. If the
assumptions underlying our interestingness measures are correct,
this is to be expected: Each additional passing log either gives us
reason to devalue certain events that co-occur in failing and passing
logs or contain passing-only events that are deemed uninteresting.
Most interestingness measures highly value events that
exclusively occur in failing logs, and additional passing logs help
reduce the number of events that satisfy this criteria. However, since
our method bases itself on clustering similarly scored events it is
weak to \emph{ties} in interestingness scores. It is possible that
an additional passing log introduces ties where there previously was
none. This is likely to have an exaggerated effect in situations with
little data, where each additional log can have a dramatic impact on the
interestingness scores. This might explain the gradual dip in effort
reduction seen in Test 34, for which there are only two failing logs.

Adding more failing logs, on the other hand, draws a more nuanced
picture: When the number of failing logs (y-axis) is high relative
to the number of passing logs (x-axis), effort reduction seems to suffer.
Again, while most interestingness measures will prioritize events that
only occur in failing logs, this strategy only works if there is a
sufficient corpus of passing logs to weed out false positives. When
there are far fewer passing than failing logs, many events will be
unique to the failing logs even though they merely reflect a different
valid execution path that the test can take. This is especially true for
complex integration tests like the ones in our dataset, which might test
a system's ability to recover from an error, or in other ways have many
valid execution paths.

The statistical comparisons summarized in Table~\ref{table:comparisons}
suggest that the minimal evidence strategy performs poorly compared to the
median and maximal evidence strategies. This is especially
pronounced for effort reduction, where the Vargha-Delaney
metric scores well over 80\% in favor of the maximal and median
strategy. For recall, the difference between the minimum strategy and
the other variants is small, albeit statistically significant. Furthermore,
the jump from minimal evidence to median evidence is much more
pronounced than the jump from median evidence to maximal evidence.
For effort reduction, there is in fact no statistically discernible
difference between the median and maximal strategies. For recall, the maximal
strategies seems a tiny bit better, but the $A_{12}$ measure suggests the
magnitude of the difference to be small.

Overall, SBLD seems to benefit from extra data, especially additional passing
logs. Failing logs also help, but depend on a proportional amount of passing
logs for SBLD to fully benefit. 
The performance increase from going from minimal data to some data is more pronounced than going from some data to
maximal data. This suggests that there may be diminishing returns to
collecting extra logs, but our investigation cannot prove or disprove this.

\subsection{RQ3: SBLD versus simple pattern-search}

In terms of effort reduction, Table~\ref{table:comparisons} shows that
the pattern-based search clearly beats the minimal evidence variant of
SBLD. It does not, however, beat the median and maximal variants: The
comparison to median evidence suggests a statistically significant win
in favor of median evidence, but the effect reported by $A_{12}$ is
so small that it is unlikely to matter in practice. No statistically
significant difference could be established between the pattern-based
search and SBLD with maximal evidence.

In one sense, it is to be expected that the pattern-based search does
well on effort reduction assuming that events containing words like
"fault" and "error" are rare. The fact that the pattern-based search
works so well could indicate that \CiscoNorway{our industrial partner}
has a well-designed logging infrastructure where such words are
rare and occur at relevant positions in the logs. On the other
hand, it is then notable that the median and maximum variants of SBLD perform
comparably on effort reduction without having any concept of the textual
content in the events.

In terms of recall, however, pattern-based search beats all variants of
SBLD in a statistically significant manner, where the effect size of the
differences is small to medium.  One likely explanation for this better performance is that the
pattern-based search performs very well on Test 43, which SBLD generally
performs less well on. Since the comparisons are run per failing log and test
43 constitutes 29\% of the failing logs (specifically, 267 out of 910 logs), the
performance of test 43 has a massive impact. We return to test 43 and its
impact on our results in Section~\ref{sec:testfourtythree}.

On the whole, SBLD performs similarly to pattern-based search, obtaining
slightly poorer results on recall for reasons that are likely due
to a particular test we discuss below. At any rate, there is no
contradiction in combining SBLD with a traditional pattern-based search.
Analysts could start by issuing a set of pattern-based searches and
run SBLD afterward if the pattern search returned unhelpful results.
Indeed, an excellent and intended use of SBLD is to suggest candidate
signature patterns that, once proven reliable, can be incorporated in a
regular-expression based search to automatically identify known issues
in future runs.

\subsection{What happens in Test 43?}
\label{sec:testfourtythree}

SBLD's performance is much worse on Test 43 than the other tests, which
warrants a dedicated investigation. The first thing we observed in the
results for Test 43 is that all of the ground-truth-relevant events
occurred \emph{exclusively} in failing logs and were often singular
(11 out of the 33) or infrequent (30 out of 33 events occurred in 10\%
of the failing logs or fewer). Consequently, we observed a strong
performance from the \emph{Tarantula} and \emph{Failed only}-measures
that put a high premium on failure-exclusive events. Most of the
interestingness measures, on the other hand, will prefer an event that
is very frequent in the failing logs and sometimes occur in passing logs
over a very rare event that only occurs in failing logs. This goes a
long way in explaining the poor performance on recall. The abundance of
singular events might also suggest that there is an error in the event
abstraction framework, where several events that should be treated as
instances of the same abstract event are treated as separate events. We
discuss this further in Section~\ref{sec:ttv}.

\begin{sloppypar}%
Another observation we made is that the failing logs contained only \emph{two}
ground-truth relevant events, which means that the recorded recall can quickly
fluctuate between $0$, $0.5$ and $1$.
\end{sloppypar}

Would the overall performance improve by retrieving an additional
cluster? A priori, retrieving an extra cluster would strictly improve
or not change recall since more events are retrieved without removing
the previously retrieved events. Furthermore, retrieving an additional
cluster necessarily decreases the effort reduction. We re-ran the
analysis on Test 43 and collected effort reduction and recall scores
for SBLD when retrieving \emph{two} clusters, and found that the added
cluster increased median recall from $0$ to $0.5$ while the median
effort reduction decreased from $0.97$ to $0.72$. While the proportional
increase in recall is larger than the decrease in effort reduction,
this should in our view not be seen as an improvement: As previously
mentioned, the failing logs in this set contain only two ground-truth
relevant events and thus recall is expected to fluctuate greatly.
Secondly, an effort reduction of $0.72$ implies that you still have to
manually inspect 28\% of the data, which in most information retrieval
contexts is unacceptable. An unfortunate aspect of our analysis in this
regard is that we do not account for event \emph{lengths}: An abstracted
event is treated as one atomic entity, but could in reality vary from a
single line to a stack trace that spans several pages. A better measure
of effort reduction should incorporate a notion of event length to
better reflect the real-world effect of retrieving more events.

All in all, Test 43 exhibits a challenge that SBLD is not suited for:
It asks SBLD to prioritize rare events that are exclusive to failing
logs over events that frequently occur in failing logs but might
occasionally occur in passing logs. The majority of interestingness
measures supported by SBLD would prioritize the latter category of
events. In a way, this might suggest that SBLD is not suited for finding
\emph{outliers} and rare events: Rather, it is useful for finding
events that are \emph{characteristic} for failures that have occurred
several times - a "recurring suspect", if you will. An avenue for future
research is to explore ways of letting the user combine a search for
"recurring suspects" with the search for outliers.

 %

\section{Related Work}
\label{sec:relwork}

We distinguish two main lines of related work: 
First, there is other work aimed at automated analysis of log files, 
i.e., our problem domain,
and second, there is other work that shares similarities with our technical approach, 
i.e., our solution domain.

\head{Automated log analysis}
Automated log analysis originates in \emph{system and network monitoring} for security and administration~\cite{lin1990:error,Oliner2007}, 
and saw a revival in recent years due to the needs of \emph{modern software development}, \emph{CE} and \emph{DevOps}~\cite{Hilton2017,Laukkanen2017,Debbiche2014,Olsson2012,Shahin2017,candido2019:contemporary}.

A considerable amount of research has focused on automated \emph{log parsing} or \emph{log abstraction}, 
which aims to reduce and organize log data by recognizing latent structures or templates in the events in a log~\cite{zhu2019:tools,el-masri2020:systematic}.
He et al. analyze the quality of these log parsers and conclude that many of them are not accurate or efficient enough for parsing the logs of modern software systems~\cite{he2018:automated}.
In contrast to these automated approaches, 
our study uses a handcrafted log abstracter developed by \CiscoNorway{our industrial collaborator}.

\emph{Anomaly detection} has traditionally been used for intrusion detection and computer security~\cite{liao2013:intrusion,ramaki2016:survey,ramaki2018:systematic}.
Application-level anomaly detection has been investigated for troubleshooting~\cite{chen2004:failure,zhang2019:robust},
and to assess compliance with service-level agreements~\cite{banerjee2010:logbased,He2018,sauvanaud2018:anomaly}.
Gunter et al. present an infrastructure for troubleshooting of large distributed systems, %
by first (distributively) summarizing high volume event streams before submitting those summaries to a centralized anomaly detector. 
This helps them achieve the fidelity needed for detailed troubleshooting, 
without suffering from the overhead that such detailed instrumentation would bring~\cite{Gunter2007}.
Deeplog by Du et al. enables execution-path and performance anomaly detection in system logs by training a Long Short-Term Memory neural network of the system's expected behavior from the logs, and using that model to flag events and parameter values in the logs that deviate from the model's expectations~\cite{Du2017}.
Similarly, LogRobust by Zhang et al. performs anomaly detection using a bi-LSTM neural network but also detects events that are likely evolved versions of previously seen events, making the learned model more robust to updates in the target logging infrastructure~\cite{zhang2019:robust}.

In earlier work, we use \emph{log clustering} to reduce the effort needed to process a backlog of failing CE logs 
by grouping those logs that failed for similar reasons~\cite{rosenberg2018:use,rosenberg:2018:improving}. 
They build on earlier research that uses log clustering to identify problems in system logs~\cite{Lin2016,Shang2013}.
Common to these approaches is how the contrast between passing and failing logs is used to improve accuracy, 
which is closely related to how SBLD highlights failure-relevant events.

Nagarash et al.~\cite{nagaraj:2012} explore the use of dependency networks to exploit the contrast between two sets of logs, 
one with good and one with bad performance, 
to help developers understand which component(s) likely contain the root cause of performance issues.

An often-occurring challenge is the need to (re)construct an interpretable model of a system's execution.
To this end, several authors investigate the combination of log analysis with (static) source code analysis, 
where they try to (partially) match events in logs to log statements in the code, 
and then use these statements to reconstruct a path through the source code to help determine 
what happened in a failed execution~\cite{Xu2009,yuan:2010:sherlog,zhao2014:lprof,schipper2019:tracing}.
Gadler et al. employ Hidden Markov Models to create a model of a system's usage patterns from logged events~\cite{gadler2017:mining}, while
Pettinato et al. model and analyze the behavior of a complex telescope system using Latent Dirichlet Allocation~\cite{pettinato2019:log}.

Other researchers have analyzed the logs for successful and failing builds, 
to warn for anti-patterns and decay~\cite{vassallo2019:automated}, 
give build repair hints~\cite{Vassallo2018}, 
and automatically repair build scripts~\cite{hassan2018:hirebuild, tarlow2019:learning}. 
Opposite to our work,
these techniques exploit the \emph{overlap} in build systems used by many projects to mine patterns that hint at decay or help repair a failing build, 
whereas we exploit the \emph{contrast} with passing runs for the same project to highlight failure-relevant events.

\begin{sloppypar}
\head{Fault Localization} 
As mentioned, our approach was inspired by Spectrum-Based Fault Localization (SBFL), 
where the fault-proneness of a statement is computed as a function of 
the number of times that the statement was executed in a failing test case, combined with 
the number of times that the statement was skipped in a passing test case~\cite{Jones2002,Chen2002,Abreu2007,Abreu2009,Naish2011}.
This more or less directly translates to the inclusion or exclusion of events in failing, resp. passing logs, 
where the difference is that SBLD adds clustering of the results to enable step-wise presentation of results to the user. 
\end{sloppypar}

A recent survey of Software Fault Localization includes the SBFL literature up to 2014~\cite{Wong2016}.
De Souza et. all extend this with SBFL work up to to 2017, and add an overview of seminal work on automated debugging from 1950 to 1977~\cite{deSouza2017}.
By reflecting on the information-theoretic foundations of fault localization, Perez proposes the DDU metric, 
which can be used to evaluate test suites and predict their diagnostic performance when used in SBFL~\cite{Perez2018}. 
One avenue for future work is exploring how a metric like this can be adapted to our context, 
and see if helps to explain what happened with test 43.

A recent evaluation of \emph{pure} SBFL on large-scale software systems found that it under-performs in these situations 
(only 33-40\% of the bugs are identified with the top 10 of ranked results~\cite{heiden2019:evaluation}. 
The authors discuss several directions beyond pure SBFL, such as combining it with dynamic program analysis techniques, 
including additional text analysis/IR techniques~\cite{Wang2015a}, mutation based fault localization, 
and using SBFL in an interactive feedback-based process, such as whyline-debugging~\cite{ko2008:debugging}.
Pure SBFL is closely related to the Spectrum-Based Log Diagnosis proposed here, 
so we may see similar challenges (in fact, test 43 may already show some of this). 
Of the proposed directions to go beyond pure SBFL, 
both the inclusion of additional text analysis/IR techniques, 
and the application of Spectrum-Based Log Diagnosis in an interactive feedback-based process
are plausible avenues to extend our approach. 
Closely related to the latter option, 
de Souza et al.~\cite{deSouza2018b} assess guidance and filtering strategies to \emph{contextualize} the fault localization process.
Their results suggest that contextualization by guidance and filtering can improve the effectiveness of SBFL,
by classifying more actual bugs in the top ranked results.

\begin{comment}

Direct comparison~\cite{He2018, jiang2017:what, Jones:2007:DP:1273463.1273468,
Xu2009, Hwa-YouHsu:2008:RIB:1642931.1642994}.  

Hsu et
al~\cite{Hwa-YouHsu:2008:RIB:1642931.1642994} discuss methods for extracting
failure signatures as sequences of code executions, which in spirit is rather
similar to what we are trying to accomplish.

An interesting data-structure, the event correlation
graph, is explores in~\cite{Fu2012a}. An FL metric that takes frequencies into
account~\cite{Shu2016}.
\end{comment}

 %
\section{Threats to Validity}
\label{sec:ttv}

\head{Construct Validity} %
The signatures that provide our ground truth were devised to determine whether a given log \emph{in its entirety} showed symptoms of a known error.
As discussed in Section~\ref{sec:dataset}, we have used these signatures to detect events that give sufficient evidence for a symptom, 
but there may be other events that could be useful to the user that are not part of our ground truth.
We also assume that the logs exhibit exactly the failures described by the signature expression.
In reality, the logs could contain symptoms of multiple failures beyond the ones described by the signature.

Furthermore, we currently do not distinguish between events that consist of single line of text, 
or events that contain a multi-line stack-trace, although these clearly represent different comprehension efforts.
This threat could be addressed by tracking the \emph{length} of the event contents, 
and using it to further improve the accuracy of our effort reduction measure.

The choice of clustering algorithm and parameters affects the events retrieved, 
but our investigation currently only considers HAC with complete linkage.
While we chose complete linkage to favor compact clusters, 
outliers in the dataset could cause unfavorable clustering outcomes.
Furthermore, using the uncorrected sample standard deviation as threshold criterion 
may be too lenient if the variance in the scores is high.
This threat could be addressed by investigate alternative cluster algorithm and parameter choices.

Moreover, as for the majority of log analysis frameworks, the performance of SBLD strongly depends on the quality of log abstraction. 
An error in the abstraction will directly propagate to SBLD: 
For example, if abstraction fails to identify two concrete events as being instances of the same generic event, 
their aggregated frequencies will be smaller and consequently treated as less interesting by SBLD.
Similarly, the accuracy will suffer if two events that represent distinct generic events are treated as instances of the same generic event.
Future work could investigate alternative log abstraction approaches.

\head{Internal Validity} %
While our heatmaps illustrate the interaction between additional data and SBLD performance, 
they are not sufficient to prove a causal relationship between performance and added data.
Our statistical comparisons suggests that a strategy of maximizing data is generally preferable, 
but they are not sufficient for discussing the respective contribution of failing or passing logs.

\head{External Validity} %
This investigation is concerned with a single dataset from one industrial partner.
Studies using additional datasets from other contexts is needed to assess the generalizability of SBLD to other domains.
Moreover, while SBLD is made to help users diagnose problems that are not already well understood,
we are assessing it on a dataset of \emph{known} problems.
It could be that these errors, being known, are of a kind that are generally easier to identify than most errors.
Studying SBLD in-situ over time and directly assessing whether end users found it helpful
in diagnosis would better indicate the generalizability of our approach.

 %

\section{Concluding Remarks}
\label{sec:conclusion}

\head{Contributions}
This paper presents and evaluates Spectrum-Based Log Diagnosis (SBLD), 
a method for automatically identifying segments of failing logs 
that are likely to help users diagnose failures. 
Our empirical investigation of SBLD addresses the following questions: 
(i) How well does SBLD reduce the \emph{effort needed} to identify all \emph{failure-relevant events} in the log for a failing run? 
(ii) How is the \emph{performance} of SBLD affected by \emph{available data}? 
(iii) How does SBLD compare to searching for \emph{simple textual patterns} that often occur in failure-relevant events? 

\head{Results}
In response to (i), 
we find that SBLD generally retrieves the failure-relevant events in a compact manner 
that effectively reduces the effort needed to identify failure-relevant events. 
In response to (ii), 
we find that SBLD benefits from addition data, especially more logs from successful runs. 
SBLD also benefits from additional logs from failing runs if there is a proportional amount of successful runs in the set. 
We also find that the effect of added data is most pronounced when going from little data to \emph{some} data rather than from \emph{some} data to maximal data. 
In response to (iii), 
we find that SBLD achieves roughly the same effort reduction as traditional search-based methods but obtains slightly lower recall. 
We trace the likely cause of this discrepancy on recall to a prominent part of our dataset, whose ground truth emphasizes rare events. 
A lesson learned in this regard is that SBLD is not suited for finding statistical outliers but rather \emph{recurring suspects} 
that characterize the observed failures. 
Furthermore, the investigation highlights that traditional pattern-based search and SBLD can complement each other nicely: 
Users can resort to SBLD if they are unhappy with what the pattern-based searches turn
up, and SBLD is an excellent method for finding characteristic textual patterns
that can form the basis of automated failure identification methods.

\head{Conclusions}
We conclude that SBLD shows promise as a method diagnosing failing runs, 
that its performance is positively affected by additional data, 
but that it does not outperform textual search on the dataset considered. 

\head{Future work}
We see the following directions for future work: 
(a) investigate SBLD's performance on other datasets, to better assess generalizability, 
(b) explore the impact of alternative log abstraction mechanisms,
(c) explore ways of combining SBLD with outlier detection, to accommodate different user needs, 
(d) adapt the Perez' DDU metric to our context and see if it can help predict diagnostic efficiency,
(e) experiment with extensions of \emph{pure SBLD} that include additional text analysis/IR techniques, 
    or apply it in an interactive feedback-based process
(f) rigorously assess (extensions of) SBLD in in-situ experiments.

\begin{acks}
We thank Marius Liaaen and Thomas Nornes of Cisco Systems Norway for help with obtaining and understanding the dataset, for developing the log abstraction
mechanisms and for extensive discussions.
This work is supported by the \grantsponsor{RCN}{Research Council of Norway}{https://www.rcn.no} through the
Certus SFI (\grantnum{RCN}{\#203461/030)}.
The empirical evaluation was performed on resources provided by \textsc{uninett s}igma2,
the national infrastructure for high performance computing and data
storage in Norway.
\end{acks}

 \printbibliography

\end{document}
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">{'timestamp': '2020-08-18T02:18:33', 'yymm': '2008', 'arxiv_id': '2008.06948', 'language': 'en', 'url': 'https://arxiv.org/abs/2008.06948'}</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="3"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">\section{Introduction}
When granular material in a cubic container is shaken
horizontally one observes experimentally different types of
instabilities, i.e. spontaneous formation of ripples in shallow
beds~\cite{StrassburgerBetatSchererRehberg:1996},
liquefaction~\cite{RistowStrassburgerRehberg:1997,Ristow:1997}, convective
motion~\cite{TennakoonBehringer:1997,Jaeger} and recurrent swelling of
shaken material where the period of swelling decouples from the
forcing period~\cite{RosenkranzPoeschel:1996}. Other interesting experimental results concerning simultaneously vertically and horizontally vibrated granular systems~\cite{TennakoonBehringer:1998} and enhanced packing of spheres due to horizontal vibrations~\cite{PouliquenNicolasWeidman:1997} have been reported recently. Horizontally shaken
granular systems have been simulated numerically using cellular
automata~\cite{StrassburgerBetatSchererRehberg:1996} as well as
molecular dynamics
techniques~\cite{RistowStrassburgerRehberg:1997,Ristow:1997,IwashitaEtAl:1988,LiffmanMetcalfeCleary:1997,SaluenaEsipovPoeschel:1997,SPEpre99}.
Theoretical work on horizontal shaking can be found
in~\cite{SaluenaEsipovPoeschel:1997} and the dynamics of a single
particle in a horizontally shaken box has been discussed
in~\cite{DrosselPrellberg:1997}.

\begin{figure}[htbp]
 \centerline{\psfig{file=sketch.eps,width=7cm,clip=}}  
  \caption{Sketch of the simulated system.}
  \label{fig:sketch}
\end{figure}

Recently the effect of convection in a horizontally shaken box filled with 
granular material attracted much attention and presently the effect is studied
experimentally by different
groups~\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996}.
Unlike the effect of convective motion in vertically shaken granular
material which has been studied intensively experimentally,
analytically and by means of computer simulations
(s.~e.g.~\cite{vertikalEX,JaegerVert,vertikalANA,vertikalMD}), there
exist only a few references on horizontal shaking. Different from the
vertical case, where the ``architecture'' of the convection pattern is
very simple~\cite{BizonEtAl:1998}, in horizontally shaken containers one observes a variety
of different patterns, convecting in different directions, in parallel
as well as perpendicular to the direction of
forcing~\cite{TennakoonBehringer:1997}. Under certain conditions one
observes several convection rolls on top of each other~\cite{Jaeger}.
An impression of the complicated convection can be found in the
internet~\cite{movies}.

Whereas the properties of convection in vertically sha\-ken systems
can be reproduced by two dimensional molecular dynamics simulations
with good reliability, for the case of horizontal motion the results
of simulations are inconsistent with the experimental results: in {\em
  all} experimental investigations it was reported that the material
flows downwards close to the vertical
walls~\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996,movies},
but reported numerical simulations systematically show surface rolls
in opposite direction accompanying the more realistic deeper rolls, or
even replacing them completely~\cite{LiffmanMetcalfeCleary:1997}.

Our investigation is thus concerned with the convection pattern, i.e. the
number and direction of the convection rolls in a two dimensional
molecular dynamics simulation. We will show that the choice of the
dissipative material parameters has crucial influence on the convection pattern
and, in particular, that the type of convection rolls observed experimentally
can be 
reproduced by using sufficiently high dissipation constants.

\section{Numerical Model}
The system under consideration is sketched in Fig.~\ref{fig:sketch}:
we simulate a two-dimensional vertical cross section of a three-dimensional
container.
This rectangular section of width $L=100$ (all units in cgs system), and
infinite height, contains $N=1000$ spherical particles. The system is
periodically driven by an external oscillator $x(t) = A \sin (2\pi f
t)$ along a horizontal plane. For the effect we want to show, a
working frequency $f=10$ and amplitude $A=4$ is
selected. 
These values give an acceleration amplitude of approximately $16 g$.
Lower accelerations affect the intensity of the
convection but do not change the basic features of the convection 
pattern which we want to discuss. 
As has been shown in~\cite{SPEpre99},
past the fluidization point, a much better indicator of the convective
state is the dimensionless velocity $A 2\pi f/ \sqrt{Lg}$. This means
that in small containers motion saturates earlier, hence,  results for
different container lengths at the same values of the acceleration amplitude 
cannot be compared directly. Our acceleration amplitude $\approx 16g$ corresponds to
$\approx 3g$ in a 10 cm container (provided that the frequency is the same
and particle sizes have been 
scaled by the same amount).


The radii of the particles of density $2$ are homogeneously
distributed in the interval $[0.6, 1.4]$. The rough inner walls of the
container are simulated by attaching additional particles of the same
radii and material properties (this simulation technique is similar to ``real''
experiments, e.g.~\cite{JaegerVert}). 

For the molecular dynamics simulations, we apply a modified
soft-particle model by Cundall and Strack~\cite{CundallStrack:1979}:
Two particles $i$ and $j$, with radii $R_i$ and $R_j$ and at positions
$\vec{r}_i$ and $\vec{r}_j$, interact if their compression $\xi_{ij}=
R_i+R_j-\left|\vec{r}_i -\vec{r}_j\right|$ is positive. In this case
the colliding spheres feel the force
 $F_{ij}^{N} \vec{n}^N + F_{ij}^{S} \vec{n}^S$, 
with $\vec{n}^N$ and $\vec{n}^S$ being the unit vectors in normal and shear
direction. The normal force acting between colliding spheres reads
\begin{equation}
 F_{ij}^N = \frac{Y\sqrt{R^{\,\mbox{\it\footnotesize\it eff}}_{ij}}}{1-\nu^2} 
~\left(\frac{2}{3}\xi_{ij}^{3/2} + B \sqrt{\xi_{ij}}\, 
\frac{d {\xi_{ij}}}{dt} \right)
\label{normal}
\end{equation}
where $Y$ is the Young modulus, $\nu$ is the Poisson ratio and $B$ 
is a material constant which characterizes the dissipative
character of the material~\cite{BSHP}. 
\begin{equation}
R^{\,\mbox{\it\footnotesize\it
    eff}}_{ij} = \left(R_i R_j\right)/\left(R_i + R_j\right)  
\end{equation}
 is the
effective radius. For a strict derivation of (\ref{normal})
see~\cite{BSHP,KuwabaraKono}.

For the shear force we apply the model by Haff and Werner~\cite{HaffWerner}
\begin{equation}
F_{ij}^S = \mbox{sign}\left({v}_{ij}^{\,\mbox{\it\footnotesize\it rel}}\right) 
\min \left\{\gamma_s m_{ij}^{\,\mbox{\it\footnotesize\it eff}} 
\left|{v}_{ij}^{\,\mbox{\it\footnotesize\it rel}}\right|~,~\mu 
\left|F_{ij}^N\right| \right\} 
\label{shear}      
\end{equation}
with the effective mass $m_{ij}^{\,\mbox{\it\footnotesize\it eff}} =
\left(m_i m_j\right)/\left(m_i + m_j\right)$ and the relative velocity
at the point of contact
\begin{equation}
{v}_{ij}^{\,\mbox{\it\footnotesize\it rel}} = \left(\dot{\vec{r}}_i - 
\dot{\vec{r}}_j\right)\cdot \vec{n}^S + R_i {\Omega}_i + R_j  {\Omega}_j ~.
\end{equation}
$\Omega_i$ and $\Omega_j$ are the angular velocities of the particles.
 
The resulting momenta $M_i$ and $M_j$ acting upon the particles are
$M_i = F_{ij}^S R_i$ and $M_j = - F_{ij}^S R_j$. Eq.~(\ref{shear})
takes into account that the particles slide upon each other for the
case that the Coulomb condition $\mu \mid F_{ij}^N \mid~&lt;~\left| 
F_{ij}^S \right|$ holds, otherwise they feel some viscous friction.
By means of $\gamma _{n} \equiv BY/(1-\nu ^2)$ and $\gamma _{s}$,
normal and shear damping coefficients, energy loss during particle
contact is taken into account~\cite{restitution}.

The equations of motion for translation and rotation have been solved
using a Gear predictor-corrector scheme of sixth order
(e.g.~\cite{AllenTildesley:1987}).

The values of the coefficients used in simulations are $Y/(1-\nu
^2)=1\times 10^{8}$, $\gamma _{s}=1\times 10^{3}$, $ \mu =0.5$. For
the effect we want to show, the coefficient $\gamma _{n}$ takes values within the range
$\left[10^2,10^4\right]$.

\section{Results}
The mechanisms for convection under horizontal shaking have been
discussed in \cite{LiffmanMetcalfeCleary:1997}. Now we can show that
these mechanisms can be better understood by taking into account the
particular role of dissipation in this problem. The most striking
consequence of varying the normal damping coefficient is the change
in organization of the convective pattern, i.e. the direction and
number of rolls in the stationary regime. This is shown in
Fig.~\ref{fig1}, which has been obtained after averaging particle
displacements over 200 cycles 
(2 snapshots per cycle).
The asymmetry of compression and expansion of particles close to
the walls (where the material results highly compressible) explains 
the large transverse velocities shown in the figure.
Note, however, that the upward and downward motion at the walls cannot be altered 
by this particular averaging procedure. 

The first frame shows a convection pattern with only two rolls, where
the arrows indicate that the grains slide down the walls, with at most
a slight expansion of the material at the surface. 
There are no surface rolls.
This is very
similar to what has been observed in
experiments\cite{TennakoonBehringer:1997,Jaeger,RosenkranzPoeschel:1996}.
In this case, dissipation is high enough to damp most of the sloshing
induced by the vertical walls, and not even the grains just below the
surface can overcome the pressure gradient directed downwards.

For lower damping, we see the developing of surface rolls, 
which
coexist with the inner rolls circulating in the opposite way. Some
energy is now available for upward motion when the walls compress the
material fluidized during the opening of the wall ``gap'' (empty space
which is created alternatively during the shaking motion). This is the
case reported in \cite{LiffmanMetcalfeCleary:1997}. The last frames
demonstrate how the original rolls vanish at the same time that the
surface rolls grow occupying a significant part of the system.
Another feature shown in the figure is the thin layer of material involving
3 particle rows close to the bottom, which perform a different kind
of motion. This effect, which can be seen in all frames,
is due to the presence of the constraining boundaries
but has not been analyzed separately.
\onecolumn
\begin{figure}
\centerline{\psfig{file=fric1nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric2nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric3nn.eps,width=5.7cm,clip=}}
\centerline{\psfig{file=fric4nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric5nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric6nn.eps,width=5.7cm,clip=}}
\centerline{\psfig{file=fric7nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric8nn.eps,width=5.7cm,clip=}
\hspace{0.3cm}\psfig{file=fric9nn.eps,width=5.7cm,clip=}}
\vspace{0.3cm}
\caption{Velocity field obtained after cycle averaging of 
  particle displacements, for different values of the normal damping
  coefficient, $\gamma_n$. The first one is $1\times 10^4$, and for
  obtaining each subsequent frame the coefficient has been divided by
  two. The frames are ordered from left to right and from top to
  bottom. The cell size for averaging is approximately one particle diameter.}
\label{fig1}
\vspace*{-0.2cm}
\end{figure}
\twocolumn

With decreasing normal damping $\gamma_n$ there are two transitions 
observable in Fig.~\ref{fig1}, meaning that the convection pattern changes
qualitatively at these two particular values of $\gamma_n$:
The first transition leads to the appearance of two surface rolls
laying on top of the bulk cells and circulating in opposite direction.
The second transition eliminates the bulk rolls. A more detailed analysis of 
the displacement fields  (Fig.~\ref{fig2})
allows us to locate the transitions much more precisely.
In Fig.~\ref{fig2} we have represented in  grey-scale the horizontal and
vertical components of the displacement vectors pictured in
Fig.~\ref{fig1} but in a denser sampling, analyzing data from 30 simulations 
corresponding to 
values of the normal damping coefficient within the interval [50,10000]. 
For horizontal displacements, we have chosen vertical sections 
at some representative position in horizontal direction
($x=30$). For the vertical displacements, vertical sections of the
leftmost part of the container were selected ($x=10$), s.
Fig.~\ref{fig2}, lower part.
\begin{figure}
  \centerline{\psfig{file=vx.eps,width=4.5cm,clip=}\hspace{-0.5cm}
    \psfig{file=vy.eps,width=4.5cm,clip=}

\centerline{\psfig{file=sectionn.eps,height=4.2cm,bbllx=7pt,bblly=16pt,bburx=507pt,bbury=544pt,clip=}}
\vspace*{0.2cm}
\caption{Horizontal (left) and vertical (right) displacements at 
  selected positions of the frames in Fig.~\ref{fig1} (see the text
  for details), for decreasing normal damping and as a function of
  depth. White indicates strongest flow along positive axis directions
  (up,right), and black the corresponding negative ones. The black region 
  at the bottom of the left picture corresponds to the complex boundary
  effect observed in Fig.~\ref{fig1}, involving only two particle layers.
  The 
  figure below shows a typical convection pattern together with the sections
  at $x=10$ and $x=30$ at which the displacements were recorded.}
\label{fig2}
\vspace*{-0.1cm}
\end{figure}

The horizontal axis shows the values of the normal damping
coefficient scaled logarithmically in decreasing sequence. The
vertical axis represents the position in vertical direction, with the
free surface of the system located at $y \approx 60$.  One observes first
that white surface shades, complemented by subsurface black ones,
appear quite clearly at about $\gamma =$2000 in Fig.~\ref{fig2}
(left), indicating the appearance of surface rolls. On the other
hand, Fig.~\ref{fig2} (right) shows a black area (indicative of
downward flow along the vertical wall) that vanishes at
$\gamma_n \approx 200$ (at this point the grey shade represents vanishing vertical velocity). 
The dashed lines in Fig.~\ref{fig2} lead the eye to identify the transition values.
In the interval $ 200 \lesssim \gamma_n
\lesssim 2000$ surface and inner rolls coexist, rotating in opposite
directions.

One can analyze the situation in terms of the restitution coefficient.
\ From Eq. (\ref{normal}), the equation of motion for the displacement
$\xi_{ij}$ can be integrated and the relative energy loss in a
collision $\eta=(E_0-E)/E_0$ (with $E$ and $E_0$ being the energy of
the relative motion of the particles) can be evaluated approximately.
Up to the lowest order in the expansion parameter, one
finds~\cite{Thomas-Thorsten}
\begin{equation}
\eta = 1.78 \left( \frac{\tau}{\ell} v_0\right)^{1/5}\;,
\label{energyloss}
\end{equation}
where $v_0$ is the relative initial velocity in normal direction, and
$\tau$, $\ell$, time and length scales associated with the problem
(see~\cite{Thomas-Thorsten} for details),

\begin{equation}
\tau = \frac{3}{2} B\; ,~~~~~~~~~
\ell = \left(\frac{1}{3} \frac{m_{ij}^{\,\mbox{\it\footnotesize\it eff}} 
}{\sqrt{R^{\,\mbox{\it\footnotesize\it eff}}_{ij}} 
B \gamma_{n}}\right)^{2}.
\end{equation}
For $\gamma_n = 10^4$ (the highest value analyzed) and the values of
the parameters specified above ($v_0 \approx A 2\pi f$ for collisions
with the incoming wall), $B= 10^{-4}$ and $\eta$ is typically
50\%. This means that after three more collisions the particle leaves
with an energy not enough to overcome the height of one single
particle in the gravity field. For $\gamma_n = 10^3$ and the other
parameters kept constant, $B=10^{-5}$ and $\eta$ has been
reduced to 5\%, resulting in that the number of collisions needed for
the particle to have its kinetic energy reduced to the same residual
fraction, has increased roughly by an order of magnitude. On the other
hand, given the weak dependence of Eq. (\ref{energyloss}) on the
velocity, one expects that the transitions shown in Fig.~\ref{fig2}
will depend also weakly on the amplitude of the shaking velocity. The reduction of the
inelasticity $\eta$ by an order of magnitude seems enough for
particles to ``climb'' the walls and develop the characteristic
surface rolls observed in numerical simulations.

\section{Discussion}
We have shown that the value of the normal damping coefficient
influences the convective pattern of horizontally shaken granular
materials. By means of molecular dynamics simulations in two
dimensions we can reproduce the pattern observed in real experiments,
which corresponds to a situation of comparatively high damping,
characterized by inelasticity parameters $\eta$ larger than 5\%. For
lower damping, the upper layers of the material develop additional
surface rolls as has been reported previously. As normal damping
decreases, the lower rolls descend and finally disappear completely at
inelasticities of the order of 1\%.

\begin{acknowledgement}
The authors want to thank R. P. Behringer, H. M. Jaeger, M. Medved,
and D. Rosenkranz for providing experimental results prior to
publication and V. Buchholtz, S. E. Esipov, and L. Schimansky-Geier
for discussion. The calculations have been done on the parallel
machine {\it KATJA} (http://summa.physik.hu-berlin.de/KATJA/) of the
medical department {\em Charit\'e} of the Humboldt University Berlin.
The work was supported by Deut\-sche Forschungsgemeinschaft through
grant Po 472/3-2.
\end{acknowledgement}

</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">{'timestamp': '2002-03-19T12:47:20', 'yymm': '9807', 'arxiv_id': 'cond-mat/9807071', 'language': 'en', 'url': 'https://arxiv.org/abs/cond-mat/9807071'}</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="4"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\\section{\\label{sec:intro}Introduction}\n \nDemonstration of non-abelian exchange statistics is o<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '2022-10-20T02:16:28', 'yymm': '2210', 'arxiv_id': '2210.10650', 'language': 'en', 'u<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="5"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\\section{Introduction}\n\nOver the last decade, imaging atmospheric Cherenkov telescopes\n(IACTs) <span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '1998-07-13T09:54:01', 'yymm': '9807', 'arxiv_id': 'astro-ph/9807119', 'language': 'e<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="6"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\\section{Introduction}\n\\label{sec:introduction}\nA plethora of observations have led to confirm <span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '2021-11-08T02:04:43', 'yymm': '2111', 'arxiv_id': '2111.03152', 'language': 'en', 'u<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="7"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\n\n\\section{Introduction} \\label{sec:introduction}  \\input{introduction}\n\\section{Related Wor<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '2016-06-17T02:01:41', 'yymm': '1606', 'arxiv_id': '1606.04992', 'language': 'en', 'u<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="8"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\\section{introduction}\nRecent discovery of Weyl semimetals (WSMs)~\\cite{Lv2015TaAs,Xu2015TaAs,Ya<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '2016-08-18T02:05:38', 'yymm': '1608', 'arxiv_id': '1608.03404', 'language': 'en', 'u<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="9"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"\\section{Introduction}\n\nConformal invariance was first recognised to be of physical interest whe<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto">"{'timestamp': '2019-04-24T02:04:30', 'yymm': '1904', 'arxiv_id': '1904.10101', 'language': 'en', 'u<span class="text-orange-500">(...TRUNCATED)</span></div></div>
							</td>
					</tr></tbody></table>
		<div class="bg-linear-to-b sticky left-0 border-t border-dashed border-gray-300 from-gray-100 to-white py-3 text-center font-mono text-xs dark:border-gray-700 dark:from-gray-950 dark:to-gray-900">End of preview. <a href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train" class="group"><span class="underline decoration-gray-300 group-hover:decoration-gray-400 dark:decoration-gray-500 dark:group-hover:decoration-gray-300">Expand</span>
						in <svg class="text-lg mr-0.5 inline -translate-y-px text-red-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>Data Studio
					</a></div></div>




			<div class="bg-linear-to-b from-gray-100 to-white dark:from-gray-950 dark:to-gray-900 "><hr class="flex-none -translate-y-px border-t border-dashed border-gray-300 bg-white dark:border-gray-700 dark:bg-gray-950">
					<nav><ul class="flex select-none items-center justify-between space-x-2 text-gray-700 sm:justify-center py-1 text-center font-mono text-xs rounded-b-lg"><li><a class="flex items-center rounded-lg px-2.5 py-1 hover:bg-gray-50 dark:hover:bg-gray-800 pointer-events-none cursor-default text-gray-400 hover:text-gray-700" href=""><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M10 16L20 6l1.4 1.4l-8.6 8.6l8.6 8.6L20 26z" fill="currentColor"></path></svg>
		Previous</a></li>
			<li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1 bg-gray-50 font-semibold ring-1 ring-inset ring-gray-200 dark:bg-gray-900 dark:text-yellow-500 dark:ring-gray-900 hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train?p=0">1</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train?p=1">2</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train?p=2">3</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  pointer-events-none cursor-default" href="#">...</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train?p=8499">8,500</a>
				</li>
			<li><a class="flex items-center rounded-lg px-2.5 py-1 hover:bg-gray-50 dark:hover:bg-gray-800 " href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/viewer/plain_text/train?p=1">Next
		<svg class="ml-1.5 transform rotate-180" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M10 16L20 6l1.4 1.4l-8.6 8.6l8.6 8.6L20 26z" fill="currentColor"></path></svg></a></li></ul></nav></div></div>






</div></div></div></div></div></div></div>

				
					<div class="SVELTE_HYDRATER contents" data-target="RepoCodeCopy" data-props="{}"><div></div></div>
					

					<div class="SVELTE_HYDRATER contents" data-target="SideNavigation" data-props="{&quot;titleTree&quot;:[{&quot;id&quot;:&quot;dataset-structure&quot;,&quot;label&quot;:&quot;Dataset Structure&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Dataset Structure&quot;},{&quot;id&quot;:&quot;dataset-creation&quot;,&quot;label&quot;:&quot;Dataset Creation&quot;,&quot;children&quot;:[{&quot;id&quot;:&quot;source-data&quot;,&quot;label&quot;:&quot;Source Data&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Source Data&quot;}],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Dataset Creation&quot;}],&quot;classNames&quot;:&quot;top-6&quot;}">

<div class="absolute -left-12 bottom-0 top-0 z-10 top-6"><div class="sticky top-4 flex"><div class="h-7 pt-[0.175rem]">
				<span class="peer" tabindex="0"><button class="select-none hover:cursor-pointer"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-lg opacity-80 hover:opacity-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg></button></span>
				<div class="invisible w-0 -translate-x-24 -translate-y-6 overflow-hidden rounded-xl border bg-white transition-transform hover:visible hover:w-52 hover:translate-x-0 peer-focus-within:visible peer-focus-within:w-52 peer-focus-within:translate-x-0"><nav aria-label="Secondary" class="max-h-[550px] overflow-y-auto p-3"><ul><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#dataset-structure" title="Dataset Structure"><!-- HTML_TAG_START -->Dataset Structure<!-- HTML_TAG_END --></a>
									<ul class="pl-1"></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#dataset-creation" title="Dataset Creation"><!-- HTML_TAG_START -->Dataset Creation<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#source-data" title="Source Data"><!-- HTML_TAG_START -->Source Data<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li></ul></nav></div></div></div></div></div>
					<div class="2xl:pr-6"><div class="prose pl-6 -ml-6 hf-sanitized hf-sanitized-4AD9m-WxP0IJMID4_iCux">
	<!-- HTML_TAG_START --><h1 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-card-for-dataset-name" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-card-for-dataset-name">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Card for Dataset Name
	</span>
</h1>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-summary" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-summary">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Summary
	</span>
</h3>
<p>RedPajama is a clean-room, fully open-source implementation of the LLaMa dataset.
This HuggingFace repo contains a 1B-token sample of the RedPajama dataset.
The full dataset has the following token counts and is available for <a rel="nofollow" href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T">download</a>:</p>
<div class="max-w-full overflow-auto">
	<table>
		<thead><tr>
<th>Dataset</th>
<th>Token Count</th>
</tr>

		</thead><tbody><tr>
<td>Commoncrawl</td>
<td>878 Billion</td>
</tr>
<tr>
<td>C4</td>
<td>175 Billion</td>
</tr>
<tr>
<td>GitHub</td>
<td>59 Billion</td>
</tr>
<tr>
<td>Books</td>
<td>26 Billion</td>
</tr>
<tr>
<td>ArXiv</td>
<td>28 Billion</td>
</tr>
<tr>
<td>Wikipedia</td>
<td>24 Billion</td>
</tr>
<tr>
<td>StackExchange</td>
<td>20 Billion</td>
</tr>
<tr>
<td>Total</td>
<td>1.2 Trillion</td>
</tr>
</tbody>
	</table>
</div>
<p>A full set of scripts to recreate the dataset from scratch can be found <a rel="nofollow" href="https://github.com/togethercomputer/RedPajama-Data">here</a>.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#languages" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="languages">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Languages
	</span>
</h3>
<p>Primarily English, though the Wikipedia slice contains multiple languages.</p>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-structure" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-structure">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Structure
	</span>
</h2>
<p>The dataset structure is as follows:</p>
<pre><code>{
    "text": ...,
    "meta": {"url": "...", "timestamp": "...", "source": "...", "language": "...", ...}
}
</code></pre>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-creation" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-creation">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Creation
	</span>
</h2>
<p>This dataset was created to follow the LLaMa paper as closely as possible to try to reproduce its recipe.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#source-data" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="source-data">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Source Data
	</span>
</h3>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#commoncrawl" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="commoncrawl">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Commoncrawl
	</span>
</h4>
<p>We download five dumps from Commoncrawl, and run the dumps through the official <code>cc_net</code> pipeline.
We then deduplicate on the paragraph level, and filter out low quality text using a linear classifier trained to 
classify paragraphs as Wikipedia references or random Commoncrawl samples.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#c4" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="c4">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		C4
	</span>
</h4>
<p>C4 is downloaded from Huggingface. The only preprocessing step is to bring the data into our own format.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#github" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="github">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		GitHub
	</span>
</h4>
<p>The raw GitHub data is downloaded from Google BigQuery. We deduplicate on the file level and filter out low quality 
files and only keep projects that are distributed under the MIT, BSD, or Apache license.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#wikipedia" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="wikipedia">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Wikipedia
	</span>
</h4>
<p>We use the Wikipedia dataset available on Huggingface, which is based on the Wikipedia dump from 2023-03-20 and contains
text in 20 different languages. The dataset comes in preprocessed format, so that hyperlinks, comments and other 
formatting boilerplate has been removed.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#gutenberg-and-books3" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="gutenberg-and-books3">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Gutenberg and Books3
	</span>
</h4>
<p>The PG19 subset of the Gutenberg Project and Books3 datasets are downloaded from Huggingface. After downloading, we use 
simhash to remove near duplicates.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#arxiv" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="arxiv">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		ArXiv
	</span>
</h4>
<p>ArXiv data is downloaded from Amazon S3 in the <code>arxiv</code> requester pays bucket. We only keep latex source files and 
remove preambles, comments, macros and bibliographies.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#stackexchange" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="stackexchange">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Stackexchange
	</span>
</h4>
<p>The Stack Exchange split of the dataset is download from the 
<a rel="nofollow" href="https://archive.org/download/stackexchange">Internet Archive</a>. Here we only keep the posts from the 28 largest sites,
remove html tags, group the posts into question-answer pairs, and order answers by their score.</p>
<!-- HTML_TAG_END --></div>
</div></section>
			
			<section class="pt-6 border-gray-100 md:pb-24 md:pl-6 md:w-64 lg:w-80 xl:w-96 flex-none order-first md:order-none md:border-l pt-3! md:pt-6!"><dl class="flex items-baseline justify-between"><dt class="text-sm text-gray-500">Downloads last month</dt><div class="mx-4 flex-1 border-b border-dotted"></div><dd class="font-semibold">14,211</dd></dl>
				
				<div class="divider-column-vertical"></div>
				<div class="grid grid-cols-2 gap-x-2 md:flex md:flex-row md:flex-wrap"><div class="SVELTE_HYDRATER contents" data-target="DatasetAndModelActionsDropdown" data-props="{&quot;classNames&quot;:&quot;order-last&quot;,&quot;discussionsDisabled&quot;:false,&quot;repo&quot;:{&quot;type&quot;:&quot;dataset&quot;,&quot;name&quot;:&quot;togethercomputer/RedPajama-Data-1T-Sample&quot;},&quot;canWrite&quot;:false,&quot;canDisable&quot;:false,&quot;repoIsPrivate&quot;:false,&quot;repoIsGated&quot;:false,&quot;repoIsDisabled&quot;:false,&quot;repoIsAdminFlaggedNFAA&quot;:false,&quot;repoHasBlockedOids&quot;:false}"><div class="order-last"><div class="relative ">
	<button class="btn px-1.5 py-1.5 " type="button">
		
			<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="p-0.5" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
		
		</button>
	
	
	</div></div>













</div>
					<div class="SVELTE_HYDRATER contents" data-target="DatasetLibrary" data-props="{&quot;classNames&quot;:&quot;md:w-full xl:w-auto xl:flex-none&quot;,&quot;libraries&quot;:[{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;datasets&quot;,&quot;function&quot;:&quot;load_dataset&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;plain_text&quot;,&quot;arguments&quot;:{},&quot;code&quot;:&quot;from datasets import load_dataset\n\nds = load_dataset(\&quot;togethercomputer/RedPajama-Data-1T-Sample\&quot;)&quot;}]},{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;mlcroissant&quot;,&quot;function&quot;:&quot;Dataset&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;plain_text&quot;,&quot;arguments&quot;:{&quot;record_set&quot;:&quot;plain_text&quot;,&quot;partial&quot;:true},&quot;code&quot;:&quot;from mlcroissant import Dataset\n\n# The Croissant metadata exposes the first 5GB of this dataset\nds = Dataset(jsonld=\&quot;https://huggingface.co/api/datasets/togethercomputer/RedPajama-Data-1T-Sample/croissant\&quot;)\nrecords = ds.records(\&quot;plain_text\&quot;)&quot;}]}]}"><div class="relative md:w-full xl:w-auto xl:flex-none">
	<button class="from-gray-800! to-black! max-xl:mb-2 text-white! gap-1! border-gray-800! dark:border-gray-900!  btn w-full cursor-pointer text-sm" type="button">
		<svg class="mr-1.5 mr-0.5! " xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" style="transform: rotate(360deg);"><path d="M31 16l-7 7l-1.41-1.41L28.17 16l-5.58-5.59L24 9l7 7z" fill="currentColor"></path><path d="M1 16l7-7l1.41 1.41L3.83 16l5.58 5.59L8 23l-7-7z" fill="currentColor"></path><path d="M12.419 25.484L17.639 6l1.932.518L14.35 26z" fill="currentColor"></path></svg>
			Use this dataset
		<svg class="-mr-1 text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg></button>
	
	
	</div>

</div>
					
					</div>
				<div class="divider-column-vertical"></div>
					<div class="flex flex-col flex-wrap xl:flex-row"><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="/datasets/togethercomputer/RedPajama-Data-1T-Sample/tree/refs%2Fconvert%2Fparquet/" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Size of the auto-converted Parquet files (First 5GB):</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->2.92 GB<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 pointer-events-none" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Number of rows (First 5GB):</div>
		<div class="truncate text-sm ">
			<!-- HTML_TAG_START -->850,000<!-- HTML_TAG_END --></div></a></div>
				
				
				<div class="divider-column-vertical"></div>
					<h2 class="text-smd mb-5 flex items-baseline overflow-hidden whitespace-nowrap font-semibold text-gray-800"><svg class="mr-1.5 text-sm inline self-center flex-none text-gray-400" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
						Models trained or fine-tuned on
						<span class="ml-1 truncate font-mono text-[0.87rem] font-medium">togethercomputer/RedPajama-Data-1T-Sample</span></h2>

					<div class="space-y-3"><div class=""><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/chargoddard/SmolLlamix-8x101M"><div class="w-full truncate"><header class="flex items-center mb-1" title="chargoddard/SmolLlamix-8x101M"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/630495b0ce6b12280b193c25/bT61kBtQPhDYk00AI0o0g.png" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">chargoddard/SmolLlamix-8x101M</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400"><svg class="mr-1.5 text-[.8rem] flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg>
			Text Generation
			<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
	
				<span class="truncate">Updated
					<time datetime="2023-12-15T10:48:26" title="Fri, 15 Dec 2023 10:48:26 GMT">Dec 15, 2023</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					1.76k
				
	
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>
					12

				</div></div>
		
	</a></article>
							</div><div class=""><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/chargoddard/llama2-22b"><div class="w-full truncate"><header class="flex items-center mb-1" title="chargoddard/llama2-22b"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/630495b0ce6b12280b193c25/bT61kBtQPhDYk00AI0o0g.png" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">chargoddard/llama2-22b</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400"><svg class="mr-1.5 text-[.8rem] flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg>
			Text Generation
			<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
	
				<span class="truncate">Updated
					<time datetime="2023-11-23T01:03:37" title="Thu, 23 Nov 2023 01:03:37 GMT">Nov 23, 2023</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					1.71k
				
	
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>
					46

				</div></div>
		
	</a></article>
							</div><div class=""><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/chargoddard/llama2-22b-blocktriangular"><div class="w-full truncate"><header class="flex items-center mb-1" title="chargoddard/llama2-22b-blocktriangular"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/630495b0ce6b12280b193c25/bT61kBtQPhDYk00AI0o0g.png" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">chargoddard/llama2-22b-blocktriangular</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400"><svg class="mr-1.5 text-[.8rem] flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg>
			Text Generation
			<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
	
				<span class="truncate">Updated
					<time datetime="2023-11-23T01:03:34" title="Thu, 23 Nov 2023 01:03:34 GMT">Nov 23, 2023</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					1.68k
				
	
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>
					4

				</div></div>
		
	</a></article>
							</div><div class=""><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/chargoddard/llama-2-34b-uncode"><div class="w-full truncate"><header class="flex items-center mb-1" title="chargoddard/llama-2-34b-uncode"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/630495b0ce6b12280b193c25/bT61kBtQPhDYk00AI0o0g.png" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">chargoddard/llama-2-34b-uncode</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400"><svg class="mr-1.5 text-[.8rem] flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg>
			Text Generation
			<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
	
				<span class="truncate">Updated
					<time datetime="2023-11-23T01:03:41" title="Thu, 23 Nov 2023 01:03:41 GMT">Nov 23, 2023</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					1.67k
				
	
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>
					5

				</div></div>
		
	</a></article>
							</div><div class="hidden md:block"><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/chargoddard/SmolLlamix-8x101M-take2"><div class="w-full truncate"><header class="flex items-center mb-1" title="chargoddard/SmolLlamix-8x101M-take2"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/630495b0ce6b12280b193c25/bT61kBtQPhDYk00AI0o0g.png" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">chargoddard/SmolLlamix-8x101M-take2</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400"><svg class="mr-1.5 text-[.8rem] flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.2607 8.08202L14.468 6.28928C14.3063 6.12804 14.0873 6.03749 13.859 6.03749C13.6307 6.03749 13.4117 6.12804 13.25 6.28928L5.6375 13.904V16.9125H8.64607L16.2607 9.30002C16.422 9.13836 16.5125 8.91935 16.5125 8.69102C16.5125 8.4627 16.422 8.24369 16.2607 8.08202V8.08202ZM8.1953 15.825H6.725V14.3547L11.858 9.22118L13.3288 10.6915L8.1953 15.825ZM14.0982 9.92262L12.6279 8.45232L13.8606 7.21964L15.3309 8.68994L14.0982 9.92262Z"></path><path d="M6.18125 9.84373H7.26875V6.03748H8.9V4.94998H4.55V6.03748H6.18125V9.84373Z"></path><path d="M4.55 11.475H2.375V2.775H11.075V4.95H12.1625V2.775C12.1625 2.48658 12.0479 2.20997 11.844 2.00602C11.64 1.80208 11.3634 1.6875 11.075 1.6875H2.375C2.08658 1.6875 1.80997 1.80208 1.60602 2.00602C1.40207 2.20997 1.2875 2.48658 1.2875 2.775V11.475C1.2875 11.7634 1.40207 12.04 1.60602 12.244C1.80997 12.4479 2.08658 12.5625 2.375 12.5625H4.55V11.475Z"></path></svg>
			Text Generation
			<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
	
				<span class="truncate">Updated
					<time datetime="2024-01-05T01:25:49" title="Fri, 05 Jan 2024 01:25:49 GMT">Jan 5, 2024</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					1.67k
				
	
				

				</div></div>
		
	</a></article>
							</div><div class="hidden md:block"><article class="overview-card-wrapper group/repo  "><a class="flex items-center justify-between gap-4 p-2" href="/mradermacher/SmolLlamix-8x101M-GGUF"><div class="w-full truncate"><header class="flex items-center mb-1" title="mradermacher/SmolLlamix-8x101M-GGUF"><img alt="" class="w-3 h-3 rounded-full mr-1.5 flex-none flex-none" src="/avatars/6b97d30ff0bdb5d5c633ba850af739cd.svg" crossorigin="anonymous">
				<h4 class="text-md truncate font-mono text-black dark:group-hover/repo:text-yellow-500 group-hover/repo:text-indigo-600 text-sm">mradermacher/SmolLlamix-8x101M-GGUF</h4>
				
				</header>
			<div class="mr-1 flex items-center overflow-hidden whitespace-nowrap text-sm leading-tight text-gray-400">
	
				<span class="truncate">Updated
					<time datetime="2024-05-06T06:06:42" title="Mon, 06 May 2024 06:06:42 GMT">May 6, 2024</time></span>
				
				<span class="px-1.5 text-gray-300 dark:text-gray-500">â€¢ </span>
					<svg class="flex-none w-3 text-gray-400 mr-0.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 32"><path fill="currentColor" d="M26 24v4H6v-4H4v4a2 2 0 0 0 2 2h20a2 2 0 0 0 2-2v-4zm0-10l-1.41-1.41L17 20.17V2h-2v18.17l-7.59-7.58L6 14l10 10l10-10z"></path></svg>
					535
				
	
				

				</div></div>
		
	</a></article>
							</div>
						<a class="flex items-center pt-1 text-sm text-gray-500 underline hover:text-gray-700" href="/models?dataset=dataset:togethercomputer/RedPajama-Data-1T-Sample">Browse 27 models trained on this dataset
							</a></div>
				

				
				<div class="divider-column-vertical md:hidden"></div></section></div></main>

	<footer class="b-12 mb-2 flex border-t border-gray-100 md:h-14"><nav class="container relative flex flex-col justify-between space-y-2 py-6 text-gray-500 max-md:*:self-start md:flex-row md:items-center md:space-y-0 md:py-0 md:text-sm"><div class="SVELTE_HYDRATER contents" data-target="ThemeSwitcher" data-props="{&quot;theme&quot;:&quot;system&quot;,&quot;isLoggedIn&quot;:false,&quot;menuClassNames&quot;:&quot;md:-top-24&quot;,&quot;classNames&quot;:&quot;max-md:mb-5 max-md:*:self-start&quot;}">
<div class="relative inline-block max-md:mb-5 max-md:*:self-start">
	<button class="rounded-full border border-gray-100 pl-2 py-1 pr-2.5  flex items-center text-sm text-gray-500 bg-white hover:bg-purple-50 hover:border-purple-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 dark:border-gray-800 " type="button">
		<svg class="mr-1.5 text-gray-500" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6 22.5h20a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2v13.5a2 2 0 0 0 2 2ZM7 7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h18a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1H7Z" fill="currentColor"></path><path d="M6 8a1 1 0 0 1 1-1h18a1 1 0 0 1 1 1v11a1 1 0 0 1-1 1H7a1 1 0 0 1-1-1V8Z" fill="currentColor" fill-opacity=".4"></path><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path></svg>
			System theme
		</button>
	
	
	</div></div>
		<div class="font-semibold text-black md:hidden">Company</div>
		<a class="hover:underline" href="/terms-of-service">TOS</a>
		<a class="hover:underline" href="/privacy">Privacy</a>
		<a class="hover:underline" href="/huggingface">About</a>
		<a class="hover:underline" href="https://apply.workable.com/huggingface/">Jobs</a>
		<a href="/" class="max-md:mb-4! max-md:mt-8! group flex-none max-md:order-last"><svg class="h-7 w-7 transition-transform group-hover:-translate-y-px" viewBox="0 0 95 88" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5Z" fill="#FFD21E"></path><path d="M81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75ZM8.46185 41.75C8.46185 20.349 25.8108 3 47.2119 3C68.6129 3 85.9619 20.349 85.9619 41.75C85.9619 63.151 68.6129 80.5 47.2119 80.5C25.8108 80.5 8.46185 63.151 8.46185 41.75Z" fill="#FF9D0B"></path><path d="M58.5024 32.2915C59.7768 32.7415 60.2839 35.3615 61.5713 34.6769C64.0095 33.3805 64.9351 30.353 63.6387 27.9148C62.3423 25.4767 59.3148 24.5511 56.8766 25.8475C54.4384 27.1439 53.5128 30.1714 54.8092 32.6096C55.4211 33.7604 57.3632 31.8892 58.5024 32.2915Z" fill="#3A3B45"></path><path d="M34.9454 32.2915C33.671 32.7415 33.164 35.3615 31.8766 34.6769C29.4384 33.3805 28.5128 30.353 29.8092 27.9148C31.1056 25.4767 34.1331 24.5511 36.5713 25.8475C39.0095 27.1439 39.9351 30.1714 38.6387 32.6096C38.0268 33.7604 36.0846 31.8892 34.9454 32.2915Z" fill="#3A3B45"></path><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="#3A3B45"></path><mask id="mask0" style="mask-type:alpha" maskUnits="userSpaceOnUse" x="33" y="41" width="27" height="16"><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="white"></path></mask><g mask="url(#mask0)"><path d="M47.2119 66.5C52.0018 66.5 55.8848 62.617 55.8848 57.8271C55.8848 54.0962 53.5291 50.9156 50.224 49.6915C50.1023 49.6464 49.9794 49.604 49.8553 49.5643C49.0219 49.2979 48.1337 52.1623 47.2119 52.1623C46.3506 52.1623 45.5186 49.2797 44.7332 49.5135C41.151 50.5799 38.5389 53.8984 38.5389 57.8271C38.5389 62.617 42.4219 66.5 47.2119 66.5Z" fill="#F94040"></path></g><path d="M70.7119 37C72.5068 37 73.9619 35.5449 73.9619 33.75C73.9619 31.9551 72.5068 30.5 70.7119 30.5C68.9169 30.5 67.4619 31.9551 67.4619 33.75C67.4619 35.5449 68.9169 37 70.7119 37Z" fill="#FF9D0B"></path><path d="M24.2119 37C26.0068 37 27.4619 35.5449 27.4619 33.75C27.4619 31.9551 26.0068 30.5 24.2119 30.5C22.4169 30.5 20.9619 31.9551 20.9619 33.75C20.9619 35.5449 22.4169 37 24.2119 37Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M17.5238 48C15.9048 48 14.4578 48.665 13.4488 49.871C12.8248 50.618 12.1728 51.822 12.1198 53.625C11.4408 53.43 10.7878 53.321 10.1778 53.321C8.6278 53.321 7.2278 53.915 6.2378 54.994C4.9658 56.379 4.4008 58.081 4.6468 59.784C4.7638 60.595 5.0348 61.322 5.4398 61.995C4.5858 62.686 3.9568 63.648 3.6528 64.805C3.4148 65.712 3.1708 67.601 4.4448 69.547C4.3638 69.674 4.2878 69.806 4.2168 69.941C3.4508 71.395 3.4018 73.038 4.0778 74.568C5.1028 76.887 7.6498 78.714 12.5958 80.675C15.6728 81.895 18.4878 82.675 18.5128 82.682C22.5808 83.737 26.2598 84.273 29.4448 84.273C35.2988 84.273 39.4898 82.48 41.9018 78.944C45.7838 73.25 45.2288 68.042 40.2058 63.022C37.4258 60.244 35.5778 56.148 35.1928 55.249C34.4168 52.587 32.3648 49.628 28.9538 49.628H28.9528C28.6658 49.628 28.3758 49.651 28.0898 49.696C26.5958 49.931 25.2898 50.791 24.3568 52.085C23.3498 50.833 22.3718 49.837 21.4868 49.275C20.1528 48.429 18.8198 48 17.5238 48ZM17.5238 52C18.0338 52 18.6568 52.217 19.3438 52.653C21.4768 54.006 25.5928 61.081 27.0998 63.833C27.6048 64.755 28.4678 65.145 29.2448 65.145C30.7868 65.145 31.9908 63.612 29.3858 61.664C25.4688 58.733 26.8428 53.942 28.7128 53.647C28.7948 53.634 28.8758 53.628 28.9538 53.628C30.6538 53.628 31.4038 56.558 31.4038 56.558C31.4038 56.558 33.6018 62.078 37.3778 65.851C41.1538 69.625 41.3488 72.654 38.5968 76.69C36.7198 79.442 33.1268 80.273 29.4448 80.273C25.6258 80.273 21.7108 79.379 19.5168 78.81C19.4088 78.782 6.0658 75.013 7.7558 71.805C8.0398 71.266 8.5078 71.05 9.0968 71.05C11.4768 71.05 15.8058 74.592 17.6668 74.592C18.0828 74.592 18.3758 74.415 18.4958 73.983C19.2888 71.138 6.4388 69.942 7.5218 65.821C7.7128 65.092 8.2308 64.796 8.9588 64.797C12.1038 64.797 19.1598 70.328 20.6388 70.328C20.7518 70.328 20.8328 70.295 20.8768 70.225C21.6178 69.029 21.2118 68.194 15.9888 65.033C10.7658 61.871 7.0998 59.969 9.1848 57.699C9.4248 57.437 9.7648 57.321 10.1778 57.321C13.3488 57.322 20.8408 64.14 20.8408 64.14C20.8408 64.14 22.8628 66.243 24.0858 66.243C24.3668 66.243 24.6058 66.132 24.7678 65.858C25.6348 64.396 16.7148 57.636 16.2118 54.847C15.8708 52.957 16.4508 52 17.5238 52Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M38.5967 76.6898C41.3487 72.6538 41.1537 69.6248 37.3777 65.8508C33.6017 62.0778 31.4037 56.5578 31.4037 56.5578C31.4037 56.5578 30.5827 53.3518 28.7127 53.6468C26.8427 53.9418 25.4697 58.7328 29.3867 61.6638C33.3037 64.5938 28.6067 66.5848 27.0997 63.8328C25.5927 61.0808 21.4777 54.0058 19.3437 52.6528C17.2107 51.2998 15.7087 52.0578 16.2117 54.8468C16.7147 57.6358 25.6357 64.3958 24.7677 65.8588C23.8997 67.3208 20.8407 64.1398 20.8407 64.1398C20.8407 64.1398 11.2687 55.4288 9.18465 57.6988C7.10065 59.9688 10.7657 61.8708 15.9887 65.0328C21.2127 68.1938 21.6177 69.0288 20.8767 70.2248C20.1347 71.4208 8.60465 61.6998 7.52165 65.8208C6.43965 69.9418 19.2887 71.1378 18.4957 73.9828C17.7027 76.8288 9.44465 68.5978 7.75565 71.8048C6.06565 75.0128 19.4087 78.7818 19.5167 78.8098C23.8267 79.9278 34.7727 82.2968 38.5967 76.6898Z" fill="#FFD21E"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M77.3999 48C79.0189 48 80.4659 48.665 81.4749 49.871C82.0989 50.618 82.7509 51.822 82.8039 53.625C83.4829 53.43 84.1359 53.321 84.7459 53.321C86.2959 53.321 87.6959 53.915 88.6859 54.994C89.9579 56.379 90.5229 58.081 90.2769 59.784C90.1599 60.595 89.8889 61.322 89.4839 61.995C90.3379 62.686 90.9669 63.648 91.2709 64.805C91.5089 65.712 91.7529 67.601 90.4789 69.547C90.5599 69.674 90.6359 69.806 90.7069 69.941C91.4729 71.395 91.5219 73.038 90.8459 74.568C89.8209 76.887 87.2739 78.714 82.3279 80.675C79.2509 81.895 76.4359 82.675 76.4109 82.682C72.3429 83.737 68.6639 84.273 65.4789 84.273C59.6249 84.273 55.4339 82.48 53.0219 78.944C49.1399 73.25 49.6949 68.042 54.7179 63.022C57.4979 60.244 59.3459 56.148 59.7309 55.249C60.5069 52.587 62.5589 49.628 65.9699 49.628H65.9709C66.2579 49.628 66.5479 49.651 66.8339 49.696C68.3279 49.931 69.6339 50.791 70.5669 52.085C71.5739 50.833 72.5519 49.837 73.4369 49.275C74.7709 48.429 76.1039 48 77.3999 48ZM77.3999 52C76.8899 52 76.2669 52.217 75.5799 52.653C73.4469 54.006 69.3309 61.081 67.8239 63.833C67.3189 64.755 66.4559 65.145 65.6789 65.145C64.1369 65.145 62.9329 63.612 65.5379 61.664C69.4549 58.733 68.0809 53.942 66.2109 53.647C66.1289 53.634 66.0479 53.628 65.9699 53.628C64.2699 53.628 63.5199 56.558 63.5199 56.558C63.5199 56.558 61.3219 62.078 57.5459 65.851C53.7699 69.625 53.5749 72.654 56.3269 76.69C58.2039 79.442 61.7969 80.273 65.4789 80.273C69.2979 80.273 73.2129 79.379 75.4069 78.81C75.5149 78.782 88.8579 75.013 87.1679 71.805C86.8839 71.266 86.4159 71.05 85.8269 71.05C83.4469 71.05 79.1179 74.592 77.2569 74.592C76.8409 74.592 76.5479 74.415 76.4279 73.983C75.6349 71.138 88.4849 69.942 87.4019 65.821C87.2109 65.092 86.6929 64.796 85.9649 64.797C82.8199 64.797 75.7639 70.328 74.2849 70.328C74.1719 70.328 74.0909 70.295 74.0469 70.225C73.3059 69.029 73.7119 68.194 78.9349 65.033C84.1579 61.871 87.8239 59.969 85.7389 57.699C85.4989 57.437 85.1589 57.321 84.7459 57.321C81.5749 57.322 74.0829 64.14 74.0829 64.14C74.0829 64.14 72.0609 66.243 70.8379 66.243C70.5569 66.243 70.3179 66.132 70.1559 65.858C69.2889 64.396 78.2089 57.636 78.7119 54.847C79.0529 52.957 78.4729 52 77.3999 52Z" fill="#FF9D0B"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M56.3271 76.6898C53.5751 72.6538 53.7701 69.6248 57.5461 65.8508C61.3221 62.0778 63.5201 56.5578 63.5201 56.5578C63.5201 56.5578 64.3411 53.3518 66.2111 53.6468C68.0811 53.9418 69.4541 58.7328 65.5371 61.6638C61.6201 64.5938 66.3171 66.5848 67.8241 63.8328C69.3311 61.0808 73.4461 54.0058 75.5801 52.6528C77.7131 51.2998 79.2151 52.0578 78.7121 54.8468C78.2091 57.6358 69.2881 64.3958 70.1561 65.8588C71.0241 67.3208 74.0831 64.1398 74.0831 64.1398C74.0831 64.1398 83.6551 55.4288 85.7391 57.6988C87.8231 59.9688 84.1581 61.8708 78.9351 65.0328C73.7111 68.1938 73.3061 69.0288 74.0471 70.2248C74.7891 71.4208 86.3191 61.6998 87.4021 65.8208C88.4841 69.9418 75.6351 71.1378 76.4281 73.9828C77.2211 76.8288 85.4791 68.5978 87.1681 71.8048C88.8581 75.0128 75.5151 78.7818 75.4071 78.8098C71.0971 79.9278 60.1511 82.2968 56.3271 76.6898Z" fill="#FFD21E"></path></svg></a>
		<div class="max-md:mt-8! font-semibold text-black md:hidden">Website</div>

		<a class="hover:underline" href="/models">Models</a>
		<a class="hover:underline" href="/datasets">Datasets</a>
		<a class="hover:underline" href="/spaces">Spaces</a>
		<a class="hover:underline" href="/pricing">Pricing</a>
		<a class="hover:underline" href="/docs">Docs</a></nav></footer></div>

		<script>
			import("\/front\/build\/kube-68d7aa0\/index.js");
			window.moonSha = "kube-68d7aa0\/";
			window.__hf_deferred = {};
		</script>

		<!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>
	</body>
</html>
