<!doctype html>
<html class="">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
		<meta name="description" content="We’re on a journey to advance and democratize artificial intelligence through open source and open science." />
		<meta property="fb:app_id" content="1321688464574422" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@huggingface" />
		<meta name="twitter:image" content="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/saifkhichi96/mpii-human-pose-captions.png" />
		<meta property="og:title" content="saifkhichi96/mpii-human-pose-captions · Datasets at Hugging Face" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://huggingface.co/datasets/saifkhichi96/mpii-human-pose-captions" />
		<meta property="og:image" content="https://cdn-thumbnails.huggingface.co/social-thumbnails/datasets/saifkhichi96/mpii-human-pose-captions.png" />

		<link rel="stylesheet" href="/front/build/kube-68d7aa0/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript>
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" />
		</noscript>

		<script>const guestTheme = document.cookie.match(/theme=(\w+)/)?.[1]; document.documentElement.classList.toggle('dark', guestTheme === 'dark' || ( (!guestTheme || guestTheme === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches));</script>
<link rel="canonical" href="https://huggingface.co/datasets/saifkhichi96/mpii-human-pose-captions"> <script type="application/ld+json">{
  "@context": {
    "@language": "en",
    "@vocab": "https:\/\/schema.org\/",
    "citeAs": "cr:citeAs",
    "column": "cr:column",
    "conformsTo": "dct:conformsTo",
    "cr": "http:\/\/mlcommons.org\/croissant\/",
    "data": {
      "@id": "cr:data",
      "@type": "@json"
    },
    "dataBiases": "cr:dataBiases",
    "dataCollection": "cr:dataCollection",
    "dataType": {
      "@id": "cr:dataType",
      "@type": "@vocab"
    },
    "dct": "http:\/\/purl.org\/dc\/terms\/",
    "extract": "cr:extract",
    "field": "cr:field",
    "fileProperty": "cr:fileProperty",
    "fileObject": "cr:fileObject",
    "fileSet": "cr:fileSet",
    "format": "cr:format",
    "includes": "cr:includes",
    "isLiveDataset": "cr:isLiveDataset",
    "jsonPath": "cr:jsonPath",
    "key": "cr:key",
    "md5": "cr:md5",
    "parentField": "cr:parentField",
    "path": "cr:path",
    "personalSensitiveInformation": "cr:personalSensitiveInformation",
    "recordSet": "cr:recordSet",
    "references": "cr:references",
    "regex": "cr:regex",
    "repeated": "cr:repeated",
    "replace": "cr:replace",
    "sc": "https:\/\/schema.org\/",
    "separator": "cr:separator",
    "source": "cr:source",
    "subField": "cr:subField",
    "transform": "cr:transform"
  },
  "@type": "sc:Dataset",
  "distribution": [
    {
      "@type": "cr:FileObject",
      "@id": "repo",
      "name": "repo",
      "description": "The Hugging Face git repository.",
      "contentUrl": "https:\/\/huggingface.co\/datasets\/saifkhichi96\/mpii-human-pose-captions\/tree\/refs%2Fconvert%2Fparquet",
      "encodingFormat": "git+https",
      "sha256": "https:\/\/github.com\/mlcommons\/croissant\/issues\/80"
    },
    {
      "@type": "cr:FileSet",
      "@id": "parquet-files-for-config-gpt-4",
      "name": "parquet-files-for-config-gpt-4",
      "description": "The underlying Parquet files as converted by Hugging Face (see: https:\/\/huggingface.co\/docs\/dataset-viewer\/parquet).",
      "containedIn": {
        "@id": "repo"
      },
      "encodingFormat": "application\/x-parquet",
      "includes": "gpt-4\/*\/*.parquet"
    },
    {
      "@type": "cr:FileSet",
      "@id": "parquet-files-for-config-gpt-3.5-turbo",
      "name": "parquet-files-for-config-gpt-3.5-turbo",
      "description": "The underlying Parquet files as converted by Hugging Face (see: https:\/\/huggingface.co\/docs\/dataset-viewer\/parquet).",
      "containedIn": {
        "@id": "repo"
      },
      "encodingFormat": "application\/x-parquet",
      "includes": "gpt-3.5-turbo\/*\/*.parquet"
    },
    {
      "@type": "cr:FileSet",
      "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy",
      "name": "parquet-files-for-config-gpt-3.5-turbo-legacy",
      "description": "The underlying Parquet files as converted by Hugging Face (see: https:\/\/huggingface.co\/docs\/dataset-viewer\/parquet).",
      "containedIn": {
        "@id": "repo"
      },
      "encodingFormat": "application\/x-parquet",
      "includes": "gpt-3.5-turbo-legacy\/*\/*.parquet"
    },
    {
      "@type": "cr:FileSet",
      "@id": "parquet-files-for-config-llama-2",
      "name": "parquet-files-for-config-llama-2",
      "description": "The underlying Parquet files as converted by Hugging Face (see: https:\/\/huggingface.co\/docs\/dataset-viewer\/parquet).",
      "containedIn": {
        "@id": "repo"
      },
      "encodingFormat": "application\/x-parquet",
      "includes": "llama-2\/*\/*.parquet"
    }
  ],
  "recordSet": [
    {
      "@type": "cr:RecordSet",
      "dataType": "cr:Split",
      "key": {
        "@id": "gpt-4_splits\/split_name"
      },
      "@id": "gpt-4_splits",
      "name": "gpt-4_splits",
      "description": "Splits for the gpt-4 config.",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-4_splits\/split_name",
          "name": "split_name",
          "description": "The name of the split.",
          "dataType": "sc:Text"
        }
      ],
      "data": [
        {
          "gpt-4_splits\/split_name": "train"
        },
        {
          "gpt-4_splits\/split_name": "validation"
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "@id": "gpt-4",
      "name": "gpt-4",
      "description": "saifkhichi96\/mpii-human-pose-captions - 'gpt-4' subset\n\nAdditional information:\n- 2 splits: train, validation",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/split",
          "name": "gpt-4\/split",
          "description": "Split to which the example belongs to.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "gpt\\-4\/(?:partial-)?(train|validation)\/.+parquet$"
            }
          },
          "references": {
            "field": {
              "@id": "gpt-4_splits\/split_name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/description",
          "name": "gpt-4\/description",
          "description": "Column 'description' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "description"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/people",
          "name": "gpt-4\/people",
          "description": "Column 'people' from the Hugging Face parquet file.",
          "subField": [
            {
              "@type": "cr:Field",
              "@id": "gpt-4\/people\/center",
              "name": "gpt-4\/people\/center",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-4"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-4\/people\/id",
              "name": "gpt-4\/people\/id",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-4"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "id"
                }
              }
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-4\/people\/kpts",
              "name": "gpt-4\/people\/kpts",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-4"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-4\/people\/kpts_vis",
              "name": "gpt-4\/people\/kpts_vis",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-4"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-4\/people\/scale",
              "name": "gpt-4\/people\/scale",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-4"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "scale"
                }
              }
            }
          ],
          "repeated": true
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/activity_id",
          "name": "gpt-4\/activity_id",
          "description": "Column 'activity_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "activity_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/video_id",
          "name": "gpt-4\/video_id",
          "description": "Column 'video_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "video_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/video_frame",
          "name": "gpt-4\/video_frame",
          "description": "Column 'video_frame' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "video_frame"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/activity",
          "name": "gpt-4\/activity",
          "description": "Column 'activity' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "activity"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/image",
          "name": "gpt-4\/image",
          "description": "Column 'image' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "image"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-4\/count",
          "name": "gpt-4\/count",
          "description": "Column 'count' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-4"
            },
            "extract": {
              "column": "count"
            }
          }
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "dataType": "cr:Split",
      "key": {
        "@id": "gpt-3.5-turbo_splits\/split_name"
      },
      "@id": "gpt-3.5-turbo_splits",
      "name": "gpt-3.5-turbo_splits",
      "description": "Splits for the gpt-3.5-turbo config.",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo_splits\/split_name",
          "name": "split_name",
          "description": "The name of the split.",
          "dataType": "sc:Text"
        }
      ],
      "data": [
        {
          "gpt-3.5-turbo_splits\/split_name": "train"
        },
        {
          "gpt-3.5-turbo_splits\/split_name": "validation"
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "@id": "gpt-3.5-turbo",
      "name": "gpt-3.5-turbo",
      "description": "saifkhichi96\/mpii-human-pose-captions - 'gpt-3.5-turbo' subset\n\nAdditional information:\n- 2 splits: train, validation",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/split",
          "name": "gpt-3.5-turbo\/split",
          "description": "Split to which the example belongs to.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "gpt\\-3\\.5\\-turbo\/(?:partial-)?(train|validation)\/.+parquet$"
            }
          },
          "references": {
            "field": {
              "@id": "gpt-3.5-turbo_splits\/split_name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/image",
          "name": "gpt-3.5-turbo\/image",
          "description": "Column 'image' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "image"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/activity_id",
          "name": "gpt-3.5-turbo\/activity_id",
          "description": "Column 'activity_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "activity_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/description",
          "name": "gpt-3.5-turbo\/description",
          "description": "Column 'description' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "description"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/activity",
          "name": "gpt-3.5-turbo\/activity",
          "description": "Column 'activity' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "activity"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/count",
          "name": "gpt-3.5-turbo\/count",
          "description": "Column 'count' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "count"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/people",
          "name": "gpt-3.5-turbo\/people",
          "description": "Column 'people' from the Hugging Face parquet file.",
          "subField": [
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo\/people\/center",
              "name": "gpt-3.5-turbo\/people\/center",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo\/people\/id",
              "name": "gpt-3.5-turbo\/people\/id",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "id"
                }
              }
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo\/people\/kpts",
              "name": "gpt-3.5-turbo\/people\/kpts",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo\/people\/kpts_vis",
              "name": "gpt-3.5-turbo\/people\/kpts_vis",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo\/people\/scale",
              "name": "gpt-3.5-turbo\/people\/scale",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "scale"
                }
              }
            }
          ],
          "repeated": true
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/video_id",
          "name": "gpt-3.5-turbo\/video_id",
          "description": "Column 'video_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "video_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo\/video_frame",
          "name": "gpt-3.5-turbo\/video_frame",
          "description": "Column 'video_frame' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo"
            },
            "extract": {
              "column": "video_frame"
            }
          }
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "dataType": "cr:Split",
      "key": {
        "@id": "gpt-3.5-turbo-legacy_splits\/split_name"
      },
      "@id": "gpt-3.5-turbo-legacy_splits",
      "name": "gpt-3.5-turbo-legacy_splits",
      "description": "Splits for the gpt-3.5-turbo-legacy config.",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy_splits\/split_name",
          "name": "split_name",
          "description": "The name of the split.",
          "dataType": "sc:Text"
        }
      ],
      "data": [
        {
          "gpt-3.5-turbo-legacy_splits\/split_name": "train"
        },
        {
          "gpt-3.5-turbo-legacy_splits\/split_name": "validation"
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "@id": "gpt-3.5-turbo-legacy",
      "name": "gpt-3.5-turbo-legacy",
      "description": "saifkhichi96\/mpii-human-pose-captions - 'gpt-3.5-turbo-legacy' subset\n\nAdditional information:\n- 2 splits: train, validation",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/split",
          "name": "gpt-3.5-turbo-legacy\/split",
          "description": "Split to which the example belongs to.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "gpt\\-3\\.5\\-turbo\\-legacy\/(?:partial-)?(train|validation)\/.+parquet$"
            }
          },
          "references": {
            "field": {
              "@id": "gpt-3.5-turbo-legacy_splits\/split_name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/video_frame",
          "name": "gpt-3.5-turbo-legacy\/video_frame",
          "description": "Column 'video_frame' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "video_frame"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/count",
          "name": "gpt-3.5-turbo-legacy\/count",
          "description": "Column 'count' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "count"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/description",
          "name": "gpt-3.5-turbo-legacy\/description",
          "description": "Column 'description' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "description"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/video_id",
          "name": "gpt-3.5-turbo-legacy\/video_id",
          "description": "Column 'video_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "video_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/activity_id",
          "name": "gpt-3.5-turbo-legacy\/activity_id",
          "description": "Column 'activity_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "activity_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/image",
          "name": "gpt-3.5-turbo-legacy\/image",
          "description": "Column 'image' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "image"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/people",
          "name": "gpt-3.5-turbo-legacy\/people",
          "description": "Column 'people' from the Hugging Face parquet file.",
          "subField": [
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo-legacy\/people\/center",
              "name": "gpt-3.5-turbo-legacy\/people\/center",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo-legacy\/people\/id",
              "name": "gpt-3.5-turbo-legacy\/people\/id",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "id"
                }
              }
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo-legacy\/people\/kpts",
              "name": "gpt-3.5-turbo-legacy\/people\/kpts",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo-legacy\/people\/kpts_vis",
              "name": "gpt-3.5-turbo-legacy\/people\/kpts_vis",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "gpt-3.5-turbo-legacy\/people\/scale",
              "name": "gpt-3.5-turbo-legacy\/people\/scale",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "scale"
                }
              }
            }
          ],
          "repeated": true
        },
        {
          "@type": "cr:Field",
          "@id": "gpt-3.5-turbo-legacy\/activity",
          "name": "gpt-3.5-turbo-legacy\/activity",
          "description": "Column 'activity' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-gpt-3.5-turbo-legacy"
            },
            "extract": {
              "column": "activity"
            }
          }
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "dataType": "cr:Split",
      "key": {
        "@id": "llama-2_splits\/split_name"
      },
      "@id": "llama-2_splits",
      "name": "llama-2_splits",
      "description": "Splits for the llama-2 config.",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "llama-2_splits\/split_name",
          "name": "split_name",
          "description": "The name of the split.",
          "dataType": "sc:Text"
        }
      ],
      "data": [
        {
          "llama-2_splits\/split_name": "train"
        },
        {
          "llama-2_splits\/split_name": "validation"
        }
      ]
    },
    {
      "@type": "cr:RecordSet",
      "@id": "llama-2",
      "name": "llama-2",
      "description": "saifkhichi96\/mpii-human-pose-captions - 'llama-2' subset\n\nAdditional information:\n- 2 splits: train, validation",
      "field": [
        {
          "@type": "cr:Field",
          "@id": "llama-2\/split",
          "name": "llama-2\/split",
          "description": "Split to which the example belongs to.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "fileProperty": "fullpath"
            },
            "transform": {
              "regex": "llama\\-2\/(?:partial-)?(train|validation)\/.+parquet$"
            }
          },
          "references": {
            "field": {
              "@id": "llama-2_splits\/split_name"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/description",
          "name": "llama-2\/description",
          "description": "Column 'description' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "description"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/people",
          "name": "llama-2\/people",
          "description": "Column 'people' from the Hugging Face parquet file.",
          "subField": [
            {
              "@type": "cr:Field",
              "@id": "llama-2\/people\/center",
              "name": "llama-2\/people\/center",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-llama-2"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "llama-2\/people\/id",
              "name": "llama-2\/people\/id",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-llama-2"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "id"
                }
              }
            },
            {
              "@type": "cr:Field",
              "@id": "llama-2\/people\/kpts",
              "name": "llama-2\/people\/kpts",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-llama-2"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "llama-2\/people\/kpts_vis",
              "name": "llama-2\/people\/kpts_vis",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Integer",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-llama-2"
                },
                "extract": {
                  "column": "people"
                }
              },
              "repeated": true
            },
            {
              "@type": "cr:Field",
              "@id": "llama-2\/people\/scale",
              "name": "llama-2\/people\/scale",
              "description": "Column 'people' from the Hugging Face parquet file.",
              "dataType": "sc:Float",
              "source": {
                "fileSet": {
                  "@id": "parquet-files-for-config-llama-2"
                },
                "extract": {
                  "column": "people"
                },
                "transform": {
                  "jsonPath": "scale"
                }
              }
            }
          ],
          "repeated": true
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/activity_id",
          "name": "llama-2\/activity_id",
          "description": "Column 'activity_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "activity_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/video_id",
          "name": "llama-2\/video_id",
          "description": "Column 'video_id' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "video_id"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/video_frame",
          "name": "llama-2\/video_frame",
          "description": "Column 'video_frame' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "video_frame"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/activity",
          "name": "llama-2\/activity",
          "description": "Column 'activity' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "activity"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/image",
          "name": "llama-2\/image",
          "description": "Column 'image' from the Hugging Face parquet file.",
          "dataType": "sc:Text",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "image"
            }
          }
        },
        {
          "@type": "cr:Field",
          "@id": "llama-2\/count",
          "name": "llama-2\/count",
          "description": "Column 'count' from the Hugging Face parquet file.",
          "dataType": "sc:Integer",
          "source": {
            "fileSet": {
              "@id": "parquet-files-for-config-llama-2"
            },
            "extract": {
              "column": "count"
            }
          }
        }
      ]
    }
  ],
  "conformsTo": "http:\/\/mlcommons.org\/croissant\/1.0",
  "name": "mpii-human-pose-captions",
  "identifier": "10.57967\/hf\/1876",
  "description": "\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MPII Human Pose Descriptions\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe MPII Human Pose Descriptions dataset extends the widely-used MPII Human Pose Dataset with rich textual annotations. These annotations are generated by various state-of-the-art language models (LLMs) and include detailed descriptions of the activities being performed, the count of people present, and their specific poses.\nThe dataset consists of the same image splits as provided in MMPose, with 14644… See the full description on the dataset page: https:\/\/huggingface.co\/datasets\/saifkhichi96\/mpii-human-pose-captions.",
  "alternateName": [
    "saifkhichi96\/mpii-human-pose-captions",
    "MPII Human Pose Descriptions"
  ],
  "creator": {
    "@type": "Person",
    "name": "Saif Khan",
    "url": "https:\/\/huggingface.co\/saifkhichi96"
  },
  "keywords": [
    "zero-shot-classification",
    "image-to-text",
    "English",
    "bsd-2-clause",
    "10K - 100K",
    "json",
    "Tabular",
    "Text",
    "Datasets",
    "pandas",
    "Croissant",
    "Polars",
    "arxiv:2403.06904",
    "doi:10.57967\/hf\/1876",
    "🇺🇸 Region: US"
  ],
  "license": "https:\/\/choosealicense.com\/licenses\/bsd-2-clause\/",
  "sameAs": "https:\/\/www.saifkhichi.com\/research\/focusclip\/",
  "url": "https:\/\/huggingface.co\/datasets\/saifkhichi96\/mpii-human-pose-captions"
}</script> 

		<title>saifkhichi96/mpii-human-pose-captions · Datasets at Hugging Face</title>

		<script
			defer
			data-domain="huggingface.co"
			event-loggedIn="false"
			src="/js/script.pageview-props.js"
		></script>
		<script>
			window.plausible =
				window.plausible ||
				function () {
					(window.plausible.q = window.plausible.q || []).push(arguments);
				};
		</script>
		<script>
			window.hubConfig = {"features":{"signupDisabled":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https:\/\/huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","captchaDisabledOnSignup":true,"datasetViewerPublicUrl":"https:\/\/datasets-server.huggingface.co","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)","spacesIframeDomain":"hf.space","spacesApiUrl":"https:\/\/api.hf.space","docSearchKey":"ece5e02e57300e17d152c08056145326e90c4bff3dd07d7d1ae40cf1c8d39cb6","logoDev":{"apiUrl":"https:\/\/img.logo.dev\/","apiKey":"pk_UHS2HZOeRnaSOdDp7jbd5w"}};
		</script>
		<script type="text/javascript" src="https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js" defer></script>
	</head>
	<body class="flex flex-col min-h-dvh bg-white dark:bg-gray-950 text-black DatasetPage">
		<div class="flex min-h-dvh flex-col"><div class="SVELTE_HYDRATER contents" data-target="SystemThemeMonitor" data-props="{&quot;isLoggedIn&quot;:false}"></div>

	<div class="SVELTE_HYDRATER contents" data-target="MainHeader" data-props="{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:false,&quot;isZh&quot;:false,&quot;isPro&quot;:false}"><header class="border-b border-gray-100 "><div class="w-full px-4 container flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl " name="" placeholder="Search models, datasets, users..."   spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-40 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center space-x-1.5 2xl:space-x-2"><li class="hover:text-indigo-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
					Models</a>
			</li><li class="hover:text-red-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					Datasets</a>
			</li><li class="hover:text-blue-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
					Spaces</a>
			</li><li class="hover:text-yellow-700 max-xl:hidden"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/posts"><svg class="mr-1.5 text-gray-400 group-hover:text-yellow-500 text-yellow-500!" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 12 12" preserveAspectRatio="xMidYMid meet"><path fill="currentColor" fill-rule="evenodd" d="M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z" clip-rule="evenodd"></path></svg>
					Posts</a>
			</li><li class="hover:text-yellow-700"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 16 16"><path d="m2.28 3.7-.3.16a.67.67 0 0 0-.34.58v8.73l.01.04.02.07.01.04.03.06.02.04.02.03.04.06.05.05.04.04.06.04.06.04.08.04.08.02h.05l.07.02h.11l.04-.01.07-.02.03-.01.07-.03.22-.12a5.33 5.33 0 0 1 5.15.1.67.67 0 0 0 .66 0 5.33 5.33 0 0 1 5.33 0 .67.67 0 0 0 1-.58V4.36a.67.67 0 0 0-.34-.5l-.3-.17v7.78a.63.63 0 0 1-.87.59 4.9 4.9 0 0 0-4.35.35l-.65.39a.29.29 0 0 1-.15.04.29.29 0 0 1-.16-.04l-.65-.4a4.9 4.9 0 0 0-4.34-.34.63.63 0 0 1-.87-.59V3.7Z" fill="currentColor" class="dark:opacity-40"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M8 3.1a5.99 5.99 0 0 0-5.3-.43.66.66 0 0 0-.42.62v8.18c0 .45.46.76.87.59a4.9 4.9 0 0 1 4.34.35l.65.39c.05.03.1.04.16.04.05 0 .1-.01.15-.04l.65-.4a4.9 4.9 0 0 1 4.35-.34.63.63 0 0 0 .86-.59V3.3a.67.67 0 0 0-.41-.62 5.99 5.99 0 0 0-5.3.43l-.3.17L8 3.1Zm.73 1.87a.43.43 0 1 0-.86 0v5.48a.43.43 0 0 0 .86 0V4.97Z" fill="currentColor" class="opacity-40 dark:opacity-100"></path><path d="M8.73 4.97a.43.43 0 1 0-.86 0v5.48a.43.43 0 1 0 .86 0V4.96Z" fill="currentColor" class="dark:opacity-40"></path></svg>
					Docs</a>
			</li><li class="hover:text-black dark:hover:text-white"><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/enterprise"><svg class="mr-1.5 text-gray-400 group-hover:text-black dark:group-hover:text-white" xmlns="http://www.w3.org/2000/svg" fill="none" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 33 27"><path fill="currentColor" fill-rule="evenodd" d="M13.5.7a8.7 8.7 0 0 0-7.7 5.7L1 20.6c-1 3.1.9 5.7 4.1 5.7h15c3.3 0 6.8-2.6 7.8-5.7l4.6-14.2c1-3.1-.8-5.7-4-5.7h-15Zm1.1 5.7L9.8 20.3h9.8l1-3.1h-5.8l.8-2.5h4.8l1.1-3h-4.8l.8-2.3H23l1-3h-9.5Z" clip-rule="evenodd"></path></svg>
					Enterprise</a>
			</li>

		<li><a class="group flex items-center px-2 py-0.5 dark:text-gray-300 dark:hover:text-gray-100" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class=" text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>
			
		</button>
	
	
	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><a class="block cursor-pointer whitespace-nowrap px-2 py-0.5 hover:text-gray-500 dark:text-gray-300 dark:hover:text-gray-100" href="/login">Log In
				</a></li>
			<li><a class="whitespace-nowrap rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black" href="/join">Sign Up
					</a></li></ul></nav></div></header></div>
	
	
	
	<div class="SVELTE_HYDRATER contents" data-target="SSOBanner" data-props="{}"></div>
	
	

	<main class="flex flex-1 flex-col">
	<div class="SVELTE_HYDRATER contents" data-target="DatasetHeader" data-props="{&quot;activeTab&quot;:&quot;datasetCard&quot;,&quot;author&quot;:{&quot;_id&quot;:&quot;64da1dd841f0e6c0e9638b67&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/AVclbx51CufhItKagXkRi.png&quot;,&quot;fullname&quot;:&quot;Saif Khan&quot;,&quot;name&quot;:&quot;saifkhichi96&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false},&quot;canReadRepoSettings&quot;:false,&quot;dataset&quot;:{&quot;author&quot;:&quot;saifkhichi96&quot;,&quot;cardData&quot;:{&quot;license&quot;:&quot;bsd-2-clause&quot;,&quot;language&quot;:[&quot;en&quot;],&quot;pretty_name&quot;:&quot;MPII Human Pose Descriptions&quot;,&quot;size_categories&quot;:[&quot;10K<n<100K&quot;],&quot;configs&quot;:[{&quot;config_name&quot;:&quot;gpt-4&quot;,&quot;default&quot;:true,&quot;data_files&quot;:[{&quot;split&quot;:&quot;train&quot;,&quot;path&quot;:&quot;gpt-4-0613/train.json&quot;},{&quot;split&quot;:&quot;validation&quot;,&quot;path&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}]},{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;data_files&quot;:[{&quot;split&quot;:&quot;train&quot;,&quot;path&quot;:&quot;gpt-3.5-turbo-0301/train.json&quot;},{&quot;split&quot;:&quot;validation&quot;,&quot;path&quot;:&quot;gpt-3.5-turbo-0301/val.json&quot;}]},{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;data_files&quot;:[{&quot;split&quot;:&quot;train&quot;,&quot;path&quot;:&quot;gpt-3.5-turbo-0613/train.json&quot;},{&quot;split&quot;:&quot;validation&quot;,&quot;path&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}]},{&quot;config_name&quot;:&quot;llama-2&quot;,&quot;data_files&quot;:[{&quot;split&quot;:&quot;train&quot;,&quot;path&quot;:&quot;llama-2-70b-chat-hf/train.json&quot;},{&quot;split&quot;:&quot;validation&quot;,&quot;path&quot;:&quot;llama-2-70b-chat-hf/val.json&quot;}]}],&quot;task_categories&quot;:[&quot;zero-shot-classification&quot;,&quot;image-to-text&quot;]},&quot;cardExists&quot;:true,&quot;createdAt&quot;:&quot;2023-08-17T17:30:50.000Z&quot;,&quot;description&quot;:&quot;\n\t\n\t\t\n\t\n\t\n\t\tDataset Card for MPII Human Pose Descriptions\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThe MPII Human Pose Descriptions dataset extends the widely-used MPII Human Pose Dataset with rich textual annotations. These annotations are generated by various state-of-the-art language models (LLMs) and include detailed descriptions of the activities being performed, the count of people present, and their specific poses.\nThe dataset consists of the same image splits as provided in MMPose, with 14644… See the full description on the dataset page: https://huggingface.co/datasets/saifkhichi96/mpii-human-pose-captions.&quot;,&quot;doi&quot;:{&quot;id&quot;:&quot;10.57967/hf/1876&quot;,&quot;commit&quot;:&quot;1b7e8cee5fed55545e6dccaa3c03cdea5f1cb6e1&quot;},&quot;downloads&quot;:144,&quot;downloadsAllTime&quot;:1342,&quot;id&quot;:&quot;saifkhichi96/mpii-human-pose-captions&quot;,&quot;isLikedByUser&quot;:false,&quot;lastModified&quot;:&quot;2024-07-02T09:23:49.000Z&quot;,&quot;likes&quot;:2,&quot;datasetsServerInfo&quot;:{&quot;viewer&quot;:&quot;viewer&quot;,&quot;numRows&quot;:69468,&quot;libraries&quot;:[&quot;datasets&quot;,&quot;pandas&quot;,&quot;mlcroissant&quot;,&quot;polars&quot;],&quot;formats&quot;:[&quot;json&quot;],&quot;modalities&quot;:[&quot;tabular&quot;,&quot;text&quot;]},&quot;discussionsDisabled&quot;:false,&quot;repoType&quot;:&quot;dataset&quot;,&quot;private&quot;:false,&quot;gated&quot;:false,&quot;tags&quot;:[&quot;task_categories:zero-shot-classification&quot;,&quot;task_categories:image-to-text&quot;,&quot;language:en&quot;,&quot;license:bsd-2-clause&quot;,&quot;size_categories:10K<n<100K&quot;,&quot;format:json&quot;,&quot;modality:tabular&quot;,&quot;modality:text&quot;,&quot;library:datasets&quot;,&quot;library:pandas&quot;,&quot;library:mlcroissant&quot;,&quot;library:polars&quot;,&quot;arxiv:2403.06904&quot;,&quot;doi:10.57967/hf/1876&quot;,&quot;region:us&quot;],&quot;tag_objs&quot;:[{&quot;id&quot;:&quot;task_categories:zero-shot-classification&quot;,&quot;label&quot;:&quot;zero-shot-classification&quot;,&quot;type&quot;:&quot;task_categories&quot;,&quot;subType&quot;:&quot;nlp&quot;},{&quot;id&quot;:&quot;task_categories:image-to-text&quot;,&quot;label&quot;:&quot;image-to-text&quot;,&quot;type&quot;:&quot;task_categories&quot;,&quot;subType&quot;:&quot;cv&quot;},{&quot;id&quot;:&quot;language:en&quot;,&quot;label&quot;:&quot;English&quot;,&quot;type&quot;:&quot;language&quot;},{&quot;id&quot;:&quot;license:bsd-2-clause&quot;,&quot;label&quot;:&quot;bsd-2-clause&quot;,&quot;type&quot;:&quot;license&quot;},{&quot;id&quot;:&quot;size_categories:10K<n<100K&quot;,&quot;label&quot;:&quot;10K - 100K&quot;,&quot;type&quot;:&quot;size_categories&quot;},{&quot;id&quot;:&quot;format:json&quot;,&quot;label&quot;:&quot;json&quot;,&quot;type&quot;:&quot;format&quot;},{&quot;id&quot;:&quot;modality:tabular&quot;,&quot;label&quot;:&quot;Tabular&quot;,&quot;type&quot;:&quot;modality&quot;},{&quot;id&quot;:&quot;modality:text&quot;,&quot;label&quot;:&quot;Text&quot;,&quot;type&quot;:&quot;modality&quot;},{&quot;id&quot;:&quot;library:datasets&quot;,&quot;label&quot;:&quot;Datasets&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;library:pandas&quot;,&quot;label&quot;:&quot;pandas&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;library:mlcroissant&quot;,&quot;label&quot;:&quot;Croissant&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;library:polars&quot;,&quot;label&quot;:&quot;Polars&quot;,&quot;type&quot;:&quot;library&quot;},{&quot;id&quot;:&quot;arxiv:2403.06904&quot;,&quot;label&quot;:&quot;arxiv:2403.06904&quot;,&quot;type&quot;:&quot;arxiv&quot;,&quot;extra&quot;:{&quot;paperTitle&quot;:&quot;FocusCLIP: Multimodal Subject-Level Guidance for Zero-Shot Transfer in\n  Human-Centric Tasks&quot;}},{&quot;id&quot;:&quot;doi:10.57967/hf/1876&quot;,&quot;label&quot;:&quot;doi:10.57967/hf/1876&quot;,&quot;type&quot;:&quot;doi&quot;},{&quot;type&quot;:&quot;region&quot;,&quot;label&quot;:&quot;🇺🇸 Region: US&quot;,&quot;id&quot;:&quot;region:us&quot;}],&quot;homepage&quot;:&quot;https://www.saifkhichi.com/research/focusclip/&quot;,&quot;hasBlockedOids&quot;:false,&quot;region&quot;:&quot;us&quot;,&quot;xetEnabled&quot;:false},&quot;discussionsStats&quot;:{&quot;closed&quot;:0,&quot;open&quot;:1,&quot;total&quot;:1}}"><header class="bg-linear-to-t border-b border-gray-100 pt-6 sm:pt-9 from-gray-50-to-white via-white dark:via-gray-950"><div class="container relative "><h1 class="flex flex-wrap items-center max-md:leading-tight mb-3 text-lg max-sm:gap-y-1.5 md:text-xl"><a href="/datasets" class="group flex items-center"><svg class="sm:mr-1.5 -mr-1 text-gray-400" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					<span class="mr-2.5 font-semibold text-gray-400 group-hover:text-gray-500 max-sm:hidden">Datasets:</span></a>
				<hr class="mx-1.5 h-2 translate-y-px rounded-sm border-r dark:border-gray-600 sm:hidden">
			<div class="group flex flex-none items-center"><div class="relative mr-1 flex items-center">

			

<span class="inline-block "><span class="contents"><a href="/saifkhichi96" class="text-gray-400 hover:text-blue-600"><img alt="" class="w-3.5 h-3.5 rounded-full  flex-none" src="https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/AVclbx51CufhItKagXkRi.png" crossorigin="anonymous"></a></span>
	</span></div>
		

<span class="inline-block "><span class="contents"><a href="/saifkhichi96" class="text-gray-400 hover:text-blue-600">saifkhichi96</a></span>
	</span>
		<div class="mx-0.5 text-gray-300">/</div></div>

<div class="max-w-full "><a class="break-words font-mono font-semibold hover:text-blue-600 " href="/datasets/saifkhichi96/mpii-human-pose-captions">mpii-human-pose-captions</a>
	<button class="relative text-sm mr-4 focus:outline-hidden inline-flex cursor-pointer items-center text-sm  mx-0.5   text-gray-600 " title="Copy dataset name to clipboard" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	
	</button></div>
			<div class="inline-flex items-center overflow-hidden whitespace-nowrap rounded-md border bg-white text-sm leading-none text-gray-500  mr-2"><button class="relative flex items-center overflow-hidden from-red-50 to-transparent dark:from-red-900 px-1.5 py-1 hover:bg-linear-to-t focus:outline-hidden"  title="Like"><svg class="left-1.5 absolute" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" fill="currentColor"><path d="M22.45,6a5.47,5.47,0,0,1,3.91,1.64,5.7,5.7,0,0,1,0,8L16,26.13,5.64,15.64a5.7,5.7,0,0,1,0-8,5.48,5.48,0,0,1,7.82,0L16,10.24l2.53-2.58A5.44,5.44,0,0,1,22.45,6m0-2a7.47,7.47,0,0,0-5.34,2.24L16,7.36,14.89,6.24a7.49,7.49,0,0,0-10.68,0,7.72,7.72,0,0,0,0,10.82L16,29,27.79,17.06a7.72,7.72,0,0,0,0-10.82A7.49,7.49,0,0,0,22.45,4Z"></path></svg>

		
		<span class="ml-4 pl-0.5 ">like</span></button>
	<button class="focus:outline-hidden flex items-center border-l px-1.5 py-1 text-gray-400 hover:bg-gray-50 focus:bg-gray-100 dark:hover:bg-gray-900 dark:focus:bg-gray-800" title="See users who liked this repository">2</button></div>




			
			
	</h1>
		<div class="mb-3 flex flex-wrap md:mb-4"><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Tasks:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?task_categories=task_categories%3Azero-shot-classification"><div class="tag tag-white   "><div class="tag-ico -ml-2 tag-ico-yellow"><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 18 18"><path d="M16.7125 8.75625H9.64375V1.6875H8.55625V8.75625H1.4875V9.84375H8.55625V16.9125H9.64375V9.84375H16.7125V8.75625Z"></path><path d="M3.11875 16.9125C2.79612 16.9125 2.48073 16.8168 2.21247 16.6376C1.94421 16.4584 1.73513 16.2036 1.61167 15.9055C1.4882 15.6074 1.4559 15.2794 1.51884 14.963C1.58178 14.6466 1.73714 14.3559 1.96528 14.1278C2.19341 13.8997 2.48407 13.7443 2.8005 13.6814C3.11694 13.6184 3.44493 13.6507 3.743 13.7742C4.04107 13.8976 4.29584 14.1067 4.47508 14.375C4.65432 14.6432 4.75 14.9586 4.75 15.2813C4.74956 15.7138 4.57756 16.1284 4.27174 16.4343C3.96591 16.7401 3.55125 16.9121 3.11875 16.9125V16.9125ZM3.11875 14.7375C3.0112 14.7375 2.90607 14.7694 2.81665 14.8291C2.72724 14.8889 2.65754 14.9738 2.61639 15.0732C2.57523 15.1725 2.56446 15.2819 2.58544 15.3873C2.60642 15.4928 2.65821 15.5897 2.73426 15.6657C2.8103 15.7418 2.90719 15.7936 3.01267 15.8146C3.11814 15.8355 3.22747 15.8248 3.32683 15.7836C3.42619 15.7425 3.51111 15.6728 3.57086 15.5834C3.63061 15.4939 3.6625 15.3888 3.6625 15.2813C3.66235 15.1371 3.60502 14.9989 3.50308 14.8969C3.40113 14.795 3.26291 14.7377 3.11875 14.7375Z"></path><path d="M4.75 4.95C4.42737 4.95 4.11198 4.85433 3.84372 4.67509C3.57547 4.49584 3.36639 4.24107 3.24292 3.943C3.11945 3.64493 3.08715 3.31694 3.15009 3.00051C3.21303 2.68408 3.3684 2.39342 3.59653 2.16528C3.82466 1.93715 4.11533 1.78179 4.43176 1.71884C4.74819 1.6559 5.07618 1.68821 5.37425 1.81167C5.67232 1.93514 5.92709 2.14422 6.10633 2.41248C6.28558 2.68073 6.38125 2.99612 6.38125 3.31875C6.38082 3.75125 6.20881 4.16592 5.90299 4.47174C5.59716 4.77757 5.1825 4.94957 4.75 4.95ZM4.75 2.775C4.64245 2.775 4.53733 2.80689 4.44791 2.86664C4.35849 2.92639 4.28879 3.01131 4.24764 3.11067C4.20648 3.21002 4.19572 3.31935 4.2167 3.42483C4.23768 3.53031 4.28946 3.62719 4.36551 3.70324C4.44155 3.77928 4.53844 3.83107 4.64392 3.85205C4.7494 3.87303 4.85873 3.86227 4.95808 3.82111C5.05744 3.77995 5.14236 3.71026 5.20211 3.62084C5.26186 3.53142 5.29375 3.42629 5.29375 3.31875C5.2936 3.17458 5.23627 3.03636 5.13433 2.93442C5.03239 2.83248 4.89417 2.77514 4.75 2.775Z"></path><path d="M12.3625 7.66875C12.0399 7.66875 11.7245 7.57308 11.4562 7.39384C11.188 7.21459 10.9789 6.95982 10.8554 6.66175C10.732 6.36368 10.6996 6.03569 10.7626 5.71926C10.8255 5.40283 10.9809 5.11217 11.209 4.88403C11.4372 4.6559 11.7278 4.50054 12.0443 4.43759C12.3607 4.37465 12.6887 4.40696 12.9867 4.53042C13.2848 4.65389 13.5396 4.86297 13.7188 5.13123C13.8981 5.39948 13.9937 5.71487 13.9937 6.0375C13.9933 6.47 13.8213 6.88467 13.5155 7.19049C13.2097 7.49632 12.795 7.66832 12.3625 7.66875ZM12.3625 5.49375C12.255 5.49375 12.1498 5.52564 12.0604 5.58539C11.971 5.64514 11.9013 5.73006 11.8601 5.82942C11.819 5.92877 11.8082 6.0381 11.8292 6.14358C11.8502 6.24906 11.902 6.34595 11.978 6.42199C12.0541 6.49803 12.1509 6.54982 12.2564 6.5708C12.3619 6.59178 12.4712 6.58102 12.5706 6.53986C12.6699 6.4987 12.7549 6.42901 12.8146 6.33959C12.8744 6.25017 12.9062 6.14504 12.9062 6.0375C12.9061 5.89333 12.8488 5.75511 12.7468 5.65317C12.6449 5.55123 12.5067 5.49389 12.3625 5.49375Z"></path><path d="M6.38125 7.66876C6.98186 7.66876 7.46875 7.18187 7.46875 6.58126C7.46875 5.98065 6.98186 5.49376 6.38125 5.49376C5.78064 5.49376 5.29375 5.98065 5.29375 6.58126C5.29375 7.18187 5.78064 7.66876 6.38125 7.66876Z"></path><path d="M6.38125 13.1063C6.98186 13.1063 7.46875 12.6194 7.46875 12.0188C7.46875 11.4181 6.98186 10.9313 6.38125 10.9313C5.78064 10.9313 5.29375 11.4181 5.29375 12.0188C5.29375 12.6194 5.78064 13.1063 6.38125 13.1063Z"></path><path d="M11.8187 13.1063C12.4194 13.1063 12.9062 12.6194 12.9062 12.0188C12.9062 11.4181 12.4194 10.9313 11.8187 10.9313C11.2181 10.9313 10.7312 11.4181 10.7312 12.0188C10.7312 12.6194 11.2181 13.1063 11.8187 13.1063Z"></path><path d="M12.3625 16.9125C12.9631 16.9125 13.45 16.4256 13.45 15.825C13.45 15.2244 12.9631 14.7375 12.3625 14.7375C11.7619 14.7375 11.275 15.2244 11.275 15.825C11.275 16.4256 11.7619 16.9125 12.3625 16.9125Z"></path><path d="M15.625 14.7375C16.2256 14.7375 16.7125 14.2506 16.7125 13.65C16.7125 13.0494 16.2256 12.5625 15.625 12.5625C15.0244 12.5625 14.5375 13.0494 14.5375 13.65C14.5375 14.2506 15.0244 14.7375 15.625 14.7375Z"></path><path d="M2.575 7.66876C3.17561 7.66876 3.6625 7.18187 3.6625 6.58126C3.6625 5.98065 3.17561 5.49376 2.575 5.49376C1.97439 5.49376 1.4875 5.98065 1.4875 6.58126C1.4875 7.18187 1.97439 7.66876 2.575 7.66876Z"></path><path d="M15.625 3.8625C16.2256 3.8625 16.7125 3.37561 16.7125 2.775C16.7125 2.17439 16.2256 1.6875 15.625 1.6875C15.0244 1.6875 14.5375 2.17439 14.5375 2.775C14.5375 3.37561 15.0244 3.8625 15.625 3.8625Z"></path></svg></div>

	

	<span>Zero-Shot Classification</span>
	

	</div></a><a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?task_categories=task_categories%3Aimage-to-text"><div class="tag tag-white   "><div class="tag-ico -ml-2 tag-ico-red"><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M29.707 19.293l-3-3a1 1 0 0 0-1.414 0L16 25.586V30h4.414l9.293-9.293a1 1 0 0 0 0-1.414zM19.586 28H18v-1.586l5-5L24.586 23zM26 21.586L24.414 20L26 18.414L27.586 20z" fill="currentColor"></path><path d="M20 13v-2h-2.142a3.94 3.94 0 0 0-.425-1.019l1.517-1.517l-1.414-1.414l-1.517 1.517A3.944 3.944 0 0 0 15 8.142V6h-2v2.142a3.944 3.944 0 0 0-1.019.425L10.464 7.05L9.05 8.464l1.517 1.517A3.94 3.94 0 0 0 10.142 11H8v2h2.142a3.94 3.94 0 0 0 .425 1.019L9.05 15.536l1.414 1.414l1.517-1.517a3.944 3.944 0 0 0 1.019.425V18h2v-2.142a3.944 3.944 0 0 0 1.019-.425l1.517 1.517l1.414-1.414l-1.517-1.517A3.94 3.94 0 0 0 17.858 13zm-6 1a2 2 0 1 1 2-2a2.002 2.002 0 0 1-2 2z" fill="currentColor"></path><path d="M12 30H6a2.002 2.002 0 0 1-2-2V4a2.002 2.002 0 0 1 2-2h16a2.002 2.002 0 0 1 2 2v10h-2V4H6v24h6z" fill="currentColor"></path></svg></div>

	

	<span>Image-to-Text</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Modalities:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?modality=modality%3Atabular"><div class="tag tag-white   ">
		<svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.619 4.619C2.667 6.572 2.667 9.715 2.667 16s0 9.43 1.952 11.38C6.572 29.333 9.715 29.333 16 29.333s9.43 0 11.38-1.953c1.953-1.952 1.953-5.095 1.953-11.38 0-6.285 0-9.427-1.953-11.381C25.428 2.667 22.285 2.667 16 2.667c-6.285 0-9.427 0-11.381 1.952ZM16.615 10a1 1 0 1 1 0 2h-1.23a1 1 0 1 1 0-2h1.23Zm0 5a1 1 0 1 1 0 2h-1.23a1 1 0 1 1 0-2h1.23Zm3.154 1a1 1 0 0 0 1 1H22a1 1 0 1 0 0-2h-1.23a1 1 0 0 0-1 1Zm-3.154 4a1 1 0 1 1 0 2h-1.23a1 1 0 1 1 0-2h1.23Zm3.154 1a1 1 0 0 0 1 1H22a1 1 0 1 0 0-2h-1.23a1 1 0 0 0-1 1Zm0-10a1 1 0 0 0 1 1H22a1 1 0 1 0 0-2h-1.23a1 1 0 0 0-1 1Zm-8.538-1H10a1 1 0 1 0 0 2h1.23a1 1 0 1 0 0-2Zm0 5H10a1 1 0 1 0 0 2h1.23a1 1 0 1 0 0-2Zm0 5H10a1 1 0 1 0 0 2h1.23a1 1 0 1 0 0-2Z" fill="currentColor"></path></svg>

	

	<span>Tabular</span>
	

	</div></a><a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?modality=modality%3Atext"><div class="tag tag-white   ">
		<svg class="text-red-700 dark:text-red-600" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.619 4.619C2.667 6.573 2.667 9.715 2.667 16s0 9.428 1.952 11.38C6.573 29.333 9.715 29.333 16 29.333s9.428 0 11.38-1.953c1.953-1.95 1.953-5.095 1.953-11.38s0-9.428-1.953-11.381C25.43 2.667 22.285 2.667 16 2.667s-9.428 0-11.381 1.952m8.65 3.714c-.573 0-1.109 0-1.546.066-.495.073-1.003.248-1.41.7-.392.436-.53.956-.59 1.452-.056.464-.056 1.04-.056 1.689V13a1 1 0 1 0 2 0v-.704c0-.724.001-1.176.041-1.505q.015-.15.061-.294a.2.2 0 0 1 .031-.061q0-.003.016-.01a.8.8 0 0 1 .203-.05c.272-.04.654-.043 1.314-.043H15v11.334h-2.333a1 1 0 1 0 0 2H20a1 1 0 0 0 0-2h-3V10.333h1.667c.66 0 1.042.003 1.314.043.123.019.18.04.203.05l.015.009a.2.2 0 0 1 .032.061c.018.05.042.14.061.295.04.329.041.781.041 1.506V13a1 1 0 1 0 2 0v-.76c0-.65 0-1.225-.056-1.69-.06-.495-.198-1.015-.59-1.453-.407-.45-.915-.625-1.41-.698-.437-.067-.973-.067-1.546-.066z" fill="currentColor"></path></svg>

	

	<span>Text</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Formats:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?format=format%3Ajson"><div class="tag tag-white   ">
		<svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill-rule="evenodd" clip-rule="evenodd" d="M8.917 2.25h-.834v.833h.834v2.084A.833.833 0 0 0 9.75 6a.833.833 0 0 0-.833.833v2.084h-.834v.833h.834c.446-.113.833-.375.833-.833V7.25a.833.833 0 0 1 .833-.833H11v-.834h-.417a.833.833 0 0 1-.833-.833V3.083a.833.833 0 0 0-.833-.833Zm-5.834 0a.833.833 0 0 0-.833.833V4.75a.833.833 0 0 1-.833.833H1v.834h.417a.833.833 0 0 1 .833.833v1.667a.833.833 0 0 0 .833.833h.834v-.833h-.834V6.833A.833.833 0 0 0 2.25 6a.833.833 0 0 0 .833-.833V3.083h.834V2.25h-.834ZM6 7.25a.417.417 0 1 0 0 .833.417.417 0 0 0 0-.833Zm1.667 0a.417.417 0 1 0 0 .833.417.417 0 0 0 0-.833Zm-3.334 0a.417.417 0 1 0 0 .833.417.417 0 0 0 0-.833Z" fill="currentColor"></path></svg>

	

	<span>json</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Languages:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?language=language%3Aen"><div class="tag tag-white   ">
		<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="text-green-600/80" preserveAspectRatio="xMidYMid meet" width="1em" height="1em" viewBox="0 0 10 10"><path fill-rule="evenodd" clip-rule="evenodd" d="M0.625 5C0.625 6.16032 1.08594 7.27312 1.90641 8.09359C2.72688 8.91406 3.83968 9.375 5 9.375C6.16032 9.375 7.27312 8.91406 8.09359 8.09359C8.91406 7.27312 9.375 6.16032 9.375 5C9.375 3.83968 8.91406 2.72688 8.09359 1.90641C7.27312 1.08594 6.16032 0.625 5 0.625C3.83968 0.625 2.72688 1.08594 1.90641 1.90641C1.08594 2.72688 0.625 3.83968 0.625 5ZM7.64365 7.48027C7.61734 7.50832 7.59054 7.53598 7.56326 7.56326C7.13828 7.98824 6.61864 8.2968 6.0539 8.46842C6.29802 8.11949 6.49498 7.64804 6.63475 7.09483C7.00845 7.18834 7.35014 7.3187 7.64365 7.48027ZM8.10076 6.87776C8.37677 6.42196 8.55005 5.90894 8.60556 5.37499H6.86808C6.85542 5.71597 6.82551 6.04557 6.77971 6.35841C7.25309 6.47355 7.68808 6.6414 8.062 6.85549C8.07497 6.86283 8.08789 6.87025 8.10076 6.87776ZM6.03795 6.22536C6.07708 5.95737 6.1044 5.67232 6.11705 5.37499H3.88295C3.89666 5.69742 3.92764 6.00542 3.9722 6.29287C4.37075 6.21726 4.79213 6.17749 5.224 6.17749C5.50054 6.17749 5.77294 6.19376 6.03795 6.22536ZM4.1261 7.02673C4.34894 7.84835 4.68681 8.375 5 8.375C5.32122 8.375 5.66839 7.82101 5.8908 6.963C5.67389 6.93928 5.45082 6.92699 5.224 6.92699C4.84316 6.92699 4.47332 6.96176 4.1261 7.02673ZM3.39783 7.21853C3.53498 7.71842 3.72038 8.14579 3.9461 8.46842C3.42141 8.30898 2.93566 8.03132 2.52857 7.65192C2.77253 7.48017 3.06711 7.33382 3.39783 7.21853ZM3.23916 6.48077C3.18263 6.13193 3.14625 5.76074 3.13192 5.37499H1.39444C1.4585 5.99112 1.67936 6.57938 2.03393 7.08403C2.3706 6.83531 2.78055 6.63162 3.23916 6.48077ZM1.39444 4.62499H3.13192C3.14615 4.24204 3.18211 3.87344 3.23794 3.52681C2.77814 3.37545 2.36731 3.17096 2.03024 2.92123C1.67783 3.42469 1.45828 4.011 1.39444 4.62499ZM2.5237 2.35262C2.76812 2.52552 3.06373 2.67281 3.39584 2.78875C3.53318 2.28573 3.71928 1.85578 3.9461 1.53158C3.41932 1.69166 2.93178 1.97089 2.5237 2.35262ZM3.97101 3.71489C3.92709 4.00012 3.89654 4.30547 3.88295 4.62499H6.11705C6.10453 4.33057 6.07761 4.04818 6.03909 3.78248C5.77372 3.81417 5.50093 3.83049 5.224 3.83049C4.79169 3.83049 4.3699 3.79065 3.97101 3.71489ZM5.8928 3.04476C5.67527 3.06863 5.45151 3.08099 5.224 3.08099C4.84241 3.08099 4.47186 3.04609 4.12405 2.98086C4.34686 2.1549 4.68584 1.625 5 1.625C5.32218 1.625 5.67048 2.18233 5.8928 3.04476ZM6.78083 3.6493C6.826 3.95984 6.85552 4.28682 6.86808 4.62499H8.60556C8.55029 4.09337 8.37827 3.58251 8.10436 3.1282C8.0903 3.1364 8.07618 3.14449 8.062 3.15249C7.68838 3.36641 7.25378 3.53417 6.78083 3.6493ZM7.64858 2.52499C7.35446 2.68754 7.0117 2.81868 6.63664 2.91268C6.49676 2.35623 6.29913 1.88209 6.0539 1.53158C6.61864 1.7032 7.13828 2.01176 7.56326 2.43674C7.59224 2.46572 7.62068 2.49514 7.64858 2.52499Z" fill="currentColor"></path></svg>

	

	<span>English</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Size:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?size_categories=size_categories%3A10K%3Cn%3C100K"><div class="tag tag-white   ">

	

	<span>10K - 100K</span>
	

	</div></a>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">ArXiv:
	</span>
	

	<div class="relative inline-block ">
	<button class="group mr-1 mb-1 md:mr-1.5 md:mb-1.5  rounded-full rounded-br-none " type="button">
		<div class="tag tag-white rounded-full  relative rounded-br-none pr-2.5">
		<svg class="-mr-1 text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 12 12" preserveAspectRatio="xMidYMid meet" fill="none"><path fill="currentColor" fill-rule="evenodd" d="M8.007 1.814a1.176 1.176 0 0 0-.732-.266H3.088c-.64 0-1.153.512-1.153 1.152v6.803c0 .64.513 1.152 1.153 1.152h5.54c.632 0 1.144-.511 1.144-1.152V3.816c0-.338-.137-.658-.412-.887L8.007 1.814Zm-1.875 1.81c0 .695.55 1.253 1.244 1.253h.983a.567.567 0 0 1 .553.585v4.041c0 .165-.119.302-.283.302h-5.55c-.156 0-.275-.137-.275-.302V2.7a.284.284 0 0 1 .284-.301h2.468a.574.574 0 0 1 .434.19.567.567 0 0 1 .142.395v.64Z" clip-rule="evenodd"></path><path fill="currentColor" fill-opacity=".2" fill-rule="evenodd" d="M6.132 3.624c0 .695.55 1.253 1.244 1.253h.97a.567.567 0 0 1 .566.585v4.041c0 .165-.119.302-.283.302h-5.55c-.156 0-.275-.137-.275-.302V2.7a.284.284 0 0 1 .284-.301h2.468a.567.567 0 0 1 .576.585v.64Z" clip-rule="evenodd"></path></svg>

	

	<span class="-mr-2 text-gray-400">arxiv:</span>
		<span>2403.06904</span>
	

	<div class="border-br-gray-200 absolute bottom-0.5 right-0.5 h-1 w-1 border-[3px] border-l-transparent border-t-transparent border-b-gray-200 border-r-gray-200 dark:border-b-gray-700 dark:border-r-gray-700"></div></div>
		
		</button>
	
	
	</div>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">DOI:
	</span>
	

	<div class="relative inline-block ">
	<button class="group mr-1 mb-1 md:mr-1.5 md:mb-1.5  rounded-lg rounded-br-none " type="button">
		<div class="tag tag-white   relative rounded-br-none pr-2.5">

	

	<span>doi:10.57967/hf/1876</span>
	

	<div class="border-br-gray-200 absolute bottom-0.5 right-0.5 h-1 w-1 border-[3px] border-l-transparent border-t-transparent border-b-gray-200 border-r-gray-200 dark:border-b-gray-700 dark:border-r-gray-700"></div></div>
		
		</button>
	
	
	</div>

	</div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">Libraries:
	</span>
	<a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?library=library%3Adatasets"><div class="tag tag-white   "><svg class="text-black inline-block text-sm" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" width="1em" height="1em" viewBox="0 0 95 88"><path fill="#fff" d="M94.25 70.08a8.28 8.28 0 0 1-.43 6.46 10.57 10.57 0 0 1-3 3.6 25.18 25.18 0 0 1-5.7 3.2 65.74 65.74 0 0 1-7.56 2.65 46.67 46.67 0 0 1-11.42 1.68c-5.42.05-10.09-1.23-13.4-4.5a40.4 40.4 0 0 1-10.14.03c-3.34 3.25-7.99 4.52-13.39 4.47a46.82 46.82 0 0 1-11.43-1.68 66.37 66.37 0 0 1-7.55-2.65c-2.28-.98-4.17-2-5.68-3.2a10.5 10.5 0 0 1-3.02-3.6c-.99-2-1.18-4.3-.42-6.46a8.54 8.54 0 0 1-.33-5.63c.25-.95.66-1.83 1.18-2.61a8.67 8.67 0 0 1 2.1-8.47 8.23 8.23 0 0 1 2.82-2.07 41.75 41.75 0 1 1 81.3-.12 8.27 8.27 0 0 1 3.11 2.19 8.7 8.7 0 0 1 2.1 8.47c.52.78.93 1.66 1.18 2.61a8.61 8.61 0 0 1-.32 5.63Z"></path><path fill="#FFD21E" d="M47.21 76.5a34.75 34.75 0 1 0 0-69.5 34.75 34.75 0 0 0 0 69.5Z"></path><path fill="#FF9D0B" d="M81.96 41.75a34.75 34.75 0 1 0-69.5 0 34.75 34.75 0 0 0 69.5 0Zm-73.5 0a38.75 38.75 0 1 1 77.5 0 38.75 38.75 0 0 1-77.5 0Z"></path><path fill="#3A3B45" d="M58.5 32.3c1.28.44 1.78 3.06 3.07 2.38a5 5 0 1 0-6.76-2.07c.61 1.15 2.55-.72 3.7-.32ZM34.95 32.3c-1.28.44-1.79 3.06-3.07 2.38a5 5 0 1 1 6.76-2.07c-.61 1.15-2.56-.72-3.7-.32Z"></path><path fill="#FF323D" d="M46.96 56.29c9.83 0 13-8.76 13-13.26 0-2.34-1.57-1.6-4.09-.36-2.33 1.15-5.46 2.74-8.9 2.74-7.19 0-13-6.88-13-2.38s3.16 13.26 13 13.26Z"></path><path fill="#3A3B45" fill-rule="evenodd" d="M39.43 54a8.7 8.7 0 0 1 5.3-4.49c.4-.12.81.57 1.24 1.28.4.68.82 1.37 1.24 1.37.45 0 .9-.68 1.33-1.35.45-.7.89-1.38 1.32-1.25a8.61 8.61 0 0 1 5 4.17c3.73-2.94 5.1-7.74 5.1-10.7 0-2.34-1.57-1.6-4.09-.36l-.14.07c-2.31 1.15-5.39 2.67-8.77 2.67s-6.45-1.52-8.77-2.67c-2.6-1.29-4.23-2.1-4.23.29 0 3.05 1.46 8.06 5.47 10.97Z" clip-rule="evenodd"></path><path fill="#FF9D0B" d="M70.71 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM24.21 37a3.25 3.25 0 1 0 0-6.5 3.25 3.25 0 0 0 0 6.5ZM17.52 48c-1.62 0-3.06.66-4.07 1.87a5.97 5.97 0 0 0-1.33 3.76 7.1 7.1 0 0 0-1.94-.3c-1.55 0-2.95.59-3.94 1.66a5.8 5.8 0 0 0-.8 7 5.3 5.3 0 0 0-1.79 2.82c-.24.9-.48 2.8.8 4.74a5.22 5.22 0 0 0-.37 5.02c1.02 2.32 3.57 4.14 8.52 6.1 3.07 1.22 5.89 2 5.91 2.01a44.33 44.33 0 0 0 10.93 1.6c5.86 0 10.05-1.8 12.46-5.34 3.88-5.69 3.33-10.9-1.7-15.92-2.77-2.78-4.62-6.87-5-7.77-.78-2.66-2.84-5.62-6.25-5.62a5.7 5.7 0 0 0-4.6 2.46c-1-1.26-1.98-2.25-2.86-2.82A7.4 7.4 0 0 0 17.52 48Zm0 4c.51 0 1.14.22 1.82.65 2.14 1.36 6.25 8.43 7.76 11.18.5.92 1.37 1.31 2.14 1.31 1.55 0 2.75-1.53.15-3.48-3.92-2.93-2.55-7.72-.68-8.01.08-.02.17-.02.24-.02 1.7 0 2.45 2.93 2.45 2.93s2.2 5.52 5.98 9.3c3.77 3.77 3.97 6.8 1.22 10.83-1.88 2.75-5.47 3.58-9.16 3.58-3.81 0-7.73-.9-9.92-1.46-.11-.03-13.45-3.8-11.76-7 .28-.54.75-.76 1.34-.76 2.38 0 6.7 3.54 8.57 3.54.41 0 .7-.17.83-.6.79-2.85-12.06-4.05-10.98-8.17.2-.73.71-1.02 1.44-1.02 3.14 0 10.2 5.53 11.68 5.53.11 0 .2-.03.24-.1.74-1.2.33-2.04-4.9-5.2-5.21-3.16-8.88-5.06-6.8-7.33.24-.26.58-.38 1-.38 3.17 0 10.66 6.82 10.66 6.82s2.02 2.1 3.25 2.1c.28 0 .52-.1.68-.38.86-1.46-8.06-8.22-8.56-11.01-.34-1.9.24-2.85 1.31-2.85Z"></path><path fill="#FFD21E" d="M38.6 76.69c2.75-4.04 2.55-7.07-1.22-10.84-3.78-3.77-5.98-9.3-5.98-9.3s-.82-3.2-2.69-2.9c-1.87.3-3.24 5.08.68 8.01 3.91 2.93-.78 4.92-2.29 2.17-1.5-2.75-5.62-9.82-7.76-11.18-2.13-1.35-3.63-.6-3.13 2.2.5 2.79 9.43 9.55 8.56 11-.87 1.47-3.93-1.71-3.93-1.71s-9.57-8.71-11.66-6.44c-2.08 2.27 1.59 4.17 6.8 7.33 5.23 3.16 5.64 4 4.9 5.2-.75 1.2-12.28-8.53-13.36-4.4-1.08 4.11 11.77 5.3 10.98 8.15-.8 2.85-9.06-5.38-10.74-2.18-1.7 3.21 11.65 6.98 11.76 7.01 4.3 1.12 15.25 3.49 19.08-2.12Z"></path><path fill="#FF9D0B" d="M77.4 48c1.62 0 3.07.66 4.07 1.87a5.97 5.97 0 0 1 1.33 3.76 7.1 7.1 0 0 1 1.95-.3c1.55 0 2.95.59 3.94 1.66a5.8 5.8 0 0 1 .8 7 5.3 5.3 0 0 1 1.78 2.82c.24.9.48 2.8-.8 4.74a5.22 5.22 0 0 1 .37 5.02c-1.02 2.32-3.57 4.14-8.51 6.1-3.08 1.22-5.9 2-5.92 2.01a44.33 44.33 0 0 1-10.93 1.6c-5.86 0-10.05-1.8-12.46-5.34-3.88-5.69-3.33-10.9 1.7-15.92 2.78-2.78 4.63-6.87 5.01-7.77.78-2.66 2.83-5.62 6.24-5.62a5.7 5.7 0 0 1 4.6 2.46c1-1.26 1.98-2.25 2.87-2.82A7.4 7.4 0 0 1 77.4 48Zm0 4c-.51 0-1.13.22-1.82.65-2.13 1.36-6.25 8.43-7.76 11.18a2.43 2.43 0 0 1-2.14 1.31c-1.54 0-2.75-1.53-.14-3.48 3.91-2.93 2.54-7.72.67-8.01a1.54 1.54 0 0 0-.24-.02c-1.7 0-2.45 2.93-2.45 2.93s-2.2 5.52-5.97 9.3c-3.78 3.77-3.98 6.8-1.22 10.83 1.87 2.75 5.47 3.58 9.15 3.58 3.82 0 7.73-.9 9.93-1.46.1-.03 13.45-3.8 11.76-7-.29-.54-.75-.76-1.34-.76-2.38 0-6.71 3.54-8.57 3.54-.42 0-.71-.17-.83-.6-.8-2.85 12.05-4.05 10.97-8.17-.19-.73-.7-1.02-1.44-1.02-3.14 0-10.2 5.53-11.68 5.53-.1 0-.19-.03-.23-.1-.74-1.2-.34-2.04 4.88-5.2 5.23-3.16 8.9-5.06 6.8-7.33-.23-.26-.57-.38-.98-.38-3.18 0-10.67 6.82-10.67 6.82s-2.02 2.1-3.24 2.1a.74.74 0 0 1-.68-.38c-.87-1.46 8.05-8.22 8.55-11.01.34-1.9-.24-2.85-1.31-2.85Z"></path><path fill="#FFD21E" d="M56.33 76.69c-2.75-4.04-2.56-7.07 1.22-10.84 3.77-3.77 5.97-9.3 5.97-9.3s.82-3.2 2.7-2.9c1.86.3 3.23 5.08-.68 8.01-3.92 2.93.78 4.92 2.28 2.17 1.51-2.75 5.63-9.82 7.76-11.18 2.13-1.35 3.64-.6 3.13 2.2-.5 2.79-9.42 9.55-8.55 11 .86 1.47 3.92-1.71 3.92-1.71s9.58-8.71 11.66-6.44c2.08 2.27-1.58 4.17-6.8 7.33-5.23 3.16-5.63 4-4.9 5.2.75 1.2 12.28-8.53 13.36-4.4 1.08 4.11-11.76 5.3-10.97 8.15.8 2.85 9.05-5.38 10.74-2.18 1.69 3.21-11.65 6.98-11.76 7.01-4.31 1.12-15.26 3.49-19.08-2.12Z"></path></svg>

	

	<span>Datasets</span>
	

	</div></a><a class="mb-1 mr-1 md:mb-1.5 md:mr-1.5 rounded-lg" href="/datasets?library=library%3Apandas"><div class="tag tag-white   "><svg class="text-black inline-block text-sm text-[#130754] dark:text-gray-200" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid slice" viewBox="0 0 210.21 280.43"><rect fill="currentColor" x="74.51" y="43.03" width="24.09" height="50.02"></rect><rect fill="currentColor" x="74.51" y="145.78" width="24.09" height="50.02"></rect><rect fill="#ffca00" x="74.51" y="107.65" width="24.09" height="23.6"></rect><rect fill="currentColor" x="35.81" y="84.15" width="24.09" height="166.27"></rect><rect fill="currentColor" x="112.41" y="187.05" width="24.09" height="50.02"></rect><rect fill="currentColor" x="112.41" y="84.21" width="24.09" height="50.02"></rect><rect fill="#e70488" x="112.41" y="148.84" width="24.09" height="23.6"></rect><rect fill="currentColor" x="150.3" y="30" width="24.09" height="166.27"></rect></svg>

	

	<span>pandas</span>
	

	</div></a><div class="relative inline-block ">
	<button class="group mr-1 mb-1 md:mr-1.5 md:mb-1.5  rounded-lg rounded-br-none " type="button">
		<div class="tag tag-white   relative rounded-br-none pr-2.5"><svg class="text-black inline-block text-sm" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="none" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M22.2812 12.2656L25.9532 15.7187C26.8932 16.6587 28.0913 17.3931 29.0313 16.4531C29.8594 15.7812 29.9332 14.1 29.9532 13.5C29.9532 11.5625 28.9219 8.375 27.25 6.71875C25.5604 5.04493 23.3782 3.91692 22.7032 3.78125L22.2812 12.2656Z" fill="#F5AB6A"></path><path d="M22.2812 12.2656L25.9532 15.7187C26.8932 16.6587 28.0913 17.3931 29.0313 16.4531C29.8594 15.7812 29.9332 14.1 29.9532 13.5C29.9532 11.5625 28.9219 8.375 27.25 6.71875C25.5604 5.04493 23.3782 3.91692 22.7032 3.78125L22.2812 12.2656Z" fill="url(#paint0_radial_18_31665)"></path><g filter="url(#filter0_f_18_31665)"><path d="M22.2849 12.1817L23.4375 13.2656L24.4375 4.70312C23.5121 4.1242 23.0198 3.96369 22.6563 3.89062L22.2849 12.1817Z" fill="url(#paint1_linear_18_31665)"></path></g><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint2_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint3_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint4_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint5_radial_18_31665)"></path><path d="M22.7969 3.05741L21.8437 2.65269C19.6421 1.96765 17.2344 1.81208 14.6719 2.23236C12.1094 2.65264 11.5156 3.2442 11.5156 3.2442C10.896 3.3674 10.8671 3.88898 11.1718 4.45363C13.0797 6.72576 15.176 13.4043 18.0469 14.2506C18.89 14.4662 21.3791 14.4776 22.2019 14.1593L22.3238 14.108C22.6692 13.9745 23.1672 13.2814 23.1875 12.9118L23.4219 4.03043C23.4523 3.59924 23.1484 3.25204 22.7969 3.05741Z" fill="url(#paint6_linear_18_31665)"></path><g filter="url(#filter1_f_18_31665)"><path d="M13.1016 2.72656C11.862 3.06924 11.5298 3.40016 11.5298 3.40016C10.9102 3.52335 10.936 4.11525 11.2408 4.6799C13.1487 6.95202 15.1361 13.2496 18.007 14.0958C18.2707 14.1633 18.6953 14.2107 19.1797 14.2344L13.1016 2.72656Z" fill="url(#paint7_linear_18_31665)"></path></g><path d="M12.2187 22.7187L15.7656 26.2031C16.7332 27.1171 17.3334 28.2487 16.4219 29.2188C15.7749 30.0687 14.2241 29.9933 13.625 30.0313C11.6883 30.0891 9.09014 29.5622 6.84373 27.5313C5.07737 25.9343 4.09321 23.688 3.93751 23.0156L12.2187 22.7187Z" fill="url(#paint8_radial_18_31665)"></path><path d="M12.2187 22.7187L15.7656 26.2031C16.7332 27.1171 17.3334 28.2487 16.4219 29.2188C15.7749 30.0687 14.2241 29.9933 13.625 30.0313C11.6883 30.0891 9.09014 29.5622 6.84373 27.5313C5.07737 25.9343 4.09321 23.688 3.93751 23.0156L12.2187 22.7187Z" fill="url(#paint9_radial_18_31665)"></path><g filter="url(#filter2_f_18_31665)"><path d="M12.0523 22.7916L13.2187 23.9375L4.81018 24.5721C4.4328 23.8671 4.20835 23.2768 4.14062 22.9844L12.0523 22.7916Z" fill="url(#paint10_linear_18_31665)"></path><path d="M12.0523 22.7916L13.2187 23.9375L4.81018 24.5721C4.4328 23.8671 4.20835 23.2768 4.14062 22.9844L12.0523 22.7916Z" fill="url(#paint11_radial_18_31665)"></path></g><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="#EC9F6A"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint12_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint13_linear_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint14_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint15_radial_18_31665)"></path><path d="M2.99219 22.6484C2.07068 20.538 1.78913 17.4452 2.21096 15.0703C2.63279 12.6953 3.20759 11.951 3.20759 11.951C3.31231 11.3264 3.83281 11.2818 4.40626 11.5703C6.73409 13.4144 13.3119 15.2264 14.2432 18.0781C14.5947 19.3034 14.6279 21.3125 14.1641 22.5156C14.0409 22.8657 13.5 23.3516 13.0625 23.4141C12.625 23.4765 9.47656 23.3516 8.61719 23.3516C7.75781 23.3516 4.64844 23.6719 4.14062 23.6172C3.63281 23.5625 3.23437 23.2031 2.99219 22.6484Z" fill="url(#paint16_radial_18_31665)"></path><g filter="url(#filter3_f_18_31665)"><path d="M2.70313 13.6719C3.04135 12.4711 3.36224 12.0555 3.36224 12.0555C3.46697 11.4309 3.98746 11.3864 4.56092 11.6749C6.88874 13.5189 13.0809 15.1104 14.0121 17.9622C14.1731 18.5231 14.2766 19.0394 14.3287 19.5128L2.70313 13.6719Z" fill="url(#paint17_linear_18_31665)"></path><path d="M2.70313 13.6719C3.04135 12.4711 3.36224 12.0555 3.36224 12.0555C3.46697 11.4309 3.98746 11.3864 4.56092 11.6749C6.88874 13.5189 13.0809 15.1104 14.0121 17.9622C14.1731 18.5231 14.2766 19.0394 14.3287 19.5128L2.70313 13.6719Z" fill="url(#paint18_linear_18_31665)"></path></g><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="#D79453"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint19_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint20_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint21_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint22_linear_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint23_radial_18_31665)"></path><path d="M9.83184 2.82184C6.62184 4.07184 4.07184 6.62184 2.82184 9.83184C2.48184 10.7118 2.82184 11.7018 3.62184 12.1918L14.0418 18.5418C14.6618 18.9218 15.4418 18.9218 16.0618 18.5418C17.0718 17.9218 17.9318 17.0718 18.5418 16.0618C18.9218 15.4418 18.9218 14.6618 18.5418 14.0418L12.1918 3.62184C11.7018 2.82184 10.7118 2.48184 9.83184 2.82184Z" fill="url(#paint24_radial_18_31665)"></path><defs><filter id="filter0_f_18_31665" x="22.0349" y="3.64062" width="2.65265" height="9.875" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter1_f_18_31665" x="10.7815" y="2.47656" width="8.64819" height="12.0078" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter2_f_18_31665" x="3.89062" y="22.5416" width="9.57812" height="2.2804" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><filter id="filter3_f_18_31665" x="2.45312" y="11.2538" width="12.1255" height="8.50903" filterUnits="userSpaceOnUse" color-interpolation-filters="sRGB"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend mode="normal" in="SourceGraphic" in2="BackgroundImageFix" result="shape"></feBlend><feGaussianBlur stdDeviation="0.125" result="effect1_foregroundBlur_18_31665"></feGaussianBlur></filter><radialGradient id="paint0_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.8125 12.9375) rotate(42.7741) scale(12.5164 7.08839)"><stop offset="0.0937591" stop-color="#C05159"></stop><stop offset="0.553697" stop-color="#F6AC6A"></stop><stop offset="0.832916" stop-color="#FFD186"></stop><stop offset="0.916927" stop-color="#FFDC87"></stop></radialGradient><linearGradient id="paint1_linear_18_31665" x1="24.7344" y1="4.67187" x2="20.8594" y2="12.8906" gradientUnits="userSpaceOnUse"><stop stop-color="#EBD67C"></stop><stop offset="0.0655686" stop-color="#FFFFA6"></stop><stop offset="0.530552" stop-color="#F8C281"></stop><stop offset="0.937338" stop-color="#E99E6B"></stop></linearGradient><radialGradient id="paint2_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.9009 13.1847) rotate(-127.648) scale(14.3438 11.7966)"><stop stop-color="#FFBE66"></stop><stop offset="1" stop-color="#E2AE5B"></stop></radialGradient><radialGradient id="paint3_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(18 11.4375) rotate(53.9726) scale(11.9013 4.84018)"><stop stop-color="#D67C63"></stop><stop offset="1" stop-color="#D97D67" stop-opacity="0"></stop></radialGradient><radialGradient id="paint4_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(23 4.1875) rotate(45.7639) scale(3.31486 5.75622)"><stop stop-color="#FFE4A6"></stop><stop offset="0.711285" stop-color="#F8B76F"></stop><stop offset="1" stop-color="#F9B870" stop-opacity="0"></stop></radialGradient><radialGradient id="paint5_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.875 12.4375) rotate(88.9391) scale(3.37558 1.29066)"><stop stop-color="#FFBC67"></stop><stop offset="1" stop-color="#FFBC67" stop-opacity="0"></stop></radialGradient><linearGradient id="paint6_linear_18_31665" x1="20.375" y1="15.6875" x2="20.125" y2="12.7813" gradientUnits="userSpaceOnUse"><stop offset="0.461609" stop-color="#B45077"></stop><stop offset="0.855389" stop-color="#B75077" stop-opacity="0"></stop></linearGradient><linearGradient id="paint7_linear_18_31665" x1="12.9375" y1="2.57056" x2="18.5625" y2="14.3891" gradientUnits="userSpaceOnUse"><stop stop-color="#DDC173"></stop><stop offset="0.485173" stop-color="#D59F65"></stop><stop offset="1" stop-color="#E49966"></stop></linearGradient><radialGradient id="paint8_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(13.5625 23.5) rotate(109.113) scale(6.68078 10.2578)"><stop offset="0.165756" stop-color="#FFBF7E"></stop><stop offset="0.827674" stop-color="#DF8C6D"></stop><stop offset="1" stop-color="#B05A66"></stop></radialGradient><radialGradient id="paint9_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.1875 26) rotate(41.0652) scale(8.37243 2.03649)"><stop stop-color="#FFD483"></stop><stop offset="1" stop-color="#FFD688" stop-opacity="0"></stop></radialGradient><linearGradient id="paint10_linear_18_31665" x1="3.96063" y1="23.794" x2="13.3748" y2="23.5143" gradientUnits="userSpaceOnUse"><stop stop-color="#A8716F"></stop><stop offset="0.103615" stop-color="#B37173"></stop><stop offset="0.225484" stop-color="#DB9F84"></stop><stop offset="0.799889" stop-color="#F1BB8A"></stop><stop offset="1" stop-color="#FFD780"></stop></linearGradient><radialGradient id="paint11_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(11.4219 23.1719) rotate(-178.616) scale(3.23532 0.569081)"><stop offset="0.621498" stop-color="#AF5A3E"></stop><stop offset="1" stop-color="#B35445" stop-opacity="0"></stop></radialGradient><radialGradient id="paint12_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(13.625 19.125) rotate(-171.737) scale(15.2205 15.0767)"><stop offset="0.138435" stop-color="#FFB974"></stop><stop offset="0.403618" stop-color="#F2A56D"></stop><stop offset="0.925938" stop-color="#A16948"></stop></radialGradient><linearGradient id="paint13_linear_18_31665" x1="8.22184" y1="13.125" x2="6.81191" y2="15.4996" gradientUnits="userSpaceOnUse"><stop offset="0.610751" stop-color="#984847"></stop><stop offset="0.850075" stop-color="#9A4947" stop-opacity="0"></stop></linearGradient><radialGradient id="paint14_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(7.25 23.7461) scale(11.25 5.68361)"><stop stop-color="#C66364"></stop><stop offset="1" stop-color="#D4766B" stop-opacity="0"></stop></radialGradient><radialGradient id="paint15_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(7.875 23.5313) scale(10.0937 1.29657)"><stop stop-color="#B64B4B"></stop><stop offset="1" stop-color="#C56158" stop-opacity="0"></stop></radialGradient><radialGradient id="paint16_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(11.4375 19.875) rotate(-46.8882) scale(4.02385 7.51767)"><stop stop-color="#FFC083"></stop><stop offset="0.620218" stop-color="#FFBD7D" stop-opacity="0"></stop></radialGradient><linearGradient id="paint17_linear_18_31665" x1="2.8125" y1="13.0312" x2="14.5582" y2="18.9404" gradientUnits="userSpaceOnUse"><stop stop-color="#B89367"></stop><stop offset="1" stop-color="#C5835E"></stop></linearGradient><linearGradient id="paint18_linear_18_31665" x1="8.21875" y1="14.6406" x2="7.59349" y2="15.6717" gradientUnits="userSpaceOnUse"><stop offset="0.351552" stop-color="#A74746"></stop><stop offset="0.845198" stop-color="#A04346" stop-opacity="0"></stop></linearGradient><radialGradient id="paint19_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.5625 14.5625) rotate(140.244) scale(18.3733 13.7403)"><stop stop-color="#FDAE69"></stop><stop offset="0.729021" stop-color="#CE8C4F"></stop><stop offset="0.921546" stop-color="#AD7B45"></stop><stop offset="1" stop-color="#8B6B4A"></stop></radialGradient><radialGradient id="paint20_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.0625 7) rotate(65.3152) scale(11.0745 3.16547)"><stop offset="0.233237" stop-color="#FFD47C"></stop><stop offset="0.853648" stop-color="#FFD98B" stop-opacity="0"></stop></radialGradient><radialGradient id="paint21_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.3125 8.875) rotate(100.886) scale(6.6191 5.57808)"><stop offset="0.128419" stop-color="#FFD88C"></stop><stop offset="0.924134" stop-color="#FFBE7B" stop-opacity="0"></stop></radialGradient><linearGradient id="paint22_linear_18_31665" x1="7.25" y1="15.1875" x2="10.7588" y2="10.3142" gradientUnits="userSpaceOnUse"><stop offset="0.142353" stop-color="#C15F4D"></stop><stop offset="1" stop-color="#D58366" stop-opacity="0"></stop></linearGradient><radialGradient id="paint23_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(8.15625 15.7813) rotate(28.5422) scale(12.5574 1.96589)"><stop offset="0.149989" stop-color="#E4745D"></stop><stop offset="0.453292" stop-color="#C8604C"></stop><stop offset="0.632597" stop-color="#C0605F"></stop><stop offset="1" stop-color="#C0605F" stop-opacity="0"></stop></radialGradient><radialGradient id="paint24_radial_18_31665" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(1.40625 2.69067) rotate(46.0943) scale(22.3963)"><stop offset="0.935802" stop-color="#C17C61" stop-opacity="0"></stop><stop offset="0.982109" stop-color="#C17C61"></stop></radialGradient></defs></svg>

	

	<span>Croissant</span>
	

	<div class="border-br-gray-200 absolute bottom-0.5 right-0.5 h-1 w-1 border-[3px] border-l-transparent border-t-transparent border-b-gray-200 border-r-gray-200 dark:border-b-gray-700 dark:border-r-gray-700"></div></div>
		
		</button>
	
	
	</div>

	<button class="tag tag-ghost px-1! -ml-0.5 mb-1 md:mb-1.5" type="button">+ 1</button></div><div class="mr-1 flex flex-wrap items-center"><span class="mb-1 mr-1 p-1 text-sm leading-tight text-gray-400 md:mb-1.5">License:
	</span>
	<div class="relative inline-block ">
	<button class="group mr-1 mb-1 md:mr-1.5 md:mb-1.5  rounded-full rounded-br-none " type="button">
		<div class="tag tag-white rounded-full  relative rounded-br-none pr-2.5">
		<svg class="text-xs text-gray-900" width="1em" height="1em" viewBox="0 0 10 10" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1.46009 5.0945V6.88125C1.46009 7.25201 1.75937 7.55129 2.13012 7.55129C2.50087 7.55129 2.80016 7.25201 2.80016 6.88125V5.0945C2.80016 4.72375 2.50087 4.42446 2.13012 4.42446C1.75937 4.42446 1.46009 4.72375 1.46009 5.0945ZM4.14022 5.0945V6.88125C4.14022 7.25201 4.4395 7.55129 4.81026 7.55129C5.18101 7.55129 5.48029 7.25201 5.48029 6.88125V5.0945C5.48029 4.72375 5.18101 4.42446 4.81026 4.42446C4.4395 4.42446 4.14022 4.72375 4.14022 5.0945ZM1.23674 9.78473H8.38377C8.75452 9.78473 9.0538 9.48545 9.0538 9.1147C9.0538 8.74395 8.75452 8.44466 8.38377 8.44466H1.23674C0.865993 8.44466 0.566711 8.74395 0.566711 9.1147C0.566711 9.48545 0.865993 9.78473 1.23674 9.78473ZM6.82036 5.0945V6.88125C6.82036 7.25201 7.11964 7.55129 7.49039 7.55129C7.86114 7.55129 8.16042 7.25201 8.16042 6.88125V5.0945C8.16042 4.72375 7.86114 4.42446 7.49039 4.42446C7.11964 4.42446 6.82036 4.72375 6.82036 5.0945ZM4.39484 0.623142L0.865993 2.48137C0.682851 2.57517 0.566711 2.76725 0.566711 2.97273C0.566711 3.28094 0.816857 3.53109 1.12507 3.53109H8.49991C8.80365 3.53109 9.0538 3.28094 9.0538 2.97273C9.0538 2.76725 8.93766 2.57517 8.75452 2.48137L5.22568 0.623142C4.9666 0.484669 4.65391 0.484669 4.39484 0.623142V0.623142Z" fill="currentColor"></path></svg>

	

	<span>bsd-2-clause</span>
	

	<div class="border-br-gray-200 absolute bottom-0.5 right-0.5 h-1 w-1 border-[3px] border-l-transparent border-t-transparent border-b-gray-200 border-r-gray-200 dark:border-b-gray-700 dark:border-r-gray-700"></div></div>
		
		</button>
	
	
	</div>

	</div></div>

		<div class="flex flex-col-reverse lg:flex-row lg:items-center lg:justify-between"><div class="-mb-px flex h-12 items-center overflow-x-auto overflow-y-hidden ">
	<a class="tab-alternate active" href="/datasets/saifkhichi96/mpii-human-pose-captions"><svg class="mr-1.5 text-gray-400 flex-none" style="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
	Dataset card
	

	
		</a><a class="tab-alternate" href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
	Data Studio
	

	
		</a><a class="tab-alternate" href="/datasets/saifkhichi96/mpii-human-pose-captions/tree/main"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-tertiary" d="M21 19h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0-4h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0-8h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2zm0 4h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M9 19a1 1 0 0 1-1-1V6a1 1 0 0 1 2 0v12a1 1 0 0 1-1 1zm-6-4.333a1 1 0 0 1-.64-1.769L3.438 12l-1.078-.898a1 1 0 0 1 1.28-1.538l2 1.667a1 1 0 0 1 0 1.538l-2 1.667a.999.999 0 0 1-.64.231z" fill="currentColor"></path></svg>
	<span class="xl:hidden">Files</span>
		<span class="hidden xl:inline">Files and versions</span>
	

	
		</a><a class="tab-alternate" href="/datasets/saifkhichi96/mpii-human-pose-captions/discussions"><svg class="mr-1.5 text-gray-400 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M20.6081 3C21.7684 3 22.8053 3.49196 23.5284 4.38415C23.9756 4.93678 24.4428 5.82749 24.4808 7.16133C24.9674 7.01707 25.4353 6.93643 25.8725 6.93643C26.9833 6.93643 27.9865 7.37587 28.696 8.17411C29.6075 9.19872 30.0124 10.4579 29.8361 11.7177C29.7523 12.3177 29.5581 12.8555 29.2678 13.3534C29.8798 13.8646 30.3306 14.5763 30.5485 15.4322C30.719 16.1032 30.8939 17.5006 29.9808 18.9403C30.0389 19.0342 30.0934 19.1319 30.1442 19.2318C30.6932 20.3074 30.7283 21.5229 30.2439 22.6548C29.5093 24.3704 27.6841 25.7219 24.1397 27.1727C21.9347 28.0753 19.9174 28.6523 19.8994 28.6575C16.9842 29.4379 14.3477 29.8345 12.0653 29.8345C7.87017 29.8345 4.8668 28.508 3.13831 25.8921C0.356375 21.6797 0.754104 17.8269 4.35369 14.1131C6.34591 12.058 7.67023 9.02782 7.94613 8.36275C8.50224 6.39343 9.97271 4.20438 12.4172 4.20438H12.4179C12.6236 4.20438 12.8314 4.2214 13.0364 4.25468C14.107 4.42854 15.0428 5.06476 15.7115 6.02205C16.4331 5.09583 17.134 4.359 17.7682 3.94323C18.7242 3.31737 19.6794 3 20.6081 3ZM20.6081 5.95917C20.2427 5.95917 19.7963 6.1197 19.3039 6.44225C17.7754 7.44319 14.8258 12.6772 13.7458 14.7131C13.3839 15.3952 12.7655 15.6837 12.2086 15.6837C11.1036 15.6837 10.2408 14.5497 12.1076 13.1085C14.9146 10.9402 13.9299 7.39584 12.5898 7.1776C12.5311 7.16799 12.4731 7.16355 12.4172 7.16355C11.1989 7.16355 10.6615 9.33114 10.6615 9.33114C10.6615 9.33114 9.0863 13.4148 6.38031 16.206C3.67434 18.998 3.5346 21.2388 5.50675 24.2246C6.85185 26.2606 9.42666 26.8753 12.0653 26.8753C14.8021 26.8753 17.6077 26.2139 19.1799 25.793C19.2574 25.7723 28.8193 22.984 27.6081 20.6107C27.4046 20.212 27.0693 20.0522 26.6471 20.0522C24.9416 20.0522 21.8393 22.6726 20.5057 22.6726C20.2076 22.6726 19.9976 22.5416 19.9116 22.222C19.3433 20.1173 28.552 19.2325 27.7758 16.1839C27.639 15.6445 27.2677 15.4256 26.746 15.4263C24.4923 15.4263 19.4358 19.5181 18.3759 19.5181C18.2949 19.5181 18.2368 19.4937 18.2053 19.4419C17.6743 18.557 17.9653 17.9394 21.7082 15.6009C25.4511 13.2617 28.0783 11.8545 26.5841 10.1752C26.4121 9.98141 26.1684 9.8956 25.8725 9.8956C23.6001 9.89634 18.2311 14.9403 18.2311 14.9403C18.2311 14.9403 16.7821 16.496 15.9057 16.496C15.7043 16.496 15.533 16.4139 15.4169 16.2112C14.7956 15.1296 21.1879 10.1286 21.5484 8.06535C21.7928 6.66715 21.3771 5.95917 20.6081 5.95917Z" fill="#FF9D00"></path><path d="M5.50686 24.2246C3.53472 21.2387 3.67446 18.9979 6.38043 16.206C9.08641 13.4147 10.6615 9.33111 10.6615 9.33111C10.6615 9.33111 11.2499 6.95933 12.59 7.17757C13.93 7.39581 14.9139 10.9401 12.1069 13.1084C9.29997 15.276 12.6659 16.7489 13.7459 14.713C14.8258 12.6772 17.7747 7.44316 19.304 6.44221C20.8326 5.44128 21.9089 6.00204 21.5484 8.06532C21.188 10.1286 14.795 15.1295 15.4171 16.2118C16.0391 17.2934 18.2312 14.9402 18.2312 14.9402C18.2312 14.9402 25.0907 8.49588 26.5842 10.1752C28.0776 11.8545 25.4512 13.2616 21.7082 15.6008C17.9646 17.9393 17.6744 18.557 18.2054 19.4418C18.7372 20.3266 26.9998 13.1351 27.7759 16.1838C28.5513 19.2324 19.3434 20.1173 19.9117 22.2219C20.48 24.3274 26.3979 18.2382 27.6082 20.6107C28.8193 22.9839 19.2574 25.7722 19.18 25.7929C16.0914 26.62 8.24723 28.3726 5.50686 24.2246Z" fill="#FFD21E"></path></svg>
	Community
	<div class="ml-1.5 flex h-4 min-w-[1rem] items-center justify-center rounded px-1 text-xs leading-none shadow-sm bg-black text-white dark:bg-gray-800 dark:text-gray-200">1</div>

	
		</a></div>
	
			</div></div></header>
</div>
	
<div class="container relative flex flex-col md:grid md:space-y-0 w-full md:grid-cols-12 md:flex-1 md:grid-rows-full space-y-4 md:gap-6 ">
		<section class="pt-6 border-gray-100 md:col-span-8 pb-24 relative break-words copiable-code-container">
				<div class="SVELTE_HYDRATER contents" data-target="UnsafeBanner" data-props="{&quot;classNames&quot;:&quot;mb-4&quot;,&quot;repoId&quot;:&quot;saifkhichi96/mpii-human-pose-captions&quot;,&quot;repoType&quot;:&quot;dataset&quot;,&quot;minLevel&quot;:&quot;unsafe&quot;}"></div>
					<div class="SVELTE_HYDRATER contents" data-target="DatasetViewer" data-props="{&quot;data&quot;:{&quot;kind&quot;:&quot;DatasetAndSampleData&quot;,&quot;datasetInfo&quot;:[{&quot;isValid&quot;:true,&quot;href&quot;:&quot;&quot;,&quot;label&quot;:&quot;Size of downloaded dataset files:&quot;,&quot;value&quot;:&quot;136 MB&quot;},{&quot;isValid&quot;:true,&quot;href&quot;:&quot;/datasets/saifkhichi96/mpii-human-pose-captions/tree/refs%2Fconvert%2Fparquet/&quot;,&quot;label&quot;:&quot;Size of the auto-converted Parquet files:&quot;,&quot;value&quot;:&quot;38.3 MB&quot;},{&quot;isValid&quot;:true,&quot;href&quot;:&quot;&quot;,&quot;label&quot;:&quot;Number of rows:&quot;,&quot;value&quot;:&quot;69,468&quot;}],&quot;partial&quot;:false,&quot;configsData&quot;:{&quot;configInfos&quot;:[{&quot;name&quot;:&quot;gpt-4&quot;,&quot;status&quot;:&quot;ok&quot;,&quot;numRows&quot;:17367},{&quot;name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;status&quot;:&quot;ok&quot;,&quot;numRows&quot;:17367},{&quot;name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;status&quot;:&quot;ok&quot;,&quot;numRows&quot;:17367},{&quot;name&quot;:&quot;llama-2&quot;,&quot;status&quot;:&quot;ok&quot;,&quot;numRows&quot;:17367}],&quot;selectedConfig&quot;:&quot;gpt-4&quot;,&quot;hasSelectedConfigParquet&quot;:true},&quot;splitsData&quot;:{&quot;splitInfos&quot;:[{&quot;name&quot;:&quot;train&quot;,&quot;numRows&quot;:14644},{&quot;name&quot;:&quot;validation&quot;,&quot;numRows&quot;:2723}],&quot;selectedSplit&quot;:&quot;train&quot;},&quot;sampleData&quot;:{&quot;dataset&quot;:&quot;saifkhichi96/mpii-human-pose-captions&quot;,&quot;config&quot;:&quot;gpt-4&quot;,&quot;split&quot;:&quot;train&quot;,&quot;capabilities&quot;:{&quot;rows&quot;:true,&quot;search&quot;:true,&quot;filter&quot;:true,&quot;statistics&quot;:true},&quot;navigation&quot;:{&quot;p&quot;:0},&quot;jwt&quot;:&quot;eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc0MjkyMzE1MCwic3ViIjoiL2RhdGFzZXRzL3NhaWZraGljaGk5Ni9tcGlpLWh1bWFuLXBvc2UtY2FwdGlvbnMiLCJleHAiOjE3NDI5MjY3NTAsImlzcyI6Imh0dHBzOi8vaHVnZ2luZ2ZhY2UuY28ifQ.99NiAGT2ftyNCkGsVWATh9H0UCZoPblTssPvxsLy4jIT1C7pUInl6ymw1mFNtp_2Hb6qAruuptv6xHAREn0WCQ&quot;,&quot;sampleData&quot;:{&quot;columns&quot;:[{&quot;name&quot;:&quot;description&quot;,&quot;align&quot;:&quot;depends on text direction&quot;,&quot;type&quot;:&quot;string&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;description&quot;,&quot;column_type&quot;:&quot;string_text&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:697,&quot;max&quot;:3443,&quot;mean&quot;:1365.02834,&quot;median&quot;:1318,&quot;std&quot;:282.07019,&quot;histogram&quot;:{&quot;hist&quot;:[381,5027,6076,2191,653,181,47,37,34,17],&quot;bin_edges&quot;:[697,972,1247,1522,1797,2072,2347,2622,2897,3172,3443]}}}},{&quot;name&quot;:&quot;people&quot;,&quot;align&quot;:&quot;left&quot;,&quot;type&quot;:&quot;list&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;people&quot;,&quot;column_type&quot;:&quot;list&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:1,&quot;max&quot;:13,&quot;mean&quot;:1.52281,&quot;median&quot;:1,&quot;std&quot;:1.06034,&quot;histogram&quot;:{&quot;hist&quot;:[13038,1207,297,81,15,3,3],&quot;bin_edges&quot;:[1,3,5,7,9,11,13,13]}}}},{&quot;name&quot;:&quot;activity_id&quot;,&quot;align&quot;:&quot;right&quot;,&quot;type&quot;:&quot;int64&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;activity_id&quot;,&quot;column_type&quot;:&quot;int&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:1,&quot;max&quot;:983,&quot;mean&quot;:461.04152,&quot;median&quot;:420,&quot;std&quot;:268.7672,&quot;histogram&quot;:{&quot;hist&quot;:[1303,1555,1916,2131,1735,1093,1223,1757,1019,912],&quot;bin_edges&quot;:[1,100,199,298,397,496,595,694,793,892,983]}}}},{&quot;name&quot;:&quot;video_id&quot;,&quot;align&quot;:&quot;right&quot;,&quot;type&quot;:&quot;int64&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;video_id&quot;,&quot;column_type&quot;:&quot;int&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:1,&quot;max&quot;:2821,&quot;mean&quot;:1402.688,&quot;median&quot;:1384,&quot;std&quot;:809.29627,&quot;histogram&quot;:{&quot;hist&quot;:[1453,1461,1550,1468,1535,1444,1537,1342,1462,1392],&quot;bin_edges&quot;:[1,284,567,850,1133,1416,1699,1982,2265,2548,2821]}}}},{&quot;name&quot;:&quot;video_frame&quot;,&quot;align&quot;:&quot;right&quot;,&quot;type&quot;:&quot;int64&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;video_frame&quot;,&quot;column_type&quot;:&quot;int&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:0,&quot;max&quot;:2424,&quot;mean&quot;:138.63876,&quot;median&quot;:90,&quot;std&quot;:160.90467,&quot;histogram&quot;:{&quot;hist&quot;:[12333,1763,382,100,36,11,10,4,3,2],&quot;bin_edges&quot;:[0,243,486,729,972,1215,1458,1701,1944,2187,2424]}}}},{&quot;name&quot;:&quot;activity&quot;,&quot;align&quot;:&quot;depends on text direction&quot;,&quot;type&quot;:&quot;string&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;activity&quot;,&quot;column_type&quot;:&quot;string_label&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;no_label_count&quot;:0,&quot;no_label_proportion&quot;:0,&quot;n_unique&quot;:396,&quot;frequencies&quot;:{&quot;winter activities, dog sledding&quot;:42,&quot;occupation, orange grove work, picking fruit&quot;:20,&quot;conditioning exercise, slide board exercise, general&quot;:35,&quot;home activities, cooking or food preparation&quot;:175,&quot;sports, trampoline, competitive&quot;:11,&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;:107,&quot;sports, soccer&quot;:109,&quot;music playing, guitar, rock and roll band, standing&quot;:32,&quot;sports, racquetball&quot;:48,&quot;occupation, moving, carrying or pushing heavy objects, 75 lbs or more, only active time (e.g., desks, moving van&quot;:9,&quot;conditioning exercise, home exercise, general&quot;:48,&quot;home activities, mopping, standing, light effort&quot;:44,&quot;home activities, polishing floors, standing, walking slowly, using electric polishing machine&quot;:34,&quot;dancing, general dancing (e.g., disco, folk, Irish step dancing, line dancing, polka, contra, country)&quot;:13,&quot;sports, juggling&quot;:29,&quot;water activities, swimming, synchronized&quot;:11,&quot;sports, Alaska Native Games, Eskimo Olympics, general&quot;:12,&quot;home activities, elder care&quot;:24,&quot;water activities, swimming, butterfly, general&quot;:19,&quot;sports, orienteering&quot;:11,&quot;music playing, piano, sitting&quot;:18,&quot;inactivity quiet/light, reclining&quot;:49,&quot;sports, tai chi, qi gong, general&quot;:39,&quot;winter activities, skiing, cross-country&quot;:11,&quot;music playing, trombone, standing&quot;:30,&quot;running, running, cross country&quot;:17,&quot;occupation, serving food and drinks&quot;:47,&quot;transportation, pulling rickshaw&quot;:12,&quot;running, jogging, on a mini-tramp&quot;:11,&quot;lawn and garden, wheelbarrow, pushing garden cart or wheelbarrow&quot;:24,&quot;home activities, dusting or polishing furniture, general&quot;:15,&quot;walking, walking, for exerceise, with ski poles&quot;:67,&quot;occupation, using heavy tools&quot;:16,&quot;occupation, machine tooling&quot;:34,&quot;home repair, painting, outside home (Taylor Code 650)&quot;:57,&quot;walking, pushing a wheelchair, non-occupational&quot;:16,&quot;religious activities, standing, talking in church&quot;:47,&quot;home repair, scraping and painting sailboat or powerboat&quot;:27,&quot;sports, track and field&quot;:35,&quot;music playing, guitar, classical, folk, sitting&quot;:44,&quot;sports, boxing, in ring, general&quot;:23,&quot;lawn and garden, riding snow blower&quot;:16,&quot;sports, darts, wall or lawn&quot;:17,&quot;religious activities, serving food in church&quot;:10,&quot;home activities, tanning hides, general&quot;:24,&quot;home activities, putting away groceries (e.g. carrying groceries, shopping without a grocery cart), carrying packages&quot;:13,&quot;dancing, Anishinaabe Jingle Dancing&quot;:23,&quot;home repair, cleaning gutters&quot;:27,&quot;water activities, canoeing, on camping trip (Taylor Code 270)&quot;:52,&quot;home activities, wash dishes&quot;:43,&quot;home activities, sweeping garage, sidewalk or outside of house&quot;:23,&quot;miscellaneous, sitting, writing, desk work, typing&quot;:5,&quot;sports, rock climbing&quot;:125,&quot;music playing, woodwind, sitting&quot;:15,&quot;water activities, canoeing, harvesting wild rice, knocking rice off the stalks&quot;:12,&quot;self care, eating, sitting&quot;:58,&quot;home repair, hammering nails&quot;:11,&quot;occupation, police, directing traffic, standing&quot;:6,&quot;fishing and hunting, fishing in stream, in waders (Taylor Code 670)&quot;:75,&quot;fishing and hunting, hunting, birds&quot;:36,&quot;sports, hockey, field&quot;:17,&quot;occupation, farming, rice, planting, grain milling activities&quot;:51,&quot;sports, volleyball, beach, in sand&quot;:23,&quot;sports, wallyball, general&quot;:18,&quot;fishing and hunting, pistol shooting or trap shooting, standing&quot;:21,&quot;lawn and garden, irrigation channels, opening and closing ports&quot;:8,&quot;home repair, carpentry, outside house, building a fence&quot;:23,&quot;sports, horseback riding&quot;:120,&quot;home activities, playing with children&quot;:62,&quot;walking, marching, military, no pack&quot;:1,&quot;home repair, caulking, except log cabin&quot;:6,&quot;sports, rugby, touch, non-competitive&quot;:23,&quot;water activities, diving, springboard or platform&quot;:19,&quot;occupation, fire fighter, hauling hoses on ground, carryinghoisting equipment, breaking down walls etc., wearin&quot;:19,&quot;home repair, roofing&quot;:48,&quot;occupation, police, general&quot;:15,&quot;walking, bird watching, slow walk&quot;:29,&quot;music playing, trumpet, standing&quot;:9,&quot;sports, lacrosse&quot;:25,&quot;occupation, garbage collector, walking, dumping bins into truck&quot;:56,&quot;running, running, marathon&quot;:24,&quot;sports, frisbee&quot;:64,&quot;occupation, hairstylist (e.g., plaiting hair, manicure, make-up artist)&quot;:65,&quot;water activities, water walking&quot;:52,&quot;water activities, water jogging&quot;:1,&quot;occupation, engineer (e.g., mechanical or electrical)&quot;:19,&quot;water activities, paddle boarding, standing&quot;:40,&quot;home repair, home repair, general&quot;:61,&quot;music playing, drumming (e.g., bongo, conga, benbe), moderate, sitting&quot;:12,&quot;home repair, washing fence, painting fence, moderate effort&quot;:29,&quot;winter activities, windsurfing or kitesurfing, winter&quot;:12,&quot;water activities, surfing&quot;:36,&quot;walking, carrying load, upstairs&quot;:3,&quot;sports, archery, non-hunting&quot;:48,&quot;occupation, printing, paper industry worker, standing&quot;:18,&quot;miscellaneous, sitting at a sporting event, spectator&quot;:2,&quot;sports, trampoline, recreational&quot;:20,&quot;lawn and garden, walking, applying fertilizer or seeding a lawn, push applicator&quot;:15,&quot;home activities, maple syrupingsugar bushing (including carrying buckets, carrying wood)&quot;:10,&quot;religious activities, kneeling in church or at home, praying&quot;:2,&quot;sports, volleyball, indoor&quot;:44,&quot;sports, fencing&quot;:46,&quot;volunteer activities, standing, child care, only active periods&quot;:3,&quot;sports, tennis&quot;:44,&quot;winter activities, sledding, tobogganing, bobsledding, luge (Taylor Code 370)&quot;:22,&quot;winter activities, skating, ice dancing&quot;:54,&quot;conditioning exercise, ski machine, general&quot;:25,&quot;occupation, skindiving or SCUBA diving as a frogman, Navy Seal&quot;:10,&quot;sports, softball, general&quot;:142,&quot;sports, skating, roller (Taylor Code 360)&quot;:3,&quot;winter activities, ski jumping&quot;:17,&quot;dancing, Caribbean dance (Abakua, Beguine, Bellair, Bongo, Brukin's, Caribbean Quadrills, Dinki Mini, Gere, G&quot;:9,&quot;miscellaneous, standing, arts and crafts, sand painting, carving, weaving&quot;:108,&quot;lawn and garden, digging, spading, filling garden, composting&quot;:55,&quot;music playing, horn, standing&quot;:30,&quot;home repair, carpentry, finishing or refinishing cabinets or furniture&quot;:97,&quot;sports, squash&quot;:51,&quot;bicycling, bicycling, mountain&quot;:190,&quot;music playing, organ, sitting&quot;:3,&quot;occupation, plumbing activities&quot;:11,&quot;sports, handball&quot;:10,&quot;occupation, farming, feeding cattle, horses&quot;:30,&quot;home activities, feeding household animals&quot;:9,&quot;bicycling, bicycling, racing and road&quot;:119,&quot;occupation, shoe repair, general&quot;:35,&quot;home activities, non-food shopping, with or without a cart, standing or walking&quot;:20,&quot;sports, skateboarding&quot;:163,&quot;home activities, breastfeeding, sitting or reclining&quot;:15,&quot;sports, horseshoe pitching, quoits&quot;:19,&quot;sports, street skiing&quot;:12,&quot;sports, high ropes course, multiple elements&quot;:23,&quot;miscellaneous, touringtravelingvacation involving riding in a vehicle&quot;:46,&quot;sports, hang gliding&quot;:19,&quot;music playing, conducting orchestra, standing&quot;:12,&quot;miscellaneous, sitting, playing traditional video game, computer game&quot;:3,&quot;occupation, manager, property&quot;:9,&quot;miscellaneous, laughing, sitting&quot;:16,&quot;music playing, accordion, sitting&quot;:30,&quot;fishing and hunting, fishing with a spear, standing&quot;:5,&quot;running, running&quot;:91,&quot;home activities, child care&quot;:64,&quot;dancing, aerobic, general&quot;:51,&quot;conditioning exercise, rowing, stationary&quot;:126,&quot;religious activities, sitting, playing an instrument at church&quot;:30,&quot;occupation, standing, doing work&quot;:55,&quot;occupation, farming, driving tasks (e.g., driving tractor or harvester)&quot;:8,&quot;water activities, snorkeling (Taylor Code 310)&quot;:39,&quot;home repair, automobile repair&quot;:38,&quot;fishing and hunting, trapping game, general&quot;:24,&quot;self care, grooming, washing hands, shaving,brushing teeth, putting on make-up, sitting or standing&quot;:3,&quot;walking, stair climbing, fast pace&quot;:6,&quot;self care, hairstyling&quot;:14,&quot;home activities, cleaning windows, washing windows, general&quot;:36,&quot;sports, volleyball, non-competitive&quot;:1,&quot;water activities, swimming, breaststroke, recreational&quot;:8,&quot;lawn and garden, clearing brush&quot;:49,&quot;sports, kickball&quot;:19,&quot;water activities, swimming, general&quot;:57,&quot;home activities, ironing&quot;:47,&quot;sports, wrestling (one match = 5 minutes)&quot;:20,&quot;occupation, typing, electric, manual or computer&quot;:12,&quot;fishing and hunting, fishing, catching fish with hands&quot;:15,&quot;walking, loading unloading a car, implied walking&quot;:33,&quot;music playing, marching band&quot;:29,&quot;inactivity quiet/light, lying quietly, sleeping&quot;:11,&quot;fishing and hunting, hunting, general&quot;:28,&quot;water activities, swimming, lake, ocean, river (Taylor Codes 280, 295)&quot;:58,&quot;volunteer activities, walkrun play with children, moderate, only active periods&quot;:29,&quot;water activities, sailing&quot;:24,&quot;occupation, sitting tasks, light effort (e.g., office work, chemistry lab work, computer work, light assembly re&quot;:2,&quot;walking, backpacking&quot;:86,&quot;sports, football, touch, flag&quot;:29,&quot;occupation, tailoring&quot;:97,&quot;home repair, laying tile or linoleum,repairing appliances&quot;:29,&quot;sports, boxing, sparring&quot;:25,&quot;sports, football, competitive&quot;:5,&quot;lawn and garden, mowing lawn, power mower&quot;:6,&quot;sports, table tennis, ping pong (Taylor Code 410)&quot;:24,&quot;water activities, jet skiing, driving, in water&quot;:1,&quot;miscellaneous, chess game, sitting&quot;:26,&quot;winter activities, snowmobiling&quot;:35,&quot;water activities, tubing, floating on a river, general&quot;:9,&quot;water activities, swimming, sidestroke, general&quot;:22,&quot;sports, hockey, ice, general&quot;:4,&quot;lawn and garden, shoveling snow, by hand&quot;:44,&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;:48,&quot;conditioning exercise, upper body exercise, stationary bicycle - Airdyne (arms only) 40 rpm, moderate&quot;:30,&quot;transportation, pushing plane in and out of hangar&quot;:14,&quot;occupation, farming, milking by hand, cleaning pails, moderate effort&quot;:17,&quot;lawn and garden, picking fruits/vegetables&quot;:35,&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;:10,&quot;water activities, windsurfing&quot;:57,&quot;sports, bowling&quot;:44,&quot;home activities, moving furniture, household items, carrying boxes&quot;:52,&quot;conditioning exercise, circuit training&quot;:124,&quot;lawn and garden, felling trees&quot;:20,&quot;water activities, skindiving, scuba diving, snorkeling&quot;:41,&quot;lawn and garden, yard work, general&quot;:25,&quot;sports, skydiving, base jumping, bungee jumping&quot;:39,&quot;sports, jai alai&quot;:45,&quot;lawn and garden, gardening, general, moderate effort&quot;:44,&quot;inactivity quiet/light, standing quietly, standing in a line&quot;:53,&quot;sports, paddleball&quot;:91,&quot;home repair, wiring, tapping-splicing&quot;:29,&quot;sports, coaching&quot;:40,&quot;home activities, cutting and smoking fish, drying fish or meat&quot;:23,&quot;miscellaneous, standing, miscellaneous&quot;:111,&quot;sports, hacky sack&quot;:40,&quot;walking, hiking&quot;:22,&quot;home repair, washing and waxing car&quot;:75,&quot;conditioning exercise, resistance training&quot;:118,&quot;walking, race walking&quot;:24,&quot;lawn and garden, gardening, using containers, older adults > 60 years&quot;:4,&quot;sports, tennis, doubles&quot;:59,&quot;sports, moto-cross, off-road motor sports, all-terrain vehicle, general&quot;:29,&quot;fishing and hunting, fishing, ice, sitting&quot;:56,&quot;sports, boxing, punching bag&quot;:30,&quot;occupation, cook, chef&quot;:57,&quot;dancing, ballet, modern, or jazz&quot;:108,&quot;occupation, construction, outside, remodeling, new structures (e.g., roof repair, miscellaneous)&quot;:7,&quot;lawn and garden, trimming shrubs or trees&quot;:101,&quot;fishing and hunting, fishing, dip net, setting net and retrieving fish, general&quot;:22,&quot;lawn and garden, mowing lawn, walk, hand mower (Taylor Code 570)&quot;:82,&quot;lawn and garden, planting seedlings, shrub, stooping, moderate effort&quot;:51,&quot;home repair, laying or removing carpet&quot;:38,&quot;water activities, water volleyball&quot;:11,&quot;water activities, whitewater rafting, kayaking, or canoeing&quot;:4,&quot;lawn and garden, shoveling dirt or mud&quot;:24,&quot;walking, using crutches&quot;:30,&quot;sports, rollerblading&quot;:78,&quot;occupation, fishing, commercial&quot;:54,&quot;music playing, playing musical instruments, general&quot;:9,&quot;occupation, manual or unskilled labor&quot;:50,&quot;sports, martial arts, different types&quot;:110,&quot;sports, shuffleboard&quot;:12,&quot;running, running, stairs, up&quot;:21,&quot;lawn and garden, digging sandbox, shoveling sand&quot;:12,&quot;conditioning exercise, yoga, Nadisodhana&quot;:51,&quot;home repair, washing and waxing hull of sailboat or airplane&quot;:18,&quot;water activities, canoeing, kayaking, rowing, competitive&quot;:107,&quot;sports, curling&quot;:13,&quot;dancing, ethnic or cultural dancing (e.g., Greek, Middle Eastern, hula, salsa, merengue, bamba y plena, flame&quot;:55,&quot;home repair, sharpening tools&quot;:51,&quot;home activities, moving household items upstairs, carrying boxes or furniture&quot;:9,&quot;home activities, cleaning, general&quot;:75,&quot;sports, rope skipping, general&quot;:135,&quot;occupation, coal mining&quot;:26,&quot;home activities, vacuuming, general, moderate effort&quot;:43,&quot;religious activities, sitting in church&quot;:1,&quot;sports, rodeo sports&quot;:12,&quot;occupation, steel mill, moderate effort (e.g., fettling, forging, tipping molds)&quot;:16,&quot;home repair, put on and removal of tarp - sailboat&quot;:22,&quot;lawn and garden, planting trees&quot;:19,&quot;home repair, carpentry, home remodeling tasks&quot;:14,&quot;transportation, driving automobile or light truck&quot;:8,&quot;occupation, horse racing&quot;:61,&quot;running, running, on a track, team practice&quot;:14,&quot;music playing, drums, sitting&quot;:52,&quot;lawn and garden, watering lawn or garden, standing or walking&quot;:25,&quot;sports, tennis, hitting balls, non-game play, moderate effort&quot;:29,&quot;music playing, double bass, standing&quot;:37,&quot;occupation, painting,house, furniture, moderate effort&quot;:20,&quot;lawn and garden, planting, potting, transplanting seedlings or plants, light effort&quot;:71,&quot;music playing, cello, sitting&quot;:36,&quot;conditioning exercise, teaching exercise class&quot;:1,&quot;winter activities, skiing, cross-country, biathlon, skating technique&quot;:52,&quot;music playing, violin, sitting&quot;:36,&quot;walking, walking the dog&quot;:28,&quot;lawn and garden, carrying, loading or stacking wood&quot;:24,&quot;home repair, sanding floors with a power sander&quot;:15,&quot;home repair, hanging sheet rock inside house&quot;:7,&quot;miscellaneous, sitting, studying, general, including reading andor writing, light effort&quot;:1,&quot;sports, children_s games, adults playing (e.g., hopscotch, 4-square, dodgeball, playground apparatus, t-ball&quot;:43,&quot;occupation, police, making an arrest, standing&quot;:15,&quot;sports, gymnastics, general&quot;:41,&quot;conditioning exercise, Elliptical trainer, moderate effort&quot;:12,&quot;inactivity quiet/light, sitting quietly&quot;:42,&quot;water activities, boating, power&quot;:12,&quot;occupation, chambermaid, hotel housekeeper, making bed, cleaning bathroom, pushing cart&quot;:48,&quot;winter activities, skating, speed, competitive&quot;:33,&quot;home activities, organizing room&quot;:14,&quot;home repair, repairing appliances&quot;:30,&quot;lawn and garden, weeding, cultivating garden&quot;:37,&quot;conditioning exercise, bicycling, stationary&quot;:86,&quot;occupation, sitting meetings, light effort, general, andor with talking involved (e.g., eating at a business me&quot;:10,&quot;dancing, Irish step dancing&quot;:23,&quot;occupation, airline flight attendant&quot;:21,&quot;sports, cricket, batting, bowling, fielding&quot;:31,&quot;home activities, knitting, sewing&quot;:15,&quot;occupation, fire fighter&quot;:45,&quot;running, jogging&quot;:48,&quot;conditioning exercise, calisthenics&quot;:101,&quot;fishing and hunting, hunting, bow and arrow, or crossbow&quot;:16,&quot;winter activities, snowboarding&quot;:14,&quot;miscellaneous, standing, talking in person&quot;:70,&quot;sports, basketball&quot;:101,&quot;home activities, scrubbing floors&quot;:25,&quot;home activities, making bed, changing linens&quot;:50,&quot;occupation, laundry worker&quot;:44,&quot;occupation, massage therapist, standing&quot;:52,&quot;home activities, landry&quot;:52,&quot;water activities, swimming, backstroke&quot;:27,&quot;occupation, custodial work&quot;:48,&quot;home repair, carpentry, general, workshop (Taylor Code 620)&quot;:23,&quot;lawn and garden, gardening with heavy power tools, tilling a garden, chain saw&quot;:3,&quot;conditioning exercise, slimnastics, jazzercise&quot;:27,&quot;sports, hockey, ice, competitive&quot;:9,&quot;occupation, active workstation, treadmill desk, walking&quot;:34,&quot;water activities, skiing, water or wakeboarding (Taylor Code 220)&quot;:29,&quot;conditioning exercise, stretching, mild&quot;:52,&quot;bicycling, unicycling&quot;:18,&quot;miscellaneous, sitting, arts and crafts,  carving wood, weaving, spinning wool&quot;:46,&quot;occupation, farming, milking by machine, light effort&quot;:8,&quot;water activities, water aerobics, water calisthenics&quot;:42,&quot;home activities, cleaning, sweeping floor or carpet&quot;:24,&quot;walking, pushing or pulling stroller with child or walking with children, 2.5 to 3.1 mph&quot;:14,&quot;winter activities, skiing, climbing up&quot;:30,&quot;winter activities, operating snow blower, walking&quot;:27,&quot;fishing and hunting, fishing from boat or canoe, sitting&quot;:70,&quot;lawn and garden, racking lawn&quot;:2,&quot;water activities, sailing, in competition&quot;:18,&quot;occupation, carpentry, general&quot;:134,&quot;sports, lawn bowling, bocce ball, outdoor&quot;:3,&quot;lawn and garden, laying crushed rock&quot;:8,&quot;lawn and garden, chopping wood&quot;:77,&quot;conditioning exercise, weight lifting, power lifting&quot;:28,&quot;lawn and garden, driving tractor&quot;:50,&quot;music playing, flute, sitting&quot;:14,&quot;transportation, riding in a bus or train&quot;:18,&quot;sports, horse cart, driving, standing or sitting&quot;:15,&quot;sports, badminton, competitive (Taylor Code 450)&quot;:24,&quot;miscellaneous, sitting, in class, general, including note-taking or class discussion&quot;:23,&quot;dancing, aerobic, step&quot;:101,&quot;occupation, masonry, concrete&quot;:43,&quot;home activities, kitchen activity, general, (e.g., cooking, washing dishes, cleaning up), moderate effort&quot;:46,&quot;sports, polo, on horseback&quot;:15,&quot;transportation, motor scooter, motorcycle&quot;:13,&quot;walking, stair climbing, using or climbing up ladder (Taylor Code 030)&quot;:20,&quot;home repair, hanging storm windows&quot;:23,&quot;winter activities, skiing, general&quot;:31,&quot;fishing and hunting, hunting, rabbit, squirrel, prairie chick, raccoon, small game (Taylor Code 690)&quot;:26,&quot;sports, broomball&quot;:29,&quot;volunteer activities, sitting, doing work&quot;:3,&quot;transportation, riding in a car or truck&quot;:2,&quot;occupation, driving delivery truck, taxi, shuttle bus, school bus&quot;:4,&quot;conditioning exercise, yoga, Power&quot;:247,&quot;self care, taking medication, sitting or standing&quot;:1,&quot;occupation, forestry&quot;:134,&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;:41,&quot;conditioning exercise, health club exerceise classes&quot;:36,&quot;occupation, farming, taking care of animals (e.g., grooming, brushing, shearing sheep, assisting with birthing,&quot;:23,&quot;walking, climbing hills&quot;:25,&quot;water activities, paddle boat&quot;:7,&quot;sports, billiards&quot;:25,&quot;occupation, postal carrier, walking to deliver mail&quot;:8,&quot;occupation, sitting, teaching stretching or yoga, or light effort exercise class&quot;:71,&quot;sports, croquet&quot;:3,&quot;occupation, farming, feeding small animals&quot;:19,&quot;walking, descending stairs&quot;:8,&quot;sports, badminton, social singles and doubles, general&quot;:39,&quot;occupation, bakery, general&quot;:62,&quot;miscellaneous, drawing, writing, painting, standing&quot;:48,&quot;fishing and hunting, fishing from river bank&quot;:108,&quot;walking, walking, general&quot;:54,&quot;lawn and garden, raking roof with snow rake&quot;:23,&quot;occupation, working in scene shop, theater actor, backstage employee&quot;:9,&quot;sports, basketball, game (Taylor Code 490)&quot;:25,&quot;home activities, food shopping with or without a grocery cart, standing or walking&quot;:23,&quot;occupation, locksmith&quot;:4,&quot;winter activities, skating, ice&quot;:45,&quot;miscellaneous, touringtravelingvacation involving walking&quot;:5,&quot;winter activities, skiing, downhill&quot;:175,&quot;miscellaneous, card playing,sitting&quot;:13,&quot;occupation, farming, cultivating field&quot;:25,&quot;sports, golf&quot;:119,&quot;bicycling, bicycling, BMX&quot;:75,&quot;fishing and hunting, fishing, general&quot;:110,&quot;home activities, playing with animals&quot;:76,&quot;conditioning exercise, native New Zealander physical activities&quot;:18,&quot;occupation, bookbinding&quot;:13,&quot;occupation, farming&quot;:19,&quot;fishing and hunting, fishing, set net, setting net and retrieving fish, general&quot;:28,&quot;home repair, carpentry, sawing hardwood&quot;:52,&quot;dancing, ballroom&quot;:115,&quot;water activities, kayaking, moderate effort&quot;:43,&quot;miscellaneous, reading&quot;:18,&quot;conditioning exercise, pilates, general&quot;:78,&quot;transportation, pushing car&quot;:11,&quot;home repair, caulking, chinking log cabin&quot;:12,&quot;conditioning exercise, therapeutic exercise ball, Fitball exercise&quot;:79,&quot;home repair, painting inside house,wallpapering, scraping paint&quot;:75,&quot;miscellaneous, copying documents, standing&quot;:21,&quot;bicycling, bicycling, general&quot;:41,&quot;conditioning exercise, video exercise workouts, TV conditioning programs&quot;:130,&quot;water activities, canoeing, portaging&quot;:8,&quot;winter activities, snow shoeing&quot;:34}}}},{&quot;name&quot;:&quot;image&quot;,&quot;align&quot;:&quot;depends on text direction&quot;,&quot;type&quot;:&quot;string&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;image&quot;,&quot;column_type&quot;:&quot;string_text&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:13,&quot;max&quot;:13,&quot;mean&quot;:13,&quot;median&quot;:13,&quot;std&quot;:0,&quot;histogram&quot;:{&quot;hist&quot;:[14644],&quot;bin_edges&quot;:[13,13]}}}},{&quot;name&quot;:&quot;count&quot;,&quot;align&quot;:&quot;right&quot;,&quot;type&quot;:&quot;int64&quot;,&quot;statistics&quot;:{&quot;column_name&quot;:&quot;count&quot;,&quot;column_type&quot;:&quot;int&quot;,&quot;column_statistics&quot;:{&quot;nan_count&quot;:0,&quot;nan_proportion&quot;:0,&quot;min&quot;:1,&quot;max&quot;:13,&quot;mean&quot;:1.52281,&quot;median&quot;:1,&quot;std&quot;:1.06034,&quot;histogram&quot;:{&quot;hist&quot;:[13038,1207,297,81,15,3,3],&quot;bin_edges&quot;:[1,3,5,7,9,11,13,13]}}}}],&quot;rows&quot;:[{&quot;rowIdx&quot;:0,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are playing sports, specifically curling. Curling is a sport where players slide stones on a sheet of ice towards a target area which is segmented into four concentric circles. It requires precise movements and often involves squatting or kneeling poses.\n\nThe leftmost person is in the center of the image with their body scaled up to 3 times its original size. They appear to be in an active state, possibly in the middle of delivering a stone or sweeping. Their right leg is slightly bent at the knee and ankle, suggesting that they may be moving or about to move. The right leg appears straighter but still maintaining some bend at the knee and ankle joints as well. Both legs are angled towards each other with their hips relatively close together indicating that they might be maintaining balance during movement.\n\nTheir arms seem to be held out from their body, potentially for balance or action related to game play - right arm bent upwards at elbow while left arm seems extended downwards. The torso leans forward slightly implying concentration on target area.\n\nThe head position indicates focus on something below them - perhaps watching stone's path closely.\n\nThe second person, located near right edge of image with 2.5 times scale up, seems more stationary compared to first individual - possibly monitoring game progress or preparing for next turn.\n\nTheir legs show distinct difference: left leg fully extended while right one bent significantly at knee joint suggesting they're either stepping forward or backward.\n\nArms display different angles too: left arm appears fairly straight whereas right one exhibits significant bend at elbow joint pointing upwards which might suggest readiness for next move in game play.\n \nTorso orientation suggests attention directed towards left side (from viewer's perspective) probably observing current state of play while head position reinforces this assumption as it aligns with torso direction.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[594,257],&quot;id&quot;:0,&quot;kpts&quot;:[[620,394],[616,269],[573,185],[647,188],[661,221],[656,231],[610,187],[647,176],[637.0201,189.8183],[695.9799,108.1817],[606,217],[553,161],[601,167],[692,185],[693,240],[688,313]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.021046},{&quot;center&quot;:[952,222],&quot;id&quot;:1,&quot;kpts&quot;:[[895,293],[910,279],[945,223],[1012,218],[961,315],[960,403],[979,221],[906,190],[912.4915,190.6586],[830.5085,182.3414],[871,304],[883,229],[888,174],[924,206],[1013,203],[955,263]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.472117}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      594,\n      257\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        620,\n        394\n      ],\n      [\n        616,\n        269\n      ],\n      [\n        573,\n        185\n      ],\n      [\n        647,\n        188\n      ],\n      [\n        661,\n        221\n      ],\n      [\n        656,\n        231\n      ],\n      [\n        610,\n        187\n      ],\n      [\n        647,\n        176\n      ],\n      [\n        637.0201,\n        189.8183\n      ],\n      [\n        695.9799,\n        108.1817\n      ],\n      [\n        606,\n        217\n      ],\n      [\n        553,\n        161\n      ],\n      [\n        601,\n        167\n      ],\n      [\n        692,\n        185\n      ],\n      [\n        693,\n        240\n      ],\n      [\n        688,\n        313\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.021046\n  },\n  {\n    \&quot;center\&quot;: [\n      952,\n      222\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        895,\n        293\n      ],\n      [\n        910,\n        279\n      ],\n      [\n        945,\n        223\n      ],\n      [\n        1012,\n        218\n      ],\n      [\n        961,\n        315\n      ],\n      [\n        960,\n        403\n      ],\n      [\n        979,\n        221\n      ],\n      [\n        906,\n        190\n      ],\n      [\n        912.4915,\n        190.6586\n      ],\n      [\n        830.5085,\n        182.3414\n      ],\n      [\n        871,\n        304\n      ],\n      [\n        883,\n        229\n      ],\n      [\n        888,\n        174\n      ],\n      [\n        924,\n        206\n      ],\n      [\n        1013,\n        203\n      ],\n      [\n        955,\n        263\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.472117\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1660,&quot;string&quot;:&quot;1,660&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;015601864.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:1,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are three people in the image who are playing sports, specifically curling. This activity involves sliding stones on a sheet of ice towards a target area segmented into four concentric circles. It is evident from the keypoints that these individuals are engaged in different stages of the game.\n\nThe person at center coordinates (619.0, 329.0) with scale 5.641276 is standing upright with their right arm extended forward and left arm bent at an angle towards the back. Their legs seem to be positioned wide apart, indicating stability while they perform their action.\n\nThe person located at center coordinates (1010.0, 412.0) with scale 6.071051 seems to be in motion as both arms appear extended and slightly bent possibly holding or releasing the stone for sliding it across the ice.\n\nLastly, there's a person at center coordinates (133.0, 315.0) with scale 5.728162 who appears to be standing upright but slightly leaning forward with their right arm stretched out as if guiding or aiming for something.\n\nIn all three cases due to lack of visibility of lower body keypoints like ankles and knees we can't accurately determine if they are kneeling or have one leg raised which is common in curling sport while launching stones on ice sheet.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[619,329],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[806,543],[720,593],[-1,-1],[-1,-1],[763,568],[683,290],[682,256],[676,68],[563,296],[555,410],[647,281],[719,299],[711,516],[545,466]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.641276},{&quot;center&quot;:[1010,412],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[-1,-1],[987,607],[1194,571],[-1,-1],[-1,-1],[1091,589],[1038,292],[1025,261],[947,74],[914,539],[955,470],[931,315],[1145,269],[1226,475],[1096,433]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:6.071051},{&quot;center&quot;:[133,315],&quot;id&quot;:2,&quot;kpts&quot;:[[-1,-1],[-1,-1],[228,537],[74,536],[-1,-1],[-1,-1],[151,537],[129,251],[123,218],[89,31],[220,373],[297,456],[232,251],[26,251],[26,423],[-1,-1]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,0],&quot;scale&quot;:5.728162}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      619,\n      329\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        806,\n        543\n      ],\n      [\n        720,\n        593\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        763,\n        568\n      ],\n      [\n        683,\n        290\n      ],\n      [\n        682,\n        256\n      ],\n      [\n        676,\n        68\n      ],\n      [\n        563,\n        296\n      ],\n      [\n        555,\n        410\n      ],\n      [\n        647,\n        281\n      ],\n      [\n        719,\n        299\n      ],\n      [\n        711,\n        516\n      ],\n      [\n        545,\n        466\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.641276\n  },\n  {\n    \&quot;center\&quot;: [\n      1010,\n      412\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        987,\n        607\n      ],\n      [\n        1194,\n        571\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1091,\n        589\n      ],\n      [\n        1038,\n        292\n      ],\n      [\n        1025,\n        261\n      ],\n      [\n        947,\n        74\n      ],\n      [\n        914,\n        539\n      ],\n      [\n        955,\n        470\n      ],\n      [\n        931,\n        315\n      ],\n      [\n        1145,\n        269\n      ],\n      [\n        1226,\n        475\n      ],\n      [\n        1096,\n        433\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 6.071051\n  },\n  {\n    \&quot;center\&quot;: [\n      133,\n      315\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        228,\n        537\n      ],\n      [\n        74,\n        536\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        151,\n        537\n      ],\n      [\n        129,\n        251\n      ],\n      [\n        123,\n        218\n      ],\n      [\n        89,\n        31\n      ],\n      [\n        220,\n        373\n      ],\n      [\n        297,\n        456\n      ],\n      [\n        232,\n        251\n      ],\n      [\n        26,\n        251\n      ],\n      [\n        26,\n        423\n      ],\n      [\n        -1,\n        -1\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0\n    ],\n    \&quot;scale\&quot;: 5.728162\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1660,&quot;string&quot;:&quot;1,660&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:84,&quot;string&quot;:&quot;84&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;015599452.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;}}},{&quot;rowIdx&quot;:2,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are participating in sports, specifically curling. The activity involves a low and bent posture, with one knee nearly touching the ground while the other leg extends back. The arms extend forward to guide a curling stone.\n\nThe first person is located near the center of the image and they appear to be in motion with their body lowered close to the ground. Their right leg is bent at the knee and extended backward while their left leg supports their weight, also bent at an angle. Their pelvis is slightly tilted towards their right side suggesting that they are likely leaning on this side for balance. The torso is inclined forward from waist upwards, indicating that they might be pushing or guiding something on ground like a curling stone.\n\nTheir right arm is extended forward with elbow slightly bent, possibly holding onto something for support or guidance; whereas left arm appears to be extended straight out towards left side of body providing counterbalance. Their head seems to be looking straight ahead or slightly downwards which aligns with action of focusing on path ahead.\n\nThe second person located towards far right of image seems to have similar pose as first but more upright position suggesting less active role like waiting for turn or observing play. This person's both legs are relatively closer together compared to first individual but still maintaining bend at knees reflecting readiness stance.\n\nTheir arms' positioning suggests anticipation or readiness - right arm extending outwards and downwards while left arm bends at elbow pointing upwards possibly holding broom used in curling sport. Similar to first individual, this person's head top also points straight ahead indicating focus on game happening in front of them.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[291,353],&quot;id&quot;:0,&quot;kpts&quot;:[[301,461],[305,375],[201,340],[294,342],[335,370],[331,455],[248,341],[279,263],[277.021,268.7786],[305.979,184.2214],[328,354],[260,335],[244,261],[314,264],[327,320],[362,346]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.681349},{&quot;center&quot;:[472,377],&quot;id&quot;:1,&quot;kpts&quot;:[[515,512],[514,420],[406,388],[392,360],[493,434],[518,504],[399,374],[498,317],[504.5953,315.1758],[585.4047,292.8242],[628,426],[551,398],[501,351],[495,282],[425,301],[483,334]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.51531}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      291,\n      353\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        301,\n        461\n      ],\n      [\n        305,\n        375\n      ],\n      [\n        201,\n        340\n      ],\n      [\n        294,\n        342\n      ],\n      [\n        335,\n        370\n      ],\n      [\n        331,\n        455\n      ],\n      [\n        248,\n        341\n      ],\n      [\n        279,\n        263\n      ],\n      [\n        277.021,\n        268.7786\n      ],\n      [\n        305.979,\n        184.2214\n      ],\n      [\n        328,\n        354\n      ],\n      [\n        260,\n        335\n      ],\n      [\n        244,\n        261\n      ],\n      [\n        314,\n        264\n      ],\n      [\n        327,\n        320\n      ],\n      [\n        362,\n        346\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.681349\n  },\n  {\n    \&quot;center\&quot;: [\n      472,\n      377\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        515,\n        512\n      ],\n      [\n        514,\n        420\n      ],\n      [\n        406,\n        388\n      ],\n      [\n        392,\n        360\n      ],\n      [\n        493,\n        434\n      ],\n      [\n        518,\n        504\n      ],\n      [\n        399,\n        374\n      ],\n      [\n        498,\n        317\n      ],\n      [\n        504.5953,\n        315.1758\n      ],\n      [\n        585.4047,\n        292.8242\n      ],\n      [\n        628,\n        426\n      ],\n      [\n        551,\n        398\n      ],\n      [\n        501,\n        351\n      ],\n      [\n        495,\n        282\n      ],\n      [\n        425,\n        301\n      ],\n      [\n        483,\n        334\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.51531\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2462,&quot;string&quot;:&quot;2,462&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:240,&quot;string&quot;:&quot;240&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;086617615.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:3,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is participating in curling. This sport typically involves a crouched position, with one leg extended behind and arms forward to push the stone.\n\nThe person located at the center of the image is engaged in action, with their limbs positioned for curling. \n\nTheir right leg appears bent at the knee and ankle, suggesting it's supporting most of their weight. The right hip is higher than the left hip indicating they are leaning towards their right side. \n\nTheir left leg seems to be extended behind them, with both left knee and ankle visible suggesting a stretched pose.\n\nThe torso appears slightly inclined forward from pelvis to thorax indicating an active posture associated with pushing or sliding something on ice.\n\nThe head of this individual seems tilted down slightly from upper neck to head top implying concentration on a task at hand.\n\nAs for their arms, both seem extended forward but not symmetrically. The right arm from wrist to shoulder has all keypoints visible showing that it's fully stretched out possibly holding or guiding an object while the left arm has its elbow bent and wrist raised higher than shoulder possibly providing balance during action.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[897,171],&quot;id&quot;:0,&quot;kpts&quot;:[[980,322],[896,318],[865,248],[943,226],[948,290],[881,349],[904,237],[858,135],[871.1877,180.4244],[835.8123,58.5756],[772,294],[754,247],[792,147],[923,123],[995,163],[961,223]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.806403}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      897,\n      171\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        980,\n        322\n      ],\n      [\n        896,\n        318\n      ],\n      [\n        865,\n        248\n      ],\n      [\n        943,\n        226\n      ],\n      [\n        948,\n        290\n      ],\n      [\n        881,\n        349\n      ],\n      [\n        904,\n        237\n      ],\n      [\n        858,\n        135\n      ],\n      [\n        871.1877,\n        180.4244\n      ],\n      [\n        835.8123,\n        58.5756\n      ],\n      [\n        772,\n        294\n      ],\n      [\n        754,\n        247\n      ],\n      [\n        792,\n        147\n      ],\n      [\n        923,\n        123\n      ],\n      [\n        995,\n        163\n      ],\n      [\n        961,\n        223\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.806403\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:89,&quot;string&quot;:&quot;89&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:6,&quot;string&quot;:&quot;6&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;060111501.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:4,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are participating in curling. Curling is a sport where players slide stones on a sheet of ice towards a target area segmented into four concentric circles. It requires precision, strategy, and teamwork.\n\nThe person at the center-left of the image is engaged in the throwing motion typical of curling. Their right leg is bent at the knee with their ankle positioned behind them, while their left leg is extended forward with no visible knee or ankle joint. The right arm is bent slightly at the elbow and wrist, indicating they might be holding or releasing a stone. The left arm appears to be extended for balance.\n\nThe person located more towards center-right appears to be observing or waiting their turn to play. Their body posture indicates readiness but not immediate action - both legs are visible with knees slightly bent and ankles firmly on ground suggesting stability; arms seem relaxed but ready for action with elbows slightly flexed - right one higher than left one; head position suggests they're focused on game.\n\nOverall, this scene captures different stages of participation within a curling match – from active play to strategic observation.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[582,268],&quot;id&quot;:0,&quot;kpts&quot;:[[461,398],[509,335],[517,218],[570,203],[-1,-1],[568,309],[544,211],[620,273],[614,267],[668,326],[537,288],[503,234],[587,280],[652,265],[636,356],[621,417]],&quot;kpts_vis&quot;:[1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.40012},{&quot;center&quot;:[765,394],&quot;id&quot;:1,&quot;kpts&quot;:[[896,436],[875,397],[885,295],[852,363],[797,442],[823,505],[869,329],[737,323],[719,326],[648,338],[804,305],[804,237],[741,285],[732,361],[758,411],[757,485]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.155328}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      582,\n      268\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        461,\n        398\n      ],\n      [\n        509,\n        335\n      ],\n      [\n        517,\n        218\n      ],\n      [\n        570,\n        203\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        568,\n        309\n      ],\n      [\n        544,\n        211\n      ],\n      [\n        620,\n        273\n      ],\n      [\n        614,\n        267\n      ],\n      [\n        668,\n        326\n      ],\n      [\n        537,\n        288\n      ],\n      [\n        503,\n        234\n      ],\n      [\n        587,\n        280\n      ],\n      [\n        652,\n        265\n      ],\n      [\n        636,\n        356\n      ],\n      [\n        621,\n        417\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.40012\n  },\n  {\n    \&quot;center\&quot;: [\n      765,\n      394\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        896,\n        436\n      ],\n      [\n        875,\n        397\n      ],\n      [\n        885,\n        295\n      ],\n      [\n        852,\n        363\n      ],\n      [\n        797,\n        442\n      ],\n      [\n        823,\n        505\n      ],\n      [\n        869,\n        329\n      ],\n      [\n        737,\n        323\n      ],\n      [\n        719,\n        326\n      ],\n      [\n        648,\n        338\n      ],\n      [\n        804,\n        305\n      ],\n      [\n        804,\n        237\n      ],\n      [\n        741,\n        285\n      ],\n      [\n        732,\n        361\n      ],\n      [\n        758,\n        411\n      ],\n      [\n        757,\n        485\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.155328\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:89,&quot;string&quot;:&quot;89&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:81,&quot;string&quot;:&quot;81&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;070807258.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:5,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is playing curling. The sport involves a lot of bending and stretching, with players often seen in a crouched position, sliding the stone on the ice.\n\nThe person located at coordinates (924.0, 445.0) appears to be in an active state of play with their limbs positioned for action.\n\nRegarding their right leg, it seems to be bent at the knee with the ankle positioned slightly behind and lower than the hip joint. The left leg appears extended straight from hip to ankle, possibly providing balance during play.\n\nThe right arm is bent at a sharp angle at elbow joint suggesting that they might be holding or about to release curling stone. The wrist of this arm is found higher than elbow indicating an upward movement or grip.\n\nThe left arm appears almost straight but slightly bent at elbow pointing towards ground which could be used for stability during sliding motion on ice.\n\nTheir torso leans forward as indicated by relatively low position of thorax compared to pelvis which aligns well with typical pose seen in curling where player bends forward while delivering stone.\n\nFinally, their head seems tilted downwards as per alignment between neck and head top keypoints which suggests concentration on target or stone being played.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[924,445],&quot;id&quot;:0,&quot;kpts&quot;:[[918,456],[659,518],[713,413],[979,288],[1222,453],[974,399],[846,351],[738,259],[795.2738,314.8937],[597.7262,122.1063],[441,490],[446,434],[599,270],[877,247],[1112,384],[1012,489]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:8.28087}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      924,\n      445\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        918,\n        456\n      ],\n      [\n        659,\n        518\n      ],\n      [\n        713,\n        413\n      ],\n      [\n        979,\n        288\n      ],\n      [\n        1222,\n        453\n      ],\n      [\n        974,\n        399\n      ],\n      [\n        846,\n        351\n      ],\n      [\n        738,\n        259\n      ],\n      [\n        795.2738,\n        314.8937\n      ],\n      [\n        597.7262,\n        122.1063\n      ],\n      [\n        441,\n        490\n      ],\n      [\n        446,\n        434\n      ],\n      [\n        599,\n        270\n      ],\n      [\n        877,\n        247\n      ],\n      [\n        1112,\n        384\n      ],\n      [\n        1012,\n        489\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 8.28087\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:89,&quot;string&quot;:&quot;89&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:162,&quot;string&quot;:&quot;162&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, curling&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;002058449.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:6,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are sitting quietly. This typically involves the individuals being in a seated position with their legs bent at the knees, and arms either resting on their laps or placed on armrests. The overall posture is relaxed and there is minimal movement.\n\nThe person located towards the left of the image is sitting with their right leg obscured from view. Their left leg appears to be bent at the knee, with their hip and knee keypoints indicating a relaxed seated position. The right arm seems to be raised slightly, with both elbow and wrist keypoints positioned above those of shoulder and hip respectively. The left arm appears extended outwards, possibly resting on an object or surface.\n\nThe person located towards the right of the image seems to be in a more upright seated position compared to their counterpart. Both legs appear visible, bent at knees suggesting they might be sitting on an elevated surface such as a chair or stool. Their right arm looks like it's resting comfortably on their lap while left arm appears slightly raised but still relaxed.\n\nIn both cases, torso keypoints suggest an upright posture while head keypoints indicate that heads are facing forward - typical traits when someone is engaged in quiet activities such as reading or watching something.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[304,264],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[355,408],[269,354],[432,333],[464,425],[-1,-1],[351,344],[310,158],[308.4257,139.7834],[297.5743,14.2166],[335,328],[212,304],[230,168],[389,147],[492,259],[413,321]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.781047},{&quot;center&quot;:[361,303],&quot;id&quot;:1,&quot;kpts&quot;:[[357,353],[369,330],[366,296],[443,308],[470,332],[435,371],[405,302],[404,201],[405.772,194.4489],[435.228,85.5511],[331,252],[354,261],[357,200],[451,202],[484,246],[468,253]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.38434}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      304,\n      264\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        355,\n        408\n      ],\n      [\n        269,\n        354\n      ],\n      [\n        432,\n        333\n      ],\n      [\n        464,\n        425\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        351,\n        344\n      ],\n      [\n        310,\n        158\n      ],\n      [\n        308.4257,\n        139.7834\n      ],\n      [\n        297.5743,\n        14.2166\n      ],\n      [\n        335,\n        328\n      ],\n      [\n        212,\n        304\n      ],\n      [\n        230,\n        168\n      ],\n      [\n        389,\n        147\n      ],\n      [\n        492,\n        259\n      ],\n      [\n        413,\n        321\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.781047\n  },\n  {\n    \&quot;center\&quot;: [\n      361,\n      303\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        357,\n        353\n      ],\n      [\n        369,\n        330\n      ],\n      [\n        366,\n        296\n      ],\n      [\n        443,\n        308\n      ],\n      [\n        470,\n        332\n      ],\n      [\n        435,\n        371\n      ],\n      [\n        405,\n        302\n      ],\n      [\n        404,\n        201\n      ],\n      [\n        405.772,\n        194.4489\n      ],\n      [\n        435.228,\n        85.5511\n      ],\n      [\n        331,\n        252\n      ],\n      [\n        354,\n        261\n      ],\n      [\n        357,\n        200\n      ],\n      [\n        451,\n        202\n      ],\n      [\n        484,\n        246\n      ],\n      [\n        468,\n        253\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.38434\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2615,&quot;string&quot;:&quot;2,615&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:28,&quot;string&quot;:&quot;28&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;inactivity quiet/light, sitting quietly&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;021233911.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:7,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are sitting quietly. Both individuals appear to be in a seated position, with their legs bent at the knees and their upper bodies upright.\n\nThe first person is located towards the right of center and is larger in scale. They are sitting with their torso leaning slightly to the left. Their right leg appears to be bent at a sharper angle than their left, suggesting that they might be shifting weight onto it. The right ankle and knee are visible while the left hip, knee, and ankle suggest that they're folded underneath them or possibly extended out of frame. Their arms seem relaxed; the right arm hangs down naturally while the left arm is slightly raised with elbow bent.\n\nThe second person is located towards center-left and is larger than the first person. Unfortunately, some keypoints such as both ankles aren't visible which limits our understanding of this individual's pose; however, based on available data we can infer that they're also seated but more upright compared to person one. Their right leg appears extended forward with knee bent while visibility of only left hip suggests this leg might be folded underneath or extended outwards like person one's pose but we can't confirm without further data. The arms appear relaxed but extended; both elbows show a significant bend indicating hands may be resting on lap or nearby surface.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[316,283],&quot;id&quot;:0,&quot;kpts&quot;:[[325,349],[341,327],[326,302],[385,277],[409,302],[399,377],[356,290],[314,209],[315.2436,213.9744],[286.7564,100.0256],[318,325],[280,288],[267,231],[360,187],[406,218],[374,258]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.523671},{&quot;center&quot;:[261,296],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[329,409],[262,352],[399,316],[439,423],[-1,-1],[331,334],[245,213],[211.002,177.0151],[124.998,85.9849],[157,477],[159,371],[169,254],[320,171],[443,231],[364,300]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.756978}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      316,\n      283\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        325,\n        349\n      ],\n      [\n        341,\n        327\n      ],\n      [\n        326,\n        302\n      ],\n      [\n        385,\n        277\n      ],\n      [\n        409,\n        302\n      ],\n      [\n        399,\n        377\n      ],\n      [\n        356,\n        290\n      ],\n      [\n        314,\n        209\n      ],\n      [\n        315.2436,\n        213.9744\n      ],\n      [\n        286.7564,\n        100.0256\n      ],\n      [\n        318,\n        325\n      ],\n      [\n        280,\n        288\n      ],\n      [\n        267,\n        231\n      ],\n      [\n        360,\n        187\n      ],\n      [\n        406,\n        218\n      ],\n      [\n        374,\n        258\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.523671\n  },\n  {\n    \&quot;center\&quot;: [\n      261,\n      296\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        329,\n        409\n      ],\n      [\n        262,\n        352\n      ],\n      [\n        399,\n        316\n      ],\n      [\n        439,\n        423\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        331,\n        334\n      ],\n      [\n        245,\n        213\n      ],\n      [\n        211.002,\n        177.0151\n      ],\n      [\n        124.998,\n        85.9849\n      ],\n      [\n        157,\n        477\n      ],\n      [\n        159,\n        371\n      ],\n      [\n        169,\n        254\n      ],\n      [\n        320,\n        171\n      ],\n      [\n        443,\n        231\n      ],\n      [\n        364,\n        300\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.756978\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2615,&quot;string&quot;:&quot;2,615&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:177,&quot;string&quot;:&quot;177&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;inactivity quiet/light, sitting quietly&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;018182497.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:8,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaging in miscellaneous activities, sitting, talking in person, on the phone, computer or text messaging with light effort. The activities suggest a relaxed situation with individuals likely seated and interacting with each other or devices.\n\nThe first person located towards the left is seemingly engaged in an activity involving their upper body. Their right leg is bent at the knee and hip while their left leg appears to be straight. The right arm seems to be extended forward possibly holding or interacting with an object as indicated by its position relative to the torso. Their left arm is slightly bent at the elbow and appears relaxed. The head is tilted downwards suggesting focused attention on something below eye level.\n\nThe second person located towards the right of frame also appears to be seated but their pose suggests they might be engaged in conversation or looking at something ahead of them. Both legs appear bent at knees and hips indicating a sitting posture similar to first individual but more upright based on relative positions of hips and shoulders. Their arms are positioned differently; while their right arm seems slightly extended forward, perhaps resting on a surface or holding an object, their left arm seems closer to body possibly resting against it. They have their head held higher compared to first individual suggesting engagement with someone/something ahead rather than below eye level.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[333,246],&quot;id&quot;:0,&quot;kpts&quot;:[[392,390],[388,300],[289,296],[302,283],[395,296],[400,389],[296,290],[287,191],[289.5053,184.9874],[314.4947,125.0126],[366,284],[307,275],[281,194],[292,187],[320,262],[362,276]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.949178},{&quot;center&quot;:[408,263],&quot;id&quot;:1,&quot;kpts&quot;:[[423,378],[411,288],[344,259],[394,251],[456,283],[453,369],[369,255],[344,190],[345.6244,184.3958],[362.3756,126.6042],[381,264],[337,247],[316,189],[372,190],[394,239],[421,257]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.805113}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      333,\n      246\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        392,\n        390\n      ],\n      [\n        388,\n        300\n      ],\n      [\n        289,\n        296\n      ],\n      [\n        302,\n        283\n      ],\n      [\n        395,\n        296\n      ],\n      [\n        400,\n        389\n      ],\n      [\n        296,\n        290\n      ],\n      [\n        287,\n        191\n      ],\n      [\n        289.5053,\n        184.9874\n      ],\n      [\n        314.4947,\n        125.0126\n      ],\n      [\n        366,\n        284\n      ],\n      [\n        307,\n        275\n      ],\n      [\n        281,\n        194\n      ],\n      [\n        292,\n        187\n      ],\n      [\n        320,\n        262\n      ],\n      [\n        362,\n        276\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.949178\n  },\n  {\n    \&quot;center\&quot;: [\n      408,\n      263\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        423,\n        378\n      ],\n      [\n        411,\n        288\n      ],\n      [\n        344,\n        259\n      ],\n      [\n        394,\n        251\n      ],\n      [\n        456,\n        283\n      ],\n      [\n        453,\n        369\n      ],\n      [\n        369,\n        255\n      ],\n      [\n        344,\n        190\n      ],\n      [\n        345.6244,\n        184.3958\n      ],\n      [\n        362.3756,\n        126.6042\n      ],\n      [\n        381,\n        264\n      ],\n      [\n        337,\n        247\n      ],\n      [\n        316,\n        189\n      ],\n      [\n        372,\n        190\n      ],\n      [\n        394,\n        239\n      ],\n      [\n        421,\n        257\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.805113\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:622,&quot;string&quot;:&quot;622&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:842,&quot;string&quot;:&quot;842&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:10,&quot;string&quot;:&quot;10&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;018340451.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:9,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaged in miscellaneous activities, sitting, talking in person, on the phone, computer, or text messaging with light effort. Their poses suggest a relaxed and casual setting with some level of interaction.\n\nThe first person located near the center of the image is seated with their body facing forward. Their right leg is bent at the knee and extended outward while their left leg is also bent at a similar angle but slightly inward. The right arm appears to be resting on a surface or holding an object as it's extended forward from the shoulder with slight bend at elbow. The left arm seems to be held closer to body indicating possible interaction with an object close by.\n\nThe second person situated towards right side of image exhibits similar pose characteristics but mirrored along vertical axis. They have their left leg stretched out while their right leg is slightly folded inwardly. This individual's left arm extends forward possibly resting on a surface or interacting with an object nearby while their right arm seems closer to body suggesting engagement with something within close reach.\n\nIn both cases, heads are tilted slightly downwards indicating focus on objects they're interacting with which could be devices such as phones or computers given activity context.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[374,255],&quot;id&quot;:0,&quot;kpts&quot;:[[324,406],[322,291],[293,262],[355,267],[401,292],[394,404],[324,265],[334,170],[338.6651,157.2087],[360.3349,97.7913],[363,167],[319,205],[298,168],[369,172],[390,221],[398,179]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.897367},{&quot;center&quot;:[540,267],&quot;id&quot;:1,&quot;kpts&quot;:[[476,407],[476,295],[510,264],[564,265],[581,303],[575,412],[537,265],[535,175],[534.9093,172.7919],[532.0907,104.2081],[508,183],[492,238],[493,173],[577,176],[591,235],[556,190]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.05925}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      374,\n      255\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        324,\n        406\n      ],\n      [\n        322,\n        291\n      ],\n      [\n        293,\n        262\n      ],\n      [\n        355,\n        267\n      ],\n      [\n        401,\n        292\n      ],\n      [\n        394,\n        404\n      ],\n      [\n        324,\n        265\n      ],\n      [\n        334,\n        170\n      ],\n      [\n        338.6651,\n        157.2087\n      ],\n      [\n        360.3349,\n        97.7913\n      ],\n      [\n        363,\n        167\n      ],\n      [\n        319,\n        205\n      ],\n      [\n        298,\n        168\n      ],\n      [\n        369,\n        172\n      ],\n      [\n        390,\n        221\n      ],\n      [\n        398,\n        179\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.897367\n  },\n  {\n    \&quot;center\&quot;: [\n      540,\n      267\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        476,\n        407\n      ],\n      [\n        476,\n        295\n      ],\n      [\n        510,\n        264\n      ],\n      [\n        564,\n        265\n      ],\n      [\n        581,\n        303\n      ],\n      [\n        575,\n        412\n      ],\n      [\n        537,\n        265\n      ],\n      [\n        535,\n        175\n      ],\n      [\n        534.9093,\n        172.7919\n      ],\n      [\n        532.0907,\n        104.2081\n      ],\n      [\n        508,\n        183\n      ],\n      [\n        492,\n        238\n      ],\n      [\n        493,\n        173\n      ],\n      [\n        577,\n        176\n      ],\n      [\n        591,\n        235\n      ],\n      [\n        556,\n        190\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.05925\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:622,&quot;string&quot;:&quot;622&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:842,&quot;string&quot;:&quot;842&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:95,&quot;string&quot;:&quot;95&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;030424224.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:10,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaging in light effort activities such as miscellaneous sitting, talking in person, on the phone, or text messaging. This may include using a computer. \n\nThe first person is centrally located within the image and appears to be interacting with an object or performing an action with their right arm. Their right leg is bent at the knee and hip, suggesting they might be seated on a chair or similar surface. Their left leg is also bent at the knee but less so than their right leg - it could be resting on a surface. The upper body leans slightly towards their right side while their head faces forward.\n\nThe second person is positioned towards the right of the image and appears to also be seated given that both legs are bent at knees and hips, possibly resting on a surface. They seem to have both arms raised; left arm more elevated than the right one which suggests they might be engaged in conversation or holding an object like a phone near their face for interaction.\n\nIn general, these poses suggest casual indoor activities where individuals may engage with objects around them or communicate with others through various means including direct conversation, phone calls or text messaging.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[338,258],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[477,423],[300,416],[321,400],[519,408],[-1,-1],[311,408],[309,208],[314.9696,197.6361],[375.0304,93.3639],[461,395],[334,380],[309,225],[309,191],[299,58],[260,156]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.609986},{&quot;center&quot;:[546,249],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[575,416],[498,377],[577,365],[693,405],[-1,-1],[538,371],[472,219],[472.0517,218.5069],[482.9483,114.4931],[444,185],[456,296],[419,231],[524,207],[577,132],[477,138]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.137489}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      338,\n      258\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        477,\n        423\n      ],\n      [\n        300,\n        416\n      ],\n      [\n        321,\n        400\n      ],\n      [\n        519,\n        408\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        311,\n        408\n      ],\n      [\n        309,\n        208\n      ],\n      [\n        314.9696,\n        197.6361\n      ],\n      [\n        375.0304,\n        93.3639\n      ],\n      [\n        461,\n        395\n      ],\n      [\n        334,\n        380\n      ],\n      [\n        309,\n        225\n      ],\n      [\n        309,\n        191\n      ],\n      [\n        299,\n        58\n      ],\n      [\n        260,\n        156\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.609986\n  },\n  {\n    \&quot;center\&quot;: [\n      546,\n      249\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        575,\n        416\n      ],\n      [\n        498,\n        377\n      ],\n      [\n        577,\n        365\n      ],\n      [\n        693,\n        405\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        538,\n        371\n      ],\n      [\n        472,\n        219\n      ],\n      [\n        472.0517,\n        218.5069\n      ],\n      [\n        482.9483,\n        114.4931\n      ],\n      [\n        444,\n        185\n      ],\n      [\n        456,\n        296\n      ],\n      [\n        419,\n        231\n      ],\n      [\n        524,\n        207\n      ],\n      [\n        577,\n        132\n      ],\n      [\n        477,\n        138\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.137489\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:622,&quot;string&quot;:&quot;622&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:842,&quot;string&quot;:&quot;842&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:469,&quot;string&quot;:&quot;469&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;043194502.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:11,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads.\n\nThe centrally located person is standing facing slightly to the left with their right arm extended downwards and slightly bent at the elbow. Their left arm appears to be reaching across their body towards the right side. \n\nFor their legs, it seems that they are standing with weight primarily on their left leg. The right leg appears to be slightly bent at the knee indicating possible movement or preparation for stepping.\n\nAs for their torso and head position; they are upright with a slight lean towards the left side likely due to weight distribution of what they might be carrying or preparing to lift. Their head is straight looking forward or possibly downwards considering occupational safety during lifting heavy objects.\n\nIn conclusion, this pose indicates an individual engaged in manual labor tasks such as lifting or moving items possibly related to truck loading/unloading activities.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[316,299],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[301,473],[302,346],[362,345],[367,470],[-1,-1],[332,346],[325,217],[326.2681,196.1669],[330.7319,122.8331],[275,299],[262,300],[278,220],[371,213],[396,309],[393,290]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.204083}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      316,\n      299\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        301,\n        473\n      ],\n      [\n        302,\n        346\n      ],\n      [\n        362,\n        345\n      ],\n      [\n        367,\n        470\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        332,\n        346\n      ],\n      [\n        325,\n        217\n      ],\n      [\n        326.2681,\n        196.1669\n      ],\n      [\n        330.7319,\n        122.8331\n      ],\n      [\n        275,\n        299\n      ],\n      [\n        262,\n        300\n      ],\n      [\n        278,\n        220\n      ],\n      [\n        371,\n        213\n      ],\n      [\n        396,\n        309\n      ],\n      [\n        393,\n        290\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.204083\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;029122914.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:12,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in the occupation of truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads.\n\nThe person centered at coordinates (435.0, 295.0) on a scale of 4.143112 is seen performing an activity related to their occupation. Their right arm appears to be extended towards the front with a bend at the elbow while their left arm seems to be raised slightly higher than their right shoulder.\n\nStarting with the head region: The upper neck keypoint indicates that they are looking straight ahead or slightly upwards as it's positioned above thorax keypoint.\n\nMoving onto torso: The thorax keypoint indicates that they are standing upright as it's vertically aligned with upper neck and pelvis keypoints which are not visible in this case.\n\nRight arm: The right wrist is lower than the right elbow suggesting that their forearm might be elevated or bent upwards. The position of right shoulder suggests that this arm might be stretched out towards front or side.\n\nLeft Arm: There's no information available for left elbow and wrist but given the position of left shoulder being higher than right one, it can be inferred that this arm might also be raised or stretched outwards.\n\nLegs: Unfortunately there're no visible keypoints for legs so we cannot infer anything about them.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[435,295],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[533,322],[515.0945,277.1333],[463.9055,148.8667],[353,172],[426,239],[513,288],[552,355],[-1,-1],[-1,-1]],&quot;kpts_vis&quot;:[0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0],&quot;scale&quot;:4.143112}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      435,\n      295\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        533,\n        322\n      ],\n      [\n        515.0945,\n        277.1333\n      ],\n      [\n        463.9055,\n        148.8667\n      ],\n      [\n        353,\n        172\n      ],\n      [\n        426,\n        239\n      ],\n      [\n        513,\n        288\n      ],\n      [\n        552,\n        355\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0,\n      0\n    ],\n    \&quot;scale\&quot;: 4.143112\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:72,&quot;string&quot;:&quot;72&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;061185289.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:13,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is loading and unloading a truck. This activity involves standing, walking, carrying heavy loads, and tying down the load. \n\nThe person centered around coordinates (183.0, 327.0) appears to be in an active state with their limbs engaged in some form of movement or action.\n\nTheir right leg seems invisible or obscured from view as both the right ankle and knee are not visible. The right hip is located at coordinate (110, 385), indicating that it may be bent or raised.\n\nThe left leg's hip is positioned at coordinate (208, 355), but both the knee and ankle are also not visible suggesting that this leg might also be bent or obscured from view.\n\nThe pelvis is situated higher than both hips at coordinate (159,370), implying an upright posture.\n\nTheir torso appears to be leaning forward slightly as indicated by the position of thorax at coordinate (189,228) which is lower than the pelvis but higher than upper neck located at coordinate (191,227).\n\nThe head seems to be tilted upwards since its topmost point located at coordinate (326,168) lies significantly above all other keypoints.\n\nFor their arms: \n- The right arm has its wrist positioned higher up at coordinate(367 ,363). The elbow joint sits lower down on coordinates(254 ,429). This suggests that this arm might be raised up.\n- In contrast to this pattern seen on their right side; on their left side - wrist joint rests relatively low on coordinates(376 ,39), while elbow joint sits much higher up placed on coordinates(319 ,123). This implies a possible bending angle where forearm could potentially lie parallel with ground surface.\n  \nDespite some keypoints being invisible due to occlusion or other reasons; overall body pose suggests engagement in physical activity involving lifting/carrying loads given context of occupation provided for MPII dataset image analysis.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[183,327],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[110,385],[208,355],[-1,-1],[-1,-1],[159,370],[189,228],[191.1195,227.0916],[326.8805,168.9084],[367,363],[254,429],[166,303],[212,153],[319,123],[376,39]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.431105}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      183,\n      327\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        110,\n        385\n      ],\n      [\n        208,\n        355\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        159,\n        370\n      ],\n      [\n        189,\n        228\n      ],\n      [\n        191.1195,\n        227.0916\n      ],\n      [\n        326.8805,\n        168.9084\n      ],\n      [\n        367,\n        363\n      ],\n      [\n        254,\n        429\n      ],\n      [\n        166,\n        303\n      ],\n      [\n        212,\n        153\n      ],\n      [\n        319,\n        123\n      ],\n      [\n        376,\n        39\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.431105\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:137,&quot;string&quot;:&quot;137&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;013949386.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:14,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy loads. This activity requires a lot of physical effort and coordination as it involves various movements such as standing, walking and lifting heavy items. \n\nThe person located at the center of the image appears to be in a dynamic pose with their limbs oriented towards performing some task.\n\nStarting with their right leg: The right hip is visible but the knee and ankle are not visible which suggests that this leg might be bent or obscured from view.\n\nMoving on to their left leg: We can see that this limb is slightly bent at the hip joint but other keypoints like knee and ankle are not visible which indicates that this leg may also be bent or obscured.\n\nTheir torso seems to be leaning forward given that we can trace a line from pelvis through thorax to upper neck. This posture often signifies an action involving reaching out or bending over something.\n\nFor their right arm: It seems extended outwards with both wrist and elbow visible. The arm appears to be reaching upwards suggesting they might be lifting or holding something aloft.\n\nRegarding their left arm: It's extended downwards with both elbow and wrist keypoints discernible. The orientation suggests they could have been using this hand for support while performing tasks.\n\nLastly for head position: From neck up through top of head there's a clear upward inclination indicating they're looking upwards possibly focusing on task at hand.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[244,190],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[208,331],[159,313],[-1,-1],[-1,-1],[184,322],[198,105],[216.6135,87.6702],[295.3865,14.3298],[322,385],[254,278],[222,118],[174,92],[181,226],[197,364]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.22887}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      244,\n      190\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        208,\n        331\n      ],\n      [\n        159,\n        313\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        184,\n        322\n      ],\n      [\n        198,\n        105\n      ],\n      [\n        216.6135,\n        87.6702\n      ],\n      [\n        295.3865,\n        14.3298\n      ],\n      [\n        322,\n        385\n      ],\n      [\n        254,\n        278\n      ],\n      [\n        222,\n        118\n      ],\n      [\n        174,\n        92\n      ],\n      [\n        181,\n        226\n      ],\n      [\n        197,\n        364\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.22887\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:244,&quot;string&quot;:&quot;244&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;029214465.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:15,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is working, specifically involved in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy load.\n\nThe person at the center of the image appears to be in a state of motion or engaging in some physical activity. Their body orientation suggests they might be involved in lifting or carrying something heavy.\n\nThe left leg of this individual seems to be slightly bent at the knee and shifted backward whereas their right leg appears straighter and more forward. This might suggest that they are stepping forward with their right foot while supporting weight on their left.\n\nTheir right arm seems to be bent at an angle near the elbow with wrist higher than elbow level suggesting that they may be holding or lifting something. The left arm also shows a similar bend but it's positioned lower than the right one indicating it's possibly supporting weight from below.\n\nThe torso leans slightly towards their right side perhaps due to weight distribution. The head is tilted downward indicating focus on whatever task they are performing with their hands.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[472,245],&quot;id&quot;:0,&quot;kpts&quot;:[[525,478],[529,369],[517,220],[570,204],[574,371],[581,480],[544,212],[488,76],[479.0873,71.5436],[392.9127,28.4564],[416,251],[469,201],[459,104],[516,48],[588,132],[587,242]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.890381}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      472,\n      245\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        525,\n        478\n      ],\n      [\n        529,\n        369\n      ],\n      [\n        517,\n        220\n      ],\n      [\n        570,\n        204\n      ],\n      [\n        574,\n        371\n      ],\n      [\n        581,\n        480\n      ],\n      [\n        544,\n        212\n      ],\n      [\n        488,\n        76\n      ],\n      [\n        479.0873,\n        71.5436\n      ],\n      [\n        392.9127,\n        28.4564\n      ],\n      [\n        416,\n        251\n      ],\n      [\n        469,\n        201\n      ],\n      [\n        459,\n        104\n      ],\n      [\n        516,\n        48\n      ],\n      [\n        588,\n        132\n      ],\n      [\n        587,\n        242\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.890381\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:383,&quot;string&quot;:&quot;383&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;036636184.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:16,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. These activities typically involve a lot of movement and physical effort.\n\nThe centrally located person is actively engaged in their task with their limbs positioned for heavy lifting or carrying. \n\nTheir right leg appears to be slightly bent at the knee and hip which may suggest some form of movement or preparation for lifting. The left leg seems to be straightened out more towards the back which could indicate that they're bracing themselves for physical exertion.\n\nThe right arm has a noticeable bend at the elbow with wrist directed towards the body's center. This could suggest that they are holding onto something or preparing to lift an object. The left arm also appears bent at the elbow but not as much as the right one, possibly because it's being used for balance or support.\n\nTheir torso seems slightly inclined forward indicating an active pose often associated with lifting or moving heavy objects. This forward inclination can also provide additional momentum needed when carrying heavy loads.\n\nFinally, their head seems tilted slightly downwards perhaps focusing on an object they are about to lift or carry. Their neck appears aligned with their upper body further suggesting concentration on tasks performed by hands.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[573,288],&quot;id&quot;:0,&quot;kpts&quot;:[[555,370],[568,298],[559,255],[645,140],[600,343],[610,480],[602,198],[515,179],[508.3448,181.3768],[395.6552,221.6232],[495,361],[470,285],[464,170],[566,187],[671,230],[591,316]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.589826}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      573,\n      288\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        555,\n        370\n      ],\n      [\n        568,\n        298\n      ],\n      [\n        559,\n        255\n      ],\n      [\n        645,\n        140\n      ],\n      [\n        600,\n        343\n      ],\n      [\n        610,\n        480\n      ],\n      [\n        602,\n        198\n      ],\n      [\n        515,\n        179\n      ],\n      [\n        508.3448,\n        181.3768\n      ],\n      [\n        395.6552,\n        221.6232\n      ],\n      [\n        495,\n        361\n      ],\n      [\n        470,\n        285\n      ],\n      [\n        464,\n        170\n      ],\n      [\n        566,\n        187\n      ],\n      [\n        671,\n        230\n      ],\n      [\n        591,\n        316\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.589826\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:607,&quot;string&quot;:&quot;607&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;045606998.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:17,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. \n\nThe person centered around coordinates (591.0, 378.0) appears to be performing a task with their right arm extended while their left arm is bent at the elbow.\n\nTheir right leg seems to be slightly bent at the knee and positioned behind them while the left leg appears to be straight and bearing most of their weight.\n\nThe right ankle keypoint isn't visible in this image but judging from the position of their right knee and hip keypoints, it's safe to say that they are possibly stepping backwards or maintaining balance.\n\nTheir torso leans slightly towards the left side indicating they are either turning or shifting weight towards that direction.\n\nTheir head is tilted downward suggesting concentration on a task at hand or looking at something below eye level. Their neck also seems to be slightly extended forward which further supports this observation.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[591,378],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[548,675],[563,514],[626,510],[602,664],[-1,-1],[595,512],[611,308],[615.2092,299.334],[657.7908,211.666],[522,488],[522,404],[571,304],[651,312],[687,324],[716,299]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.923866}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      591,\n      378\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        548,\n        675\n      ],\n      [\n        563,\n        514\n      ],\n      [\n        626,\n        510\n      ],\n      [\n        602,\n        664\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        595,\n        512\n      ],\n      [\n        611,\n        308\n      ],\n      [\n        615.2092,\n        299.334\n      ],\n      [\n        657.7908,\n        211.666\n      ],\n      [\n        522,\n        488\n      ],\n      [\n        522,\n        404\n      ],\n      [\n        571,\n        304\n      ],\n      [\n        651,\n        312\n      ],\n      [\n        687,\n        324\n      ],\n      [\n        716,\n        299\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.923866\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:75,&quot;string&quot;:&quot;75&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;059241457.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:18,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy load. This activity involves a lot of physical work and movement.\n\nThe centrally positioned person is standing with their limbs involved in some form of action.\n\nThe right leg appears to be straight with the ankle slightly behind the knee and hip. The left leg seems to be stepping forward or sideways as it's bent at the knee with the ankle ahead of both knee and hip.\n\nTheir right arm seems to be reaching out or pulling something as it's extended straight from wrist through elbow to shoulder. The left arm appears bent at elbow forming an angle between shoulder and wrist which suggests lifting or holding onto something.\n\nThe torso leans slightly towards left possibly due to weight distribution from whatever they are carrying or pulling. \n\nFinally, their head is tilted downwards indicating focus on their task at hand.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[662,359],&quot;id&quot;:0,&quot;kpts&quot;:[[679,637],[663,528],[639,374],[748,369],[727,532],[727,666],[694,372],[595,219],[592.5583,210.0951],[563.4417,103.9049],[495,354],[526,310],[553,217],[636,220],[616,329],[529,353]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.303293}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      662,\n      359\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        679,\n        637\n      ],\n      [\n        663,\n        528\n      ],\n      [\n        639,\n        374\n      ],\n      [\n        748,\n        369\n      ],\n      [\n        727,\n        532\n      ],\n      [\n        727,\n        666\n      ],\n      [\n        694,\n        372\n      ],\n      [\n        595,\n        219\n      ],\n      [\n        592.5583,\n        210.0951\n      ],\n      [\n        563.4417,\n        103.9049\n      ],\n      [\n        495,\n        354\n      ],\n      [\n        526,\n        310\n      ],\n      [\n        553,\n        217\n      ],\n      [\n        636,\n        220\n      ],\n      [\n        616,\n        329\n      ],\n      [\n        529,\n        353\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.303293\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:283,&quot;string&quot;:&quot;283&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;017052412.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:19,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. The individual appears to be standing with their upper body twisted slightly towards their right side.\n\nThe person located at the center of the image appears to be in an active state with their limbs positioned for manual labor. \n\nTheir right leg seems to be slightly bent at the hip joint as indicated by keypoint 2 (right hip). However, we cannot infer more about this leg's pose due to invisible keypoints of right knee and ankle.\n\nThe left leg appears straightened out with no bend visible from hip to ankle (keypoints 3-5), suggesting that it might be bearing most of the person's weight.\n\nTheir torso is tilted towards their right side which can be interpreted from relative positions of pelvis (keypoint 6), thorax (7) and neck (8).\n\nAs for arms, they seem stretched out. The left arm seems extended outward from shoulder to wrist (keypoints 13-15), possibly reaching for something or performing an action. The right arm also looks extended but slightly bent at elbow joint as seen between keypoints 12-10.\n\nFinally, head orientation can't be precisely determined due its close proximity between upper neck and head top keypoints but it seems aligned with torso direction indicating focus on current activity.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[542,483],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[531,597],[629,588],[-1,-1],[-1,-1],[580,593],[571,388],[572,384],[612,279],[496,638],[490,531],[516,403],[626,372],[653,403],[697,364]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.38434}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      542,\n      483\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        531,\n        597\n      ],\n      [\n        629,\n        588\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        580,\n        593\n      ],\n      [\n        571,\n        388\n      ],\n      [\n        572,\n        384\n      ],\n      [\n        612,\n        279\n      ],\n      [\n        496,\n        638\n      ],\n      [\n        490,\n        531\n      ],\n      [\n        516,\n        403\n      ],\n      [\n        626,\n        372\n      ],\n      [\n        653,\n        403\n      ],\n      [\n        697,\n        364\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.38434\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:376,&quot;string&quot;:&quot;376&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;006505159.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:20,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in occupational activities related to truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. This involves a lot of physical activity which can be seen through the keypoints.\n\nThe centrally positioned person appears to be in motion with their limbs actively engaged.\n\nStarting with their legs:\n- The right leg seems slightly bent at the knee and hip as indicated by coordinates of right ankle (836, 666), right knee (841, 595) and right hip (830, 500). It may suggest that this foot is about to step forward.\n- The left leg appears more straightened out but still slightly bent at the knee. Given coordinates for left ankle (912, 691), left knee (895, 593) and left hip (900,515), it might be bearing most of the weight currently.\n\nMoving on to their arms:\n- Their right arm seems bent at elbow with wrist lower than shoulder level. This could mean they are holding or lifting something.\n- Similarly for the left arm where elbow is also bent but wrist is almost aligned with shoulder suggesting it's readying to lift or already holding onto something.\n\nTheir torso shows an upright position given by pelvis coordinate at center point between hips (865,508) and thorax coordinate above it at higher y-value(876 ,397).\n\nFinally considering head position using upper neck keypoint(875 ,390) and head top keypoint(873 ,325), it can be inferred that they are looking straight ahead or slightly upwards which aligns with other observations suggesting active engagement in physical work.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[878,493],&quot;id&quot;:0,&quot;kpts&quot;:[[836,666],[841,595],[830,500],[900,515],[895,593],[912,691],[865,508],[876,397],[875.7539,390.6023],[873.2461,325.3977],[775,457],[817,441],[844,390],[907,404],[898,460],[862,504]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.957582}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      878,\n      493\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        836,\n        666\n      ],\n      [\n        841,\n        595\n      ],\n      [\n        830,\n        500\n      ],\n      [\n        900,\n        515\n      ],\n      [\n        895,\n        593\n      ],\n      [\n        912,\n        691\n      ],\n      [\n        865,\n        508\n      ],\n      [\n        876,\n        397\n      ],\n      [\n        875.7539,\n        390.6023\n      ],\n      [\n        873.2461,\n        325.3977\n      ],\n      [\n        775,\n        457\n      ],\n      [\n        817,\n        441\n      ],\n      [\n        844,\n        390\n      ],\n      [\n        907,\n        404\n      ],\n      [\n        898,\n        460\n      ],\n      [\n        862,\n        504\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.957582\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:459,&quot;string&quot;:&quot;459&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;094888554.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:21,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. The activity involves a lot of physical work and movement.\n\nThe person centered at coordinates (359.0, 460.0) is captured performing an action with their limbs positioned as follows:\n\nThe left leg's hip joint is visible at (227,655), but the knee and ankle joints are not visible in the image which might suggest that the leg could be bent or obscured from view.\n\nThe right leg's hip joint can be seen at (118,644), but like the left leg, its knee and ankle joints are not visible either implying similar possibilities.\n\nTheir pelvis can be identified at point (173,650) indicating an upright posture considering its relative position to other visible points.\n\nFor their upper body; starting with their right arm: The shoulder joint is located at point (228,275), elbow joint at point (180,540) while wrist joint is placed further down towards pelvis level at point (430,592). This suggests that they're possibly reaching out or holding onto something with their right hand.\n \nTheir left arm's shoulder can be seen higher up around thorax level on coordinates (401 ,355). The elbow appears to be slightly bent given its position on coordinates(336 ,506). Finally their left wrist seems to have moved closer towards center of body near pelvis area as it's located on coordinates(342 ,603).\n\nTheir torso has key points marked from thorax located around middle of frame(315 ,315), going upwards through neck region placed higher up(364 ,271) till top of head marked by highest point in frame(535 ,124).\n\nThis pose indicates that they may be involved in a task requiring them to reach out for objects while maintaining an upright stance.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[359,460],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[118,644],[227,655],[-1,-1],[-1,-1],[173,650],[315,315],[364.6897,271.9356],[535.3103,124.0644],[430,592],[180,540],[228,275],[401,355],[336,506],[342,603]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:6.773445}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      359,\n      460\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        118,\n        644\n      ],\n      [\n        227,\n        655\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        173,\n        650\n      ],\n      [\n        315,\n        315\n      ],\n      [\n        364.6897,\n        271.9356\n      ],\n      [\n        535.3103,\n        124.0644\n      ],\n      [\n        430,\n        592\n      ],\n      [\n        180,\n        540\n      ],\n      [\n        228,\n        275\n      ],\n      [\n        401,\n        355\n      ],\n      [\n        336,\n        506\n      ],\n      [\n        342,\n        603\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 6.773445\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:577,&quot;string&quot;:&quot;577&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;096563203.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:22,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in an occupation-related activity, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. \n\nThe centrally-located person is seen standing with their limbs in motion indicative of the described activities.\n\nStarting with the legs:\n- The right leg appears to be slightly bent at the knee and hip. The right ankle seems to be firmly planted on the ground indicating weight-bearing.\n- The left leg also appears to be slightly bent at the knee but more so at the hip than its counterpart. Like its counterpart, it also seems to bear some weight.\n\nMoving on to arms:\n- The right arm appears extended outwards with a noticeable bend at elbow; possibly reaching for something or carrying a load.\n- Similarly, left arm shows an extended pose but much more raised compared to right arm suggesting it could be lifting or supporting something heavy.\n\nAs for torso and head:\n- The torso leans slightly towards their right side indicating possible effort or strain from lifting or carrying.\n- Their head seems tilted upwards perhaps looking towards where they are reaching or lifting.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[454,336],&quot;id&quot;:0,&quot;kpts&quot;:[[409,642],[425,535],[410,402],[498,398],[519,505],[517,619],[454,400],[508,242],[514.0306,232.5234],[564.9694,152.4766],[346,378],[370,296],[452,228],[563,255],[632,318],[728,304]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.846404}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      454,\n      336\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        409,\n        642\n      ],\n      [\n        425,\n        535\n      ],\n      [\n        410,\n        402\n      ],\n      [\n        498,\n        398\n      ],\n      [\n        519,\n        505\n      ],\n      [\n        517,\n        619\n      ],\n      [\n        454,\n        400\n      ],\n      [\n        508,\n        242\n      ],\n      [\n        514.0306,\n        232.5234\n      ],\n      [\n        564.9694,\n        152.4766\n      ],\n      [\n        346,\n        378\n      ],\n      [\n        370,\n        296\n      ],\n      [\n        452,\n        228\n      ],\n      [\n        563,\n        255\n      ],\n      [\n        632,\n        318\n      ],\n      [\n        728,\n        304\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.846404\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:748,&quot;string&quot;:&quot;748&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:707,&quot;string&quot;:&quot;707&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;030461377.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:23,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. The person's pose suggests that they are currently engaged in a task that involves lifting or carrying.\n\nThe centrally located person is relatively large scale with their limbs mostly visible except for the legs. \n\nTheir right leg appears to be slightly bent at the hip and positioned towards the left side of their body. However, due to invisible knee and ankle keypoints it's not possible to provide more detailed information about the right leg.\n\nTheir left leg seems straight with hip joint being higher than right one indicating potential lifting of their left side. But again due to missing knee and ankle keypoints precise state cannot be predicted.\n\nThe torso appears upright with pelvis slightly tilted towards right indicating weight transfer or balance maintenance during lifting action.\n\nThe head seems tilted upward which might suggest looking at an object above or preparing for a lift motion.\n\nTheir right arm appears extended outwards with elbow joint showing high bend angle suggesting holding or grabbing something perhaps related to loading activity.\n\nTheir left arm also seems extended outwards but less than the right one with wrist being higher than elbow possibly supporting holding position of other arm or readying for another task.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[201,256],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[211,364],[287,346],[-1,-1],[-1,-1],[249,355],[224,171],[232.9115,147.0199],[270.0885,46.9801],[270,295],[171,316],[178,177],[270,164],[296,247],[297,287]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.20173}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      201,\n      256\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        211,\n        364\n      ],\n      [\n        287,\n        346\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        249,\n        355\n      ],\n      [\n        224,\n        171\n      ],\n      [\n        232.9115,\n        147.0199\n      ],\n      [\n        270.0885,\n        46.9801\n      ],\n      [\n        270,\n        295\n      ],\n      [\n        171,\n        316\n      ],\n      [\n        178,\n        177\n      ],\n      [\n        270,\n        164\n      ],\n      [\n        296,\n        247\n      ],\n      [\n        297,\n        287\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.20173\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:30,&quot;string&quot;:&quot;30&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;009767211.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:24,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in an occupation, specifically truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. The activity involves a lot of physical work and movement.\n\nThe person located near the center of the image is captured in mid-action with their limbs positioned for carrying out heavy-duty tasks.\n\nStarting with the legs, their right leg appears to be bent at the knee with the hip joint visible. The right ankle isn't visible in this pose. The left leg seems to be slightly bent at both hip and knee joints while left ankle isn't visible either indicating that they might be standing on uneven ground or stepping on something not captured within frame.\n\nMoving onto their torso region - it's inclined towards right side suggesting they're leaning or reaching out for something. Their pelvis area shows a slight tilt towards right which aligns with overall posture.\n\nTheir arms seem to be actively engaged as well; right arm appears slightly bent at elbow joint while wrist joint is aligned straight suggesting holding or lifting action. Left arm seems more flexed than right one with elbow pointing downwards indicating a firm grip on object being handled.\n\nLastly, their head position suggests attention focused downwards possibly checking footing or inspecting object being handled.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[424,298],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[474,452],[560,290],[493,322],[402,460],[-1,-1],[527,306],[416,201],[401.5918,197.7582],[310.4082,177.2418],[467,304],[466,271],[446,160],[385,242],[409,357],[393,426]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.803894}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      424,\n      298\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        474,\n        452\n      ],\n      [\n        560,\n        290\n      ],\n      [\n        493,\n        322\n      ],\n      [\n        402,\n        460\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        527,\n        306\n      ],\n      [\n        416,\n        201\n      ],\n      [\n        401.5918,\n        197.7582\n      ],\n      [\n        310.4082,\n        177.2418\n      ],\n      [\n        467,\n        304\n      ],\n      [\n        466,\n        271\n      ],\n      [\n        446,\n        160\n      ],\n      [\n        385,\n        242\n      ],\n      [\n        409,\n        357\n      ],\n      [\n        393,\n        426\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.803894\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:91,&quot;string&quot;:&quot;91&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;068423303.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:25,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is performing occupational tasks related to truck driving, specifically loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. This activity involves significant physical movement and exertion.\n\nThe person centered at coordinates (285.0, 235.0) appears to be in the midst of moving or lifting an object with their left arm extended outward. Their right arm isn't visible within the frame of the image.\n\nAs for their legs and lower body, these parts are not visible within this frame either; therefore it's not possible to determine their stance or foot placement.\n\nTheir torso is slightly leaning towards the left side indicating some sort of action being performed using their left arm. The angle between their upper neck (keypoint 8) and thorax (keypoint 7), suggests that they are looking straight ahead or possibly downwards at what they're doing.\n\nThe head seems to be tilted downward slightly as indicated by the position of upper neck (keypoint 8) compared to head top (keypoint 9). This suggests that they might be focusing on something below their eye level - possibly on a task at hand like tying down load or picking up something heavy.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[285,235],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[166,305],[180.5447,264.2038],[233.4553,115.7962],[-1,-1],[-1,-1],[116,321],[215,288],[295,300],[386,302]],&quot;kpts_vis&quot;:[0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,1],&quot;scale&quot;:4.726721}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      285,\n      235\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        166,\n        305\n      ],\n      [\n        180.5447,\n        264.2038\n      ],\n      [\n        233.4553,\n        115.7962\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        116,\n        321\n      ],\n      [\n        215,\n        288\n      ],\n      [\n        295,\n        300\n      ],\n      [\n        386,\n        302\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.726721\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:298,&quot;string&quot;:&quot;298&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;044015249.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:26,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in the activity of truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. This activity involves a wide range of movements and positions that can be seen through the keypoints.\n\nThe person located towards the center-right part of the image is standing with their body slightly turned to their left. \n\nTheir right leg appears to be straight with their right ankle positioned below their right knee which aligns vertically with the hip. The left leg seems to be bending at the knee as indicated by alignment of left hip, knee and ankle.\n\nThe person's torso leans slightly forward while maintaining an upright position from pelvis through thorax to upper neck.\n\nTheir head is tilted downward as seen from alignment between upper neck and top of head keypoints. \n\nThe right arm appears bent at elbow forming an acute angle with wrist lower than shoulder level indicating possible carrying or lifting action. The left arm also shows similar bend but it's more extended outwards possibly for balance or grasping something.\n\nOverall pose suggests that this individual might be involved in lifting or moving heavy objects typically found during loading/unloading activities in truck driving occupation.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[452,261],&quot;id&quot;:0,&quot;kpts&quot;:[[466,365],[493,284],[518,179],[591,163],[520,356],[509,476],[555,171],[427,140],[416.801,136.9332],[294.199,100.0668],[300,293],[351,229],[378,140],[475,139],[578,225],[520,310]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.84075}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      452,\n      261\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        466,\n        365\n      ],\n      [\n        493,\n        284\n      ],\n      [\n        518,\n        179\n      ],\n      [\n        591,\n        163\n      ],\n      [\n        520,\n        356\n      ],\n      [\n        509,\n        476\n      ],\n      [\n        555,\n        171\n      ],\n      [\n        427,\n        140\n      ],\n      [\n        416.801,\n        136.9332\n      ],\n      [\n        294.199,\n        100.0668\n      ],\n      [\n        300,\n        293\n      ],\n      [\n        351,\n        229\n      ],\n      [\n        378,\n        140\n      ],\n      [\n        475,\n        139\n      ],\n      [\n        578,\n        225\n      ],\n      [\n        520,\n        310\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.84075\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:600,&quot;string&quot;:&quot;600&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;012203823.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:27,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads.\n\nThe person located at the center of the image appears to be standing upright with their body slightly turned towards their right. Their right leg seems to be bent at the knee and hip while their left leg seems straight but slightly bent at the hip. The left ankle is not visible which might suggest that it's behind or obscured by something.\n\nTheir torso is upright with their pelvis shifted slightly towards their left. The thorax appears to be leaning towards the right indicating a slight twist in the upper body.\n\nThe head of this individual is tilted upwards as indicated by relative positions of upper neck and head top keypoints.\n\nAs for arms, they are both raised. The right arm seems to be extended outward with a bend at elbow while holding onto something heavy as suggested by activity context. Meanwhile, left arm appears flexed at elbow forming an approximate 90-degree angle with shoulder joint.\n\nOverall, this pose suggests that this person might be in process of lifting or moving heavy objects possibly during loading or unloading a truck.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[116,182],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[189,473],[91,299],[39,276],[118,467],[-1,-1],[65,288],[122,85],[132.94,76.4196],[213.06,13.5804],[238,291],[199,234],[158,103],[86,67],[141,174],[183,248]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.054701}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      116,\n      182\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        189,\n        473\n      ],\n      [\n        91,\n        299\n      ],\n      [\n        39,\n        276\n      ],\n      [\n        118,\n        467\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        65,\n        288\n      ],\n      [\n        122,\n        85\n      ],\n      [\n        132.94,\n        76.4196\n      ],\n      [\n        213.06,\n        13.5804\n      ],\n      [\n        238,\n        291\n      ],\n      [\n        199,\n        234\n      ],\n      [\n        158,\n        103\n      ],\n      [\n        86,\n        67\n      ],\n      [\n        141,\n        174\n      ],\n      [\n        183,\n        248\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.054701\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:889,&quot;string&quot;:&quot;889&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:714,&quot;string&quot;:&quot;714&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;049517691.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:28,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are seven people in the image who are participating in synchronized swimming. All of them seem to be executing a similar pose, which is likely part of their routine. Each person's limbs and torso appear to be positioned in a way that suggests they are either moving through water or preparing to dive.\n\nThe first person is located towards the left side of the image and appears to be leaning slightly forward with their right leg bent at the knee and extended backward. Their arms are raised above their head, with elbows bent at approximately 90 degrees.\n\nThe second individual is situated near the center-left of the image. They also have their right leg extended backward but it seems less bent than that of the first person. Their arms appear straighter as well, extending diagonally upward from their shoulders.\n\nPerson three, located at center-middle position, has both legs slightly spread apart with knees slightly bent. This individual's arms seem to be reaching out horizontally on either side, forming an almost straight line perpendicular to their body.\n\nThe fourth individual is positioned near center-right and seems to have a similar pose as person three but with legs more spread apart and knees more visibly bent. Their arms also extend outward from shoulders like third person's but appear less straightened.\n\nPerson five is found towards far-right center area and displays a unique posture among all individuals - while others' right legs were extended backwards or apart from left leg; this one has both legs close together giving impression they're standing upright underwater possibly supported by toes' contact with pool floor or due buoyancy effect. Arms' positioning resembles those seen in persons two &amp; four.\n\nMoving further rightwards we see sixth swimmer who mirrors fifth one's stance except for slight differences - left arm isn't fully stretched out &amp; there appears some bend at elbow; moreover both feet aren't visible so can't confirm if they're standing like fifth swimmer or floating mid-water while maintaining vertical alignment of body parts.\n\nFinally seventh participant situated extreme far-right does an almost perfect imitation of sixth one's pose barring minor variations - for instance: unlike sixth swimmer whose head was tilted upwards facing skyward direction indicating possible inhalation before submersion; this one looks directly ahead perhaps focusing on synchronizing movements with teammates.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[327,208],&quot;id&quot;:0,&quot;kpts&quot;:[[349,393],[298,350],[318,236],[355,231],[354,351],[363,441],[337,234],[341,152],[338.8426,128.0531],[333.1574,64.9469],[305,103],[275,158],[312,145],[370,159],[377,223],[398,276]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.900855},{&quot;center&quot;:[468,306],&quot;id&quot;:1,&quot;kpts&quot;:[[411,397],[384,311],[457,306],[486,315],[450,421],[480,474],[472,311],[464,220],[461.7728,205.2052],[452.2272,141.7948],[400,216],[406,257],[441,213],[487,227],[442,277],[404,320]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.923746},{&quot;center&quot;:[599,334],&quot;id&quot;:2,&quot;kpts&quot;:[[577,467],[556,403],[624,311],[578,313],[585,415],[608,470],[601,312],[607,240],[604.4911,216.9637],[598.5089,162.0363],[624,361],[630,289],[636,238],[577,241],[547,286],[522,329]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.657564},{&quot;center&quot;:[749,315],&quot;id&quot;:3,&quot;kpts&quot;:[[723,485],[699,433],[756,330],[715,333],[717,438],[736,503],[736,332],[745,251],[745.6255,227.4393],[747.3745,161.5607],[782,368],[778,319],[777,253],[713,248],[680,306],[640,355]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.977052},{&quot;center&quot;:[869,305],&quot;id&quot;:4,&quot;kpts&quot;:[[794,490],[797,412],[805,301],[859,294],[863,416],[857,496],[832,298],[840,226],[842.9392,220.4311],[875.0608,159.5689],[880,207],[851,244],[809,222],[871,230],[871,286],[870,335]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.064558},{&quot;center&quot;:[992,356],&quot;id&quot;:5,&quot;kpts&quot;:[[903,519],[920,447],[941,342],[982,351],[994,447],[993,533],[962,347],[971,245],[972.1366,241.7266],[994.8634,176.2734],[1005,221],[991,269],[946,243],[995,246],[999,311],[1002,365]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.0786},{&quot;center&quot;:[1076,317],&quot;id&quot;:6,&quot;kpts&quot;:[[1032,537],[1043,462],[1050,343],[1098,351],[1115,457],[1116,542],[1074,347],[1076,254],[1077.5291,251.6877],[1115.4709,194.3123],[1124,252],[1104,292],[1047,258],[1104,249],[1107,306],[1109,356]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.063581}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      327,\n      208\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        349,\n        393\n      ],\n      [\n        298,\n        350\n      ],\n      [\n        318,\n        236\n      ],\n      [\n        355,\n        231\n      ],\n      [\n        354,\n        351\n      ],\n      [\n        363,\n        441\n      ],\n      [\n        337,\n        234\n      ],\n      [\n        341,\n        152\n      ],\n      [\n        338.8426,\n        128.0531\n      ],\n      [\n        333.1574,\n        64.9469\n      ],\n      [\n        305,\n        103\n      ],\n      [\n        275,\n        158\n      ],\n      [\n        312,\n        145\n      ],\n      [\n        370,\n        159\n      ],\n      [\n        377,\n        223\n      ],\n      [\n        398,\n        276\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.900855\n  },\n  {\n    \&quot;center\&quot;: [\n      468,\n      306\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        411,\n        397\n      ],\n      [\n        384,\n        311\n      ],\n      [\n        457,\n        306\n      ],\n      [\n        486,\n        315\n      ],\n      [\n        450,\n        421\n      ],\n      [\n        480,\n        474\n      ],\n      [\n        472,\n        311\n      ],\n      [\n        464,\n        220\n      ],\n      [\n        461.7728,\n        205.2052\n      ],\n      [\n        452.2272,\n        141.7948\n      ],\n      [\n        400,\n        216\n      ],\n      [\n        406,\n        257\n      ],\n      [\n        441,\n        213\n      ],\n      [\n        487,\n        227\n      ],\n      [\n        442,\n        277\n      ],\n      [\n        404,\n        320\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.923746\n  },\n  {\n    \&quot;center\&quot;: [\n      599,\n      334\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        577,\n        467\n      ],\n      [\n        556,\n        403\n      ],\n      [\n        624,\n        311\n      ],\n      [\n        578,\n        313\n      ],\n      [\n        585,\n        415\n      ],\n      [\n        608,\n        470\n      ],\n      [\n        601,\n        312\n      ],\n      [\n        607,\n        240\n      ],\n      [\n        604.4911,\n        216.9637\n      ],\n      [\n        598.5089,\n        162.0363\n      ],\n      [\n        624,\n        361\n      ],\n      [\n        630,\n        289\n      ],\n      [\n        636,\n        238\n      ],\n      [\n        577,\n        241\n      ],\n      [\n        547,\n        286\n      ],\n      [\n        522,\n        329\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.657564\n  },\n  {\n    \&quot;center\&quot;: [\n      749,\n      315\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        723,\n        485\n      ],\n      [\n        699,\n        433\n      ],\n      [\n        756,\n        330\n      ],\n      [\n        715,\n        333\n      ],\n      [\n        717,\n        438\n      ],\n      [\n        736,\n        503\n      ],\n      [\n        736,\n        332\n      ],\n      [\n        745,\n        251\n      ],\n      [\n        745.6255,\n        227.4393\n      ],\n      [\n        747.3745,\n        161.5607\n      ],\n      [\n        782,\n        368\n      ],\n      [\n        778,\n        319\n      ],\n      [\n        777,\n        253\n      ],\n      [\n        713,\n        248\n      ],\n      [\n        680,\n        306\n      ],\n      [\n        640,\n        355\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.977052\n  },\n  {\n    \&quot;center\&quot;: [\n      869,\n      305\n    ],\n    \&quot;id\&quot;: 4,\n    \&quot;kpts\&quot;: [\n      [\n        794,\n        490\n      ],\n      [\n        797,\n        412\n      ],\n      [\n        805,\n        301\n      ],\n      [\n        859,\n        294\n      ],\n      [\n        863,\n        416\n      ],\n      [\n        857,\n        496\n      ],\n      [\n        832,\n        298\n      ],\n      [\n        840,\n        226\n      ],\n      [\n        842.9392,\n        220.4311\n      ],\n      [\n        875.0608,\n        159.5689\n      ],\n      [\n        880,\n        207\n      ],\n      [\n        851,\n        244\n      ],\n      [\n        809,\n        222\n      ],\n      [\n        871,\n        230\n      ],\n      [\n        871,\n        286\n      ],\n      [\n        870,\n        335\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.064558\n  },\n  {\n    \&quot;center\&quot;: [\n      992,\n      356\n    ],\n    \&quot;id\&quot;: 5,\n    \&quot;kpts\&quot;: [\n      [\n        903,\n        519\n      ],\n      [\n        920,\n        447\n      ],\n      [\n        941,\n        342\n      ],\n      [\n        982,\n        351\n      ],\n      [\n        994,\n        447\n      ],\n      [\n        993,\n        533\n      ],\n      [\n        962,\n        347\n      ],\n      [\n        971,\n        245\n      ],\n      [\n        972.1366,\n        241.7266\n      ],\n      [\n        994.8634,\n        176.2734\n      ],\n      [\n        1005,\n        221\n      ],\n      [\n        991,\n        269\n      ],\n      [\n        946,\n        243\n      ],\n      [\n        995,\n        246\n      ],\n      [\n        999,\n        311\n      ],\n      [\n        1002,\n        365\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.0786\n  },\n  {\n    \&quot;center\&quot;: [\n      1076,\n      317\n    ],\n    \&quot;id\&quot;: 6,\n    \&quot;kpts\&quot;: [\n      [\n        1032,\n        537\n      ],\n      [\n        1043,\n        462\n      ],\n      [\n        1050,\n        343\n      ],\n      [\n        1098,\n        351\n      ],\n      [\n        1115,\n        457\n      ],\n      [\n        1116,\n        542\n      ],\n      [\n        1074,\n        347\n      ],\n      [\n        1076,\n        254\n      ],\n      [\n        1077.5291,\n        251.6877\n      ],\n      [\n        1115.4709,\n        194.3123\n      ],\n      [\n        1124,\n        252\n      ],\n      [\n        1104,\n        292\n      ],\n      [\n        1047,\n        258\n      ],\n      [\n        1104,\n        249\n      ],\n      [\n        1107,\n        306\n      ],\n      [\n        1109,\n        356\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.063581\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:4,&quot;string&quot;:&quot;4&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1456,&quot;string&quot;:&quot;1,456&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:7,&quot;string&quot;:&quot;7&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;water activities, swimming, synchronized&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;003438852.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:7,&quot;string&quot;:&quot;7&quot;}}},{&quot;rowIdx&quot;:29,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are three people in the image who are sitting quietly. Given the activity, it can be inferred that their body postures are relaxed, with most of them having their legs and arms bent.\n\nThe first person located towards the left side of the image is sitting with their right leg folded up towards their chest. Their right arm appears to be resting on this leg as both the elbow and wrist keypoints align closely with it. The left shoulder is raised slightly higher than the right, suggesting a slight tilt or turn in torso.\n\nThe second person situated around center of image has both legs bent at similar angles, possibly indicating they're seated on a flat surface like chair or floor. They have raised their right arm slightly higher than shoulder level while left arm seems to be resting more naturally.\n\nFinally, the third person positioned towards the right side of image is also seated but with only visible data for one leg which appears to be stretched out or leaning against something given its alignment with hip joint. They have both arms bent at elbows where left arm seems to extend forward while right one rests lower down near waist level.\n\nAll three individuals' upper bodies appear upright based on thorax and neck keypoints positioning relative to pelvis points. Head position also remains fairly central over torso across all three persons which further suggests an overall relaxed posture during this quiet/light activity.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[191,283],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[135,404],[253,411],[-1,-1],[-1,-1],[194,408],[238,210],[232.8147,177.994],[214.1853,63.006],[136,407],[119,331],[150,211],[326,208],[315,364],[187,394]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.494618},{&quot;center&quot;:[453,373],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[308,464],[386,395],[516,415],[344,465],[-1,-1],[451,405],[466,231],[464.3743,194.4217],[459.6257,87.5783],[370,399],[384,362],[394,228],[537,234],[547,391],[412,412]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.208469},{&quot;center&quot;:[733,341],&quot;id&quot;:2,&quot;kpts&quot;:[[-1,-1],[-1,-1],[616,417],[742,437],[-1,-1],[-1,-1],[679,427],[721,232],[706.7914,182.4918],[671.2086,58.5082],[531,328],[603,354],[622,227],[819,237],[820,390],[727,410]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.86966}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      191,\n      283\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        135,\n        404\n      ],\n      [\n        253,\n        411\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        194,\n        408\n      ],\n      [\n        238,\n        210\n      ],\n      [\n        232.8147,\n        177.994\n      ],\n      [\n        214.1853,\n        63.006\n      ],\n      [\n        136,\n        407\n      ],\n      [\n        119,\n        331\n      ],\n      [\n        150,\n        211\n      ],\n      [\n        326,\n        208\n      ],\n      [\n        315,\n        364\n      ],\n      [\n        187,\n        394\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.494618\n  },\n  {\n    \&quot;center\&quot;: [\n      453,\n      373\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        308,\n        464\n      ],\n      [\n        386,\n        395\n      ],\n      [\n        516,\n        415\n      ],\n      [\n        344,\n        465\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        451,\n        405\n      ],\n      [\n        466,\n        231\n      ],\n      [\n        464.3743,\n        194.4217\n      ],\n      [\n        459.6257,\n        87.5783\n      ],\n      [\n        370,\n        399\n      ],\n      [\n        384,\n        362\n      ],\n      [\n        394,\n        228\n      ],\n      [\n        537,\n        234\n      ],\n      [\n        547,\n        391\n      ],\n      [\n        412,\n        412\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.208469\n  },\n  {\n    \&quot;center\&quot;: [\n      733,\n      341\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        616,\n        417\n      ],\n      [\n        742,\n        437\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        679,\n        427\n      ],\n      [\n        721,\n        232\n      ],\n      [\n        706.7914,\n        182.4918\n      ],\n      [\n        671.2086,\n        58.5082\n      ],\n      [\n        531,\n        328\n      ],\n      [\n        603,\n        354\n      ],\n      [\n        622,\n        227\n      ],\n      [\n        819,\n        237\n      ],\n      [\n        820,\n        390\n      ],\n      [\n        727,\n        410\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.86966\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:877,&quot;string&quot;:&quot;877&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:187,&quot;string&quot;:&quot;187&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:134,&quot;string&quot;:&quot;134&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;inactivity quiet/light, sitting quietly&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;031171108.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;}}},{&quot;rowIdx&quot;:30,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are four people in the image who are participating in synchronized swimming. The activity involves maintaining a coordinated body pose while in water. It requires strength, flexibility, and precision.\n\nThe first person is located towards the left side of the image and appears to be moving upwards with their body slightly tilted to the right. Their right leg is bent at the knee and hip, while their left leg seems straighter with a slight bend at knee. Both arms are extended outwards, with elbows slightly bent forming an arc shape. The head is tilted backwards.\n\nThe second person is positioned near the center of the image and appears to be floating on water surface with their body oriented upwards. Their legs appear straighter than their arms which are fully extended above their head forming a 'V' shape. The head is also tilted backwards similar to first person.\n\nThe third individual can be seen towards right side of center position in an upright pose as if they're rising from water surface or hovering on it. Their legs seem straight whereas arms form an inverted 'V' shape above them similar to second individual's arm position but lower down closer to face level.\n\nLastly, fourth person can be seen on extreme right side appearing as if they're about to dive into water or just came out from it due its forward tilt orientation compared other individuals who have upward orientation instead. Legs seem semi-bent at knees while arms form a 'U' shape below them indicating possible diving motion or preparation for next move by pushing against water surface for propulsion force.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[159,294],&quot;id&quot;:0,&quot;kpts&quot;:[[110,330],[134,338],[118,298],[144,311],[153,338],[125,336],[131,305],[173,296],[171.63,297.2558],[198.37,272.7442],[107,286],[137,272],[162,289],[184,302],[200,321],[223,330]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.088235},{&quot;center&quot;:[338,251],&quot;id&quot;:1,&quot;kpts&quot;:[[306,358],[331,320],[324,260],[341,268],[351,320],[326,355],[333,264],[363,206],[362.5363,205.0436],[347.4637,173.9564],[352,155],[347,180],[365,206],[361,206],[389,176],[385,162]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.036455},{&quot;center&quot;:[514,224],&quot;id&quot;:2,&quot;kpts&quot;:[[510,366],[499,317],[507,267],[533,266],[525,318],[537,365],[520,267],[509,207],[511.3591,213.2908],[497.6409,176.7092],[466,166],[476,188],[493,207],[524,206],[530,175],[524,159]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.172075},{&quot;center&quot;:[681,315],&quot;id&quot;:3,&quot;kpts&quot;:[[712,360],[682,330],[705,312],[728,309],[702,327],[726,356],[717,311],[680,286],[681.7108,288.6613],[660.2892,255.3387],[643,323],[659,309],[663,286],[696,286],[724,296],[749,306]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.188424}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      159,\n      294\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        110,\n        330\n      ],\n      [\n        134,\n        338\n      ],\n      [\n        118,\n        298\n      ],\n      [\n        144,\n        311\n      ],\n      [\n        153,\n        338\n      ],\n      [\n        125,\n        336\n      ],\n      [\n        131,\n        305\n      ],\n      [\n        173,\n        296\n      ],\n      [\n        171.63,\n        297.2558\n      ],\n      [\n        198.37,\n        272.7442\n      ],\n      [\n        107,\n        286\n      ],\n      [\n        137,\n        272\n      ],\n      [\n        162,\n        289\n      ],\n      [\n        184,\n        302\n      ],\n      [\n        200,\n        321\n      ],\n      [\n        223,\n        330\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.088235\n  },\n  {\n    \&quot;center\&quot;: [\n      338,\n      251\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        306,\n        358\n      ],\n      [\n        331,\n        320\n      ],\n      [\n        324,\n        260\n      ],\n      [\n        341,\n        268\n      ],\n      [\n        351,\n        320\n      ],\n      [\n        326,\n        355\n      ],\n      [\n        333,\n        264\n      ],\n      [\n        363,\n        206\n      ],\n      [\n        362.5363,\n        205.0436\n      ],\n      [\n        347.4637,\n        173.9564\n      ],\n      [\n        352,\n        155\n      ],\n      [\n        347,\n        180\n      ],\n      [\n        365,\n        206\n      ],\n      [\n        361,\n        206\n      ],\n      [\n        389,\n        176\n      ],\n      [\n        385,\n        162\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.036455\n  },\n  {\n    \&quot;center\&quot;: [\n      514,\n      224\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        510,\n        366\n      ],\n      [\n        499,\n        317\n      ],\n      [\n        507,\n        267\n      ],\n      [\n        533,\n        266\n      ],\n      [\n        525,\n        318\n      ],\n      [\n        537,\n        365\n      ],\n      [\n        520,\n        267\n      ],\n      [\n        509,\n        207\n      ],\n      [\n        511.3591,\n        213.2908\n      ],\n      [\n        497.6409,\n        176.7092\n      ],\n      [\n        466,\n        166\n      ],\n      [\n        476,\n        188\n      ],\n      [\n        493,\n        207\n      ],\n      [\n        524,\n        206\n      ],\n      [\n        530,\n        175\n      ],\n      [\n        524,\n        159\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.172075\n  },\n  {\n    \&quot;center\&quot;: [\n      681,\n      315\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        712,\n        360\n      ],\n      [\n        682,\n        330\n      ],\n      [\n        705,\n        312\n      ],\n      [\n        728,\n        309\n      ],\n      [\n        702,\n        327\n      ],\n      [\n        726,\n        356\n      ],\n      [\n        717,\n        311\n      ],\n      [\n        680,\n        286\n      ],\n      [\n        681.7108,\n        288.6613\n      ],\n      [\n        660.2892,\n        255.3387\n      ],\n      [\n        643,\n        323\n      ],\n      [\n        659,\n        309\n      ],\n      [\n        663,\n        286\n      ],\n      [\n        696,\n        286\n      ],\n      [\n        724,\n        296\n      ],\n      [\n        749,\n        306\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.188424\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:4,&quot;string&quot;:&quot;4&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:187,&quot;string&quot;:&quot;187&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:197,&quot;string&quot;:&quot;197&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;water activities, swimming, synchronized&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;052006802.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:4,&quot;string&quot;:&quot;4&quot;}}},{&quot;rowIdx&quot;:31,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is participating in synchronized swimming. This activity typically involves precise and coordinated movements, often with a focus on arm positions and body twists.\n\nThe centrally positioned person seems to be floating on water with their body slightly twisted. \n\nTheir right leg is invisible, suggesting it's either submerged or behind the body. The same goes for the left leg.\n\nThe torso appears to be twisted as the thorax and pelvis keypoints are not visible. This indicates a possible rotation of the upper body.\n\nTheir head is tilted upwards as indicated by the large vertical distance between upper neck and head top keypoints, possibly looking towards the sky or ceiling.\n\nThe right arm seems to be fully extended above their head, judging from wrist to elbow keypoint positions relative to shoulder keypoint.\n\nTheir left arm appears bent at a sharp angle judging from wrist position relative to elbow and shoulder keypoints, likely performing a specific pose or movement typical in synchronized swimming.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[362,181],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[417,243],[417.9901,234.5243],[441.0099,37.4757],[433,291],[233,302],[308,234],[525,252],[733,282],[541,301]],&quot;kpts_vis&quot;:[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.951661}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      362,\n      181\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        417,\n        243\n      ],\n      [\n        417.9901,\n        234.5243\n      ],\n      [\n        441.0099,\n        37.4757\n      ],\n      [\n        433,\n        291\n      ],\n      [\n        233,\n        302\n      ],\n      [\n        308,\n        234\n      ],\n      [\n        525,\n        252\n      ],\n      [\n        733,\n        282\n      ],\n      [\n        541,\n        301\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.951661\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:4,&quot;string&quot;:&quot;4&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:187,&quot;string&quot;:&quot;187&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:288,&quot;string&quot;:&quot;288&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;water activities, swimming, synchronized&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;054671028.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:32,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in home activities, specifically scrubbing floors. This activity typically involves a bent posture, with the person's body close to the floor and their arms actively engaged.\n\nThe center-positioned person is likely kneeling or squatting down with their body close to the ground as they scrub the floor. \n\nStarting with their legs: \nThe right leg appears to be folded at the knee and positioned under or behind them, as indicated by keypoint coordinates of right ankle (1087, 973), right knee (657, 915), and right hip (963, 802). The left leg seems to be extended forward or sideways from what can be seen from left hip (1241,812), left knee (1403,909) and left ankle coordinates(1041,910).\n\nMoving on to their torso:\nIt seems slightly bent forward given that pelvis point (1102,807) is closer vertically to thorax point(1089 ,384) than it would typically be in an upright standing pose.\n\nTheir head:\nConsidering upper neck point(1089 ,301) and head top point(1091 ,26), it appears that they are looking downwards possibly focusing on where they're scrubbing.\n\nRegarding arms:\nThe right arm appears extended towards ground which might indicate active engagement in scrubbing action. This can be inferred from wrist position at lower height than elbow for both arms - Right wrist(984 ,841), Right elbow(906 ,700), Left wrist(1316 ,555), Left elbow(1271 ,742). The exact direction of arm movement cannot be determined without temporal information but this static pose suggests an ongoing activity involving hands.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1101,700],&quot;id&quot;:0,&quot;kpts&quot;:[[1087,973],[657,915],[963,802],[1241,812],[1403,909],[1041,910],[1102,807],[1089,384],[1089.5645,301.2061],[1091.4355,26.7939],[984,841],[906,700],[908,397],[1270,371],[1271,742],[1316,555]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:8.23256}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1101,\n      700\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        1087,\n        973\n      ],\n      [\n        657,\n        915\n      ],\n      [\n        963,\n        802\n      ],\n      [\n        1241,\n        812\n      ],\n      [\n        1403,\n        909\n      ],\n      [\n        1041,\n        910\n      ],\n      [\n        1102,\n        807\n      ],\n      [\n        1089,\n        384\n      ],\n      [\n        1089.5645,\n        301.2061\n      ],\n      [\n        1091.4355,\n        26.7939\n      ],\n      [\n        984,\n        841\n      ],\n      [\n        906,\n        700\n      ],\n      [\n        908,\n        397\n      ],\n      [\n        1270,\n        371\n      ],\n      [\n        1271,\n        742\n      ],\n      [\n        1316,\n        555\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 8.23256\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:868,&quot;string&quot;:&quot;868&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2575,&quot;string&quot;:&quot;2,575&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:12,&quot;string&quot;:&quot;12&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, scrubbing floors&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;018485446.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:33,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is performing light effort home activities, specifically mopping while standing. This activity involves using both arms, mainly the right arm for holding and maneuvering the mop, with a slight bending of the knees and a firm stance for balance.\n\nThe person located at center coordinates (452.0, 226.0) with a scale of 3.535176 is standing upright with their limbs in various positions.\n\nTheir left leg seems to be invisible or obscured from view as there are no visible keypoints for the left ankle and knee. The right leg appears to be slightly bent at the knee as suggested by relative positions of right hip (381,327) and right knee (379,472).\n\nThe torso appears straight given that thorax (439,142) lies relatively vertically above pelvis point (430,327). \n\nThe head seems to be looking straight ahead or slightly upwards considering upper neck point at (439,134) lies just below head top point at (450,16).\n\nFor arms: The right arm appears bent significantly at elbow while holding something - possibly a mop; this can be inferred from relative positions of right wrist (346,323), elbow(343,242), shoulder(378,143). The left arm also seems bent but less than the other one; it may be supporting action of holding mop as suggested by points corresponding to left wrist(514288), elbow(579221), shoulder(500141).&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[452,226],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[379,472],[381,327],[479,326],[447,470],[-1,-1],[430,327],[439,142],[439.7055,134.1812],[450.2945,16.8188],[346,323],[343,242],[378,143],[500,141],[579,221],[514,288]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.535176}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      452,\n      226\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        379,\n        472\n      ],\n      [\n        381,\n        327\n      ],\n      [\n        479,\n        326\n      ],\n      [\n        447,\n        470\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        430,\n        327\n      ],\n      [\n        439,\n        142\n      ],\n      [\n        439.7055,\n        134.1812\n      ],\n      [\n        450.2945,\n        16.8188\n      ],\n      [\n        346,\n        323\n      ],\n      [\n        343,\n        242\n      ],\n      [\n        378,\n        143\n      ],\n      [\n        500,\n        141\n      ],\n      [\n        579,\n        221\n      ],\n      [\n        514,\n        288\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.535176\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:27,&quot;string&quot;:&quot;27&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;096958463.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:34,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is performing light effort mopping as a home activity. This activity generally involves standing and moving around with a mop, requiring the use of both arms and legs, with occasional bending at the waist.\n\nThe centrally positioned person is caught mid-motion while mopping. They are standing upright with their body slightly tilted towards right.\n\nTheir right leg seems to be bearing most of their weight, as it's straight and firmly planted on the ground from hip (406, 254) to knee (406, 397) and down to ankle (369, 474). The left leg appears slightly bent at the knee (461, 386), suggesting that they're in mid-step or shifting their balance from hip (471, 252) to ankle (448, 470).\n\nThe right arm appears extended but not fully straightened out towards lower-right direction from shoulder (404,97) through elbow (432,193) to wrist(489 ,139). This could be indicative of them holding onto a mop handle. Their left arm is bent at an angle approximately around ninety degrees between shoulder(477 ,100), elbow(496 ,186), and wrist(533 ,246). It might be supporting or balancing out the movement of their right arm.\n\nTheir torso is upright but slightly leaning towards right side indicated by alignment from pelvis point(439 ,253 ) up through thorax point(441 ,99 )to upper neck point(446 ,89 ).\n\nLastly for head positioning; it seems like they are looking downwards given by coordinates between upper neck point(446 ,89 )and top head point position which lies far above on y-axis coordinate at position (492 ,2 ).&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[469,204],&quot;id&quot;:0,&quot;kpts&quot;:[[369,474],[406,397],[406,254],[471,252],[461,386],[448,470],[439,253],[441,99],[446.2789,89.1831],[492.7211,2.8169],[489,139],[432,193],[404,97],[477,100],[496,186],[533,246]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.941836}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      469,\n      204\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        369,\n        474\n      ],\n      [\n        406,\n        397\n      ],\n      [\n        406,\n        254\n      ],\n      [\n        471,\n        252\n      ],\n      [\n        461,\n        386\n      ],\n      [\n        448,\n        470\n      ],\n      [\n        439,\n        253\n      ],\n      [\n        441,\n        99\n      ],\n      [\n        446.2789,\n        89.1831\n      ],\n      [\n        492.7211,\n        2.8169\n      ],\n      [\n        489,\n        139\n      ],\n      [\n        432,\n        193\n      ],\n      [\n        404,\n        97\n      ],\n      [\n        477,\n        100\n      ],\n      [\n        496,\n        186\n      ],\n      [\n        533,\n        246\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.941836\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:91,&quot;string&quot;:&quot;91&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;077513282.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:35,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is doing light effort home activities, specifically mopping while standing. The activity involves movement of arms and torso, with legs providing support.\n\nThe person located at the center of the image has their body facing slightly to the right. Their left leg appears to be supporting most of their weight, while their right leg is partially obscured or not visible.\n\nStarting from the lower body, their right hip joint is visible but both knee and ankle are not detectable. The left hip joint seems slightly raised compared to the right one, possibly due to a slight bend in that leg but it's hard to confirm as neither knee nor ankle on this side are detectable either.\n\nMoving up towards the torso, it's tilted forward indicating a leaning posture which is common during mopping. This can also be inferred from pelvis and thorax keypoints being closer vertically than horizontally.\n\nThe upper body shows more activity - both shoulders are clearly seen with left shoulder being higher than its counterpart indicating an upward arm movement on that side. This can also be confirmed by comparing elbow and wrist positions - left elbow seems bent with wrist positioned near waist level suggesting a grip on mop handle.\n\nOn contrary, right arm appears extended downwards with elbow lower than shoulder level and wrist near waist level - possibly holding bottom part of mop stick for support during cleaning motion.\n\nUnfortunately head top isn't visible but considering neck position relative to shoulders we can assume head faced downwards focusing on cleaning task at hand.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[320,237],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[282,331],[412,360],[-1,-1],[-1,-1],[347,346],[369,91],[371,104],[-1,-1],[221,126],[269,214],[293,84],[445,98],[441,307],[266,266]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,0,1,1,1,1,1,1],&quot;scale&quot;:3.493876}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      320,\n      237\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        282,\n        331\n      ],\n      [\n        412,\n        360\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        347,\n        346\n      ],\n      [\n        369,\n        91\n      ],\n      [\n        371,\n        104\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        221,\n        126\n      ],\n      [\n        269,\n        214\n      ],\n      [\n        293,\n        84\n      ],\n      [\n        445,\n        98\n      ],\n      [\n        441,\n        307\n      ],\n      [\n        266,\n        266\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.493876\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:162,&quot;string&quot;:&quot;162&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;093949894.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:36,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in home activities, specifically mopping with light effort. The activity involves standing and using upper body strength to move the mop.\n\nThe person located near the center of the image appears to be in a slightly leaned forward position, as if they're pushing a mop forward. Their right leg seems to be behind them while their left leg is more forward, suggesting that they are placing most of their weight on their left foot. However, due to missing key points for both knees and ankles, it's difficult to confirm this.\n\nTheir right arm looks extended outwards with a slight bend at the elbow which could indicate holding onto a mop handle. The wrist appears lower than the elbow suggesting that they're applying downward pressure on an object like a mop. Meanwhile, their left arm seems raised with more bend at the elbow compared to right arm which indicates that it's supporting top part of mop handle.\n\nTheir torso leans forward slightly indicating engagement in an activity such as mopping or sweeping. The head tilts upward slightly from neck possibly focusing on area being cleaned.\n\nUnfortunately without visibility of knees and ankles we can't accurately describe leg positions but based on hip positions we can infer about possible stance during this cleaning activity.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[297,216],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[254,318],[357,381],[-1,-1],[-1,-1],[306,350],[309,95],[310.7676,110.3785],[297.2324,-7.3785],[206,226],[192,189],[231,107],[386,83],[336,161],[188,132]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.555971}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      297,\n      216\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        254,\n        318\n      ],\n      [\n        357,\n        381\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        306,\n        350\n      ],\n      [\n        309,\n        95\n      ],\n      [\n        310.7676,\n        110.3785\n      ],\n      [\n        297.2324,\n        -7.3785\n      ],\n      [\n        206,\n        226\n      ],\n      [\n        192,\n        189\n      ],\n      [\n        231,\n        107\n      ],\n      [\n        386,\n        83\n      ],\n      [\n        336,\n        161\n      ],\n      [\n        188,\n        132\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.555971\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:225,&quot;string&quot;:&quot;225&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;089482735.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:37,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is mopping. This activity involves standing and performing a light effort task, typically involving the use of one's arms to move the mop and legs to provide stability.\n\nThe person centered around coordinates (366.0, 242.0) with a scale of 3.370014 is standing upright with their limbs engaged in cleaning activity.\n\nTheir right leg appears straight with the ankle, knee, and hip aligned vertically which provides balance for their stance while mopping. The left leg is slightly bent at the knee suggesting that it bears less weight than the right.\n\nThe right arm has a slight bend at elbow while holding onto what could be assumed as mop handle; wrist positioned lower than elbow indicating grip on an object below shoulder level. The left arm appears extended outwards from body possibly maintaining balance or holding another part of mop handle; there's a noticeable bend at elbow with wrist higher than it indicating grip on an object above waist level.\n\nTorso maintains an upright position indicative of stance during light effort tasks like mopping; pelvis slightly tilted towards right side suggesting majority weight bearing on right leg.\n\nFinally, head seems to be facing forward or slightly downwards perhaps focusing on area being cleaned. This can be inferred from positions of upper neck and top of head keypoints which are almost vertically aligned.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[366,242],&quot;id&quot;:0,&quot;kpts&quot;:[[305,403],[313,294],[301,202],[404,222],[386,320],[400,412],[353,212],[356,144],[350.0271,116.6241],[373.9729,226.3759],[265,166],[273,107],[294,136],[418,152],[420,282],[396,371]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.370014}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      366,\n      242\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        305,\n        403\n      ],\n      [\n        313,\n        294\n      ],\n      [\n        301,\n        202\n      ],\n      [\n        404,\n        222\n      ],\n      [\n        386,\n        320\n      ],\n      [\n        400,\n        412\n      ],\n      [\n        353,\n        212\n      ],\n      [\n        356,\n        144\n      ],\n      [\n        350.0271,\n        116.6241\n      ],\n      [\n        373.9729,\n        226.3759\n      ],\n      [\n        265,\n        166\n      ],\n      [\n        273,\n        107\n      ],\n      [\n        294,\n        136\n      ],\n      [\n        418,\n        152\n      ],\n      [\n        420,\n        282\n      ],\n      [\n        396,\n        371\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.370014\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:318,&quot;string&quot;:&quot;318&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;059789998.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:38,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is performing home activities, specifically mopping with light effort while standing. This activity typically involves a slightly bent pose with one arm extended holding the mop and legs spaced apart for balance.\n\nThe centrally located person is presumably cleaning their surroundings with their mop. Their body appears to be leaning slightly forward, suggesting that they are applying force onto the mop.\n\nThe right leg of this individual seems to be straight and firmly planted on the ground from ankle to hip, providing stability. The left leg, however, seems slightly bent at the knee which might be due to shifting weight or movement.\n\nTheir right arm appears extended towards the ground indicating that it's holding onto a tool like a mop. There's a slight bend in elbow suggesting an active movement rather than static hold. The left arm also seems engaged but less extended than right one, possibly maintaining balance or aiding in mopping motion.\n\nThe torso of this individual leans forward slightly indicating engagement in task at hand. The head position suggests focus on immediate vicinity as if looking at something close by on floor - likely where they're mopping next.\n\nOverall posture suggests an active stance involved in household chores requiring moderate physical effort like mopping.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[382,201],&quot;id&quot;:0,&quot;kpts&quot;:[[447,396],[454,275],[505,154],[615,66],[543,347],[552,455],[560,110],[338,155],[334.4195,154.4292],[203.5805,133.5708],[295,243],[334,200],[317,141],[358,169],[518,183],[518,282]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.974736}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      382,\n      201\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        447,\n        396\n      ],\n      [\n        454,\n        275\n      ],\n      [\n        505,\n        154\n      ],\n      [\n        615,\n        66\n      ],\n      [\n        543,\n        347\n      ],\n      [\n        552,\n        455\n      ],\n      [\n        560,\n        110\n      ],\n      [\n        338,\n        155\n      ],\n      [\n        334.4195,\n        154.4292\n      ],\n      [\n        203.5805,\n        133.5708\n      ],\n      [\n        295,\n        243\n      ],\n      [\n        334,\n        200\n      ],\n      [\n        317,\n        141\n      ],\n      [\n        358,\n        169\n      ],\n      [\n        518,\n        183\n      ],\n      [\n        518,\n        282\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.974736\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:341,&quot;string&quot;:&quot;341&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2716,&quot;string&quot;:&quot;2,716&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:382,&quot;string&quot;:&quot;382&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, mopping, standing, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;092187424.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:39,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is working as a chambermaid or hotel housekeeper, possibly making a bed, cleaning a bathroom, or pushing a cart. This activity involves various movements such as bending, reaching out and possibly lifting items.\n\nThe central person is relatively large scale with their body parts spread across the frame. They seem to be in an active state with multiple limbs engaged in different actions.\n\nTheir right leg appears bent at the knee and slightly raised from their hip, indicating that they might be stepping forward or supporting their weight while performing an action. The left leg seems to be straight and stable on the ground providing balance.\n\nThe right arm looks extended towards something perhaps holding or reaching out for an object. The left arm appears to be bent at the elbow suggesting it could also be engaged in holding something or performing another task.\n\nTheir torso seems inclined forward slightly indicating that they might be leaning into their work. This posture suggests engagement and focus on the task at hand.\n\nLastly, considering head's position relative to other body parts it appears that they are looking downwards likely focused on what they are doing with their hands.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[273,249],&quot;id&quot;:0,&quot;kpts&quot;:[[240,417],[353,356],[189,339],[249,289],[341,268],[233,393],[219,314],[272,187],[284.4743,176.2583],[367.5257,104.7417],[407,345],[331,332],[270,210],[274,163],[324,232],[380,261]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.288}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      273,\n      249\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        240,\n        417\n      ],\n      [\n        353,\n        356\n      ],\n      [\n        189,\n        339\n      ],\n      [\n        249,\n        289\n      ],\n      [\n        341,\n        268\n      ],\n      [\n        233,\n        393\n      ],\n      [\n        219,\n        314\n      ],\n      [\n        272,\n        187\n      ],\n      [\n        284.4743,\n        176.2583\n      ],\n      [\n        367.5257,\n        104.7417\n      ],\n      [\n        407,\n        345\n      ],\n      [\n        331,\n        332\n      ],\n      [\n        270,\n        210\n      ],\n      [\n        274,\n        163\n      ],\n      [\n        324,\n        232\n      ],\n      [\n        380,\n        261\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.288\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:148,&quot;string&quot;:&quot;148&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:787,&quot;string&quot;:&quot;787&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, chambermaid, hotel housekeeper, making bed, cleaning bathroom, pushing cart&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;008849250.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:40,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in home activities, specifically cleaning. This activity involves movements such as bending, reaching out, and possibly squatting or kneeling.\n\nThe person located at the center of the image is actively cleaning with their limbs positioned to perform this task. \n\nTheir right leg appears slightly bent at the knee, indicating that they may be shifting their weight or preparing to move. The right ankle is further forward than the hip and knee, suggesting a step forward or a slight lean.\n\nThe left leg seems straighter compared to the right leg with both hip and knee aligned vertically. The ankle position suggests that it's bearing most of the body's weight.\n\nFor their arms, we see that their right arm appears extended outward with a slight bend at elbow while wrist positioned lower than elbow indicating a reaching out gesture possibly towards an object of interest for cleaning.\n\nTheir left arm seems more relaxed compared to their right arm with elbow bent more prominently than on other side and wrist positioned higher than elbow suggesting it might be holding something closer to body or being used for support.\n\nLooking at torso keypoints - pelvis and thorax - we can infer that they are leaning slightly towards right side which aligns well with positioning of rest of body parts in performing cleaning action.\n\nFinally head keypoints - upper neck and head top - are tilted downwards suggesting focus on task being performed by hands.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[348,132],&quot;id&quot;:0,&quot;kpts&quot;:[[413,316],[420,268],[431,175],[432,176],[318,197],[325,232],[432,176],[240,42],[171,30],[63,13],[204,109],[214,74],[231,3],[248,80],[404,193],[282,188]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.271139}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      348,\n      132\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        413,\n        316\n      ],\n      [\n        420,\n        268\n      ],\n      [\n        431,\n        175\n      ],\n      [\n        432,\n        176\n      ],\n      [\n        318,\n        197\n      ],\n      [\n        325,\n        232\n      ],\n      [\n        432,\n        176\n      ],\n      [\n        240,\n        42\n      ],\n      [\n        171,\n        30\n      ],\n      [\n        63,\n        13\n      ],\n      [\n        204,\n        109\n      ],\n      [\n        214,\n        74\n      ],\n      [\n        231,\n        3\n      ],\n      [\n        248,\n        80\n      ],\n      [\n        404,\n        193\n      ],\n      [\n        282,\n        188\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.271139\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:620,&quot;string&quot;:&quot;620&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:787,&quot;string&quot;:&quot;787&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:82,&quot;string&quot;:&quot;82&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;home activities, cleaning, general&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;019598286.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:41,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is working as a chambermaid, possibly tidying up a hotel room or pushing a cart. The activity involves various movements and poses, often requiring bending or kneeling.\n\nThe person centered around the coordinates (200.0, 301.0) and scaled at 4.751879 appears to be in action with their limbs engaged in different activities.\n\nStarting with the legs: Their right leg seems to be slightly bent at the knee with their ankle positioned lower than it; suggesting that they might be stepping forward or standing on uneven ground. Their left leg appears to be more bent at the knee compared to their right leg, indicating that they might have weight shifted onto this side.\n\nMoving onto arms: The right arm is stretched out towards something probably indicating that they are reaching for an object or stabilizing themselves against something. The elbow of this arm is higher than wrist and shoulder suggesting an elevated reach while left arm seems folded at elbow which could suggest holding of some object close to body.\n\nTheir torso leans slightly towards right side which aligns with position of arms and legs suggesting dynamic movement such as reaching out for something while maintaining balance on uneven surface.\n\nFinally, head appears tilted downwards pointing towards what could potentially be area of focus - perhaps an item being picked up or place where cleaning process is focused.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[200,301],&quot;id&quot;:0,&quot;kpts&quot;:[[175,412],[204,247],[104,413],[18,348],[126,240],[124,382],[61,381],[74,261],[62.9805,278.3163],[148.0195,144.6837],[370,284],[261,346],[119,327],[28,194],[159,145],[268,121]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.751879}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      200,\n      301\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        175,\n        412\n      ],\n      [\n        204,\n        247\n      ],\n      [\n        104,\n        413\n      ],\n      [\n        18,\n        348\n      ],\n      [\n        126,\n        240\n      ],\n      [\n        124,\n        382\n      ],\n      [\n        61,\n        381\n      ],\n      [\n        74,\n        261\n      ],\n      [\n        62.9805,\n        278.3163\n      ],\n      [\n        148.0195,\n        144.6837\n      ],\n      [\n        370,\n        284\n      ],\n      [\n        261,\n        346\n      ],\n      [\n        119,\n        327\n      ],\n      [\n        28,\n        194\n      ],\n      [\n        159,\n        145\n      ],\n      [\n        268,\n        121\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.751879\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:148,&quot;string&quot;:&quot;148&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:787,&quot;string&quot;:&quot;787&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:144,&quot;string&quot;:&quot;144&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, chambermaid, hotel housekeeper, making bed, cleaning bathroom, pushing cart&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;004522729.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:42,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in light yard work, specifically picking flowers or vegetables. This activity involves a good deal of bending over and reaching down, as well as occasional walking or standing.\n\nThe centrally-located person is in a slightly bent over position with their limbs oriented towards the ground. \n\nStarting with the legs, both are slightly bent at the knees indicating that this person is not standing upright but rather leaning forward. The right ankle and knee appear to be directly aligned with each other, suggesting that most weight may be on this leg. The left leg seems to be positioned slightly behind the right one.\n\nMoving onto arms, both arms are extended downwards towards the ground which aligns with picking up objects from ground level. The right arm appears to be more stretched out than left one which could suggest that it's actively engaged in picking something up.\n\nThe torso of this individual leans forward from pelvis to thorax creating an angle with vertical axis which further confirms that they're bending over for their task.\n\nLastly, considering head position relative to upper neck and shoulders suggests they're looking downwards likely focusing on what they're picking up from ground level.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[719,298],&quot;id&quot;:0,&quot;kpts&quot;:[[720,638],[707,524],[684,365],[784,366],[792,520],[797,649],[734,366],[739,175],[737.8234,153.0862],[732.1766,47.9138],[694,378],[659,288],[683,176],[795,174],[803,294],[771,377]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.159716}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      719,\n      298\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        720,\n        638\n      ],\n      [\n        707,\n        524\n      ],\n      [\n        684,\n        365\n      ],\n      [\n        784,\n        366\n      ],\n      [\n        792,\n        520\n      ],\n      [\n        797,\n        649\n      ],\n      [\n        734,\n        366\n      ],\n      [\n        739,\n        175\n      ],\n      [\n        737.8234,\n        153.0862\n      ],\n      [\n        732.1766,\n        47.9138\n      ],\n      [\n        694,\n        378\n      ],\n      [\n        659,\n        288\n      ],\n      [\n        683,\n        176\n      ],\n      [\n        795,\n        174\n      ],\n      [\n        803,\n        294\n      ],\n      [\n        771,\n        377\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.159716\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:513,&quot;string&quot;:&quot;513&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;082873751.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:43,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is tending to a garden, implied to be walking or standing while picking up yard items, lightly picking flowers or vegetables. The activity involves bending, reaching and possibly squatting.\n\nThe person centered around coordinates (885.0, 379.0) and scaled at 6.245398 is engaging in this activity with their limbs positioned as follows:\n\nTheir right leg's hip joint is visible but knee and ankle joints are not visible which could mean that they're obscured by an object or bent towards the camera.\nTheir left leg seems to be slightly bent at the hip as it's higher than the right hip indicating a lifting or stepping motion.\nThe pelvis area suggests they might be turned slightly towards their left.\n\nThe torso seems upright given the positions of thorax and pelvis keypoints. The upper neck keypoint being close to thorax indicates that their head might be tilted downwards – likely focused on what they are picking up.\n\nTheir right arm appears extended with both elbow and wrist lower than shoulder hinting they may be reaching out for something or have just picked something up.\nTheir left arm appears bent at elbow with wrist higher than elbow suggesting it could be holding onto something like a basket for collecting items.\n\nIn terms of head position, considering only neck and top of head keypoints due to lack of facial feature data - it seems like they're looking downwards possibly focusing on what they're doing with their hands.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[885,379],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[788,577],[944,621],[-1,-1],[-1,-1],[866,599],[872,293],[865.7188,278.0061],[785.2812,85.9939],[702,533],[754,444],[768,282],[975,303],[989,552],[980,710]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:6.245398}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      885,\n      379\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        788,\n        577\n      ],\n      [\n        944,\n        621\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        866,\n        599\n      ],\n      [\n        872,\n        293\n      ],\n      [\n        865.7188,\n        278.0061\n      ],\n      [\n        785.2812,\n        85.9939\n      ],\n      [\n        702,\n        533\n      ],\n      [\n        754,\n        444\n      ],\n      [\n        768,\n        282\n      ],\n      [\n        975,\n        303\n      ],\n      [\n        989,\n        552\n      ],\n      [\n        980,\n        710\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 6.245398\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:513,&quot;string&quot;:&quot;513&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:93,&quot;string&quot;:&quot;93&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;035675333.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:44,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in gardening, specifically implied walking or standing while picking up yard items, possibly light objects like flowers or vegetables. The activity involves bending down and reaching out with their arms.\n\nThe person centered towards the right-middle of the image appears to be reaching downwards with their left arm, possibly to pick something up from the ground. Their right leg seems to be slightly bent at the knee, supporting their weight as they lean over.\n\nThe right leg of this person is slightly bent at the knee with foot not visible in this frame. The left leg appears straight and firmly planted on ground providing balance.\n\nTheir left arm is extended downwards and slightly forward - indicating they might be reaching for something on ground level. The right arm seems to be hanging relaxed by their side.\n\nTheir torso leans forward suggesting a bending motion at waistline. This posture supports idea that they are picking something up from the ground level.\n\nThe head position suggests that they are looking down towards what they are reaching for with their left hand.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[611,374],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[544,624],[509,409],[624,413],[621,628],[-1,-1],[567,411],[584,185],[581.6629,154.7729],[571.3371,21.2271],[399,313],[490,323],[506,190],[661,179],[647,322],[512,294]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.018334}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      611,\n      374\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        544,\n        624\n      ],\n      [\n        509,\n        409\n      ],\n      [\n        624,\n        413\n      ],\n      [\n        621,\n        628\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        567,\n        411\n      ],\n      [\n        584,\n        185\n      ],\n      [\n        581.6629,\n        154.7729\n      ],\n      [\n        571.3371,\n        21.2271\n      ],\n      [\n        399,\n        313\n      ],\n      [\n        490,\n        323\n      ],\n      [\n        506,\n        190\n      ],\n      [\n        661,\n        179\n      ],\n      [\n        647,\n        322\n      ],\n      [\n        512,\n        294\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.018334\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:513,&quot;string&quot;:&quot;513&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:215,&quot;string&quot;:&quot;215&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;028093451.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:45,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaging in lawn and garden activities, implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending over to pick items from the ground and some level of arm movement.\n\nThe person located towards the left of the image is bending over with their right leg slightly bent. The right knee is positioned lower than the hip indicating a bend. The right arm is extended downwards with a slight bend at the elbow suggesting that they might be reaching for something on the ground. Their head is tilted downwards pointing towards what they are reaching for.\n\nThe second person, located more towards the center of image, appears to be standing upright with their right hip visible but knee and ankle not visible which suggests that they may have one foot slightly behind them or out of frame. Their arms are also extended with a noticeable bend at both elbows suggesting an active engagement in an activity such as holding or manipulating something. Their head seems to be tilted downward slightly indicating focus on whatever task they're performing.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[269,237],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[233,449],[217,316],[277,311],[279,455],[-1,-1],[247,314],[232,198],[231.0347,196.0005],[190.9653,112.9995],[217,138],[172,189],[198,206],[265,190],[308,261],[287,194]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.765004},{&quot;center&quot;:[386,341],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[-1,-1],[388,450],[451,437],[-1,-1],[-1,-1],[420,444],[389,295],[388.2573,293.2791],[348.7427,201.7209],[420,290],[399,367],[348,307],[429,282],[493,375],[509,292]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.991636}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      269,\n      237\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        233,\n        449\n      ],\n      [\n        217,\n        316\n      ],\n      [\n        277,\n        311\n      ],\n      [\n        279,\n        455\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        247,\n        314\n      ],\n      [\n        232,\n        198\n      ],\n      [\n        231.0347,\n        196.0005\n      ],\n      [\n        190.9653,\n        112.9995\n      ],\n      [\n        217,\n        138\n      ],\n      [\n        172,\n        189\n      ],\n      [\n        198,\n        206\n      ],\n      [\n        265,\n        190\n      ],\n      [\n        308,\n        261\n      ],\n      [\n        287,\n        194\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.765004\n  },\n  {\n    \&quot;center\&quot;: [\n      386,\n      341\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        388,\n        450\n      ],\n      [\n        451,\n        437\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        420,\n        444\n      ],\n      [\n        389,\n        295\n      ],\n      [\n        388.2573,\n        293.2791\n      ],\n      [\n        348.7427,\n        201.7209\n      ],\n      [\n        420,\n        290\n      ],\n      [\n        399,\n        367\n      ],\n      [\n        348,\n        307\n      ],\n      [\n        429,\n        282\n      ],\n      [\n        493,\n        375\n      ],\n      [\n        509,\n        292\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.991636\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1164,&quot;string&quot;:&quot;1,164&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:101,&quot;string&quot;:&quot;101&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;098688694.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:46,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are four people in the image who are engaging in lawn and garden activities, implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending over to pick items from the ground and standing upright.\n\nThe first person is located at coordinates (319.0, 228.0) with a scale of 2.618971. This person is bending over with their torso leaning forward towards the ground. The right leg is straight while the left leg appears to be slightly bent at the knee. Both arms are extended downwards towards the ground with elbows slightly bent.\n\nThe second person is located at coordinates (369.0, 149.0) with a scale of 2.290586.This individual appears to be standing upright with both legs straight and parallel to each other.The arms appear to be held close to their body with elbows slightly bent.\n\nThe third person can be found at coordinates (553.0, 192.) with a scale of 2.157465.This individual's pose suggests they may be reaching for something as one arm extends outwards while other keypoints such as ankles and knees remain invisible.\n\nThe fourth person can be found at coordinates (452.,175.) on a scale of 1 .978072.They seem to stand erectly.Their right arm seems extended outwards whereas left arm remains close to body.Right knee appears slightly bent whereas left one seems straight.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[319,228],&quot;id&quot;:0,&quot;kpts&quot;:[[248,405],[237,322],[246,239],[322,232],[307,340],[310,408],[284,236],[291,103],[288.3711,85.182],[275.6289,-1.182],[233,254],[235,187],[242,109],[340,97],[359,165],[338,223]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.618971},{&quot;center&quot;:[369,149],&quot;id&quot;:1,&quot;kpts&quot;:[[343,322],[342,260],[341,184],[385,184],[383,261],[381,328],[363,184],[366,107],[364.9148,100.6336],[352.0852,25.3664],[385,161],[333,167],[335,109],[397,105],[408,164],[346,157]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.290586},{&quot;center&quot;:[553,192],&quot;id&quot;:2,&quot;kpts&quot;:[[-1,-1],[-1,-1],[487,254],[603,256],[-1,-1],[-1,-1],[545,255],[560,58],[557.8465,53.2497],[528.1535,-12.2497],[407,276],[462,183],[487,67],[632,48],[639,182],[639,302]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.157465},{&quot;center&quot;:[452,175],&quot;id&quot;:3,&quot;kpts&quot;:[[433,370],[438,306],[448,200],[499,200],[488,295],[485,365],[474,200],[483,55],[482.663,54.2261],[456.337,-6.2261],[434,183],[450,131],[448,58],[518,52],[525,129],[511,196]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.978072}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      319,\n      228\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        248,\n        405\n      ],\n      [\n        237,\n        322\n      ],\n      [\n        246,\n        239\n      ],\n      [\n        322,\n        232\n      ],\n      [\n        307,\n        340\n      ],\n      [\n        310,\n        408\n      ],\n      [\n        284,\n        236\n      ],\n      [\n        291,\n        103\n      ],\n      [\n        288.3711,\n        85.182\n      ],\n      [\n        275.6289,\n        -1.182\n      ],\n      [\n        233,\n        254\n      ],\n      [\n        235,\n        187\n      ],\n      [\n        242,\n        109\n      ],\n      [\n        340,\n        97\n      ],\n      [\n        359,\n        165\n      ],\n      [\n        338,\n        223\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.618971\n  },\n  {\n    \&quot;center\&quot;: [\n      369,\n      149\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        343,\n        322\n      ],\n      [\n        342,\n        260\n      ],\n      [\n        341,\n        184\n      ],\n      [\n        385,\n        184\n      ],\n      [\n        383,\n        261\n      ],\n      [\n        381,\n        328\n      ],\n      [\n        363,\n        184\n      ],\n      [\n        366,\n        107\n      ],\n      [\n        364.9148,\n        100.6336\n      ],\n      [\n        352.0852,\n        25.3664\n      ],\n      [\n        385,\n        161\n      ],\n      [\n        333,\n        167\n      ],\n      [\n        335,\n        109\n      ],\n      [\n        397,\n        105\n      ],\n      [\n        408,\n        164\n      ],\n      [\n        346,\n        157\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.290586\n  },\n  {\n    \&quot;center\&quot;: [\n      553,\n      192\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        487,\n        254\n      ],\n      [\n        603,\n        256\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        545,\n        255\n      ],\n      [\n        560,\n        58\n      ],\n      [\n        557.8465,\n        53.2497\n      ],\n      [\n        528.1535,\n        -12.2497\n      ],\n      [\n        407,\n        276\n      ],\n      [\n        462,\n        183\n      ],\n      [\n        487,\n        67\n      ],\n      [\n        632,\n        48\n      ],\n      [\n        639,\n        182\n      ],\n      [\n        639,\n        302\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.157465\n  },\n  {\n    \&quot;center\&quot;: [\n      452,\n      175\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        433,\n        370\n      ],\n      [\n        438,\n        306\n      ],\n      [\n        448,\n        200\n      ],\n      [\n        499,\n        200\n      ],\n      [\n        488,\n        295\n      ],\n      [\n        485,\n        365\n      ],\n      [\n        474,\n        200\n      ],\n      [\n        483,\n        55\n      ],\n      [\n        482.663,\n        54.2261\n      ],\n      [\n        456.337,\n        -6.2261\n      ],\n      [\n        434,\n        183\n      ],\n      [\n        450,\n        131\n      ],\n      [\n        448,\n        58\n      ],\n      [\n        518,\n        52\n      ],\n      [\n        525,\n        129\n      ],\n      [\n        511,\n        196\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.978072\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1164,&quot;string&quot;:&quot;1,164&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:277,&quot;string&quot;:&quot;277&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;077224477.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:4,&quot;string&quot;:&quot;4&quot;}}},{&quot;rowIdx&quot;:47,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in lawn and garden activities, specifically implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending down and reaching out to pick things from the ground, which might involve a slight bend at the hips and knees.\n\nThe centered person is at a large scale with their body parts positioned as follows:\n\nTheir right leg isn't visible in this dataset. The left leg appears to be slightly bent at the hip, indicating a possible crouch or bend down motion.\n\nThe right arm seems to be extended outwards with a noticeable bend at the elbow. This could imply that they're reaching out for something. Their left arm also appears extended but it's unclear if there's any significant bend at the elbow due to lack of data for left wrist.\n\nTheir torso leans forward slightly, possibly due to bending down motion involved in their activity. \n\nThe head position suggests they are looking downwards - perhaps towards what they're picking up from the ground.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[454,261],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[379,327],[506,371],[-1,-1],[-1,-1],[443,349],[446,135],[450.0434,152.8844],[415.9566,2.1156],[201,280],[266,209],[367,128],[524,141],[483,321],[339,320]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.63722}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      454,\n      261\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        379,\n        327\n      ],\n      [\n        506,\n        371\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        443,\n        349\n      ],\n      [\n        446,\n        135\n      ],\n      [\n        450.0434,\n        152.8844\n      ],\n      [\n        415.9566,\n        2.1156\n      ],\n      [\n        201,\n        280\n      ],\n      [\n        266,\n        209\n      ],\n      [\n        367,\n        128\n      ],\n      [\n        524,\n        141\n      ],\n      [\n        483,\n        321\n      ],\n      [\n        339,\n        320\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.63722\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1164,&quot;string&quot;:&quot;1,164&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:442,&quot;string&quot;:&quot;442&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;019871568.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:48,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are five people in image who are engaging in gardening activities, specifically picking up yard items and possibly picking flowers or vegetables.\n\nThe first person is located at the far left of the image and appears to be bending down slightly with their right leg bent and left leg straight. Their right arm is raised at approximately a 45-degree angle, indicating that they might be reaching for something.\n\nThe second person, located towards the center-left of the image, is standing upright with both legs slightly bent. They appear to be reaching forward with their right arm while their left arm hangs by their side.\n\nThe third person, positioned roughly in the middle of the frame, seems to have most of their body turned away from view. Their visible limbs suggest a slight bend as if leaning or stepping forward.\n\nThe fourth individual is found near center-right of the image. They appear to be leaning forward with both arms extended downwards and knees slightly bent - possibly indicating an action such as lifting or digging.\n\nLastly, an individual on far right has been captured mid-motion which makes it difficult to discern specific limb positions due to several keypoints being invisible. However, judging from available data it can be inferred that they have one arm raised - potentially performing similar tasks as others.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[92,258],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[82,375],[74,290],[33,277],[81,380],[-1,-1],[54,284],[66,186],[72,173],[108,109],[105,231],[112,263],[77,195],[54,176],[95,226],[93,253]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.215552},{&quot;center&quot;:[226,257],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[215,452],[207,352],[273,343],[287,445],[-1,-1],[240,348],[220,173],[222,154],[233,63],[218,312],[146,273],[162,178],[278,168],[320,260],[305,311]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.769063},{&quot;center&quot;:[325,237],&quot;id&quot;:2,&quot;kpts&quot;:[[-1,-1],[-1,-1],[282,268],[327,262],[-1,-1],[-1,-1],[305,265],[304,176],[304,165],[306,95],[287,278],[276,234],[281,178],[327,173],[331,241],[338,276]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.124237},{&quot;center&quot;:[571,363],&quot;id&quot;:3,&quot;kpts&quot;:[[-1,-1],[496,459],[509,378],[573,387],[551,469],[-1,-1],[541,383],[557,252],[550,230],[522,138],[476,344],[511,318],[522,246],[592,257],[602,350],[549,381]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.856101},{&quot;center&quot;:[500,386],&quot;id&quot;:4,&quot;kpts&quot;:[[-1,-1],[-1,-1],[459,466],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[512,366],[512,348],[512,254],[462,446],[468,416],[485,354],[539,377],[542,449],[-1,-1]],&quot;kpts_vis&quot;:[0,0,1,0,0,0,0,1,1,1,1,1,1,1,1,0],&quot;scale&quot;:2.820383}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      92,\n      258\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        82,\n        375\n      ],\n      [\n        74,\n        290\n      ],\n      [\n        33,\n        277\n      ],\n      [\n        81,\n        380\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        54,\n        284\n      ],\n      [\n        66,\n        186\n      ],\n      [\n        72,\n        173\n      ],\n      [\n        108,\n        109\n      ],\n      [\n        105,\n        231\n      ],\n      [\n        112,\n        263\n      ],\n      [\n        77,\n        195\n      ],\n      [\n        54,\n        176\n      ],\n      [\n        95,\n        226\n      ],\n      [\n        93,\n        253\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.215552\n  },\n  {\n    \&quot;center\&quot;: [\n      226,\n      257\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        215,\n        452\n      ],\n      [\n        207,\n        352\n      ],\n      [\n        273,\n        343\n      ],\n      [\n        287,\n        445\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        240,\n        348\n      ],\n      [\n        220,\n        173\n      ],\n      [\n        222,\n        154\n      ],\n      [\n        233,\n        63\n      ],\n      [\n        218,\n        312\n      ],\n      [\n        146,\n        273\n      ],\n      [\n        162,\n        178\n      ],\n      [\n        278,\n        168\n      ],\n      [\n        320,\n        260\n      ],\n      [\n        305,\n        311\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.769063\n  },\n  {\n    \&quot;center\&quot;: [\n      325,\n      237\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        282,\n        268\n      ],\n      [\n        327,\n        262\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        305,\n        265\n      ],\n      [\n        304,\n        176\n      ],\n      [\n        304,\n        165\n      ],\n      [\n        306,\n        95\n      ],\n      [\n        287,\n        278\n      ],\n      [\n        276,\n        234\n      ],\n      [\n        281,\n        178\n      ],\n      [\n        327,\n        173\n      ],\n      [\n        331,\n        241\n      ],\n      [\n        338,\n        276\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.124237\n  },\n  {\n    \&quot;center\&quot;: [\n      571,\n      363\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        496,\n        459\n      ],\n      [\n        509,\n        378\n      ],\n      [\n        573,\n        387\n      ],\n      [\n        551,\n        469\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        541,\n        383\n      ],\n      [\n        557,\n        252\n      ],\n      [\n        550,\n        230\n      ],\n      [\n        522,\n        138\n      ],\n      [\n        476,\n        344\n      ],\n      [\n        511,\n        318\n      ],\n      [\n        522,\n        246\n      ],\n      [\n        592,\n        257\n      ],\n      [\n        602,\n        350\n      ],\n      [\n        549,\n        381\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.856101\n  },\n  {\n    \&quot;center\&quot;: [\n      500,\n      386\n    ],\n    \&quot;id\&quot;: 4,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        459,\n        466\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        512,\n        366\n      ],\n      [\n        512,\n        348\n      ],\n      [\n        512,\n        254\n      ],\n      [\n        462,\n        446\n      ],\n      [\n        468,\n        416\n      ],\n      [\n        485,\n        354\n      ],\n      [\n        539,\n        377\n      ],\n      [\n        542,\n        449\n      ],\n      [\n        -1,\n        -1\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0\n    ],\n    \&quot;scale\&quot;: 2.820383\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:11,&quot;string&quot;:&quot;11&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1164,&quot;string&quot;:&quot;1,164&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:517,&quot;string&quot;:&quot;517&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;000552212.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:5,&quot;string&quot;:&quot;5&quot;}}},{&quot;rowIdx&quot;:49,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in image who are engaged in various activities such as sitting, talking in person, on the phone, computer, or text messaging with light effort. The interactions seem casual and relaxed.\n\nThe first person is located towards the right side of the image. They appear to be sitting with their body slightly tilted towards their right. Their right leg is bent at the knee and extended forward while their left leg is also bent at the knee but positioned backward. The pelvis and thorax indicate a slight twist in torso suggesting they might be turning to their left side.\n\nTheir right arm seems to be resting on a surface or holding an object as it's bent at elbow with wrist positioned lower than elbow. Their left arm appears to be lifted higher than shoulder level possibly holding something up near head level.\n\nThe second person is located towards the left side of the image. This individual seems to be seated as well but appears more upright compared to first individual based on position of hips and thorax keypoints. However, visibility of this person's right leg joints are not clear which makes precise pose description difficult for that limb.\n\nTheir arms suggest they might also be interacting with an object or a device - perhaps texting or typing - given both wrists being elevated above elbows' height and closer proximity between wrist-elbow-shoulder keypoints indicating bend in arms.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[878,464],&quot;id&quot;:0,&quot;kpts&quot;:[[878,680],[751,548],[932,530],[992,550],[715,557],[752,629],[962,540],[932,329],[918.6941,300.9672],[842.3059,140.0328],[831,431],[894,423],[896,321],[967,337],[1011,507],[860,487]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.344299},{&quot;center&quot;:[345,459],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[530,582],[261,598],[349,499],[518,530],[458,603],[305,549],[316,314],[323.844,279.5133],[366.156,93.4867],[432,533],[331,511],[267,334],[364,293],[398,436],[509,498]],&quot;kpts_vis&quot;:[0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.723333}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      878,\n      464\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        878,\n        680\n      ],\n      [\n        751,\n        548\n      ],\n      [\n        932,\n        530\n      ],\n      [\n        992,\n        550\n      ],\n      [\n        715,\n        557\n      ],\n      [\n        752,\n        629\n      ],\n      [\n        962,\n        540\n      ],\n      [\n        932,\n        329\n      ],\n      [\n        918.6941,\n        300.9672\n      ],\n      [\n        842.3059,\n        140.0328\n      ],\n      [\n        831,\n        431\n      ],\n      [\n        894,\n        423\n      ],\n      [\n        896,\n        321\n      ],\n      [\n        967,\n        337\n      ],\n      [\n        1011,\n        507\n      ],\n      [\n        860,\n        487\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.344299\n  },\n  {\n    \&quot;center\&quot;: [\n      345,\n      459\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        530,\n        582\n      ],\n      [\n        261,\n        598\n      ],\n      [\n        349,\n        499\n      ],\n      [\n        518,\n        530\n      ],\n      [\n        458,\n        603\n      ],\n      [\n        305,\n        549\n      ],\n      [\n        316,\n        314\n      ],\n      [\n        323.844,\n        279.5133\n      ],\n      [\n        366.156,\n        93.4867\n      ],\n      [\n        432,\n        533\n      ],\n      [\n        331,\n        511\n      ],\n      [\n        267,\n        334\n      ],\n      [\n        364,\n        293\n      ],\n      [\n        398,\n        436\n      ],\n      [\n        509,\n        498\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.723333\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:622,&quot;string&quot;:&quot;622&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:315,&quot;string&quot;:&quot;315&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:36,&quot;string&quot;:&quot;36&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;035846573.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:50,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are partaking in miscellaneous activities such as sitting, talking in person, on the phone, computer use, or text messaging with light effort. The poses suggest a casual and relaxed setting with both individuals engaged in some form of communication.\n\nThe first person located towards the right side of the image is seated with their body slightly turned to their left. Their right leg appears to be folded at the knee and drawn up towards their torso while their left leg is bent at the knee pointing outwardly. Unfortunately, both ankles and feet are not visible for further details. Their torso is upright with a slight lean to the left indicating engagement in conversation or activity. The head is tilted downward suggesting focus on something possibly held by their hands.\n\nTheir right arm seems to be resting on an elevated surface like a table or desk as indicated by its stretched state from shoulder to wrist. The hand might be interacting with an object like a phone or mouse due to its position relative to other keypoints but it's speculative without clear visibility of fingers' orientation. On contrast, their left arm exhibits more flexibility; it's bent at elbow making an angle slightly less than 90 degrees which suggests that this hand might also be involved in handling some object.\n\nThe second person positioned towards center-left of the image appears seated too but facing more directly forward compared to first one. Similar to first person, this individual's legs seem folded at knees but exact pose isn't clear due lack of visible ankles and feet data points.\n\nTheir torso leans forward suggesting engagement while head tilts downward indicating concentration on something within hand reach distance which could either be a mobile device or keyboard based on activity context provided.\n\nThis individual's arms show interesting dynamics; while right arm extends fully indicating resting flat perhaps over lap or low table surface, left arm bends sharply almost making 90 degree angle at elbow hinting that they're holding something close - maybe a mobile device given nature of activities described earlier.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[761,369],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[630,632],[803,510],[938,536],[712,625],[-1,-1],[871,523],[865,293],[863,277],[841,99],[731,540],[749,430],[784,281],[946,305],[989,501],[988,649]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.362376},{&quot;center&quot;:[447,481],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[609,639],[303,668],[379,603],[590,641],[-1,-1],[341,636],[308,368],[337,292],[420,81],[376,712],[169,636],[264,394],[351,341],[401,499],[487,617]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:6.785}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      761,\n      369\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        630,\n        632\n      ],\n      [\n        803,\n        510\n      ],\n      [\n        938,\n        536\n      ],\n      [\n        712,\n        625\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        871,\n        523\n      ],\n      [\n        865,\n        293\n      ],\n      [\n        863,\n        277\n      ],\n      [\n        841,\n        99\n      ],\n      [\n        731,\n        540\n      ],\n      [\n        749,\n        430\n      ],\n      [\n        784,\n        281\n      ],\n      [\n        946,\n        305\n      ],\n      [\n        989,\n        501\n      ],\n      [\n        988,\n        649\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.362376\n  },\n  {\n    \&quot;center\&quot;: [\n      447,\n      481\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        609,\n        639\n      ],\n      [\n        303,\n        668\n      ],\n      [\n        379,\n        603\n      ],\n      [\n        590,\n        641\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        341,\n        636\n      ],\n      [\n        308,\n        368\n      ],\n      [\n        337,\n        292\n      ],\n      [\n        420,\n        81\n      ],\n      [\n        376,\n        712\n      ],\n      [\n        169,\n        636\n      ],\n      [\n        264,\n        394\n      ],\n      [\n        351,\n        341\n      ],\n      [\n        401,\n        499\n      ],\n      [\n        487,\n        617\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 6.785\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:622,&quot;string&quot;:&quot;622&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:315,&quot;string&quot;:&quot;315&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:97,&quot;string&quot;:&quot;97&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;011586906.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:51,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in miscellaneous activities, standing and talking in person. This activity involves the individual being upright with their torso relatively straight and their arms actively involved in gestures or movements that could be associated with conversation.\n\nThe center-positioned person is within a medium close-up range with their body oriented slightly towards the right. Their right leg appears to be supporting most of their weight as indicated by the position of the right hip keypoint, although both legs are not fully visible.\n\nTheir torso is straight, as inferred from the alignment of pelvis, thorax, upper neck and head top keypoints. This suggests they are standing upright.\n\nThe head seems to be tilted slightly downwards based on relative positions of upper neck and head top keypoints which might indicate that they are looking at something or someone closer to them.\n\nTheir right arm appears bent at an angle close to 90 degrees judging from wrist, elbow and shoulder keypoints' coordinates. The hand might be raised for gesturing while talking or holding an object considering its relative position above waist level but below chest level.\n\nThe left arm also seems bent but at a larger angle than the right arm - possibly around 120 degrees based on wrist, elbow and shoulder keypoints' arrangement. The left hand's location near waist level suggests it may be resting against their body or holding onto something near waist height.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[355,342],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[254,459],[369,460],[-1,-1],[-1,-1],[312,460],[327,241],[324.6475,220.3504],[311.3525,103.6496],[192,331],[222,373],[249,244],[404,237],[453,371],[412,351]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.523671}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      355,\n      342\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        254,\n        459\n      ],\n      [\n        369,\n        460\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        312,\n        460\n      ],\n      [\n        327,\n        241\n      ],\n      [\n        324.6475,\n        220.3504\n      ],\n      [\n        311.3525,\n        103.6496\n      ],\n      [\n        192,\n        331\n      ],\n      [\n        222,\n        373\n      ],\n      [\n        249,\n        244\n      ],\n      [\n        404,\n        237\n      ],\n      [\n        453,\n        371\n      ],\n      [\n        412,\n        351\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.523671\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:982,&quot;string&quot;:&quot;982&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1896,&quot;string&quot;:&quot;1,896&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:8,&quot;string&quot;:&quot;8&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, standing, talking in person&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;006355835.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:52,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in miscellaneous activities, standing, and talking in person. This activity involves upright posture with potential arm movements for gesturing during conversation.\n\nThe centrally located person is captured at a medium distance with their body oriented slightly towards the right side of the frame. \n\nStarting from their lower body:\n- The right leg of this individual appears to be bent at the knee and hip, as indicated by keypoints 1 and 2. However, the ankle isn't visible.\n- The left leg seems to be straight with a slight bend at the knee (keypoint 4), extending from hip (keypoint 3) down to ankle which isn't visible.\n \nMoving up to their torso:\n- The pelvis (keypoint 6) seems evenly positioned between both hips suggesting an upright stance.\n- The thorax (keypoint 7) aligns directly above pelvis indicating a straight back.\n\nRegarding their arms:\n- Their right arm appears raised with elbow bend (keypoint 11). Wrist position suggests that hand might be near chest or shoulder level.\n- Left arm seems extended outwards from shoulder (keypoint 13), likely bent at elbow joint (keypoint 14). Wrist position suggests that hand might be gesturing while speaking.\n\nFinally, regarding head position:\n- Neck appears erect as upper neck point aligns directly above thorax.\n- Head top's placement indicates head facing forward or slightly tilted down.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[309,222],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[293,412],[278,294],[354,306],[357,415],[-1,-1],[316,300],[316,162],[315.5619,160.2475],[297.4381,87.7525],[246,229],[247,255],[269,165],[362,159],[394,241],[361,231]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.241785}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      309,\n      222\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        293,\n        412\n      ],\n      [\n        278,\n        294\n      ],\n      [\n        354,\n        306\n      ],\n      [\n        357,\n        415\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        316,\n        300\n      ],\n      [\n        316,\n        162\n      ],\n      [\n        315.5619,\n        160.2475\n      ],\n      [\n        297.4381,\n        87.7525\n      ],\n      [\n        246,\n        229\n      ],\n      [\n        247,\n        255\n      ],\n      [\n        269,\n        165\n      ],\n      [\n        362,\n        159\n      ],\n      [\n        394,\n        241\n      ],\n      [\n        361,\n        231\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.241785\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:982,&quot;string&quot;:&quot;982&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1896,&quot;string&quot;:&quot;1,896&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:103,&quot;string&quot;:&quot;103&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, standing, talking in person&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;031098232.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:53,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaged in miscellaneous activities, standing and talking in person. The general pose suggests a conversation between the two individuals, with both of them standing upright and their arms positioned as if gesturing or expressing themselves.\n\nThe first person is located towards the right side of the image. They are standing upright with their body facing slightly to the left. Their right arm is bent at the elbow and raised to shoulder level, suggesting they may be making a gesture or pointing at something. Their left arm appears to be hanging naturally by their side.\n\nTheir right leg is visible from hip to ankle while their left leg appears obscured or not visible in this image. The torso is straight and aligned with their head which is tilted slightly downwards as if looking at something below eye level.\n\nThe second person is located towards the left side of the image. This individual also appears to be standing upright but facing more directly forward compared to the first person.\n\nTheir left arm seems raised and bent at an angle similar to that of first person's right arm - possibly indicating a reciprocal gesture in conversation. The right arm, however, seems more relaxed by their side but slightly away from body perhaps holding an object or making another gesture.\n\nLike first individual, only one leg (in this case it's left) can be seen from hip down while other isn't visible due likely being obscured by angle or clothing. Torso alignment suggests an attentive posture directed towards center-right area where other individual stands; head positioning indicates attention focused roughly same direction - possibly on aforementioned conversational partner.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[444,320],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[429,413],[513,422],[-1,-1],[-1,-1],[471,418],[480,275],[478.8023,260.0288],[471.1977,164.9712],[415,418],[425,346],[435,267],[524,283],[530,383],[505,452]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.860836},{&quot;center&quot;:[195,312],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[-1,-1],[162,438],[183,423],[-1,-1],[-1,-1],[173,431],[154,228],[160.6644,210.4896],[198.3356,111.5104],[266,276],[206,342],[128,229],[180,227],[211,308],[260,271]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.177169}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      444,\n      320\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        429,\n        413\n      ],\n      [\n        513,\n        422\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        471,\n        418\n      ],\n      [\n        480,\n        275\n      ],\n      [\n        478.8023,\n        260.0288\n      ],\n      [\n        471.1977,\n        164.9712\n      ],\n      [\n        415,\n        418\n      ],\n      [\n        425,\n        346\n      ],\n      [\n        435,\n        267\n      ],\n      [\n        524,\n        283\n      ],\n      [\n        530,\n        383\n      ],\n      [\n        505,\n        452\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.860836\n  },\n  {\n    \&quot;center\&quot;: [\n      195,\n      312\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        162,\n        438\n      ],\n      [\n        183,\n        423\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        173,\n        431\n      ],\n      [\n        154,\n        228\n      ],\n      [\n        160.6644,\n        210.4896\n      ],\n      [\n        198.3356,\n        111.5104\n      ],\n      [\n        266,\n        276\n      ],\n      [\n        206,\n        342\n      ],\n      [\n        128,\n        229\n      ],\n      [\n        180,\n        227\n      ],\n      [\n        211,\n        308\n      ],\n      [\n        260,\n        271\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.177169\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:982,&quot;string&quot;:&quot;982&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1896,&quot;string&quot;:&quot;1,896&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:190,&quot;string&quot;:&quot;190&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, standing, talking in person&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;032518332.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:54,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are engaging in miscellaneous activities, standing, and talking in person. The individuals seem to be engaged in a conversation while maintaining a standing position. \n\nThe first person located around the center of the image is turned slightly to their left side with their right side more visible to us. Their right arm is bent at the elbow and raised towards chest level with their wrist slightly lower than the elbow, possibly gesturing while speaking. The left arm seems to be relaxed by their side but not fully visible due to angle of body orientation. As for legs, they are standing straight but only right hip is visible and other leg joints aren't seen due to occlusion or body orientation.\n\nThe second person located towards the left of the image has a more frontal pose compared to first one. This individual's head is titled slightly downward with top part clearly seen from this perspective. Their torso appears straight, indicating an upright posture while standing. Both arms are bent at elbows: right arm raised higher than left one where wrist ends up being approximately at waist level; on contrary, left arm's wrist reaches almost down till hip level which could suggest it being rested or placed on some surface unseen in data representation here.\n\nFor lower body part: both knees are bent suggesting that feet might be apart providing balance during interaction; however only left ankle joint isn't visible so actual foot position remains uncertain.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[400,283],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[344,382],[447,392],[-1,-1],[-1,-1],[396,387],[403,197],[401.1966,180.3537],[391.8034,93.6463],[293,379],[320,299],[345,202],[461,191],[506,299],[443,290]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.61644},{&quot;center&quot;:[122,279],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[128,453],[99,338],[160,333],[179,452],[-1,-1],[130,336],[119,225],[117.7788,219.6008],[101.2212,146.3992],[75,263],[54,292],[81,226],[157,224],[186,289],[192,347]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.251527}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      400,\n      283\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        344,\n        382\n      ],\n      [\n        447,\n        392\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        396,\n        387\n      ],\n      [\n        403,\n        197\n      ],\n      [\n        401.1966,\n        180.3537\n      ],\n      [\n        391.8034,\n        93.6463\n      ],\n      [\n        293,\n        379\n      ],\n      [\n        320,\n        299\n      ],\n      [\n        345,\n        202\n      ],\n      [\n        461,\n        191\n      ],\n      [\n        506,\n        299\n      ],\n      [\n        443,\n        290\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.61644\n  },\n  {\n    \&quot;center\&quot;: [\n      122,\n      279\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        128,\n        453\n      ],\n      [\n        99,\n        338\n      ],\n      [\n        160,\n        333\n      ],\n      [\n        179,\n        452\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        130,\n        336\n      ],\n      [\n        119,\n        225\n      ],\n      [\n        117.7788,\n        219.6008\n      ],\n      [\n        101.2212,\n        146.3992\n      ],\n      [\n        75,\n        263\n      ],\n      [\n        54,\n        292\n      ],\n      [\n        81,\n        226\n      ],\n      [\n        157,\n        224\n      ],\n      [\n        186,\n        289\n      ],\n      [\n        192,\n        347\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.251527\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:982,&quot;string&quot;:&quot;982&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1896,&quot;string&quot;:&quot;1,896&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:449,&quot;string&quot;:&quot;449&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;miscellaneous, standing, talking in person&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;063755747.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:55,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are seven people in the image who are playing lawn bowling, bocce ball, or some other outdoor sport. They all appear to be in various stages of play, with some preparing to throw their balls and others observing.\n\nThe first person is located towards the left-middle of the image. They seem to be in a throwing position with their right arm extended forward and slightly bent at the elbow. Their left arm is also bent at the elbow but is positioned more towards their body. Both legs appear straight with their right leg slightly behind them and left leg forward.\n\nThe second person is on the far-left side of the image. They seem to be standing upright watching others play, as both arms are hanging down by their sides and both legs are straight.\n\nThe third person can be found slightly right from center of the image. This individual appears to have just thrown a ball as they're leaning forward with both arms pointing towards where they were aiming, while keeping legs straight for balance.\n\nThe fourth person is located near middle-right side of picture. Their posture suggests that they might have just finished a throw; one arm seems extended outwards while other one hangs by side, and legs look fairly relaxed but still apart for stability.\n\nIn top-right part we find fifth player who appears ready for action: right arm seems drawn back possibly holding a ball while left hand points ahead likely targeting spot; knees look slightly bent indicating preparation for movement.\n\nMoving further right we see sixth participant who's probably observing game: hands rest casually near waistline while feet stand firmly apart providing solid base; head tilts downwards as if focusing on something below them - perhaps watching trajectory of thrown ball?\n\nFinally seventh player - furthest on right - stands tall like an observer too: arms relaxed by sides suggest passive stance currently not involved in active play; body leans little backwards implying comfortability on field rather than readiness for quick movements.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[205,237],&quot;id&quot;:0,&quot;kpts&quot;:[[218,383],[204,314],[191,241],[236,238],[239,313],[257,380],[214,240],[198,146],[194.1776,131.5792],[179.8224,77.4208],[209,216],[175,203],[166,153],[229,138],[249,190],[234,218]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.680857},{&quot;center&quot;:[29,306],&quot;id&quot;:1,&quot;kpts&quot;:[[33,380],[41,402],[34,341],[72,329],[61,349],[68,398],[53,335],[45,278],[43.7956,269.569],[37.2044,223.431],[23,324],[21,306],[22,281],[68,275],[80,313],[85,347]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.398193},{&quot;center&quot;:[282,237],&quot;id&quot;:2,&quot;kpts&quot;:[[293,375],[295,322],[293,269],[345,255],[320,317],[321,390],[319,262],[305,206],[311.5009,215.9062],[277.4991,164.0938],[271,256],[268,230],[270,208],[340,204],[354,241],[333,286]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.859187},{&quot;center&quot;:[441,278],&quot;id&quot;:3,&quot;kpts&quot;:[[409,380],[418,321],[417,262],[463,252],[455,317],[452,399],[440,257],[405,203],[412.1101,212.9542],[377.8899,165.0458],[381,314],[385,259],[372,216],[438,189],[472,238],[451,287]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.766243},{&quot;center&quot;:[556,221],&quot;id&quot;:4,&quot;kpts&quot;:[[532,390],[533,323],[532,257],[586,250],[592,321],[597,388],[559,254],[551,155],[551.0621,157.8582],[549.9379,106.1418],[517,255],[502,209],[514,159],[588,150],[614,209],[593,252]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.551856},{&quot;center&quot;:[695,217],&quot;id&quot;:5,&quot;kpts&quot;:[[642,383],[656,312],[667,225],[731,224],[731,314],[723,384],[699,225],[699,138],[699.2891,140.65],[692.7109,80.35],[645,223],[636,179],[662,139],[736,136],[761,174],[750,213]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.819732},{&quot;center&quot;:[791,216],&quot;id&quot;:6,&quot;kpts&quot;:[[798,387],[788,314],[779,225],[832,226],[833,310],[837,385],[806,226],[810,138],[809.6645,128.6056],[807.3355,63.3944],[771,232],[771,183],[777,138],[843,138],[849,189],[847,238]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.957582}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      205,\n      237\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        218,\n        383\n      ],\n      [\n        204,\n        314\n      ],\n      [\n        191,\n        241\n      ],\n      [\n        236,\n        238\n      ],\n      [\n        239,\n        313\n      ],\n      [\n        257,\n        380\n      ],\n      [\n        214,\n        240\n      ],\n      [\n        198,\n        146\n      ],\n      [\n        194.1776,\n        131.5792\n      ],\n      [\n        179.8224,\n        77.4208\n      ],\n      [\n        209,\n        216\n      ],\n      [\n        175,\n        203\n      ],\n      [\n        166,\n        153\n      ],\n      [\n        229,\n        138\n      ],\n      [\n        249,\n        190\n      ],\n      [\n        234,\n        218\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.680857\n  },\n  {\n    \&quot;center\&quot;: [\n      29,\n      306\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        33,\n        380\n      ],\n      [\n        41,\n        402\n      ],\n      [\n        34,\n        341\n      ],\n      [\n        72,\n        329\n      ],\n      [\n        61,\n        349\n      ],\n      [\n        68,\n        398\n      ],\n      [\n        53,\n        335\n      ],\n      [\n        45,\n        278\n      ],\n      [\n        43.7956,\n        269.569\n      ],\n      [\n        37.2044,\n        223.431\n      ],\n      [\n        23,\n        324\n      ],\n      [\n        21,\n        306\n      ],\n      [\n        22,\n        281\n      ],\n      [\n        68,\n        275\n      ],\n      [\n        80,\n        313\n      ],\n      [\n        85,\n        347\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.398193\n  },\n  {\n    \&quot;center\&quot;: [\n      282,\n      237\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        293,\n        375\n      ],\n      [\n        295,\n        322\n      ],\n      [\n        293,\n        269\n      ],\n      [\n        345,\n        255\n      ],\n      [\n        320,\n        317\n      ],\n      [\n        321,\n        390\n      ],\n      [\n        319,\n        262\n      ],\n      [\n        305,\n        206\n      ],\n      [\n        311.5009,\n        215.9062\n      ],\n      [\n        277.4991,\n        164.0938\n      ],\n      [\n        271,\n        256\n      ],\n      [\n        268,\n        230\n      ],\n      [\n        270,\n        208\n      ],\n      [\n        340,\n        204\n      ],\n      [\n        354,\n        241\n      ],\n      [\n        333,\n        286\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.859187\n  },\n  {\n    \&quot;center\&quot;: [\n      441,\n      278\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        409,\n        380\n      ],\n      [\n        418,\n        321\n      ],\n      [\n        417,\n        262\n      ],\n      [\n        463,\n        252\n      ],\n      [\n        455,\n        317\n      ],\n      [\n        452,\n        399\n      ],\n      [\n        440,\n        257\n      ],\n      [\n        405,\n        203\n      ],\n      [\n        412.1101,\n        212.9542\n      ],\n      [\n        377.8899,\n        165.0458\n      ],\n      [\n        381,\n        314\n      ],\n      [\n        385,\n        259\n      ],\n      [\n        372,\n        216\n      ],\n      [\n        438,\n        189\n      ],\n      [\n        472,\n        238\n      ],\n      [\n        451,\n        287\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.766243\n  },\n  {\n    \&quot;center\&quot;: [\n      556,\n      221\n    ],\n    \&quot;id\&quot;: 4,\n    \&quot;kpts\&quot;: [\n      [\n        532,\n        390\n      ],\n      [\n        533,\n        323\n      ],\n      [\n        532,\n        257\n      ],\n      [\n        586,\n        250\n      ],\n      [\n        592,\n        321\n      ],\n      [\n        597,\n        388\n      ],\n      [\n        559,\n        254\n      ],\n      [\n        551,\n        155\n      ],\n      [\n        551.0621,\n        157.8582\n      ],\n      [\n        549.9379,\n        106.1418\n      ],\n      [\n        517,\n        255\n      ],\n      [\n        502,\n        209\n      ],\n      [\n        514,\n        159\n      ],\n      [\n        588,\n        150\n      ],\n      [\n        614,\n        209\n      ],\n      [\n        593,\n        252\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.551856\n  },\n  {\n    \&quot;center\&quot;: [\n      695,\n      217\n    ],\n    \&quot;id\&quot;: 5,\n    \&quot;kpts\&quot;: [\n      [\n        642,\n        383\n      ],\n      [\n        656,\n        312\n      ],\n      [\n        667,\n        225\n      ],\n      [\n        731,\n        224\n      ],\n      [\n        731,\n        314\n      ],\n      [\n        723,\n        384\n      ],\n      [\n        699,\n        225\n      ],\n      [\n        699,\n        138\n      ],\n      [\n        699.2891,\n        140.65\n      ],\n      [\n        692.7109,\n        80.35\n      ],\n      [\n        645,\n        223\n      ],\n      [\n        636,\n        179\n      ],\n      [\n        662,\n        139\n      ],\n      [\n        736,\n        136\n      ],\n      [\n        761,\n        174\n      ],\n      [\n        750,\n        213\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.819732\n  },\n  {\n    \&quot;center\&quot;: [\n      791,\n      216\n    ],\n    \&quot;id\&quot;: 6,\n    \&quot;kpts\&quot;: [\n      [\n        798,\n        387\n      ],\n      [\n        788,\n        314\n      ],\n      [\n        779,\n        225\n      ],\n      [\n        832,\n        226\n      ],\n      [\n        833,\n        310\n      ],\n      [\n        837,\n        385\n      ],\n      [\n        806,\n        226\n      ],\n      [\n        810,\n        138\n      ],\n      [\n        809.6645,\n        128.6056\n      ],\n      [\n        807.3355,\n        63.3944\n      ],\n      [\n        771,\n        232\n      ],\n      [\n        771,\n        183\n      ],\n      [\n        777,\n        138\n      ],\n      [\n        843,\n        138\n      ],\n      [\n        849,\n        189\n      ],\n      [\n        847,\n        238\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.957582\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:12,&quot;string&quot;:&quot;12&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:100,&quot;string&quot;:&quot;100&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:38,&quot;string&quot;:&quot;38&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, lawn bowling, bocce ball, outdoor&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;088721274.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:7,&quot;string&quot;:&quot;7&quot;}}},{&quot;rowIdx&quot;:56,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are three people in the image who are participating in outdoor sports, specifically lawn bowling or bocce ball. Their poses suggest that they're in various stages of the game. \n\nThe person at the left side of the image is preparing to throw a ball with their right hand. Their right shoulder and elbow are bent, indicating a pre-throw stance. The right hip is slightly raised compared to left one, suggesting a shift of weight on left leg for balance.\n\nThe person at the center of the image appears to be observing or waiting for their turn. They're standing upright with both arms slightly bent at elbows and relaxed by their sides.\n\nThe person on the right side of the image seems to be in mid-action, possibly having just thrown a ball or about to do so. Their right knee is bent while left leg seems straight supporting body weight, suggesting dynamic movement happening. The arms seem outstretched towards front with palms facing downward as if they've just released something from their hands.\n\nIn general, all three individuals have their heads turned towards what could likely be where action is happening – possibly watching trajectory of balls being thrown.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[237,217],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[173,424],[287,396],[-1,-1],[-1,-1],[230,410],[175,163],[180.8747,151.8237],[251.1253,18.1763],[258,344],[101,330],[108,171],[241,155],[279,269],[299,321]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.529583},{&quot;center&quot;:[441,284],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[-1,-1],[433,390],[552,372],[-1,-1],[-1,-1],[493,381],[480,195],[480.9821,186.1607],[493.0179,77.8393],[432,348],[387,299],[410,199],[550,190],[576,290],[511,310]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.269642},{&quot;center&quot;:[727,359],&quot;id&quot;:2,&quot;kpts&quot;:[[-1,-1],[743,461],[739,388],[810,397],[795,463],[-1,-1],[775,393],[763,291],[765.7537,297.5734],[729.2463,210.4266],[720,361],[719,334],[722,292],[803,290],[830,346],[832,398]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.834541}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      237,\n      217\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        173,\n        424\n      ],\n      [\n        287,\n        396\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        230,\n        410\n      ],\n      [\n        175,\n        163\n      ],\n      [\n        180.8747,\n        151.8237\n      ],\n      [\n        251.1253,\n        18.1763\n      ],\n      [\n        258,\n        344\n      ],\n      [\n        101,\n        330\n      ],\n      [\n        108,\n        171\n      ],\n      [\n        241,\n        155\n      ],\n      [\n        279,\n        269\n      ],\n      [\n        299,\n        321\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.529583\n  },\n  {\n    \&quot;center\&quot;: [\n      441,\n      284\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        433,\n        390\n      ],\n      [\n        552,\n        372\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        493,\n        381\n      ],\n      [\n        480,\n        195\n      ],\n      [\n        480.9821,\n        186.1607\n      ],\n      [\n        493.0179,\n        77.8393\n      ],\n      [\n        432,\n        348\n      ],\n      [\n        387,\n        299\n      ],\n      [\n        410,\n        199\n      ],\n      [\n        550,\n        190\n      ],\n      [\n        576,\n        290\n      ],\n      [\n        511,\n        310\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.269642\n  },\n  {\n    \&quot;center\&quot;: [\n      727,\n      359\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        743,\n        461\n      ],\n      [\n        739,\n        388\n      ],\n      [\n        810,\n        397\n      ],\n      [\n        795,\n        463\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        775,\n        393\n      ],\n      [\n        763,\n        291\n      ],\n      [\n        765.7537,\n        297.5734\n      ],\n      [\n        729.2463,\n        210.4266\n      ],\n      [\n        720,\n        361\n      ],\n      [\n        719,\n        334\n      ],\n      [\n        722,\n        292\n      ],\n      [\n        803,\n        290\n      ],\n      [\n        830,\n        346\n      ],\n      [\n        832,\n        398\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.834541\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:12,&quot;string&quot;:&quot;12&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:100,&quot;string&quot;:&quot;100&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:202,&quot;string&quot;:&quot;202&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, lawn bowling, bocce ball, outdoor&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;011959425.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;}}},{&quot;rowIdx&quot;:57,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are participating in religious activities, serving food in church. The activities involve a lot of movement and interaction, with both individuals engaging in different tasks.\n\nThe person on the right is standing with their body slightly turned to their left. Their left leg is visible with the hip, knee and ankle aligned vertically. The right leg isn't visible which suggests that it might be behind the left leg or obscured from view. Their torso is upright but not visible above waist level which implies they may be behind a counter or table. The right arm is extended forward at shoulder height, possibly reaching for something or someone while their left arm appears to be bent at the elbow and raised slightly above waist level.\n\nThe person on the left appears to be bending over slightly as indicated by their hip keypoints being higher than those of their shoulders. Both legs aren't fully visible suggesting they might be kneeling or bending one knee significantly more than other people around them would typically do while standing up straight. They seem to have both arms extended towards each other at chest level possibly holding onto something between them like a tray of food items for distribution during this religious activity event.\n\nIn general, these poses suggest active involvement and engagement in serving food during religious activities within a church setting.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1343,576],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[1822,1071],[1648,547],[1641,461],[1634,98],[1632,1072],[-1,-1],[-1,-1],[-1,-1],[1898,556],[-1,-1],[-1,-1],[1390,509],[1027,563],[827,460]],&quot;kpts_vis&quot;:[0,0,1,1,1,1,1,0,0,0,1,0,0,1,1,1],&quot;scale&quot;:11.813901},{&quot;center&quot;:[292,339],&quot;id&quot;:1,&quot;kpts&quot;:[[-1,-1],[-1,-1],[132,883],[172,849],[-1,-1],[-1,-1],[152,866],[64,410],[71,364],[121,39],[454,364],[320,603],[32,443],[95,376],[250,365],[415,204]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:9.885233}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1343,\n      576\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1822,\n        1071\n      ],\n      [\n        1648,\n        547\n      ],\n      [\n        1641,\n        461\n      ],\n      [\n        1634,\n        98\n      ],\n      [\n        1632,\n        1072\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1898,\n        556\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1390,\n        509\n      ],\n      [\n        1027,\n        563\n      ],\n      [\n        827,\n        460\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0,\n      0,\n      0,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 11.813901\n  },\n  {\n    \&quot;center\&quot;: [\n      292,\n      339\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        132,\n        883\n      ],\n      [\n        172,\n        849\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        152,\n        866\n      ],\n      [\n        64,\n        410\n      ],\n      [\n        71,\n        364\n      ],\n      [\n        121,\n        39\n      ],\n      [\n        454,\n        364\n      ],\n      [\n        320,\n        603\n      ],\n      [\n        32,\n        443\n      ],\n      [\n        95,\n        376\n      ],\n      [\n        250,\n        365\n      ],\n      [\n        415,\n        204\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 9.885233\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:13,&quot;string&quot;:&quot;13&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2793,&quot;string&quot;:&quot;2,793&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:154,&quot;string&quot;:&quot;154&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;religious activities, serving food in church&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;056127720.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:58,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is serving food in a church. This religious activity typically involves standing, bending, and reaching as individuals serve food to others.\n\nThe centrally located person appears to be in the middle of serving with their right arm extended. \n\nTheir left leg and right leg are not visible in this image, which could suggest that they are standing behind a counter or table.\n\nTheir torso seems to be slightly leaning forward, as indicated by the position of thorax keypoint relative to pelvis keypoint which is not visible but can be inferred from other keypoints. This posture might indicate that they are reaching out or bending over slightly to serve food.\n\nTheir right arm appears to be extended outwards with some bend at the elbow. The wrist is lower than the shoulder suggesting an angle of less than 90 degrees at the elbow joint indicating a reach-out action possibly towards someone or something like a dish or tray.\n\nThe left arm also seems bent at the elbow with wrist higher than shoulder indicating an angle more than 90 degrees at elbow joint suggesting that it may be holding something closer towards their body.\n\nThe head position suggests that they are looking down which aligns with their current activity of serving food where one would typically look downwards towards plates and dishes.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1257,297],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[1232,288],[1236.1271,311.7755],[1181.8729,-0.77553],[692,464],[902,417],[1059,247],[1405,329],[1498,613],[1303,562]],&quot;kpts_vis&quot;:[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:9.516749}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1257,\n      297\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1232,\n        288\n      ],\n      [\n        1236.1271,\n        311.7755\n      ],\n      [\n        1181.8729,\n        -0.77553\n      ],\n      [\n        692,\n        464\n      ],\n      [\n        902,\n        417\n      ],\n      [\n        1059,\n        247\n      ],\n      [\n        1405,\n        329\n      ],\n      [\n        1498,\n        613\n      ],\n      [\n        1303,\n        562\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 9.516749\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:13,&quot;string&quot;:&quot;13&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2793,&quot;string&quot;:&quot;2,793&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:224,&quot;string&quot;:&quot;224&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;religious activities, serving food in church&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;077096718.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:59,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in the image who are participating in winter activities, specifically downhill skiing. The pose of these individuals suggests dynamic movement as seen in skiing, with bent knees and leaning torsos. \n\nThe person located towards the left side of the image is in a typical downhill skiing position with their limbs oriented for balance and control. Their right leg is slightly bent at the knee and extended behind them while their left leg is also bent but more forward pointing than the right one, suggesting a turning motion. Their torso leans forward from pelvis to thorax, indicating momentum. The head is held straight above the upper neck, looking ahead.\n\nTheir right arm extends out to their side with a slight bend at elbow while their left arm appears to be more inwardly positioned with a noticeable bend at elbow - possibly due to holding ski poles not visible in this 2D perspective.\n\nThe second person towards the right side of image also exhibits a similar pose that's characteristic for downhill skiers. Both legs are noticeably bent at knees but unlike first individual, they appear symmetrically positioned relative to each other which might suggest that this person is moving straight down hill rather than making a turn.\n\nTheir torso leans forward significantly from pelvis through thorax up till upper neck creating an almost linear alignment suggesting speed or aggressive stance on skis. Unlike first individual though, this person's head appears slightly tilted downward rather than looking straight ahead.\n\nBoth arms extend outwards away from body maintaining almost equal distance throughout - from shoulders through elbows till wrists which could be indicative of maintaining balance during fast paced movement.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[633,371],&quot;id&quot;:0,&quot;kpts&quot;:[[674,492],[671,427],[673,370],[628,362],[617,422],[603,480],[651,366],[663,277],[663.2685,266.6642],[664.7315,210.3358],[697,367],[696,329],[693,281],[633,273],[619,322],[606,357]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.690425},{&quot;center&quot;:[775,350],&quot;id&quot;:1,&quot;kpts&quot;:[[769,461],[779,416],[804,361],[770,358],[754,408],[737,456],[787,360],[798,296],[796.8957,287.4414],[791.1043,242.5586],[772,276],[801,282],[818,292],[778,300],[741,296],[707,291]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.357645}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      633,\n      371\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        674,\n        492\n      ],\n      [\n        671,\n        427\n      ],\n      [\n        673,\n        370\n      ],\n      [\n        628,\n        362\n      ],\n      [\n        617,\n        422\n      ],\n      [\n        603,\n        480\n      ],\n      [\n        651,\n        366\n      ],\n      [\n        663,\n        277\n      ],\n      [\n        663.2685,\n        266.6642\n      ],\n      [\n        664.7315,\n        210.3358\n      ],\n      [\n        697,\n        367\n      ],\n      [\n        696,\n        329\n      ],\n      [\n        693,\n        281\n      ],\n      [\n        633,\n        273\n      ],\n      [\n        619,\n        322\n      ],\n      [\n        606,\n        357\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.690425\n  },\n  {\n    \&quot;center\&quot;: [\n      775,\n      350\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        769,\n        461\n      ],\n      [\n        779,\n        416\n      ],\n      [\n        804,\n        361\n      ],\n      [\n        770,\n        358\n      ],\n      [\n        754,\n        408\n      ],\n      [\n        737,\n        456\n      ],\n      [\n        787,\n        360\n      ],\n      [\n        798,\n        296\n      ],\n      [\n        796.8957,\n        287.4414\n      ],\n      [\n        791.1043,\n        242.5586\n      ],\n      [\n        772,\n        276\n      ],\n      [\n        801,\n        282\n      ],\n      [\n        818,\n        292\n      ],\n      [\n        778,\n        300\n      ],\n      [\n        741,\n        296\n      ],\n      [\n        707,\n        291\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.357645\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2331,&quot;string&quot;:&quot;2,331&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;042754102.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:60,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is skiing downhill. This activity typically involves a forward lean of the body, knees bent and arms out to maintain balance.\n\nThe centered person is relatively large in scale with their limbs positioned for downhill skiing. \n\nStarting with the legs, their right leg appears slightly bent at the knee and hip, indicating a semi-crouched position typical for downhill skiing. The left leg mirrors this position, maintaining balance and control during descent.\n\nMoving onto their arms, the right arm seems to be extended outward slightly behind them likely holding a ski pole. Similarly, the left arm also appears to be extended outward but more towards their front which could suggest they are mid-motion or adjusting direction.\n\nTheir torso leans forward suggesting momentum and speed as they descend down the slope. \n\nLastly, their head appears upright with relation to upper neck suggesting that they are looking ahead possibly scanning terrain or deciding on direction of travel.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[291,326],&quot;id&quot;:0,&quot;kpts&quot;:[[366,358],[363,241],[335,358],[245,359],[291,335],[354,271],[290,359],[282,231],[285.6428,211.9453],[304.3572,114.0547],[441,376],[384,329],[337,246],[226,215],[196,291],[215,359]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.989903}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      291,\n      326\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        366,\n        358\n      ],\n      [\n        363,\n        241\n      ],\n      [\n        335,\n        358\n      ],\n      [\n        245,\n        359\n      ],\n      [\n        291,\n        335\n      ],\n      [\n        354,\n        271\n      ],\n      [\n        290,\n        359\n      ],\n      [\n        282,\n        231\n      ],\n      [\n        285.6428,\n        211.9453\n      ],\n      [\n        304.3572,\n        114.0547\n      ],\n      [\n        441,\n        376\n      ],\n      [\n        384,\n        329\n      ],\n      [\n        337,\n        246\n      ],\n      [\n        226,\n        215\n      ],\n      [\n        196,\n        291\n      ],\n      [\n        215,\n        359\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.989903\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2331,&quot;string&quot;:&quot;2,331&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:63,&quot;string&quot;:&quot;63&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;002541913.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:61,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is skiing downhill. The activity involves a lot of lower body movement, with the knees and ankles bending to absorb shocks and navigate turns.\n\nThe center person is in an active state with their limbs positioned for downhill skiing.\n\nStarting with the legs, their right leg appears to be bent at the knee and hip, suggesting a forward leaning posture typical of downhill skiing. The right ankle seems to be slightly flexed as well. Similarly, their left leg also appears bent at the knee and hip but to a lesser extent than the right. \n\nMoving onto arms, their right arm seems extended outwards with a slight bend at the elbow which could be holding ski poles for balance and navigation during skiing. Their left arm also appears extended outwards but more so than the right arm - perhaps they are mid-motion or preparing for a turn.\n\nTheir torso leans forward slightly aligning itself with gravity's pull down slope - this helps skiers maintain control while speeding down hills.\n\nLastly, their head faces straight ahead indicating focus on path ahead - an essential aspect of safe downhill skiing.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[313,240],&quot;id&quot;:0,&quot;kpts&quot;:[[382,521],[365,400],[318,304],[251,308],[311,383],[322,467],[285,306],[303,163],[303.3578,161.5348],[323.6422,78.4652],[432,280],[382,238],[339,164],[267,162],[262,239],[303,274]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.565307}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      313,\n      240\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        382,\n        521\n      ],\n      [\n        365,\n        400\n      ],\n      [\n        318,\n        304\n      ],\n      [\n        251,\n        308\n      ],\n      [\n        311,\n        383\n      ],\n      [\n        322,\n        467\n      ],\n      [\n        285,\n        306\n      ],\n      [\n        303,\n        163\n      ],\n      [\n        303.3578,\n        161.5348\n      ],\n      [\n        323.6422,\n        78.4652\n      ],\n      [\n        432,\n        280\n      ],\n      [\n        382,\n        238\n      ],\n      [\n        339,\n        164\n      ],\n      [\n        267,\n        162\n      ],\n      [\n        262,\n        239\n      ],\n      [\n        303,\n        274\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.565307\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2331,&quot;string&quot;:&quot;2,331&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:132,&quot;string&quot;:&quot;132&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;010789143.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:62,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically downhill skiing. The skier's pose suggests a dynamic movement typically seen during a downhill ski run.\n\nThe center of the image features this person, appearing quite large due to their close proximity to the camera. They are leaning forward with their body tilted towards the right side of frame.\n\nStarting with their legs:\n- The right leg is bent at an angle, with the knee positioned ahead of the hip and ankle. The knee seems to be bearing most of body weight.\n- Similar to the right leg, left leg is also bent but it's slightly behind compared to right leg indicating a push-off position common in skiing.\n\nMoving on to arms:\n- Their right arm is extended forward and slightly towards left from viewer’s perspective, suggesting that they might be holding onto ski poles.\n- Similarly, left arm appears extended but it's angled more downwards than right arm.\n\nAs for torso and head:\n- The torso leans forward significantly as if preparing for or currently executing a swift move down hill.\n- Head faces straight ahead which suggests that skier has their eyes on path ahead.\n\nOverall, this pose captures an intense moment mid-action during downhill skiing.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[257,306],&quot;id&quot;:0,&quot;kpts&quot;:[[288,688],[274,555],[181,430],[129,429],[205,547],[213,652],[155,430],[180,153],[196.509,129.1181],[266.491,27.8819],[262,350],[226,323],[214,171],[146,134],[201,267],[250,335]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.692102}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      257,\n      306\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        288,\n        688\n      ],\n      [\n        274,\n        555\n      ],\n      [\n        181,\n        430\n      ],\n      [\n        129,\n        429\n      ],\n      [\n        205,\n        547\n      ],\n      [\n        213,\n        652\n      ],\n      [\n        155,\n        430\n      ],\n      [\n        180,\n        153\n      ],\n      [\n        196.509,\n        129.1181\n      ],\n      [\n        266.491,\n        27.8819\n      ],\n      [\n        262,\n        350\n      ],\n      [\n        226,\n        323\n      ],\n      [\n        214,\n        171\n      ],\n      [\n        146,\n        134\n      ],\n      [\n        201,\n        267\n      ],\n      [\n        250,\n        335\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.692102\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2331,&quot;string&quot;:&quot;2,331&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:196,&quot;string&quot;:&quot;196&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;003142919.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:63,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are two people in image who are engaging in winter activities, specifically downhill skiing. The keypoint data indicates that both individuals are likely in the midst of active movement, possibly mid-stride or during a turn based on the positions of their limbs and body.\n\nThe person at the center-right of the image is actively skiing with their limbs positioned for balance and control. Their right leg is slightly bent at the knee and hip, suggesting forward momentum. The left leg mirrors this position, indicating that they might be mid-stride or initiating a turn. Both arms appear to be held out to either side for balance, with slight bends at each elbow.\n\nThe person located towards the center-left of the image appears to also be actively skiing but might be leaning into a sharper turn based on their pose. Their right leg is significantly bent at both hip and knee while their left leg maintains a straighter alignment. This could suggest an aggressive carving motion or tight turn being executed by this skier. Both arms are held out from their body similarly to the first individual, likely for stability during this maneuver.\n\nIn both cases, it's worth noting that due to active movement in downhill skiing which typically involves rapid shifts in weight distribution and balance adjustment, these poses may not represent static states but rather snapshots within dynamic actions.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[651,242],&quot;id&quot;:0,&quot;kpts&quot;:[[630,287],[639,265],[645,238],[664,239],[658,266],[649,291],[655,239],[662,202],[662.1424,199.793],[663.8576,173.207],[636,236],[640,219],[647,200],[677,203],[677,216],[675,227]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:0.79924},{&quot;center&quot;:[241,252],&quot;id&quot;:1,&quot;kpts&quot;:[[239,351],[242,296],[216,246],[180,244],[212,294],[221,347],[198,245],[222,200],[222.6442,199.1337],[250.3558,161.8663],[234,265],[241,249],[240,201],[203,198],[211,230],[221,253]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.393241}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      651,\n      242\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        630,\n        287\n      ],\n      [\n        639,\n        265\n      ],\n      [\n        645,\n        238\n      ],\n      [\n        664,\n        239\n      ],\n      [\n        658,\n        266\n      ],\n      [\n        649,\n        291\n      ],\n      [\n        655,\n        239\n      ],\n      [\n        662,\n        202\n      ],\n      [\n        662.1424,\n        199.793\n      ],\n      [\n        663.8576,\n        173.207\n      ],\n      [\n        636,\n        236\n      ],\n      [\n        640,\n        219\n      ],\n      [\n        647,\n        200\n      ],\n      [\n        677,\n        203\n      ],\n      [\n        677,\n        216\n      ],\n      [\n        675,\n        227\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 0.79924\n  },\n  {\n    \&quot;center\&quot;: [\n      241,\n      252\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        239,\n        351\n      ],\n      [\n        242,\n        296\n      ],\n      [\n        216,\n        246\n      ],\n      [\n        180,\n        244\n      ],\n      [\n        212,\n        294\n      ],\n      [\n        221,\n        347\n      ],\n      [\n        198,\n        245\n      ],\n      [\n        222,\n        200\n      ],\n      [\n        222.6442,\n        199.1337\n      ],\n      [\n        250.3558,\n        161.8663\n      ],\n      [\n        234,\n        265\n      ],\n      [\n        241,\n        249\n      ],\n      [\n        240,\n        201\n      ],\n      [\n        203,\n        198\n      ],\n      [\n        211,\n        230\n      ],\n      [\n        221,\n        253\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.393241\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2331,&quot;string&quot;:&quot;2,331&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:266,&quot;string&quot;:&quot;266&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;063641041.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;}}},{&quot;rowIdx&quot;:64,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically cross-country skiing. The keypoint data suggests that the person is captured mid-action, with their body leaning forward and limbs positioned for propelling themselves forward.\n\nThe centrally-located person is standing upright with their body slightly tilted forward. This posture indicates a dynamic movement often observed in cross-country skiing.\n\nStarting from the lower body, both legs are bent at the knees suggesting a semi-crouched position typical of this activity. The right leg appears to be slightly behind relative to the left leg, possibly indicating a stride or push-off motion.\n\nMoving on to the upper body, both arms are extended outwards but not fully straightened. The right arm seems to be positioned slightly ahead compared to the left arm, which could indicate an alternating arm swing action common in cross-country skiing.\n\nThe torso appears inclined forward from pelvis towards thorax and neck areas suggesting a hunched over pose that skiers adopt for better balance and propulsion. \n\nLastly, observing head keypoints - upper neck and head top - it can be inferred that they are keeping their head down as part of maintaining this overall posture for efficient movement during skiing.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[862,426],&quot;id&quot;:0,&quot;kpts&quot;:[[873,526],[873,485],[874,427],[844,426],[845,482],[844,526],[859,427],[858,376],[857.328,367.7677],[854.672,335.2323],[891,440],[895,416],[881,374],[834,377],[824,413],[823,443]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:0.979306}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      862,\n      426\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        873,\n        526\n      ],\n      [\n        873,\n        485\n      ],\n      [\n        874,\n        427\n      ],\n      [\n        844,\n        426\n      ],\n      [\n        845,\n        482\n      ],\n      [\n        844,\n        526\n      ],\n      [\n        859,\n        427\n      ],\n      [\n        858,\n        376\n      ],\n      [\n        857.328,\n        367.7677\n      ],\n      [\n        854.672,\n        335.2323\n      ],\n      [\n        891,\n        440\n      ],\n      [\n        895,\n        416\n      ],\n      [\n        881,\n        374\n      ],\n      [\n        834,\n        377\n      ],\n      [\n        824,\n        413\n      ],\n      [\n        823,\n        443\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 0.979306\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:14,&quot;string&quot;:&quot;14&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:706,&quot;string&quot;:&quot;706&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:10,&quot;string&quot;:&quot;10&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, cross-country&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;031435598.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:65,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is participating in winter activities, specifically cross-country skiing. This activity typically involves a forward-leaning posture with arms and legs moving alternately.\n\nThe central person is large-scale and centered towards the right side of the image. They are captured mid-action, seemingly pushing off with their poles to gain momentum.\n\nStarting from their lower body, the right leg appears extended backwards with a slight bend at the knee, indicating a push-off motion typical in skiing. The right ankle is not visible suggesting that it might be obscured by snow or ski equipment. The left leg seems to be bent at the knee and hip, positioned slightly forward as if preparing for the next stride.\n\nMoving on to their upper body, both arms appear extended outwards as if gripping ski poles for balance and propulsion. The right arm is slightly bent at elbow whereas left arm appears straighter pointing downwards; this asymmetry suggests an alternate poling action common in cross-country skiing.\n\nAs for their torso and head region: they are leaning forward from pelvis up through thorax to upper neck - a typical pose when trying to maintain balance during such winter activities. Their head top seems lowered possibly focusing on terrain ahead or maintaining stability during movement.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[770,714],&quot;id&quot;:0,&quot;kpts&quot;:[[933,1074],[897,968],[863,773],[746,794],[762,1015],[-1,-1],[805,784],[774,609],[772.0811,595.1415],[757.9189,492.8585],[781,670],[827,644],[837,603],[711,614],[670,682],[707,629]],&quot;kpts_vis&quot;:[1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.097767}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      770,\n      714\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        933,\n        1074\n      ],\n      [\n        897,\n        968\n      ],\n      [\n        863,\n        773\n      ],\n      [\n        746,\n        794\n      ],\n      [\n        762,\n        1015\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        805,\n        784\n      ],\n      [\n        774,\n        609\n      ],\n      [\n        772.0811,\n        595.1415\n      ],\n      [\n        757.9189,\n        492.8585\n      ],\n      [\n        781,\n        670\n      ],\n      [\n        827,\n        644\n      ],\n      [\n        837,\n        603\n      ],\n      [\n        711,\n        614\n      ],\n      [\n        670,\n        682\n      ],\n      [\n        707,\n        629\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.097767\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:14,&quot;string&quot;:&quot;14&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:706,&quot;string&quot;:&quot;706&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:78,&quot;string&quot;:&quot;78&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, cross-country&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;050857069.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:66,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is skiing downhill. The sport of downhill skiing involves a dynamic body pose, typically with the skier leaning forward, knees bent, and arms outstretched for balance.\n\nThe person in the center of the image is engaged in this activity. Their body orientation suggests they are moving swiftly down a slope.\n\nStarting with their legs:\n- The right leg appears to be slightly bent at the knee and hip, suggesting a semi-flexed position common in downhill skiing.\n- The left leg mirrors this posture but seems to be more extended at the knee and hip joints.\n- Both ankles seem to be flexed as well, indicating that they are applying pressure on their ski boots for control.\n\nMoving onto their torso:\n- The pelvis and thorax appear to be leaning forward - a typical posture for gaining speed while skiing.\n- Their upper neck shows an upright position aligning with their torso's inclination; it suggests they're looking ahead on their path.\n\nLastly, considering their arms:\n- Their right arm appears extended towards front-right direction from shoulder joint while elbow seems slightly bent\n- Similarly, left arm also shows an extended position towards front-left direction from shoulder joint but elbow here looks more flexed than its counterpart.\n \nThis overall body posture indicates that they are actively engaged in downhill skiing.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1382,434],&quot;id&quot;:0,&quot;kpts&quot;:[[1437,624],[1381,547],[1319,455],[1395,428],[1452,533],[1499,620],[1357,442],[1331,311],[1331.574,321.475],[1326.426,227.525],[1225,402],[1232,374],[1268,318],[1393,304],[1442,332],[1496,358]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.822731}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1382,\n      434\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        1437,\n        624\n      ],\n      [\n        1381,\n        547\n      ],\n      [\n        1319,\n        455\n      ],\n      [\n        1395,\n        428\n      ],\n      [\n        1452,\n        533\n      ],\n      [\n        1499,\n        620\n      ],\n      [\n        1357,\n        442\n      ],\n      [\n        1331,\n        311\n      ],\n      [\n        1331.574,\n        321.475\n      ],\n      [\n        1326.426,\n        227.525\n      ],\n      [\n        1225,\n        402\n      ],\n      [\n        1232,\n        374\n      ],\n      [\n        1268,\n        318\n      ],\n      [\n        1393,\n        304\n      ],\n      [\n        1442,\n        332\n      ],\n      [\n        1496,\n        358\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.822731\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:661,&quot;string&quot;:&quot;661&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2,&quot;string&quot;:&quot;2&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;090756647.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:67,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is participating in winter activities, specifically downhill skiing. The person appears to be captured mid-motion, possibly during a high-speed descent or a turn maneuver.\n\nThe center of the frame person is engaged in an intense activity with their limbs positioned for balance and control. \n\nTheir right leg seems to be slightly bent at the knee and hip, while their left leg appears more flexed at both joints. This could suggest that they are leaning into a turn or adjusting their weight distribution for stability.\n\nThe right arm is bent at the elbow and extended outwards from the body, likely helping maintain balance during movement. The left arm also appears to be bent at the elbow but drawn closer towards the body compared to the right arm.\n\nTheir torso leans forward slightly indicating speed and control while skiing downhill. This posture aids in reducing air resistance and maintaining balance over skis.\n\nLastly, their head seems to be facing straight ahead suggesting focus on their path down slope.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[588,633],&quot;id&quot;:0,&quot;kpts&quot;:[[230,930],[354,784],[500,630],[642,681],[474,802],[373,936],[571,656],[663,410],[668.3875,427.5093],[625.6125,288.4907],[314,443],[429,415],[563,370],[762,450],[824,603],[805,689]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.363514}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      588,\n      633\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        230,\n        930\n      ],\n      [\n        354,\n        784\n      ],\n      [\n        500,\n        630\n      ],\n      [\n        642,\n        681\n      ],\n      [\n        474,\n        802\n      ],\n      [\n        373,\n        936\n      ],\n      [\n        571,\n        656\n      ],\n      [\n        663,\n        410\n      ],\n      [\n        668.3875,\n        427.5093\n      ],\n      [\n        625.6125,\n        288.4907\n      ],\n      [\n        314,\n        443\n      ],\n      [\n        429,\n        415\n      ],\n      [\n        563,\n        370\n      ],\n      [\n        762,\n        450\n      ],\n      [\n        824,\n        603\n      ],\n      [\n        805,\n        689\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.363514\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:661,&quot;string&quot;:&quot;661&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:62,&quot;string&quot;:&quot;62&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;024929223.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:68,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically downhill skiing. The activity typically involves a forward-leaning posture with bent knees, arms positioned to balance and guide movements, and feet secured on skis.\n\nThe person located centrally in the image appears to be mid-action while skiing downhill. Their body orientation suggests swift movement.\n\nStarting with their right leg, the ankle is slightly ahead of the knee indicating a bent position while their hip leans towards the back. This indicates that they are pushing off from this leg for momentum.\n\nThe left leg mirrors this position but seems more straightened out suggesting it's bearing most of their weight at this moment. \n\nTheir torso leans forward significantly from the pelvis up to thorax and neck indicating an aggressive skiing posture meant for speed or control during descent.\n\nThe head appears tilted upwards slightly which could suggest looking ahead down the slope or responding to wind resistance due to high speed.\n\nFor arms, both are extended wide outwards but bent at elbows forming almost right angles. The right arm extends backwards suggesting recent use of ski pole for thrust while left arm extends forward possibly preparing for next pole plant for maintaining rhythm or direction change.\n\nOverall, this pose captures an intense moment during downhill skiing where quick decisions and precise movements can greatly affect performance.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[718,351],&quot;id&quot;:0,&quot;kpts&quot;:[[736,646],[752,484],[681,370],[783,368],[856,485],[853,650],[732,369],[752,205],[745.007,214.9901],[814.993,115.0099],[601,306],[600,265],[673,195],[831,215],[889,294],[966,353]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.661239}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      718,\n      351\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        736,\n        646\n      ],\n      [\n        752,\n        484\n      ],\n      [\n        681,\n        370\n      ],\n      [\n        783,\n        368\n      ],\n      [\n        856,\n        485\n      ],\n      [\n        853,\n        650\n      ],\n      [\n        732,\n        369\n      ],\n      [\n        752,\n        205\n      ],\n      [\n        745.007,\n        214.9901\n      ],\n      [\n        814.993,\n        115.0099\n      ],\n      [\n        601,\n        306\n      ],\n      [\n        600,\n        265\n      ],\n      [\n        673,\n        195\n      ],\n      [\n        831,\n        215\n      ],\n      [\n        889,\n        294\n      ],\n      [\n        966,\n        353\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.661239\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:661,&quot;string&quot;:&quot;661&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:209,&quot;string&quot;:&quot;209&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;075555114.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:69,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in winter activities, specifically skiing and climbing up. This activity involves a lot of lower body movement, especially the legs and hips, which are crucial for maintaining balance and navigating through the snow.\n\nThe central person is captured in a dynamic pose with their limbs positioned as if they are pushing off the ground with ski poles to climb uphill.\n\nTheir right leg appears to be slightly bent at the knee and hip, suggesting that they're putting weight on it. The right ankle seems to be flexed as well.\n\nThe left leg appears straighter than the right one, with both knee and hip extended. The left ankle seems to be angled forward, likely indicating that this foot is leading at this moment of motion.\n\nTheir torso leans forward slightly from their pelvis towards their head top. It suggests an active engagement of core muscles necessary for skiing uphill.\n\nThe arms are both bent at elbows but differ in positions: The right arm extends forward from shoulder while left arm pulls back behind them - mimicking a typical pole-pushing motion during skiing.\n \nLastly, their head aligns straight above upper neck suggesting that they're looking ahead possibly focusing on their path or destination.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[738,437],&quot;id&quot;:0,&quot;kpts&quot;:[[923,630],[901,532],[836,449],[882,415],[862,515],[797,605],[859,432],[745,274],[711.9408,271.1096],[595.0592,260.8904],[524,298],[626,288],[712,215],[778,332],[649,418],[513,407]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.519827}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      738,\n      437\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        923,\n        630\n      ],\n      [\n        901,\n        532\n      ],\n      [\n        836,\n        449\n      ],\n      [\n        882,\n        415\n      ],\n      [\n        862,\n        515\n      ],\n      [\n        797,\n        605\n      ],\n      [\n        859,\n        432\n      ],\n      [\n        745,\n        274\n      ],\n      [\n        711.9408,\n        271.1096\n      ],\n      [\n        595.0592,\n        260.8904\n      ],\n      [\n        524,\n        298\n      ],\n      [\n        626,\n        288\n      ],\n      [\n        712,\n        215\n      ],\n      [\n        778,\n        332\n      ],\n      [\n        649,\n        418\n      ],\n      [\n        513,\n        407\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.519827\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:127,&quot;string&quot;:&quot;127&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:6,&quot;string&quot;:&quot;6&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;022879817.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:70,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in winter activities, specifically skiing and climbing up. The individual appears to be performing a strenuous activity, as indicated by the positioning of their limbs.\n\nThe person centered towards the right side of the image is actively moving with their limbs extended.\n\nStarting with their left leg, it seems to be stretched out behind them with a slight bend at the knee, suggesting that they are pushing off from this leg for forward movement. The right knee on the other hand is bent and raised slightly higher than hip level indicating an upward climb or stride.\n\nMoving onto arms, both arms are bent at sharp angles at elbow joints. The right arm appears to be reaching forward while left arm seems to be pulling back as if they are using ski poles for propulsion.\n\nAs for torso and head - Torso leans forward suggesting an aggressive posture needed for uphill skiing. Head position suggests looking straight ahead focusing on path ahead.\n\nPlease note that not all keypoints were visible in this dataset; specifically, we could not determine locations of ankles which could have provided further insights into pose analysis.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[739,310],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[455,648],[664,619],[854,630],[931,715],[-1,-1],[759,625],[798,314],[791.7744,341.6355],[845.2256,104.3645],[473,381],[545,299],[704,307],[892,321],[1051,205],[1038,9]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:7.296513}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      739,\n      310\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        455,\n        648\n      ],\n      [\n        664,\n        619\n      ],\n      [\n        854,\n        630\n      ],\n      [\n        931,\n        715\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        759,\n        625\n      ],\n      [\n        798,\n        314\n      ],\n      [\n        791.7744,\n        341.6355\n      ],\n      [\n        845.2256,\n        104.3645\n      ],\n      [\n        473,\n        381\n      ],\n      [\n        545,\n        299\n      ],\n      [\n        704,\n        307\n      ],\n      [\n        892,\n        321\n      ],\n      [\n        1051,\n        205\n      ],\n      [\n        1038,\n        9\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 7.296513\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:127,&quot;string&quot;:&quot;127&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:66,&quot;string&quot;:&quot;66&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;007697991.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:71,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. The pose suggests a strenuous activity with significant body tension and balance required.\n\nThe central person is positioned slightly to the right with their body almost facing directly towards us. \n\nTheir right leg appears to be bent at the knee, suggesting a stepping motion. The ankle, knee, and hip form an acute angle indicative of this movement.\n\nSimilarly, their left leg also appears to be bent at the knee but less so than the right one. This could suggest that they are using it for support as they lift themselves up.\n\nThe torso of this individual seems to be leaning forward slightly as if straining against an incline or exerting effort in climbing.\n\nTheir right arm is bent at the elbow with their wrist higher than it indicating that they might be pushing against something like ski poles for support or leverage during their climb.\n\nOn the other hand, their left arm seems slightly extended but still maintaining a bend at elbow holding another pole perhaps for balance during this uphill climb. \n\nLastly, from what can be seen of their head position relative to neck and shoulders suggests they are looking upwards or ahead possibly gauging distance or direction.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[220,238],&quot;id&quot;:0,&quot;kpts&quot;:[[253,336],[234,286],[245,236],[265,235],[250,291],[269,348],[255,236],[230,177],[224.9983,172.1265],[196.0017,143.8735],[209,222],[218,212],[221,177],[238,177],[244,215],[216,221]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.214552}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      220,\n      238\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        253,\n        336\n      ],\n      [\n        234,\n        286\n      ],\n      [\n        245,\n        236\n      ],\n      [\n        265,\n        235\n      ],\n      [\n        250,\n        291\n      ],\n      [\n        269,\n        348\n      ],\n      [\n        255,\n        236\n      ],\n      [\n        230,\n        177\n      ],\n      [\n        224.9983,\n        172.1265\n      ],\n      [\n        196.0017,\n        143.8735\n      ],\n      [\n        209,\n        222\n      ],\n      [\n        218,\n        212\n      ],\n      [\n        221,\n        177\n      ],\n      [\n        238,\n        177\n      ],\n      [\n        244,\n        215\n      ],\n      [\n        216,\n        221\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.214552\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:86,&quot;string&quot;:&quot;86&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;016122129.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:72,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. The person appears to be mid-motion, possibly exerting effort to ascend a slope.\n\nThe center person is located at coordinates (408.0, 209.0) with a scale of 1.530741 and they are actively engaged in their activity with their limbs positioned for balance and movement.\n\nStarting with the legs:\n- The right leg seems to be bent at the knee with the ankle situated behind it, indicating an active push-off motion common in skiing.\n- The left leg appears similarly bent but slightly more extended than the right one, perhaps preparing for or recovering from a stride.\n\nMoving on to the arms:\n- Their right arm is extended forward and slightly upwards as if reaching out for balance or pulling on ski poles.\n- Their left arm is also extended but directed downwards and backwards, suggesting that it was recently used for propulsion or balance.\n\nAs for their torso:\n- It leans forward suggesting active engagement and momentum towards an uphill direction which aligns well with climbing up during skiing activities.\n\nLastly regarding their head:\n- It's held high above shoulders level but tilts forward slightly hinting towards concentration on upcoming terrain or path ahead while skiing uphill.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[408,209],&quot;id&quot;:0,&quot;kpts&quot;:[[408,398],[442,337],[446,187],[362,181],[394,321],[341,384],[404,184],[441,118],[470.8992,123.4362],[521.1008,132.5638],[539,96],[503,64],[490,95],[392,140],[351,142],[342,199]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.530741}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      408,\n      209\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        408,\n        398\n      ],\n      [\n        442,\n        337\n      ],\n      [\n        446,\n        187\n      ],\n      [\n        362,\n        181\n      ],\n      [\n        394,\n        321\n      ],\n      [\n        341,\n        384\n      ],\n      [\n        404,\n        184\n      ],\n      [\n        441,\n        118\n      ],\n      [\n        470.8992,\n        123.4362\n      ],\n      [\n        521.1008,\n        132.5638\n      ],\n      [\n        539,\n        96\n      ],\n      [\n        503,\n        64\n      ],\n      [\n        490,\n        95\n      ],\n      [\n        392,\n        140\n      ],\n      [\n        351,\n        142\n      ],\n      [\n        342,\n        199\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.530741\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:147,&quot;string&quot;:&quot;147&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;092969765.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:73,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is skiing downhill. The activity involves a forward-leaning position, with arms extended for balance and knees slightly bent. \n\nThe center person appears to be in mid-movement, likely navigating a downhill slope while skiing. Their body orientation suggests active engagement with their environment.\n\nTheir right arm is extended forward, with the wrist positioned higher than the elbow, indicating an active movement or gesture. This could be for balance or steering purposes during skiing. The left arm mirrors this position but slightly lower.\n\nBoth legs are not visible in this dataset; hence we cannot provide information about them.\n\nThe torso leans forward from the pelvis to thorax and up to the neck, suggesting an aggressive or proactive stance common in downhill skiing activities.\n\nDespite missing data points for head keypoints (upper neck and head top), based on available information from thorax and shoulder positions, it can be inferred that they are looking straight ahead which aligns with typical pose during downhill skiing where focus on path ahead is crucial.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[218,372],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[216,372],[219.5859,351.381],[228.4141,300.619],[295,419],[276,414],[255,370],[176,374],[161,400],[183,397]],&quot;kpts_vis&quot;:[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.545719}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      218,\n      372\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        216,\n        372\n      ],\n      [\n        219.5859,\n        351.381\n      ],\n      [\n        228.4141,\n        300.619\n      ],\n      [\n        295,\n        419\n      ],\n      [\n        276,\n        414\n      ],\n      [\n        255,\n        370\n      ],\n      [\n        176,\n        374\n      ],\n      [\n        161,\n        400\n      ],\n      [\n        183,\n        397\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.545719\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:281,&quot;string&quot;:&quot;281&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;063340376.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:74,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are three people in the image who are engaging in winter activities, such as skiing and climbing up. All individuals appear to be in active poses associated with these activities, with their limbs positioned for movement or balance.\n\nThe person located at the center of the image is actively climbing up with their right leg visible. The right knee is bent and higher than the ankle, suggesting a stepping-up motion. The right arm is also bent at the elbow and lifted above waist level, which could indicate pushing off with a ski pole or maintaining balance during ascent. The left arm appears to be extended forward slightly. \n\nThe person on the right side of this individual seems to be skiing downhill or balancing themselves on an incline. Both legs are slightly bent at knees indicating a crouching pose common in skiing for stability and control over speed. Their arms seem to be held out wide possibly holding ski poles for balance.\n\nLastly, there's another individual towards left side of image who seems to maintain a steady upright position despite being engaged in winter activity like skiing or climbing up slope which might indicate they're either standing still or moving very slowly uphill/downhill.\nTheir legs seem slightly apart while both arms are close to torso perhaps holding onto something like ski poles for support.\n\nIn all cases heads appear upright facing forwards indicating alertness towards path ahead fitting well into context of winter sports where focus on path ahead is crucial.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[318,375],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[265,472],[290,394],[345,401],[335,472],[-1,-1],[318,398],[301,291],[294.0641,271.9758],[272.9359,214.0242],[240,382],[255,339],[261,302],[340,280],[360,354],[328,336]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.850492},{&quot;center&quot;:[501,390],&quot;id&quot;:1,&quot;kpts&quot;:[[496,471],[486,440],[474,388],[496,382],[486,434],[486,476],[485,385],[484,334],[484.5062,340.0746],[481.4938,303.9254],[439,375],[449,357],[464,332],[503,336],[522,364],[529,392]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.088235},{&quot;center&quot;:[574,352],&quot;id&quot;:2,&quot;kpts&quot;:[[566,423],[567,391],[570,362],[589,369],[592,394],[592,418],[580,366],[575,329],[574.9218,328.3481],[572.0782,304.6519],[565,361],[563,351],[564,329],[586,329],[596,355],[582,367]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:0.715989}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      318,\n      375\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        265,\n        472\n      ],\n      [\n        290,\n        394\n      ],\n      [\n        345,\n        401\n      ],\n      [\n        335,\n        472\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        318,\n        398\n      ],\n      [\n        301,\n        291\n      ],\n      [\n        294.0641,\n        271.9758\n      ],\n      [\n        272.9359,\n        214.0242\n      ],\n      [\n        240,\n        382\n      ],\n      [\n        255,\n        339\n      ],\n      [\n        261,\n        302\n      ],\n      [\n        340,\n        280\n      ],\n      [\n        360,\n        354\n      ],\n      [\n        328,\n        336\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.850492\n  },\n  {\n    \&quot;center\&quot;: [\n      501,\n      390\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        496,\n        471\n      ],\n      [\n        486,\n        440\n      ],\n      [\n        474,\n        388\n      ],\n      [\n        496,\n        382\n      ],\n      [\n        486,\n        434\n      ],\n      [\n        486,\n        476\n      ],\n      [\n        485,\n        385\n      ],\n      [\n        484,\n        334\n      ],\n      [\n        484.5062,\n        340.0746\n      ],\n      [\n        481.4938,\n        303.9254\n      ],\n      [\n        439,\n        375\n      ],\n      [\n        449,\n        357\n      ],\n      [\n        464,\n        332\n      ],\n      [\n        503,\n        336\n      ],\n      [\n        522,\n        364\n      ],\n      [\n        529,\n        392\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.088235\n  },\n  {\n    \&quot;center\&quot;: [\n      574,\n      352\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        566,\n        423\n      ],\n      [\n        567,\n        391\n      ],\n      [\n        570,\n        362\n      ],\n      [\n        589,\n        369\n      ],\n      [\n        592,\n        394\n      ],\n      [\n        592,\n        418\n      ],\n      [\n        580,\n        366\n      ],\n      [\n        575,\n        329\n      ],\n      [\n        574.9218,\n        328.3481\n      ],\n      [\n        572.0782,\n        304.6519\n      ],\n      [\n        565,\n        361\n      ],\n      [\n        563,\n        351\n      ],\n      [\n        564,\n        329\n      ],\n      [\n        586,\n        329\n      ],\n      [\n        596,\n        355\n      ],\n      [\n        582,\n        367\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 0.715989\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:376,&quot;string&quot;:&quot;376&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;087146059.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;}}},{&quot;rowIdx&quot;:75,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. This activity involves a lot of leg work, often with the knees bent and arms positioned for balance or to use ski poles.\n\nThe centrally located person is captured mid-action with their limbs positioned as if they are climbing uphill. \n\nTheir right leg appears to be bent at the knee, suggesting that it might be lifting off the ground or pushing against it for upward movement. The left leg seems to be straightened and firmly planted on the ground, providing support.\n\nThe right arm's position cannot be determined due to invisibility of some keypoints but we can observe that their left arm appears extended outwards from the shoulder towards their front-left side, possibly reaching out for support or balance.\n\nTheir torso seems slightly leaned forward indicating effort being put into climbing up. \n\nLastly, their head is upright facing forward which indicates focus on path ahead during this strenuous activity.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[417,281],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[357,438],[353,356],[433,356],[415,455],[-1,-1],[393,356],[407,202],[417.1508,169.6141],[438.8492,100.3859],[545,225],[-1,-1],[467,198],[346,205],[311,244],[309,293]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1],&quot;scale&quot;:2.176471}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      417,\n      281\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        357,\n        438\n      ],\n      [\n        353,\n        356\n      ],\n      [\n        433,\n        356\n      ],\n      [\n        415,\n        455\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        393,\n        356\n      ],\n      [\n        407,\n        202\n      ],\n      [\n        417.1508,\n        169.6141\n      ],\n      [\n        438.8492,\n        100.3859\n      ],\n      [\n        545,\n        225\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        467,\n        198\n      ],\n      [\n        346,\n        205\n      ],\n      [\n        311,\n        244\n      ],\n      [\n        309,\n        293\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.176471\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:446,&quot;string&quot;:&quot;446&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;080367208.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:76,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. This activity generally involves bending at the hips and knees, extending the arms for balance and propulsion, and leaning forward slightly from the waist.\n\nThe center person is positioned with their body facing towards the right side of the image. Their legs are apart with right hip visible at coordinates (422, 423) but both knees and ankles are not visible indicating they might be bent or obscured due to clothing or equipment.\n\nTheir torso appears to be leaning forward given that their pelvis point at (461,426) is closer to their thorax point at (474,307). Their head seems to be looking upwards as indicated by upper neck position (468,322) being lower than head top position (499,235).\n\nThe right arm appears extended diagonally downwards with wrist coordinate at (345,316), elbow coordinate at (362,331), indicating a slight bend in elbow joint. The left arm also seems extended diagonally upwards with wrist coordinate located higher than elbow coordinate which itself is higher than shoulder coordinate - suggesting an upward reach or push.\n\nIn conclusion this pose suggests a person engaged in uphill skiing motion where they are pushing themselves upward using ski poles while keeping their legs bent for stability.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[467,376],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[422,423],[499,429],[-1,-1],[-1,-1],[461,426],[474,307],[468.3917,322.7033],[499.6083,235.2967],[345,316],[362,331],[423,305],[524,309],[586,351],[612,345]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.784414}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      467,\n      376\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        422,\n        423\n      ],\n      [\n        499,\n        429\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        461,\n        426\n      ],\n      [\n        474,\n        307\n      ],\n      [\n        468.3917,\n        322.7033\n      ],\n      [\n        499.6083,\n        235.2967\n      ],\n      [\n        345,\n        316\n      ],\n      [\n        362,\n        331\n      ],\n      [\n        423,\n        305\n      ],\n      [\n        524,\n        309\n      ],\n      [\n        586,\n        351\n      ],\n      [\n        612,\n        345\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.784414\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:978,&quot;string&quot;:&quot;978&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2376,&quot;string&quot;:&quot;2,376&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:634,&quot;string&quot;:&quot;634&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, climbing up&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;018657006.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:77,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in winter activities, specifically downhill skiing. The pose suggests a dynamic action, likely captured mid-movement. \n\nThe person located towards the center of the image is actively skiing with their limbs distributed for balance and motion.\n\nThe right leg appears to be slightly bent at the knee and hip, with the ankle positioned behind. This suggests that weight might be shifted onto this leg for balance or control during a turn or maneuver.\n\nThe left leg seems to be more straightened compared to the right one, possibly taking less weight but providing stability nonetheless.\n\nThe right arm appears flexed at both elbow and wrist while being held up front, suggesting it might be holding a ski pole for guidance or support.\n\nIn contrast, their left arm seems extended outwards and slightly backwards with a slight bend at elbow which could imply additional balancing act or just part of their movement dynamics.\n\nTheir torso leans forward from pelvis area indicating an aggressive stance often seen in downhill skiing where maintaining low center of gravity helps improve control over speed and direction changes on slopes. \n\nFinally, their head faces forward suggesting they are looking ahead on their path down slope which is consistent with safety practices followed in such winter sports activities.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[284,222],&quot;id&quot;:0,&quot;kpts&quot;:[[247,328],[255,282],[280,220],[316,232],[293,275],[287,336],[298,226],[314,166],[317.5527,158.6104],[335.4473,121.3896],[255,230],[252,185],[284,156],[344,176],[353,215],[346,246]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.238967}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      284,\n      222\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        247,\n        328\n      ],\n      [\n        255,\n        282\n      ],\n      [\n        280,\n        220\n      ],\n      [\n        316,\n        232\n      ],\n      [\n        293,\n        275\n      ],\n      [\n        287,\n        336\n      ],\n      [\n        298,\n        226\n      ],\n      [\n        314,\n        166\n      ],\n      [\n        317.5527,\n        158.6104\n      ],\n      [\n        335.4473,\n        121.3896\n      ],\n      [\n        255,\n        230\n      ],\n      [\n        252,\n        185\n      ],\n      [\n        284,\n        156\n      ],\n      [\n        344,\n        176\n      ],\n      [\n        353,\n        215\n      ],\n      [\n        346,\n        246\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.238967\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:960,&quot;string&quot;:&quot;960&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1158,&quot;string&quot;:&quot;1,158&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:168,&quot;string&quot;:&quot;168&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;winter activities, skiing, downhill&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;089255900.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:78,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is grooming, feeding, cleaning, harnessing and unharnessing a horse. This activity typically involves interaction with an animal and may require bending or reaching movements.\n\nThe centrally located person is engaged with their surroundings. The right ankle keypoint isn't visible which might suggest that it's obscured or behind the horse.\n\nStarting from the lower body:\n\n- The right leg seems to be bent at the knee and hip as we can see from keypoints 1 (right knee) and 2 (right hip). This suggests that this individual might be kneeling or crouching.\n- The left leg appears to be straightened out with both knee and hip keypoints 4 (left knee) and 3 (left hip) aligned vertically. It's possible that this person is supporting their weight on this leg.\n- Unfortunately, left ankle keypoint isn't visible which restricts further analysis of left foot position.\n\nMoving up to upper body:\n\n- The torso appears upright given relatively straight alignment between pelvis keypoint 6, thorax keypoint 7 and upper neck keypoint 8.\n  \nFor arms:\n\n- Right arm seems to be lifted upwards near shoulder level as suggested by keypoints for right wrist at location [994,537] being above elbow [1023,460] which itself is above shoulder [1096,353].\n- Left arm also appears raised but more forward directed since wrist point at [1132,678] lies horizontally closer to torso than its corresponding elbow point at [1285,588].\n\nFinally for head:\n\n- Head orientation can't be precisely determined but it seems slightly tilted downwards considering alignment of upper neck point at [1185,324] with head top point at [1181,184]. \n\nOverall pose suggests an active engagement probably involving some task related to horse care.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1091,546],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[1113,899],[1077,656],[1222,671],[1210,923],[-1,-1],[1150,664],[1186,370],[1185.0154,324.5122],[1181.9846,184.4878],[994,537],[1023,460],[1096,353],[1276,387],[1285,588],[1132,678]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:4.201714}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1091,\n      546\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        1113,\n        899\n      ],\n      [\n        1077,\n        656\n      ],\n      [\n        1222,\n        671\n      ],\n      [\n        1210,\n        923\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        1150,\n        664\n      ],\n      [\n        1186,\n        370\n      ],\n      [\n        1185.0154,\n        324.5122\n      ],\n      [\n        1181.9846,\n        184.4878\n      ],\n      [\n        994,\n        537\n      ],\n      [\n        1023,\n        460\n      ],\n      [\n        1096,\n        353\n      ],\n      [\n        1276,\n        387\n      ],\n      [\n        1285,\n        588\n      ],\n      [\n        1132,\n        678\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 4.201714\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1431,&quot;string&quot;:&quot;1,431&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:5,&quot;string&quot;:&quot;5&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;053934224.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:79,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves several movements and postures that indicate interaction with an animal - likely a horse given the context.\n\nThe person located approximately at the center of the image is captured mid-action with their limbs positioned to suggest they are interacting with something or someone at their right side.\n\nTheir right leg appears to be bent at the hip, suggesting they might be kneeling or crouching. However, due to lack of visibility of knee and ankle joints for both legs, it's difficult to confirm this posture precisely.\n\nTheir torso leans slightly towards their right side indicating a possible bend from waist or hip. The thorax appears higher than hips suggesting an upright upper body position.\n\nThe head seems tilted upwards which could mean that they are looking up or ahead. As for arms, both are extended in different directions - right arm downwards and left arm upwards - possibly interacting with something on either sides of them.\n\nThe right arm shows a noticeable bend at elbow while wrist joint indicates hand might be facing downwards. This could suggest holding onto something below waist level like a brush or reins if we consider horse grooming context. \n\nOn contrary left arm seems fully extended upwards with slight bend at elbow while wrist indicates hand facing outwards possibly reaching out for something above shoulder level like hanging feed bags or harness hooks etc.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[891,556],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[820,835],[1127,842],[-1,-1],[-1,-1],[974,839],[980,436],[990.1692,341.1663],[1012.8308,129.8337],[736,869],[733,708],[795,423],[1164,448],[1170,711],[1211,959]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:6.376326}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      891,\n      556\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        820,\n        835\n      ],\n      [\n        1127,\n        842\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        974,\n        839\n      ],\n      [\n        980,\n        436\n      ],\n      [\n        990.1692,\n        341.1663\n      ],\n      [\n        1012.8308,\n        129.8337\n      ],\n      [\n        736,\n        869\n      ],\n      [\n        733,\n        708\n      ],\n      [\n        795,\n        423\n      ],\n      [\n        1164,\n        448\n      ],\n      [\n        1170,\n        711\n      ],\n      [\n        1211,\n        959\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 6.376326\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1431,&quot;string&quot;:&quot;1,431&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:65,&quot;string&quot;:&quot;65&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;080744016.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:80,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is participating in sports, specifically horse cart driving, either standing or sitting. The activity involves a mix of upper body movement for controlling the horse and maintaining balance.\n\nThe person located near the center of the image appears to be sitting with their limbs arranged accordingly. \n\nTheir right leg is bent at the knee, with their ankle positioned below and slightly to the left of it. The right hip is higher than both knee and ankle suggesting a folded posture.\n\nThe left leg mirrors this position almost identically, suggesting both legs are symmetrically positioned on either side of a possible cart or saddle. \n\nTheir torso seems upright as indicated by close proximity between pelvis and thorax keypoints, with slight tilt towards right possibly due to reins control or balance maintenance.\n\nThe arms appear to be actively engaged in holding reins or balancing. The right arm has elbow slightly above wrist level while left arm has wrist higher than elbow indicating different actions being performed by each hand.\n\nThe head appears to be tilted down slightly as if looking at something below eye level, perhaps focusing on controlling reins or observing path ahead.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[397,254],&quot;id&quot;:0,&quot;kpts&quot;:[[356,312],[355,278],[380,272],[441,272],[426,283],[429,341],[411,272],[422,209],[418.9951,197.8391],[411.0049,168.1609],[362,243],[382,239],[393,205],[450,212],[455,252],[428,244]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:0.92205}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      397,\n      254\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        356,\n        312\n      ],\n      [\n        355,\n        278\n      ],\n      [\n        380,\n        272\n      ],\n      [\n        441,\n        272\n      ],\n      [\n        426,\n        283\n      ],\n      [\n        429,\n        341\n      ],\n      [\n        411,\n        272\n      ],\n      [\n        422,\n        209\n      ],\n      [\n        418.9951,\n        197.8391\n      ],\n      [\n        411.0049,\n        168.1609\n      ],\n      [\n        362,\n        243\n      ],\n      [\n        382,\n        239\n      ],\n      [\n        393,\n        205\n      ],\n      [\n        450,\n        212\n      ],\n      [\n        455,\n        252\n      ],\n      [\n        428,\n        244\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 0.92205\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:262,&quot;string&quot;:&quot;262&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:781,&quot;string&quot;:&quot;781&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:39,&quot;string&quot;:&quot;39&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;sports, horse cart, driving, standing or sitting&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;089609130.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:81,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of bending and reaching out with arms and legs. \n\nThe person located at the center of the image is standing with their body slightly bent forward. Their right leg appears to be extended behind them while their left leg supports their weight.\n\nTheir right leg from ankle to hip (keypoints 0-2) seems to be extended backward indicating a step or a stance while performing an action. The knee appears slightly bent indicating some tension in maintaining this position.\n\nThe left leg from ankle to hip (keypoints 5-3) seems more stable or grounded as it supports the body's weight. The knee joint shows no significant bending implying that it's straightened for support.\n\nThe torso (keypoints 2-7) leans forward suggesting an active engagement with something on ground level or below their waist height.\n\nTheir head (keypoints 8-9) is tilted downward indicating focus on something below them which could be part of their task at hand.\n\nAs for the arms, they are both lifted away from the body suggesting active use. The right arm from wrist to shoulder (keypoints 10-12) seems raised and possibly reaching out towards something or someone as if performing an action such as grooming or harnessing.\n\nSimilarly, the left arm from wrist to shoulder (keypoints 15-13), though not as high as the other arm, also suggests active movement probably holding onto something like a tool used for cleaning.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[146,278],&quot;id&quot;:0,&quot;kpts&quot;:[[143,475],[175,406],[114,291],[197,267],[219,348],[204,446],[156,279],[143,135],[161.1306,112.0346],[214.8694,43.9654],[94,244],[44,213],[89,135],[197,134],[207,216],[247,246]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.601759}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      146,\n      278\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        143,\n        475\n      ],\n      [\n        175,\n        406\n      ],\n      [\n        114,\n        291\n      ],\n      [\n        197,\n        267\n      ],\n      [\n        219,\n        348\n      ],\n      [\n        204,\n        446\n      ],\n      [\n        156,\n        279\n      ],\n      [\n        143,\n        135\n      ],\n      [\n        161.1306,\n        112.0346\n      ],\n      [\n        214.8694,\n        43.9654\n      ],\n      [\n        94,\n        244\n      ],\n      [\n        44,\n        213\n      ],\n      [\n        89,\n        135\n      ],\n      [\n        197,\n        134\n      ],\n      [\n        207,\n        216\n      ],\n      [\n        247,\n        246\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.601759\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1357,&quot;string&quot;:&quot;1,357&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:106,&quot;string&quot;:&quot;106&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;011005192.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:82,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is occupied with horse grooming, feeding, cleaning, harnessing and unharnessing. The pose suggests an action of reaching out or interacting with something at a lower level.\n\nThe centrally located person is positioned mid-frame with their limbs spread out. Their body seems to be leaning forward slightly suggesting an engagement in some activity.\n\nStarting from the legs:\n- The right leg is partially visible with only the knee and hip visible. Their right knee appears to be slightly bent indicating a semi-flexed position.\n- The left leg's hip, knee and ankle are all visible. It appears to be more straightened than the right leg but still maintaining slight bend at the knee which suggests a stance that supports bending over or reaching out.\n\nMoving onto the torso:\n- The torso seems to be leaning forward as indicated by relative positions of pelvis and thorax keypoints.\n \nFor arms:\n- The right arm's wrist, elbow and shoulder are all visible. This arm seems extended forward possibly reaching for something as suggested by low position of wrist keypoint compared to shoulder keypoint.\n- Similarly, left arm also seems extended but towards side rather than front. All keypoints (wrist, elbow &amp; shoulder) are clearly seen in this case too.\n\nFinally for head,\n- Neck and head top keypoints suggest that head is turned slightly towards left side while it maintains its overall downward orientation likely focusing on task being performed by hands/arms.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[436,252],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[458,424],[427,288],[483,294],[522,400],[-1,-1],[455,291],[430,172],[435.4046,161.6065],[463.5954,107.3935],[421,57],[375,112],[397,156],[462,187],[489,231],[497,293]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.833135}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      436,\n      252\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        458,\n        424\n      ],\n      [\n        427,\n        288\n      ],\n      [\n        483,\n        294\n      ],\n      [\n        522,\n        400\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        455,\n        291\n      ],\n      [\n        430,\n        172\n      ],\n      [\n        435.4046,\n        161.6065\n      ],\n      [\n        463.5954,\n        107.3935\n      ],\n      [\n        421,\n        57\n      ],\n      [\n        375,\n        112\n      ],\n      [\n        397,\n        156\n      ],\n      [\n        462,\n        187\n      ],\n      [\n        489,\n        231\n      ],\n      [\n        497,\n        293\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.833135\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1357,&quot;string&quot;:&quot;1,357&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:171,&quot;string&quot;:&quot;171&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;022793516.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:83,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity generally involves a lot of bending and reaching with the arms, as well as squatting or kneeling to reach lower parts of the horse.\n\nThe center person is positioned slightly to the right with their body facing forward. \n\nStarting with their legs:\n- The right leg appears to be bent at the knee and slightly extended backward.\n- The left leg seems to be straight and supporting most of their weight.\n\nMoving on to their arms:\n- The right arm appears extended forward with a slight bend at elbow.\n- Unfortunately, we cannot see any information about the left wrist due to it being invisible in this dataset.\n\nAs for their torso:\n- It's leaning slightly towards left indicating some sort of engagement or interaction.\n\nLastly for their head:\n- It's tilted downwards possibly focusing on something below them.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[321,323],&quot;id&quot;:0,&quot;kpts&quot;:[[363,455],[299,404],[300,306],[345,300],[291,414],[301,472],[323,303],[328,211],[324.2447,198.5326],[306.7553,140.4674],[300,274],[350,269],[347,205],[308,216],[302,270],[-1,-1]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],&quot;scale&quot;:1.819257}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      321,\n      323\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        363,\n        455\n      ],\n      [\n        299,\n        404\n      ],\n      [\n        300,\n        306\n      ],\n      [\n        345,\n        300\n      ],\n      [\n        291,\n        414\n      ],\n      [\n        301,\n        472\n      ],\n      [\n        323,\n        303\n      ],\n      [\n        328,\n        211\n      ],\n      [\n        324.2447,\n        198.5326\n      ],\n      [\n        306.7553,\n        140.4674\n      ],\n      [\n        300,\n        274\n      ],\n      [\n        350,\n        269\n      ],\n      [\n        347,\n        205\n      ],\n      [\n        308,\n        216\n      ],\n      [\n        302,\n        270\n      ],\n      [\n        -1,\n        -1\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      0\n    ],\n    \&quot;scale\&quot;: 1.819257\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:336,&quot;string&quot;:&quot;336&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;086073058.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:84,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of movement and interaction with the horse.\n\nThe centrally located person appears to be interacting with something or someone out of frame, likely a horse given the context. Their body orientation suggests they are facing towards their right side.\n\nStarting with their legs, it appears that only the hip joints are visible while both knees and ankles are not detected. This limits precise description of leg pose but based on available data we can say that their hips are slightly apart indicating a stance wider than shoulder width.\n\nMoving up to their torso, it seems to be leaning forward slightly as indicated by position of pelvis and thorax keypoints. The head is tilted downwards suggesting focus on an object or task at hand.\n\nTheir right arm appears extended downwards with elbow joint visible but wrist joint not detected. The left arm seems to be bent at the elbow and raised upwards as if reaching for something or performing an action.\n\nIn summary, this individual's pose suggests they may be conducting tasks related to horse care such as grooming or harnessing.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[350,288],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[-1,-1],[338,385],[456,388],[-1,-1],[-1,-1],[397,387],[400,202],[396.1337,141.4287],[388.8663,27.5713],[277,429],[307,347],[315,211],[484,193],[502,368],[466,314]],&quot;kpts_vis&quot;:[0,0,1,1,0,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.422673}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      350,\n      288\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        338,\n        385\n      ],\n      [\n        456,\n        388\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        397,\n        387\n      ],\n      [\n        400,\n        202\n      ],\n      [\n        396.1337,\n        141.4287\n      ],\n      [\n        388.8663,\n        27.5713\n      ],\n      [\n        277,\n        429\n      ],\n      [\n        307,\n        347\n      ],\n      [\n        315,\n        211\n      ],\n      [\n        484,\n        193\n      ],\n      [\n        502,\n        368\n      ],\n      [\n        466,\n        314\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      0,\n      1,\n      1,\n      0,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.422673\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:336,&quot;string&quot;:&quot;336&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:69,&quot;string&quot;:&quot;69&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;000695213.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:85,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is grooming, feeding, cleaning, harnessing and unharnessing a horse. This activity involves a lot of movements and interactions with the horse.\n\nThe center person is in the middle of an action with their limbs positioned to perform various tasks related to horse care.\n\nThe right leg seems to be slightly bent at the knee and hip, possibly providing balance while performing tasks. The left leg appears straighter and grounded firmly on the surface.\n\nThe right arm appears bent at both elbow and shoulder joints indicating that it might be holding or manipulating some tool for grooming or feeding. The left arm also seems slightly bent at elbow joint but less so than right arm which suggests it might be used for stabilizing or supporting something.\n\nTheir torso leans forward slightly suggesting engagement in an activity that requires close attention. \n\nLastly, their head seems to be tilted downwards likely focusing on the task they are performing with their hands.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[307,179],&quot;id&quot;:0,&quot;kpts&quot;:[[329,345],[349,256],[362,159],[295,161],[281,270],[289,354],[329,160],[289,82],[281.6384,78.4507],[240.3616,58.5493],[325,180],[350,119],[328,76],[249,87],[263,151],[266,194]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.37472}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      307,\n      179\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        329,\n        345\n      ],\n      [\n        349,\n        256\n      ],\n      [\n        362,\n        159\n      ],\n      [\n        295,\n        161\n      ],\n      [\n        281,\n        270\n      ],\n      [\n        289,\n        354\n      ],\n      [\n        329,\n        160\n      ],\n      [\n        289,\n        82\n      ],\n      [\n        281.6384,\n        78.4507\n      ],\n      [\n        240.3616,\n        58.5493\n      ],\n      [\n        325,\n        180\n      ],\n      [\n        350,\n        119\n      ],\n      [\n        328,\n        76\n      ],\n      [\n        249,\n        87\n      ],\n      [\n        263,\n        151\n      ],\n      [\n        266,\n        194\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.37472\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2076,&quot;string&quot;:&quot;2,076&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:10,&quot;string&quot;:&quot;10&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;041741100.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:86,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity generally involves bending over or stooping down to reach the horse's level and using hands and arms for tasks such as brushing or feeding.\n\nThe person centered at coordinates (115.0, 242.0) appears to be slightly bent forward with their limbs actively engaged in a task.\n\nStarting with the legs, their right leg seems to be slightly bent at the knee while standing firm on ground as indicated by keypoints of right hip (62, 250), right knee (100, 265), and right ankle (76, 322). The left leg appears more straightened but also firmly planted on ground as per keypoints of left hip (131, 260), left knee (166,282) and left ankle (115,307).\n\nMoving onto their torso region which includes pelvis-thorax-upper neck-head top sequence of keypoints [(97,255)-(121-189)-(121-177)-(124-125)], it suggests a slight forward bend indicative of an engaging task.\n\nLooking at arms now; their right arm seems extended downwards perhaps holding something or performing a task given by keypoints from shoulder-elbow-wrist [(91-190)-(89-223)-(131-246)]. Their left arm also appears extended but angled upwards possibly reaching out for something as suggested by shoulder-elbow-wrist keypoints [(151-187),(156-239),(150 -261)].\n\nLastly considering head position relative to upper neck keypoint indicates that they are looking downwards likely focused on the task being performed.&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[115,242],&quot;id&quot;:0,&quot;kpts&quot;:[[76,322],[100,265],[62,250],[131,260],[166,282],[115,307],[97,255],[121,189],[121.5925,177.8898],[124.4075,125.1102],[131,246],[89,223],[91,190],[151,187],[156,239],[150,261]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.585636}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      115,\n      242\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        76,\n        322\n      ],\n      [\n        100,\n        265\n      ],\n      [\n        62,\n        250\n      ],\n      [\n        131,\n        260\n      ],\n      [\n        166,\n        282\n      ],\n      [\n        115,\n        307\n      ],\n      [\n        97,\n        255\n      ],\n      [\n        121,\n        189\n      ],\n      [\n        121.5925,\n        177.8898\n      ],\n      [\n        124.4075,\n        125.1102\n      ],\n      [\n        131,\n        246\n      ],\n      [\n        89,\n        223\n      ],\n      [\n        91,\n        190\n      ],\n      [\n        151,\n        187\n      ],\n      [\n        156,\n        239\n      ],\n      [\n        150,\n        261\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.585636\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2076,&quot;string&quot;:&quot;2,076&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:133,&quot;string&quot;:&quot;133&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;022210781.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:87,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There is one person in the image who is engaging in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of bending and reaching as well as interaction with an animal.\n\nThe center-right person is standing upright with their limbs arranged in a manner indicative of an action related to horse care.\n\nStarting with the left leg, the knee and hip are visible while the ankle isn't. The knee seems to be slightly bent indicating that this leg might be bearing most of the body's weight or preparing for motion. \n\nThe right leg appears to be stretched out towards the back suggesting that it's providing balance while performing an action. Both right ankle and knee are not visible which might indicate they are behind something or obscured from view.\n\nMoving onto arms, both hands appear to be lifted up near their respective shoulders indicating possible interaction or handling of objects at chest level or higher. The left arm seems more extended than right arm suggesting it could be reaching out for something.\n\nRegarding torso and head; they seem straight aligned with each other indicating upright posture. The upper neck appears higher than thorax implying that head is raised probably looking forward or upwards.\n\nIn conclusion, based on keypoints data this individual seems engaged in some sort of care-taking activity involving bending, reaching out and possibly interacting with objects at different levels around them.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[261,136],&quot;id&quot;:0,&quot;kpts&quot;:[[-1,-1],[273,234],[276,164],[213,158],[209,245],[-1,-1],[245,161],[257,53],[267.4526,37.3211],[294.5474,-3.3211],[355,137],[315,113],[302,54],[211,51],[194,98],[190,157]],&quot;kpts_vis&quot;:[0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.465376}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      261,\n      136\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        -1,\n        -1\n      ],\n      [\n        273,\n        234\n      ],\n      [\n        276,\n        164\n      ],\n      [\n        213,\n        158\n      ],\n      [\n        209,\n        245\n      ],\n      [\n        -1,\n        -1\n      ],\n      [\n        245,\n        161\n      ],\n      [\n        257,\n        53\n      ],\n      [\n        267.4526,\n        37.3211\n      ],\n      [\n        294.5474,\n        -3.3211\n      ],\n      [\n        355,\n        137\n      ],\n      [\n        315,\n        113\n      ],\n      [\n        302,\n        54\n      ],\n      [\n        211,\n        51\n      ],\n      [\n        194,\n        98\n      ],\n      [\n        190,\n        157\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      0,\n      1,\n      1,\n      1,\n      1,\n      0,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.465376\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:15,&quot;string&quot;:&quot;15&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:2076,&quot;string&quot;:&quot;2,076&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:286,&quot;string&quot;:&quot;286&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;occupation, horse grooming, feeding, cleaning, harnessing and unharnessing&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;011986537.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:1,&quot;string&quot;:&quot;1&quot;}}},{&quot;rowIdx&quot;:88,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are six people in the image who are performing conditioning exercises, video exercise workouts, or TV conditioning programs. The individuals appear to be in various stages of workout routines, involving a range of movements from stretching to aerobic exercises.\n\nThe first person is located towards the left side of the image and appears to be mid-way through an exercise routine. Their right leg is significantly bent at the knee with the ankle raised high and behind them. The left leg is slightly bent at the knee, indicating a possible balancing pose. Their right arm is bent at a sharp angle near their waist while their left arm extends outward with a slight bend at elbow.\n\nThe second person is positioned slightly towards center-left and seems to be engaged in an aerobic activity. Both legs are moderately bent suggesting they might be squatting or jumping. Their arms seem extended outwards with elbows slightly bent which could indicate that they are maintaining balance during their activity.\n\nThe third individual situated around center-right area seems to be doing a stretching or balancing exercise as well. Their right leg appears straight while their left leg shows moderate bending at knee suggesting an asymmetrical pose. Both arms show some degree of bending but not too drastically - this could suggest either reaching for something or maintaining balance.\n\nMoving further towards right we have fourth person who also looks like they're involved in some form of stretching routine as both legs appear fairly straight compared to others'. Arms seem relaxed and mildly bent which could possibly indicate rest between sets.\n\nFifth person on far-right seems engaged in another form of physical activity where both legs appear moderately flexed suggesting either squatting position or mid-motion action like running/jumping etc.. Arms display moderate bending indicating active movement rather than resting state.\n\nFinally sixth individual located on extreme far-right shows similar characteristics as fifth one - moderate flexing in knees hinting active engagement &amp; mild bending in arms suggesting ongoing motion rather than static pose.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[333,475],&quot;id&quot;:0,&quot;kpts&quot;:[[216,696],[254,600],[314,514],[383,510],[429,602],[477,690],[349,512],[328,420],[325.5228,411.7426],[303.4772,338.2574],[266,493],[245,468],[279,416],[377,423],[370,475],[324,498]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.301624},{&quot;center&quot;:[455,638],&quot;id&quot;:1,&quot;kpts&quot;:[[256,790],[347,703],[422,634],[530,619],[561,687],[545,771],[476,627],[425,507],[427.1445,520.2242],[410.8555,419.7758],[268,557],[256,535],[350,513],[499,501],[460,554],[345,564]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.052815},{&quot;center&quot;:[689,733],&quot;id&quot;:2,&quot;kpts&quot;:[[313,951],[501,848],[614,742],[737,754],[799,824],[773,941],[676,748],[696,626],[689.2714,570.7294],[674.7286,451.2706],[669,723],[580,776],[592,629],[799,622],[828,742],[734,715]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.610225},{&quot;center&quot;:[1230,672],&quot;id&quot;:3,&quot;kpts&quot;:[[1036,917],[1065,747],[1188,660],[1306,658],[1438,795],[1551,925],[1247,659],[1245,481],[1244.1275,486.4647],[1264.8725,356.5353],[1183,672],[1145,583],[1157,484],[1332,477],[1347,581],[1289,672]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.947252},{&quot;center&quot;:[1472,527],&quot;id&quot;:4,&quot;kpts&quot;:[[1377,706],[1383,597],[1418,556],[1477,560],[1537,605],[1611,667],[1448,558],[1455,477],[1456.7167,471.3036],[1475.2833,409.6964],[1443,536],[1402,552],[1404,470],[1506,483],[1508,562],[1482,536]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:1.930322},{&quot;center&quot;:[1626,628],&quot;id&quot;:5,&quot;kpts&quot;:[[1427,819],[1466,687],[1528,598],[1610,614],[1685,720],[1795,821],[1569,606],[1596,499],[1597.5457,490.1325],[1613.4543,398.8675],[1593,571],[1528,593],[1536,489],[1656,509],[1637,619],[1629,585]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.779237}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      333,\n      475\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        216,\n        696\n      ],\n      [\n        254,\n        600\n      ],\n      [\n        314,\n        514\n      ],\n      [\n        383,\n        510\n      ],\n      [\n        429,\n        602\n      ],\n      [\n        477,\n        690\n      ],\n      [\n        349,\n        512\n      ],\n      [\n        328,\n        420\n      ],\n      [\n        325.5228,\n        411.7426\n      ],\n      [\n        303.4772,\n        338.2574\n      ],\n      [\n        266,\n        493\n      ],\n      [\n        245,\n        468\n      ],\n      [\n        279,\n        416\n      ],\n      [\n        377,\n        423\n      ],\n      [\n        370,\n        475\n      ],\n      [\n        324,\n        498\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.301624\n  },\n  {\n    \&quot;center\&quot;: [\n      455,\n      638\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        256,\n        790\n      ],\n      [\n        347,\n        703\n      ],\n      [\n        422,\n        634\n      ],\n      [\n        530,\n        619\n      ],\n      [\n        561,\n        687\n      ],\n      [\n        545,\n        771\n      ],\n      [\n        476,\n        627\n      ],\n      [\n        425,\n        507\n      ],\n      [\n        427.1445,\n        520.2242\n      ],\n      [\n        410.8555,\n        419.7758\n      ],\n      [\n        268,\n        557\n      ],\n      [\n        256,\n        535\n      ],\n      [\n        350,\n        513\n      ],\n      [\n        499,\n        501\n      ],\n      [\n        460,\n        554\n      ],\n      [\n        345,\n        564\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.052815\n  },\n  {\n    \&quot;center\&quot;: [\n      689,\n      733\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        313,\n        951\n      ],\n      [\n        501,\n        848\n      ],\n      [\n        614,\n        742\n      ],\n      [\n        737,\n        754\n      ],\n      [\n        799,\n        824\n      ],\n      [\n        773,\n        941\n      ],\n      [\n        676,\n        748\n      ],\n      [\n        696,\n        626\n      ],\n      [\n        689.2714,\n        570.7294\n      ],\n      [\n        674.7286,\n        451.2706\n      ],\n      [\n        669,\n        723\n      ],\n      [\n        580,\n        776\n      ],\n      [\n        592,\n        629\n      ],\n      [\n        799,\n        622\n      ],\n      [\n        828,\n        742\n      ],\n      [\n        734,\n        715\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.610225\n  },\n  {\n    \&quot;center\&quot;: [\n      1230,\n      672\n    ],\n    \&quot;id\&quot;: 3,\n    \&quot;kpts\&quot;: [\n      [\n        1036,\n        917\n      ],\n      [\n        1065,\n        747\n      ],\n      [\n        1188,\n        660\n      ],\n      [\n        1306,\n        658\n      ],\n      [\n        1438,\n        795\n      ],\n      [\n        1551,\n        925\n      ],\n      [\n        1247,\n        659\n      ],\n      [\n        1245,\n        481\n      ],\n      [\n        1244.1275,\n        486.4647\n      ],\n      [\n        1264.8725,\n        356.5353\n      ],\n      [\n        1183,\n        672\n      ],\n      [\n        1145,\n        583\n      ],\n      [\n        1157,\n        484\n      ],\n      [\n        1332,\n        477\n      ],\n      [\n        1347,\n        581\n      ],\n      [\n        1289,\n        672\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.947252\n  },\n  {\n    \&quot;center\&quot;: [\n      1472,\n      527\n    ],\n    \&quot;id\&quot;: 4,\n    \&quot;kpts\&quot;: [\n      [\n        1377,\n        706\n      ],\n      [\n        1383,\n        597\n      ],\n      [\n        1418,\n        556\n      ],\n      [\n        1477,\n        560\n      ],\n      [\n        1537,\n        605\n      ],\n      [\n        1611,\n        667\n      ],\n      [\n        1448,\n        558\n      ],\n      [\n        1455,\n        477\n      ],\n      [\n        1456.7167,\n        471.3036\n      ],\n      [\n        1475.2833,\n        409.6964\n      ],\n      [\n        1443,\n        536\n      ],\n      [\n        1402,\n        552\n      ],\n      [\n        1404,\n        470\n      ],\n      [\n        1506,\n        483\n      ],\n      [\n        1508,\n        562\n      ],\n      [\n        1482,\n        536\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 1.930322\n  },\n  {\n    \&quot;center\&quot;: [\n      1626,\n      628\n    ],\n    \&quot;id\&quot;: 5,\n    \&quot;kpts\&quot;: [\n      [\n        1427,\n        819\n      ],\n      [\n        1466,\n        687\n      ],\n      [\n        1528,\n        598\n      ],\n      [\n        1610,\n        614\n      ],\n      [\n        1685,\n        720\n      ],\n      [\n        1795,\n        821\n      ],\n      [\n        1569,\n        606\n      ],\n      [\n        1596,\n        499\n      ],\n      [\n        1597.5457,\n        490.1325\n      ],\n      [\n        1613.4543,\n        398.8675\n      ],\n      [\n        1593,\n        571\n      ],\n      [\n        1528,\n        593\n      ],\n      [\n        1536,\n        489\n      ],\n      [\n        1656,\n        509\n      ],\n      [\n        1637,\n        619\n      ],\n      [\n        1629,\n        585\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.779237\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:849,&quot;string&quot;:&quot;849&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:288,&quot;string&quot;:&quot;288&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:75,&quot;string&quot;:&quot;75&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;conditioning exercise, video exercise workouts, TV conditioning programs&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;094290970.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:6,&quot;string&quot;:&quot;6&quot;}}},{&quot;rowIdx&quot;:89,&quot;cells&quot;:{&quot;description&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;There are three people in the image who are performing conditioning exercises, specifically video exercise workouts or TV conditioning programs. These exercises generally involve a range of movements and positions, often targeting multiple body areas for strength and flexibility.\n\nThe first person is located centrally and is quite large in scale, indicating they may be closer to the viewer. They seem to be in a standing position with their weight evenly distributed between their legs. Their right leg appears slightly bent at the knee while their left leg seems straight. The right arm is bent at the elbow with the wrist level with their waist, while the left arm is extended outwards at shoulder height. Their torso maintains an upright position and their head appears to be tilted upwards.\n\nThe second person is positioned towards the left of this scene and has a smaller scale compared to the first person suggesting they are further away from us. This individual also seems to be in an upright stance but with more noticeable bend at both knees suggesting they might be mid-motion during an exercise routine. Both arms appear curved at elbows but held differently - right arm close to body while left extends outwardly around shoulder level. The head of this person seems slightly inclined downwards.\n\nThe third individual situated towards center-right of this scene has smallest scale among all indicating farthest distance from viewer's perspective. They seem engaged in similar activity as others but possibly different movement as both knees appear significantly bent indicating squat-like posture or mid-jump action perhaps due to dynamic nature of conditioning exercises being performed by them all together here on screen.\nTheir arms display contrast - right one hangs down whereas left one extends outwards around chest level which could indicate asymmetrical movement pattern or simply different point within same exercise sequence as others.\nTheir head orientation suggests focus downwards likely on own body during these movements.\n\nOverall, each individual presents unique pose within same activity context showing diversity typical for group workout scenarios where everyone follows general instructions but adapts according personal comfort and fitness levels.\n&quot;},&quot;people&quot;:{&quot;kind&quot;:&quot;list like&quot;,&quot;value&quot;:[{&quot;center&quot;:[1320,517],&quot;id&quot;:0,&quot;kpts&quot;:[[1200,913],[1196,734],[1191,507],[1301,508],[1307,744],[1294,874],[1246,508],[1264,262],[1258.7121,240.1227],[1218.2879,72.8773],[1147,516],[1124,391],[1157,266],[1371,257],[1408,408],[1330,518]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:5.161842},{&quot;center&quot;:[684,471],&quot;id&quot;:1,&quot;kpts&quot;:[[691,885],[660,709],[622,502],[723,500],[723,702],[739,897],[673,501],[649,279],[645.5769,253.0418],[628.4231,122.9582],[562,510],[563,411],[563,282],[734,276],[810,382],[746,476]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:3.936293},{&quot;center&quot;:[821,366],&quot;id&quot;:2,&quot;kpts&quot;:[[751,624],[756,514],[751,366],[827,358],[833,502],[827,621],[789,362],[773,188],[776.5965,154.9973],[786.4035,65.0027],[715,346],[689,293],[704,191],[842,184],[883,263],[861,339]],&quot;kpts_vis&quot;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],&quot;scale&quot;:2.71582}],&quot;string&quot;:&quot;[\n  {\n    \&quot;center\&quot;: [\n      1320,\n      517\n    ],\n    \&quot;id\&quot;: 0,\n    \&quot;kpts\&quot;: [\n      [\n        1200,\n        913\n      ],\n      [\n        1196,\n        734\n      ],\n      [\n        1191,\n        507\n      ],\n      [\n        1301,\n        508\n      ],\n      [\n        1307,\n        744\n      ],\n      [\n        1294,\n        874\n      ],\n      [\n        1246,\n        508\n      ],\n      [\n        1264,\n        262\n      ],\n      [\n        1258.7121,\n        240.1227\n      ],\n      [\n        1218.2879,\n        72.8773\n      ],\n      [\n        1147,\n        516\n      ],\n      [\n        1124,\n        391\n      ],\n      [\n        1157,\n        266\n      ],\n      [\n        1371,\n        257\n      ],\n      [\n        1408,\n        408\n      ],\n      [\n        1330,\n        518\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 5.161842\n  },\n  {\n    \&quot;center\&quot;: [\n      684,\n      471\n    ],\n    \&quot;id\&quot;: 1,\n    \&quot;kpts\&quot;: [\n      [\n        691,\n        885\n      ],\n      [\n        660,\n        709\n      ],\n      [\n        622,\n        502\n      ],\n      [\n        723,\n        500\n      ],\n      [\n        723,\n        702\n      ],\n      [\n        739,\n        897\n      ],\n      [\n        673,\n        501\n      ],\n      [\n        649,\n        279\n      ],\n      [\n        645.5769,\n        253.0418\n      ],\n      [\n        628.4231,\n        122.9582\n      ],\n      [\n        562,\n        510\n      ],\n      [\n        563,\n        411\n      ],\n      [\n        563,\n        282\n      ],\n      [\n        734,\n        276\n      ],\n      [\n        810,\n        382\n      ],\n      [\n        746,\n        476\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 3.936293\n  },\n  {\n    \&quot;center\&quot;: [\n      821,\n      366\n    ],\n    \&quot;id\&quot;: 2,\n    \&quot;kpts\&quot;: [\n      [\n        751,\n        624\n      ],\n      [\n        756,\n        514\n      ],\n      [\n        751,\n        366\n      ],\n      [\n        827,\n        358\n      ],\n      [\n        833,\n        502\n      ],\n      [\n        827,\n        621\n      ],\n      [\n        789,\n        362\n      ],\n      [\n        773,\n        188\n      ],\n      [\n        776.5965,\n        154.9973\n      ],\n      [\n        786.4035,\n        65.0027\n      ],\n      [\n        715,\n        346\n      ],\n      [\n        689,\n        293\n      ],\n      [\n        704,\n        191\n      ],\n      [\n        842,\n        184\n      ],\n      [\n        883,\n        263\n      ],\n      [\n        861,\n        339\n      ]\n    ],\n    \&quot;kpts_vis\&quot;: [\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1,\n      1\n    ],\n    \&quot;scale\&quot;: 2.71582\n  }\n]&quot;},&quot;activity_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:849,&quot;string&quot;:&quot;849&quot;},&quot;video_id&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:288,&quot;string&quot;:&quot;288&quot;},&quot;video_frame&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:417,&quot;string&quot;:&quot;417&quot;},&quot;activity&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;conditioning exercise, video exercise workouts, TV conditioning programs&quot;},&quot;image&quot;:{&quot;kind&quot;:&quot;string&quot;,&quot;value&quot;:&quot;032320293.jpg&quot;},&quot;count&quot;:{&quot;kind&quot;:&quot;number&quot;,&quot;value&quot;:3,&quot;string&quot;:&quot;3&quot;}}}],&quot;truncated&quot;:true},&quot;paginationData&quot;:{&quot;pageIndex&quot;:0,&quot;numItemsPerPage&quot;:100,&quot;numTotalItems&quot;:14644,&quot;offset&quot;:0,&quot;length&quot;:100}},&quot;jwt&quot;:&quot;eyJhbGciOiJFZERTQSJ9.eyJyZWFkIjp0cnVlLCJwZXJtaXNzaW9ucyI6eyJyZXBvLmNvbnRlbnQucmVhZCI6dHJ1ZX0sImlhdCI6MTc0MjkyMzE1MCwic3ViIjoiL2RhdGFzZXRzL3NhaWZraGljaGk5Ni9tcGlpLWh1bWFuLXBvc2UtY2FwdGlvbnMiLCJleHAiOjE3NDI5MjY3NTAsImlzcyI6Imh0dHBzOi8vaHVnZ2luZ2ZhY2UuY28ifQ.99NiAGT2ftyNCkGsVWATh9H0UCZoPblTssPvxsLy4jIT1C7pUInl6ymw1mFNtp_2Hb6qAruuptv6xHAREn0WCQ&quot;,&quot;displayUrls&quot;:true},&quot;dataset&quot;:&quot;saifkhichi96/mpii-human-pose-captions&quot;,&quot;isGated&quot;:false,&quot;isPrivate&quot;:false,&quot;hasParquetFormat&quot;:false,&quot;author&quot;:{&quot;_id&quot;:&quot;64da1dd841f0e6c0e9638b67&quot;,&quot;avatarUrl&quot;:&quot;https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/AVclbx51CufhItKagXkRi.png&quot;,&quot;fullname&quot;:&quot;Saif Khan&quot;,&quot;name&quot;:&quot;saifkhichi96&quot;,&quot;type&quot;:&quot;user&quot;,&quot;isPro&quot;:false,&quot;isHf&quot;:false,&quot;isHfAdmin&quot;:false,&quot;isMod&quot;:false},&quot;compact&quot;:true}"><div class="flex flex-col overflow-hidden shadow-xs mx-auto mb-10 rounded-lg border pt-2  px-2.5"><div class="mb-2 flex flex-wrap items-center gap-2"><div class="mr-auto flex items-center"><svg class="mr-1 flex-none" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
	<div class="whitespace-nowrap font-semibold">Dataset Viewer</div>
	</div>
				<a href="/datasets/saifkhichi96/mpii-human-pose-captions/tree/refs%2Fconvert%2Fparquet/gpt-4" class="group mr-1 text-xs text-gray-400 max-sm:hidden"><svg class="text-[.6rem] mr-1 inline -translate-y-px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path fill="currentColor" d="M12 10H6.78A11 11 0 0 1 27 16h2A13 13 0 0 0 6 7.68V4H4v8h8zm8 12h5.22A11 11 0 0 1 5 16H3a13 13 0 0 0 23 8.32V28h2v-8h-8z"></path></svg>
						<span class="underline decoration-gray-300 group-hover:decoration-gray-400 dark:decoration-gray-500 dark:group-hover:decoration-gray-300">Auto-converted</span> to Parquet
					</a>
				<button class="btn shadow-xs flex cursor-pointer items-center rounded-sm border px-1 py-0.5 text-xs font-normal text-gray-700 hover:text-gray-800 hover:shadow-inner dark:hover:text-gray-200"><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" style="transform: rotate(360deg);"><path d="M31 16l-7 7l-1.41-1.41L28.17 16l-5.58-5.59L24 9l7 7z" fill="currentColor"></path><path d="M1 16l7-7l1.41 1.41L3.83 16l5.58 5.59L8 23l-7-7z" fill="currentColor"></path><path d="M12.419 25.484L17.639 6l1.932.518L14.35 26z" fill="currentColor"></path></svg>API</button>
					<button class="btn shadow-xs flex cursor-pointer items-center rounded-sm border px-1 py-0.5 text-xs font-normal text-gray-700 hover:text-gray-800 hover:shadow-inner dark:hover:text-gray-200"><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path d="M9.80603 2.86737H3.56107C3.37704 2.86737 3.20055 2.94048 3.07042 3.0706C2.94029 3.20073 2.86719 3.37723 2.86719 3.56126V9.80622C2.86719 9.99025 2.94029 10.1667 3.07042 10.2969C3.20055 10.427 3.37704 10.5001 3.56107 10.5001H9.80603C9.99006 10.5001 10.1666 10.427 10.2967 10.2969C10.4268 10.1667 10.4999 9.99025 10.4999 9.80622V3.56126C10.4999 3.37723 10.4268 3.20073 10.2967 3.0706C10.1666 2.94048 9.99006 2.86737 9.80603 2.86737Z" fill="currentColor" fill-opacity="0.3"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M2.40942 1.66191C2.05175 1.66191 1.7618 1.95186 1.7618 2.30953V6.76191H1.43799V2.30953C1.43799 1.77303 1.87291 1.3381 2.40942 1.3381H6.45704V1.66191H2.40942Z" fill="currentColor"></path></svg>Embed</button>

					<button class="bg-linear-to-b shadow-xs flex items-center gap-1.5 rounded-full border from-white to-red-100/90 px-2 py-0.5 text-xs font-medium text-[#2D3648] transition-shadow hover:shadow-inner dark:from-gray-900 dark:to-red-800/30 dark:text-gray-100 dark:hover:shadow-inner dark:hover:shadow-red-800/30" ><svg class="h-3.5 w-3.5 text-red-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>
						<span>Data Studio</span></button></div>
		<div class="flex flex-1 flex-col overflow-hidden -mx-2.5"><div class="flex flex-1 flex-col overflow-hidden"><div class="flex min-h-0 flex-1"><div class="flex flex-1 flex-col overflow-hidden"><div class="md:-mx-2.5 flex min-w-0 flex-wrap border-t"><div class="flex min-w-0 flex-1 flex-wrap"><div class="grid flex-1 grid-cols-1 overflow-hidden text-sm md:grid-cols-2 md:place-content-center sm:mx-2.5"><label class="relative block flex-1 px-3 py-2 hover:bg-gray-50 dark:border-gray-850 dark:hover:bg-gray-950 md:border-r max-md:first:border-b md:border-r" title="gpt-4"><span class="text-gray-500">Subset (4)</span>
			<div class="flex items-center whitespace-nowrap"><span class="truncate">gpt-4</span>
				<span class="mx-2 text-gray-500">·</span>
					<span class="text-gray-500">17.4k rows</span>
				<svg class="ml-auto min-w-6 pl-2" width="1em" height="1em" viewBox="0 0 12 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1 1L6 6L11 1" stroke="currentColor"></path></svg></div>
			<select class="absolute inset-0 z-10 w-full cursor-pointer border-0 bg-white text-base opacity-0"><optgroup label="Subset (4)"><option value="gpt-4" selected>gpt-4 (17.4k rows)</option><option value="gpt-3.5-turbo" >gpt-3.5-turbo (17.4k rows)</option><option value="gpt-3.5-turbo-legacy" >gpt-3.5-turbo-legacy (17.4k rows)</option><option value="llama-2" >llama-2 (17.4k rows)</option></optgroup></select></label>
		<label class="relative block flex-1 px-3 py-2 hover:bg-gray-50 dark:border-gray-850 dark:hover:bg-gray-900 md:border-r md:border-r-0" title="train"><div class="text-gray-500">Split (2)</div>
				<div class="flex items-center overflow-hidden whitespace-nowrap"><span class="truncate">train</span>
					<span class="mx-2 text-gray-500">·</span>
						<span class="text-gray-500">14.6k rows</span>
					<svg class="ml-auto min-w-6 pl-2" width="1em" height="1em" viewBox="0 0 12 7" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M1 1L6 6L11 1" stroke="currentColor"></path></svg></div>
				<select class="absolute inset-0 z-10 w-full cursor-pointer border-0 bg-white text-base opacity-0"><optgroup label="Split (2)"><option value="train" selected>train (14.6k rows)</option><option value="validation" >validation (2.72k rows)</option></optgroup></select></label></div></div>
								</div>

							<div class="flex min-h-0 flex-1 flex-col ">
	<div class="bg-linear-to-r text-smd relative flex items-center dark:border-gray-900 dark:bg-gray-950 false border-t [&amp;:has(:focus)]:from-gray-50 [&amp;:has(:focus)]:to-transparent [&amp;:has(:focus)]:to-20% dark:[&amp;:has(:focus)]:from-gray-900"><form class="flex-1"><svg class="absolute left-3 top-1/2 transform -translate-y-1/2 pointer-events-none text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
				<input disabled class="outline-hidden h-9 w-full border-none bg-transparent px-1 pl-9 pr-3 placeholder:text-gray-400 " placeholder="Search this dataset" dir="auto"></form>
			<div class="flex items-center gap-2 px-2 py-1"><button type="button" class="hover:bg-yellow-200/70 flex items-center gap-1 rounded-md border border-yellow-200 bg-yellow-100 pl-0.5 pr-1 text-[.8rem] leading-normal text-gray-700 dark:border-orange-500/25 dark:bg-orange-500/20 dark:text-gray-300 dark:hover:brightness-110 hidden"><div class="rounded-sm bg-yellow-300 px-1 font-mono text-[.7rem] font-bold text-black dark:bg-yellow-700 dark:text-gray-200">SQL
	</div>
	Console
</button></div></div>


<div class="flex flex-1 flex-col overflow-hidden min-h-64 border-t">
		

<div class="max-h-96 relative overflow-auto"><table class="w-full table-auto rounded-lg font-mono text-xs text-gray-900"><thead class="shadow-xs sticky left-0 right-0 top-0 z-1 bg-white align-top"><tr class="space-y-54 h-full min-w-fit divide-x border-b text-left"><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">description
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>string</span><span class="italic text-gray-400 before:mx-1 before:content-['·']">lengths</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="0" y="24.36965108624095" width="11.2" height="5.630348913759052" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="13.2" y="4.488808426596446" width="11.2" height="25.511191573403554" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="26.4" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="39.599999999999994" y="16.62442396313364" width="11.2" height="13.37557603686636" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="52.8" y="23.205727452271233" width="11.2" height="6.794272547728768" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="66" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="79.19999999999999" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="92.39999999999999" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="105.6" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="118.8" y="25" width="11.2" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">697</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">3.44k</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">people
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>list</span><span class="italic text-gray-400 before:mx-1 before:content-['·']">lengths</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="0" y="0" width="16.857142857142858" height="30" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="18.857142857142858" y="23.59303574167817" width="16.857142857142858" height="6.406964258321828" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="37.714285714285715" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="56.57142857142857" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="75.42857142857143" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="94.28571428571429" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="113.14285714285714" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="17.857142857142858" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="36.714285714285715" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="55.57142857142857" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="74.42857142857143" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="93.28571428571429" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="112.14285714285714" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">1</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">13</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">activity_id
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>int64</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="0" y="10.102299389957764" width="11.2" height="19.897700610042236" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="13.2" y="7.027686532144532" width="11.2" height="22.972313467855468" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="26.4" y="2.6231816048803367" width="11.2" height="27.376818395119663" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="39.599999999999994" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="52.8" y="4.831534490849368" width="11.2" height="25.168465509150632" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="66" y="12.664476771468793" width="11.2" height="17.33552322853121" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="79.19999999999999" y="11.078366963866728" width="11.2" height="18.921633036133272" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="92.39999999999999" y="4.5631159080244" width="11.2" height="25.4368840919756" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="105.6" y="13.567339277334584" width="11.2" height="16.432660722665418" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="118.8" y="14.872829657437823" width="11.2" height="15.127170342562177" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">1</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">983</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">video_id
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>int64</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="0" y="1.62709677419355" width="11.2" height="28.37290322580645" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="13.2" y="1.492903225806451" width="11.2" height="28.50709677419355" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="26.4" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="39.599999999999994" y="1.3754838709677415" width="11.2" height="28.62451612903226" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="52.8" y="0.251612903225805" width="11.2" height="29.748387096774195" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="66" y="1.7780645161290316" width="11.2" height="28.22193548387097" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="79.19999999999999" y="0.21806451612903288" width="11.2" height="29.781935483870967" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="92.39999999999999" y="3.4890322580645154" width="11.2" height="26.510967741935485" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="105.6" y="1.476129032258065" width="11.2" height="28.523870967741935" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="118.8" y="2.6503225806451596" width="11.2" height="27.34967741935484" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">1</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">2.82k</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">video_frame
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>int64</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="0" y="0" width="11.2" height="30" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="13.2" y="22.28330495418795" width="11.2" height="7.716695045812049" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="26.4" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="39.599999999999994" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="52.8" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="66" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="79.19999999999999" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="92.39999999999999" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="105.6" y="25" width="11.2" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="118.8" y="25" width="11.2" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="12.2" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="25.4" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="38.599999999999994" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="51.8" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="65" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="78.19999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="91.39999999999999" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="104.6" y="0" width="13.2" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="117.8" y="0" width="13.2" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">0</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">2.42k</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">activity
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>string</span><span class="italic text-gray-400 before:mx-1 before:content-['·']">classes</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><defs><clipPath id="rounded-bar"><rect x="0" y="0" width="130" height="8" rx="4"></rect></clipPath><pattern id="hatching" patternUnits="userSpaceOnUse" patternTransform="rotate(-45)" height="1" width="5"><line y1="0" class="stroke-gray-400 dark:stroke-gray-500/80" stroke-width="3" y2="1" x1="2" x2="2"></line></pattern><pattern id="hatching-faded" patternUnits="userSpaceOnUse" patternTransform="rotate(-45)" height="1" width="5"><line y1="0" class="stroke-gray-100 dark:stroke-gray-500/20" stroke-width="3" y2="1" x1="2" x2="2"></line></pattern></defs><g height="8" style="transform: translateY(20px)" clip-path="url(#rounded-bar)"><g style="transform: scaleX(1.0153846153846153) translateX(-1px)"><g><rect class="fill-indigo-500 dark:fill-indigo-600/80" x="1" y="0" width="0.19270691068014223" height="8" fill-opacity="1"></rect></g></g></g><g style="transform: scaleX(1.0153846153846153) translateX(-1px)"><g><rect class="fill-white cursor-pointer" x="0" y="0" width="2.1927069106801422" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="2.1927069106801422" y="0" width="1.6866976236001092" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="3.8794045342802512" y="0" width="1.5535372848948374" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="5.432941819175088" y="0" width="1.5535372848948374" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="6.986479104069925" y="0" width="1.4470090139306202" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="8.433488118000545" y="0" width="1.2605845397432394" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="9.694072657743785" y="0" width="1.198443048347446" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="10.892515706091231" y="0" width="1.1895656924337614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="12.082081398524993" y="0" width="1.1895656924337614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="13.271647090958755" y="0" width="1.1540562687790221" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="14.425703359737778" y="0" width="1.118546845124283" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="15.544250204862061" y="0" width="1.1096694892105983" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="16.65391969407266" y="0" width="1.1007921332969135" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="17.754711827369572" y="0" width="1.0652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="18.81999453701175" y="0" width="1.0564053537284896" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="19.876399890740238" y="0" width="1.0564053537284896" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="20.932805244468728" y="0" width="1.0475279978148047" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="21.980333242283532" y="0" width="1.0208959300737503" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="23.00122917235728" y="0" width="0.9853865064190113" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="23.986615678776293" y="0" width="0.9765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="24.963124829281618" y="0" width="0.9765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="25.939633979786944" y="0" width="0.9676317945916416" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="26.907265774378587" y="0" width="0.9587544386779568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="27.866020213056544" y="0" width="0.9587544386779568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="28.8247746517345" y="0" width="0.9587544386779568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="29.783529090412458" y="0" width="0.9498770827642721" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="30.73340617317673" y="0" width="0.9498770827642721" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="31.683283255941" y="0" width="0.8966129472821633" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="32.579896203223164" y="0" width="0.8966129472821633" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="33.47650915050533" y="0" width="0.8966129472821633" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="34.373122097787494" y="0" width="0.8966129472821633" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="35.26973504506966" y="0" width="0.8611035236274241" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="36.13083856869709" y="0" width="0.8611035236274241" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="36.991942092324514" y="0" width="0.8078393881453155" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="37.79978148046983" y="0" width="0.8078393881453155" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="38.60762086861515" y="0" width="0.7634526085768916" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="39.37107347719204" y="0" width="0.7634526085768916" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="40.13452608576893" y="0" width="0.7279431849221524" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="40.862469270691086" y="0" width="0.7013111171810981" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="41.563780387872185" y="0" width="0.6924337612674133" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="42.2562141491396" y="0" width="0.6924337612674133" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="42.94864791040702" y="0" width="0.6835564053537285" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="43.632204315760745" y="0" width="0.6746790494400436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="44.30688336520079" y="0" width="0.6658016935263589" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="44.97268505872715" y="0" width="0.6658016935263589" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="45.63848675225351" y="0" width="0.6658016935263589" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="46.304288445779875" y="0" width="0.6658016935263589" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="46.97009013930624" y="0" width="0.6658016935263589" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="47.6358918328326" y="0" width="0.6302922698716197" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="48.266184102704216" y="0" width="0.6302922698716197" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="48.89647637257583" y="0" width="0.621414913957935" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="49.51789128653377" y="0" width="0.621414913957935" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="50.1393062004917" y="0" width="0.5947828462168807" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="50.73408904670858" y="0" width="0.5770281343895111" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="51.31111718109809" y="0" width="0.5681507784758262" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="51.879267959573916" y="0" width="0.5681507784758262" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="52.44741873804974" y="0" width="0.5503960666484567" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="52.9978148046982" y="0" width="0.5503960666484567" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="53.54821087134666" y="0" width="0.5415187107347719" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="54.08972958208143" y="0" width="0.5415187107347719" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="54.6312482928162" y="0" width="0.5237639989074023" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="55.15501229172361" y="0" width="0.5148866429937176" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="55.669898934717324" y="0" width="0.5148866429937176" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="56.18478557771104" y="0" width="0.5060092870800328" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="56.69079486479107" y="0" width="0.5060092870800328" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="57.196804151871106" y="0" width="0.5060092870800328" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="57.70281343895114" y="0" width="0.5060092870800328" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="58.20882272603117" y="0" width="0.49713193116634796" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="58.70595465719752" y="0" width="0.49713193116634796" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="59.203086588363874" y="0" width="0.4882545752526632" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="59.691341163616535" y="0" width="0.4882545752526632" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="60.179595738869196" y="0" width="0.4882545752526632" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="60.66785031412186" y="0" width="0.4793772193389784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="61.147227533460836" y="0" width="0.4793772193389784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="61.626604752799814" y="0" width="0.4793772193389784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="62.10598197213879" y="0" width="0.47049986342529365" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="62.57648183556409" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="63.038104343075695" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="63.4997268505873" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="63.96134935809891" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="64.42297186561052" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="64.88459437312213" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="65.34621688063373" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="65.80783938814534" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="66.26946189565695" y="0" width="0.4616225075116088" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="66.73108440316855" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="67.18382955476648" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="67.6365747063644" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="68.08931985796232" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="68.54206500956025" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="68.99481016115817" y="0" width="0.45274515159792406" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="69.4475553127561" y="0" width="0.4438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="69.89142310844034" y="0" width="0.4438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="70.33529090412458" y="0" width="0.4438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="70.77915869980882" y="0" width="0.4349904397705545" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="71.21414913957938" y="0" width="0.4349904397705545" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="71.64913957934994" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="72.07525266320681" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="72.50136574706369" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="72.92747883092056" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="73.35359191477744" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="73.77970499863432" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="74.20581808249119" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="74.63193116634807" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="75.05804425020494" y="0" width="0.42611308385686975" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="75.48415733406182" y="0" width="0.4172357279431849" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="75.901393062005" y="0" width="0.4172357279431849" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="76.31862878994818" y="0" width="0.4172357279431849" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="76.73586451789136" y="0" width="0.40835837202950015" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="77.14422288992085" y="0" width="0.40835837202950015" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="77.55258126195035" y="0" width="0.40835837202950015" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="77.96093963397985" y="0" width="0.40835837202950015" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="78.36929800600934" y="0" width="0.3994810161158153" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="78.76877902212516" y="0" width="0.3994810161158153" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="79.16826003824097" y="0" width="0.3994810161158153" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="79.56774105435679" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="79.95834471455892" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="80.34894837476105" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="80.73955203496318" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="81.13015569516531" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="81.52075935536745" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="81.91136301556958" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="82.30196667577171" y="0" width="0.39060366020213055" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="82.69257033597384" y="0" width="0.3817263042884458" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="83.07429664026229" y="0" width="0.3817263042884458" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="83.45602294455074" y="0" width="0.3817263042884458" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="83.83774924883919" y="0" width="0.3817263042884458" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="84.21947555312764" y="0" width="0.3817263042884458" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="84.60120185741609" y="0" width="0.372848948374761" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="84.97405080579085" y="0" width="0.372848948374761" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="85.34689975416562" y="0" width="0.372848948374761" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="85.71974870254039" y="0" width="0.3639715924610762" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="86.08372029500146" y="0" width="0.3639715924610762" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="86.44769188746253" y="0" width="0.3639715924610762" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="86.8116634799236" y="0" width="0.3639715924610762" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="87.17563507238467" y="0" width="0.3550942365473914" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="87.53072930893205" y="0" width="0.3550942365473914" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="87.88582354547944" y="0" width="0.3550942365473914" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="88.24091778202683" y="0" width="0.34621688063370665" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="88.58713466266053" y="0" width="0.34621688063370665" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="88.93335154329424" y="0" width="0.34621688063370665" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="89.27956842392794" y="0" width="0.34621688063370665" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="89.62578530456165" y="0" width="0.3373395247200218" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="89.96312482928167" y="0" width="0.3373395247200218" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="90.30046435400169" y="0" width="0.3284621688063371" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="90.62892652280803" y="0" width="0.3284621688063371" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="90.95738869161437" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="91.27697350450703" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="91.59655831739968" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="91.91614313029234" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="92.235727943185" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="92.55531275607765" y="0" width="0.3195848128926523" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="92.87489756897031" y="0" width="0.3107074569789675" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="93.18560502594929" y="0" width="0.3107074569789675" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="93.49631248292826" y="0" width="0.3107074569789675" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="93.80701993990724" y="0" width="0.3107074569789675" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="94.11772739688621" y="0" width="0.3107074569789675" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="94.42843485386518" y="0" width="0.3018301010652827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="94.73026495493046" y="0" width="0.3018301010652827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="95.03209505599574" y="0" width="0.3018301010652827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="95.33392515706102" y="0" width="0.3018301010652827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="95.6357552581263" y="0" width="0.2929527451515979" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="95.92870800327789" y="0" width="0.2929527451515979" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="96.22166074842949" y="0" width="0.2840753892379131" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="96.5057361376674" y="0" width="0.2751980333242284" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="96.78093417099163" y="0" width="0.2751980333242284" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="97.05613220431586" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="97.3224528817264" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="97.58877355913695" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="97.8550942365475" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="98.12141491395805" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="98.3877355913686" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="98.65405626877914" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="98.92037694618969" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="99.18669762360024" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="99.45301830101079" y="0" width="0.2663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="99.71933897842133" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="99.9767822999182" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="100.23422562141506" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="100.49166894291193" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="100.7491122644088" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="101.00655558590566" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="101.26399890740252" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="101.52144222889939" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="101.77888555039625" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="102.03632887189312" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="102.29377219338998" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="102.55121551488685" y="0" width="0.2574433214968588" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="102.80865883638371" y="0" width="0.24856596558317398" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="103.05722480196688" y="0" width="0.24856596558317398" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="103.30579076755005" y="0" width="0.24856596558317398" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="103.55435673313322" y="0" width="0.24856596558317398" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="103.80292269871639" y="0" width="0.2396886096694892" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="104.04261130838587" y="0" width="0.2396886096694892" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="104.28229991805536" y="0" width="0.2396886096694892" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="104.52198852772484" y="0" width="0.2396886096694892" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="104.76167713739433" y="0" width="0.2396886096694892" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="105.00136574706382" y="0" width="0.2308112537558044" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="105.23217700081962" y="0" width="0.2308112537558044" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="105.46298825457542" y="0" width="0.2308112537558044" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="105.69379950833122" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="105.91573340617335" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="106.13766730401547" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="106.35960120185759" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="106.5815350996997" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="106.80346899754183" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="107.02540289538395" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="107.24733679322607" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="107.46927069106819" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="107.69120458891031" y="0" width="0.22193389784211964" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="107.91313848675243" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="108.12619502868087" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="108.3392515706093" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="108.55230811253774" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="108.76536465446618" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="108.97842119639462" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="109.19147773832306" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="109.4045342802515" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="109.61759082217993" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="109.83064736410837" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="110.04370390603681" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="110.25676044796525" y="0" width="0.21305654192843487" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="110.46981698989369" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="110.67399617590844" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="110.8781753619232" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="111.08235454793795" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="111.28653373395271" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="111.49071291996746" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="111.69489210598222" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="111.89907129199698" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="112.10325047801173" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="112.30742966402649" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="112.51160885004124" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="112.715788036056" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="112.91996722207075" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="113.12414640808551" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="113.32832559410026" y="0" width="0.20417918601475007" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="113.53250478011502" y="0" width="0.19530183010106528" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="113.72780661021608" y="0" width="0.19530183010106528" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="113.92310844031714" y="0" width="0.19530183010106528" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="114.1184102704182" y="0" width="0.19530183010106528" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="114.31371210051925" y="0" width="0.19530183010106528" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="114.50901393062031" y="0" width="0.1864244741873805" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="114.69543840480769" y="0" width="0.1864244741873805" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="114.88186287899507" y="0" width="0.1864244741873805" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.06828735318244" y="0" width="0.1864244741873805" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.25471182736982" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.43225894564351" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.6098060639172" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.7873531821909" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="115.96490030046459" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="116.14244741873829" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="116.31999453701198" y="0" width="0.1775471182736957" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="116.49754165528567" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="116.66621141764568" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="116.8348811800057" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.0035509423657" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.17222070472572" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.34089046708573" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.50956022944574" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.67822999180575" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="117.84689975416576" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.01556951652577" y="0" width="0.1686697623600109" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.18423927888578" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.34403168533211" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.50382409177844" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.66361649822477" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.8234089046711" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="118.98320131111743" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.14299371756375" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.30278612401008" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.46257853045641" y="0" width="0.15979240644632614" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.62237093690274" y="0" width="0.15091505053264134" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.77328598743539" y="0" width="0.15091505053264134" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="119.92420103796803" y="0" width="0.15091505053264134" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.07511608850068" y="0" width="0.15091505053264134" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.22603113903332" y="0" width="0.15091505053264134" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.37694618956597" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.51898388418493" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.6610215788039" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.80305927342286" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="120.94509696804182" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.08713466266079" y="0" width="0.14203769461895654" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.22917235727975" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.36233269598502" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.49549303469028" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.62865337339555" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.76181371210082" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="121.89497405080608" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.02813438951135" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.16129472821662" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.29445506692188" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.42761540562715" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.56077574433242" y="0" width="0.1331603387052718" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.69393608303768" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.81821906582927" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="122.94250204862085" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.06678503141244" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.19106801420402" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.3153509969956" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.43963397978719" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.56391696257877" y="0" width="0.12428298279158699" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.68819994537036" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.80360557224826" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="123.91901119912616" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.03441682600406" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.14982245288196" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.26522807975986" y="0" width="0.1154056268779022" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.38063370663777" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.48716197760199" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.5936902485662" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.70021851953042" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.80674679049464" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="124.91327506145886" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.01980333242308" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.1263316033873" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.23285987435152" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.33938814531574" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.44591641627996" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.55244468724418" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.6589729582084" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.76550122917261" y="0" width="0.10652827096421744" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.87202950013683" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="125.96968041518737" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.0673313302379" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.16498224528844" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.26263316033898" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.36028407538952" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.45793499044005" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.55558590549059" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.65323682054112" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.75088773559166" y="0" width="0.09765091505053264" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.8485386506422" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="126.93731220977905" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.0260857689159" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.11485932805276" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.20363288718961" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.29240644632647" y="0" width="0.08877355913684785" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.38118000546332" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.46107620868648" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.54097241190964" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.62086861513279" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.70076481835595" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.7806610215791" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.86055722480226" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="127.94045342802542" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.0203496312486" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.10024583447176" y="0" width="0.07989620322316307" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.18014203769494" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.25116088500442" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.3221797323139" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.3931985796234" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.4642174269329" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.53523627424238" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.60625512155187" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.67727396886136" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.74829281617085" y="0" width="0.07101884730947827" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.81931166348033" y="0" width="0.062141491395793495" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.88145315487614" y="0" width="0.062141491395793495" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="128.94359464627195" y="0" width="0.062141491395793495" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.00573613766775" y="0" width="0.05326413548210872" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.05900027314985" y="0" width="0.05326413548210872" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.11226440863194" y="0" width="0.05326413548210872" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.16552854411404" y="0" width="0.05326413548210872" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.21879267959613" y="0" width="0.04438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.26317945916455" y="0" width="0.04438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.30756623873296" y="0" width="0.04438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.35195301830137" y="0" width="0.04438677956842393" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.39633979786979" y="0" width="0.035509423654739136" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.43184922152452" y="0" width="0.035509423654739136" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.46735864517925" y="0" width="0.035509423654739136" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.50286806883398" y="0" width="0.035509423654739136" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.5383774924887" y="0" width="0.035509423654739136" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.57388691614344" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.60051898388448" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.62715105162553" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.65378311936658" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.68041518710763" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.70704725484867" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.73367932258972" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.76031139033077" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.78694345807182" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.81357552581287" y="0" width="0.02663206774105436" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.8402075935539" y="0" width="0.017754711827369568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.85796230538128" y="0" width="0.017754711827369568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.87571701720864" y="0" width="0.017754711827369568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.893471729036" y="0" width="0.017754711827369568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.91122644086337" y="0" width="0.017754711827369568" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.92898115269074" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.93785850860442" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.9467358645181" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.9556132204318" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.96449057634547" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.97336793225915" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.98224528817283" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect><rect class="fill-white cursor-pointer" x="129.99112264408652" y="0" width="0.008877355913684784" height="28" fill-opacity="0"></rect></g></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 max-w-full overflow-hidden text-ellipsis whitespace-nowrap">396
				values</div></div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">image
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>string</span><span class="italic text-gray-400 before:mx-1 before:content-['·']">lengths</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-gray-400 dark:fill-gray-500/80" rx="2" x="0" y="0" width="130" height="30" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="132" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">13</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">13</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th><th class="h-full max-w-sm p-2 text-left  relative w-auto"><div class="flex h-full flex-col flex-nowrap justify-between"><div><div class="flex items-center justify-between">count
				<form class="flex flex-col"><button id="asc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="-rotate-180 transform text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button>
						<button id="desc" class="-mr-1 ml-2 h-[0.4rem] w-[0.8rem] transition ease-in-out"><svg class="text-gray-300 hover:text-gray-500" xmlns="http://www.w3.org/2000/svg" viewBox="0 64 256 128" fill="currentColor" aria-hidden="true"><path d="M213.65674,101.657l-80,79.99976a7.99945,7.99945,0,0,1-11.31348,0l-80-79.99976A8,8,0,0,1,48,88H208a8,8,0,0,1,5.65674,13.657Z"></path></svg></button></form></div>

			<div class="mb-2 whitespace-nowrap text-xs font-normal text-gray-500"><span>int64</span></div></div>

		<div><div class="" style="height: 40px; padding-top: 2px"><svg width="130" height="28"><g><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="0" y="0" width="16.857142857142858" height="30" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="18.857142857142858" y="23.59303574167817" width="16.857142857142858" height="6.406964258321828" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="37.714285714285715" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="56.57142857142857" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="75.42857142857143" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="94.28571428571429" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect><rect class="fill-indigo-500 dark:fill-indigo-600/80" rx="2" x="113.14285714285714" y="25" width="16.857142857142858" height="5" fill-opacity="1"></rect></g><rect class="fill-white dark:fill-gray-900" x="0" y="26" width="130" height="2" stroke-opacity="1"></rect><line class="stroke-gray-100 dark:stroke-gray-500/20" x1="0" y1="27.5" x2="130" y2="27.5" stroke-opacity="1"></line><g><rect class="fill-indigo-500 cursor-pointer" x="-1" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="17.857142857142858" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="36.714285714285715" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="55.57142857142857" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="74.42857142857143" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="93.28571428571429" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect><rect class="fill-indigo-500 cursor-pointer" x="112.14285714285714" y="0" width="18.857142857142858" height="30" fill-opacity="0"></rect></g></svg>
	<div class="relative font-light text-gray-400" style="height: 10px; width: 130px;"><div class="absolute left-0 overflow-hidden text-ellipsis whitespace-nowrap" style="max-width: 60px">1</div>
			<div class="absolute overflow-hidden text-ellipsis whitespace-nowrap" style="right: 0px; max-width: 60px">13</div>
			</div></div></div></div>
	<div class="absolute right-0 top-0 z-10 h-full w-1 cursor-col-resize hover:bg-indigo-100 active:bg-indigo-500 dark:hover:bg-indigo-800 dark:active:bg-indigo-600/80"><div class="absolute right-0 top-0 h-full w-1"></div>
								</div>
						</th></tr></thead>
			<tbody class="h-16 overflow-scroll"><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="0"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are playing sports, specifically curling. Curling is a sport where players slide stones on a sheet of ice towards a target area which is segmented into four concentric circles. It requires precise movements and often involves squatting or kneeling poses.

The leftmost person is in the center of the image with their body scaled up to 3 times its original size. They appear to be in an active state, possibly in the middle of delivering a stone or sweeping. Their right leg is slightly bent at the knee and ankle, suggesting that they may be moving or about to move. The right leg appears straighter but still maintaining some bend at the knee and ankle joints as well. Both legs are angled towards each other with their hips relatively close together indicating that they might be maintaining balance during movement.

Their arms seem to be held out from their body, potentially for balance or action related to game play - right arm bent upwards at elbow while left arm seems extended downwards. The torso leans forward slightly implying concentration on target area.

The head position indicates focus on something below them - perhaps watching stone's path closely.

The second person, located near right edge of image with 2.5 times scale up, seems more stationary compared to first individual - possibly monitoring game progress or preparing for next turn.

Their legs show distinct difference: left leg fully extended while right one bent significantly at knee joint suggesting they're either stepping forward or backward.

Arms display different angles too: left arm appears fairly straight whereas right one exhibits significant bend at elbow joint pointing upwards which might suggest readiness for next move in game play.
 
Torso orientation suggests attention directed towards left side (from viewer's perspective) probably observing current state of play while head position reinforces this assumption as it aligns with torso direction.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      594,
      257
    ],
    "id": 0,
    "kpts": [
      [
        620,
        394
      ],
      [
        616,
        269
      ],
      [
        573,
        185
      ],
      [
        647,
        188
      ],
      [
        661,
        221
      ],
      [
        656,
        231
      ],
      [
        610,
        187
      ],
      [
        647,
        176
      ],
      [
        637.0201,
        189.8183
      ],
      [
        695.9799,
        108.1817
      ],
      [
        606,
        217
      ],
      [
        553,
        161
      ],
      [
        601,
        167
      ],
      [
        692,
        185
      ],
      [
        693,
        240
      ],
      [
        688,
        313
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.021046
  },
  {
    "center": [
      952,
      222
    ],
    "id": 1,
    "kpts": [
      [
        895,
        293
      ],
      [
        910,
        279
      ],
      [
        945,
        223
      ],
      [
        1012,
        218
      ],
      [
        961,
        315
      ],
      [
        960,
        403
      ],
      [
        979,
        221
      ],
      [
        906,
        190
      ],
      [
        912.4915,
        190.6586
      ],
      [
        830.5085,
        182.3414
      ],
      [
        871,
        304
      ],
      [
        883,
        229
      ],
      [
        888,
        174
      ],
      [
        924,
        206
      ],
      [
        1013,
        203
      ],
      [
        955,
        263
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.472117
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,660</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">015601864.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="1"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are three people in the image who are playing sports, specifically curling. This activity involves sliding stones on a sheet of ice towards a target area segmented into four concentric circles. It is evident from the keypoints that these individuals are engaged in different stages of the game.

The person at center coordinates (619.0, 329.0) with scale 5.641276 is standing upright with their right arm extended forward and left arm bent at an angle towards the back. Their legs seem to be positioned wide apart, indicating stability while they perform their action.

The person located at center coordinates (1010.0, 412.0) with scale 6.071051 seems to be in motion as both arms appear extended and slightly bent possibly holding or releasing the stone for sliding it across the ice.

Lastly, there's a person at center coordinates (133.0, 315.0) with scale 5.728162 who appears to be standing upright but slightly leaning forward with their right arm stretched out as if guiding or aiming for something.

In all three cases due to lack of visibility of lower body keypoints like ankles and knees we can't accurately determine if they are kneeling or have one leg raised which is common in curling sport while launching stones on ice sheet.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      619,
      329
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        806,
        543
      ],
      [
        720,
        593
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        763,
        568
      ],
      [
        683,
        290
      ],
      [
        682,
        256
      ],
      [
        676,
        68
      ],
      [
        563,
        296
      ],
      [
        555,
        410
      ],
      [
        647,
        281
      ],
      [
        719,
        299
      ],
      [
        711,
        516
      ],
      [
        545,
        466
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.641276
  },
  {
    "center": [
      1010,
      412
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        987,
        607
      ],
      [
        1194,
        571
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        1091,
        589
      ],
      [
        1038,
        292
      ],
      [
        1025,
        261
      ],
      [
        947,
        74
      ],
      [
        914,
        539
      ],
      [
        955,
        470
      ],
      [
        931,
        315
      ],
      [
        1145,
        269
      ],
      [
        1226,
        475
      ],
      [
        1096,
        433
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 6.071051
  },
  {
    "center": [
      133,
      315
    ],
    "id": 2,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        228,
        537
      ],
      [
        74,
        536
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        151,
        537
      ],
      [
        129,
        251
      ],
      [
        123,
        218
      ],
      [
        89,
        31
      ],
      [
        220,
        373
      ],
      [
        297,
        456
      ],
      [
        232,
        251
      ],
      [
        26,
        251
      ],
      [
        26,
        423
      ],
      [
        -1,
        -1
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      0
    ],
    "scale": 5.728162
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,660</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">84</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">015599452.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="2"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are participating in sports, specifically curling. The activity involves a low and bent posture, with one knee nearly touching the ground while the other leg extends back. The arms extend forward to guide a curling stone.

The first person is located near the center of the image and they appear to be in motion with their body lowered close to the ground. Their right leg is bent at the knee and extended backward while their left leg supports their weight, also bent at an angle. Their pelvis is slightly tilted towards their right side suggesting that they are likely leaning on this side for balance. The torso is inclined forward from waist upwards, indicating that they might be pushing or guiding something on ground like a curling stone.

Their right arm is extended forward with elbow slightly bent, possibly holding onto something for support or guidance; whereas left arm appears to be extended straight out towards left side of body providing counterbalance. Their head seems to be looking straight ahead or slightly downwards which aligns with action of focusing on path ahead.

The second person located towards far right of image seems to have similar pose as first but more upright position suggesting less active role like waiting for turn or observing play. This person's both legs are relatively closer together compared to first individual but still maintaining bend at knees reflecting readiness stance.

Their arms' positioning suggests anticipation or readiness - right arm extending outwards and downwards while left arm bends at elbow pointing upwards possibly holding broom used in curling sport. Similar to first individual, this person's head top also points straight ahead indicating focus on game happening in front of them.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      291,
      353
    ],
    "id": 0,
    "kpts": [
      [
        301,
        461
      ],
      [
        305,
        375
      ],
      [
        201,
        340
      ],
      [
        294,
        342
      ],
      [
        335,
        370
      ],
      [
        331,
        455
      ],
      [
        248,
        341
      ],
      [
        279,
        263
      ],
      [
        277.021,
        268.7786
      ],
      [
        305.979,
        184.2214
      ],
      [
        328,
        354
      ],
      [
        260,
        335
      ],
      [
        244,
        261
      ],
      [
        314,
        264
      ],
      [
        327,
        320
      ],
      [
        362,
        346
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.681349
  },
  {
    "center": [
      472,
      377
    ],
    "id": 1,
    "kpts": [
      [
        515,
        512
      ],
      [
        514,
        420
      ],
      [
        406,
        388
      ],
      [
        392,
        360
      ],
      [
        493,
        434
      ],
      [
        518,
        504
      ],
      [
        399,
        374
      ],
      [
        498,
        317
      ],
      [
        504.5953,
        315.1758
      ],
      [
        585.4047,
        292.8242
      ],
      [
        628,
        426
      ],
      [
        551,
        398
      ],
      [
        501,
        351
      ],
      [
        495,
        282
      ],
      [
        425,
        301
      ],
      [
        483,
        334
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.51531
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,462</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">240</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">086617615.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="3"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is participating in curling. This sport typically involves a crouched position, with one leg extended behind and arms forward to push the stone.

The person located at the center of the image is engaged in action, with their limbs positioned for curling. 

Their right leg appears bent at the knee and ankle, suggesting it's supporting most of their weight. The right hip is higher than the left hip indicating they are leaning towards their right side. 

Their left leg seems to be extended behind them, with both left knee and ankle visible suggesting a stretched pose.

The torso appears slightly inclined forward from pelvis to thorax indicating an active posture associated with pushing or sliding something on ice.

The head of this individual seems tilted down slightly from upper neck to head top implying concentration on a task at hand.

As for their arms, both seem extended forward but not symmetrically. The right arm from wrist to shoulder has all keypoints visible showing that it's fully stretched out possibly holding or guiding an object while the left arm has its elbow bent and wrist raised higher than shoulder possibly providing balance during action.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      897,
      171
    ],
    "id": 0,
    "kpts": [
      [
        980,
        322
      ],
      [
        896,
        318
      ],
      [
        865,
        248
      ],
      [
        943,
        226
      ],
      [
        948,
        290
      ],
      [
        881,
        349
      ],
      [
        904,
        237
      ],
      [
        858,
        135
      ],
      [
        871.1877,
        180.4244
      ],
      [
        835.8123,
        58.5756
      ],
      [
        772,
        294
      ],
      [
        754,
        247
      ],
      [
        792,
        147
      ],
      [
        923,
        123
      ],
      [
        995,
        163
      ],
      [
        961,
        223
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.806403
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">89</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">6</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">060111501.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="4"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are participating in curling. Curling is a sport where players slide stones on a sheet of ice towards a target area segmented into four concentric circles. It requires precision, strategy, and teamwork.

The person at the center-left of the image is engaged in the throwing motion typical of curling. Their right leg is bent at the knee with their ankle positioned behind them, while their left leg is extended forward with no visible knee or ankle joint. The right arm is bent slightly at the elbow and wrist, indicating they might be holding or releasing a stone. The left arm appears to be extended for balance.

The person located more towards center-right appears to be observing or waiting their turn to play. Their body posture indicates readiness but not immediate action - both legs are visible with knees slightly bent and ankles firmly on ground suggesting stability; arms seem relaxed but ready for action with elbows slightly flexed - right one higher than left one; head position suggests they're focused on game.

Overall, this scene captures different stages of participation within a curling match – from active play to strategic observation.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      582,
      268
    ],
    "id": 0,
    "kpts": [
      [
        461,
        398
      ],
      [
        509,
        335
      ],
      [
        517,
        218
      ],
      [
        570,
        203
      ],
      [
        -1,
        -1
      ],
      [
        568,
        309
      ],
      [
        544,
        211
      ],
      [
        620,
        273
      ],
      [
        614,
        267
      ],
      [
        668,
        326
      ],
      [
        537,
        288
      ],
      [
        503,
        234
      ],
      [
        587,
        280
      ],
      [
        652,
        265
      ],
      [
        636,
        356
      ],
      [
        621,
        417
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.40012
  },
  {
    "center": [
      765,
      394
    ],
    "id": 1,
    "kpts": [
      [
        896,
        436
      ],
      [
        875,
        397
      ],
      [
        885,
        295
      ],
      [
        852,
        363
      ],
      [
        797,
        442
      ],
      [
        823,
        505
      ],
      [
        869,
        329
      ],
      [
        737,
        323
      ],
      [
        719,
        326
      ],
      [
        648,
        338
      ],
      [
        804,
        305
      ],
      [
        804,
        237
      ],
      [
        741,
        285
      ],
      [
        732,
        361
      ],
      [
        758,
        411
      ],
      [
        757,
        485
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.155328
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">89</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">81</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">070807258.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="5"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is playing curling. The sport involves a lot of bending and stretching, with players often seen in a crouched position, sliding the stone on the ice.

The person located at coordinates (924.0, 445.0) appears to be in an active state of play with their limbs positioned for action.

Regarding their right leg, it seems to be bent at the knee with the ankle positioned slightly behind and lower than the hip joint. The left leg appears extended straight from hip to ankle, possibly providing balance during play.

The right arm is bent at a sharp angle at elbow joint suggesting that they might be holding or about to release curling stone. The wrist of this arm is found higher than elbow indicating an upward movement or grip.

The left arm appears almost straight but slightly bent at elbow pointing towards ground which could be used for stability during sliding motion on ice.

Their torso leans forward as indicated by relatively low position of thorax compared to pelvis which aligns well with typical pose seen in curling where player bends forward while delivering stone.

Finally, their head seems tilted downwards as per alignment between neck and head top keypoints which suggests concentration on target or stone being played.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      924,
      445
    ],
    "id": 0,
    "kpts": [
      [
        918,
        456
      ],
      [
        659,
        518
      ],
      [
        713,
        413
      ],
      [
        979,
        288
      ],
      [
        1222,
        453
      ],
      [
        974,
        399
      ],
      [
        846,
        351
      ],
      [
        738,
        259
      ],
      [
        795.2738,
        314.8937
      ],
      [
        597.7262,
        122.1063
      ],
      [
        441,
        490
      ],
      [
        446,
        434
      ],
      [
        599,
        270
      ],
      [
        877,
        247
      ],
      [
        1112,
        384
      ],
      [
        1012,
        489
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 8.28087
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">89</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">162</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, curling</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">002058449.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="6"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are sitting quietly. This typically involves the individuals being in a seated position with their legs bent at the knees, and arms either resting on their laps or placed on armrests. The overall posture is relaxed and there is minimal movement.

The person located towards the left of the image is sitting with their right leg obscured from view. Their left leg appears to be bent at the knee, with their hip and knee keypoints indicating a relaxed seated position. The right arm seems to be raised slightly, with both elbow and wrist keypoints positioned above those of shoulder and hip respectively. The left arm appears extended outwards, possibly resting on an object or surface.

The person located towards the right of the image seems to be in a more upright seated position compared to their counterpart. Both legs appear visible, bent at knees suggesting they might be sitting on an elevated surface such as a chair or stool. Their right arm looks like it's resting comfortably on their lap while left arm appears slightly raised but still relaxed.

In both cases, torso keypoints suggest an upright posture while head keypoints indicate that heads are facing forward - typical traits when someone is engaged in quiet activities such as reading or watching something.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      304,
      264
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        355,
        408
      ],
      [
        269,
        354
      ],
      [
        432,
        333
      ],
      [
        464,
        425
      ],
      [
        -1,
        -1
      ],
      [
        351,
        344
      ],
      [
        310,
        158
      ],
      [
        308.4257,
        139.7834
      ],
      [
        297.5743,
        14.2166
      ],
      [
        335,
        328
      ],
      [
        212,
        304
      ],
      [
        230,
        168
      ],
      [
        389,
        147
      ],
      [
        492,
        259
      ],
      [
        413,
        321
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.781047
  },
  {
    "center": [
      361,
      303
    ],
    "id": 1,
    "kpts": [
      [
        357,
        353
      ],
      [
        369,
        330
      ],
      [
        366,
        296
      ],
      [
        443,
        308
      ],
      [
        470,
        332
      ],
      [
        435,
        371
      ],
      [
        405,
        302
      ],
      [
        404,
        201
      ],
      [
        405.772,
        194.4489
      ],
      [
        435.228,
        85.5511
      ],
      [
        331,
        252
      ],
      [
        354,
        261
      ],
      [
        357,
        200
      ],
      [
        451,
        202
      ],
      [
        484,
        246
      ],
      [
        468,
        253
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.38434
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,615</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">28</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">inactivity quiet/light, sitting quietly</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">021233911.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="7"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are sitting quietly. Both individuals appear to be in a seated position, with their legs bent at the knees and their upper bodies upright.

The first person is located towards the right of center and is larger in scale. They are sitting with their torso leaning slightly to the left. Their right leg appears to be bent at a sharper angle than their left, suggesting that they might be shifting weight onto it. The right ankle and knee are visible while the left hip, knee, and ankle suggest that they're folded underneath them or possibly extended out of frame. Their arms seem relaxed; the right arm hangs down naturally while the left arm is slightly raised with elbow bent.

The second person is located towards center-left and is larger than the first person. Unfortunately, some keypoints such as both ankles aren't visible which limits our understanding of this individual's pose; however, based on available data we can infer that they're also seated but more upright compared to person one. Their right leg appears extended forward with knee bent while visibility of only left hip suggests this leg might be folded underneath or extended outwards like person one's pose but we can't confirm without further data. The arms appear relaxed but extended; both elbows show a significant bend indicating hands may be resting on lap or nearby surface.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      316,
      283
    ],
    "id": 0,
    "kpts": [
      [
        325,
        349
      ],
      [
        341,
        327
      ],
      [
        326,
        302
      ],
      [
        385,
        277
      ],
      [
        409,
        302
      ],
      [
        399,
        377
      ],
      [
        356,
        290
      ],
      [
        314,
        209
      ],
      [
        315.2436,
        213.9744
      ],
      [
        286.7564,
        100.0256
      ],
      [
        318,
        325
      ],
      [
        280,
        288
      ],
      [
        267,
        231
      ],
      [
        360,
        187
      ],
      [
        406,
        218
      ],
      [
        374,
        258
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.523671
  },
  {
    "center": [
      261,
      296
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        329,
        409
      ],
      [
        262,
        352
      ],
      [
        399,
        316
      ],
      [
        439,
        423
      ],
      [
        -1,
        -1
      ],
      [
        331,
        334
      ],
      [
        245,
        213
      ],
      [
        211.002,
        177.0151
      ],
      [
        124.998,
        85.9849
      ],
      [
        157,
        477
      ],
      [
        159,
        371
      ],
      [
        169,
        254
      ],
      [
        320,
        171
      ],
      [
        443,
        231
      ],
      [
        364,
        300
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.756978
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,615</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">177</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">inactivity quiet/light, sitting quietly</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">018182497.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="8"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaging in miscellaneous activities, sitting, talking in person, on the phone, computer or text messaging with light effort. The activities suggest a relaxed situation with individuals likely seated and interacting with each other or devices.

The first person located towards the left is seemingly engaged in an activity involving their upper body. Their right leg is bent at the knee and hip while their left leg appears to be straight. The right arm seems to be extended forward possibly holding or interacting with an object as indicated by its position relative to the torso. Their left arm is slightly bent at the elbow and appears relaxed. The head is tilted downwards suggesting focused attention on something below eye level.

The second person located towards the right of frame also appears to be seated but their pose suggests they might be engaged in conversation or looking at something ahead of them. Both legs appear bent at knees and hips indicating a sitting posture similar to first individual but more upright based on relative positions of hips and shoulders. Their arms are positioned differently; while their right arm seems slightly extended forward, perhaps resting on a surface or holding an object, their left arm seems closer to body possibly resting against it. They have their head held higher compared to first individual suggesting engagement with someone/something ahead rather than below eye level.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      333,
      246
    ],
    "id": 0,
    "kpts": [
      [
        392,
        390
      ],
      [
        388,
        300
      ],
      [
        289,
        296
      ],
      [
        302,
        283
      ],
      [
        395,
        296
      ],
      [
        400,
        389
      ],
      [
        296,
        290
      ],
      [
        287,
        191
      ],
      [
        289.5053,
        184.9874
      ],
      [
        314.4947,
        125.0126
      ],
      [
        366,
        284
      ],
      [
        307,
        275
      ],
      [
        281,
        194
      ],
      [
        292,
        187
      ],
      [
        320,
        262
      ],
      [
        362,
        276
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.949178
  },
  {
    "center": [
      408,
      263
    ],
    "id": 1,
    "kpts": [
      [
        423,
        378
      ],
      [
        411,
        288
      ],
      [
        344,
        259
      ],
      [
        394,
        251
      ],
      [
        456,
        283
      ],
      [
        453,
        369
      ],
      [
        369,
        255
      ],
      [
        344,
        190
      ],
      [
        345.6244,
        184.3958
      ],
      [
        362.3756,
        126.6042
      ],
      [
        381,
        264
      ],
      [
        337,
        247
      ],
      [
        316,
        189
      ],
      [
        372,
        190
      ],
      [
        394,
        239
      ],
      [
        421,
        257
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.805113
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">622</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">842</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">10</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">018340451.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="9"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaged in miscellaneous activities, sitting, talking in person, on the phone, computer, or text messaging with light effort. Their poses suggest a relaxed and casual setting with some level of interaction.

The first person located near the center of the image is seated with their body facing forward. Their right leg is bent at the knee and extended outward while their left leg is also bent at a similar angle but slightly inward. The right arm appears to be resting on a surface or holding an object as it's extended forward from the shoulder with slight bend at elbow. The left arm seems to be held closer to body indicating possible interaction with an object close by.

The second person situated towards right side of image exhibits similar pose characteristics but mirrored along vertical axis. They have their left leg stretched out while their right leg is slightly folded inwardly. This individual's left arm extends forward possibly resting on a surface or interacting with an object nearby while their right arm seems closer to body suggesting engagement with something within close reach.

In both cases, heads are tilted slightly downwards indicating focus on objects they're interacting with which could be devices such as phones or computers given activity context.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      374,
      255
    ],
    "id": 0,
    "kpts": [
      [
        324,
        406
      ],
      [
        322,
        291
      ],
      [
        293,
        262
      ],
      [
        355,
        267
      ],
      [
        401,
        292
      ],
      [
        394,
        404
      ],
      [
        324,
        265
      ],
      [
        334,
        170
      ],
      [
        338.6651,
        157.2087
      ],
      [
        360.3349,
        97.7913
      ],
      [
        363,
        167
      ],
      [
        319,
        205
      ],
      [
        298,
        168
      ],
      [
        369,
        172
      ],
      [
        390,
        221
      ],
      [
        398,
        179
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.897367
  },
  {
    "center": [
      540,
      267
    ],
    "id": 1,
    "kpts": [
      [
        476,
        407
      ],
      [
        476,
        295
      ],
      [
        510,
        264
      ],
      [
        564,
        265
      ],
      [
        581,
        303
      ],
      [
        575,
        412
      ],
      [
        537,
        265
      ],
      [
        535,
        175
      ],
      [
        534.9093,
        172.7919
      ],
      [
        532.0907,
        104.2081
      ],
      [
        508,
        183
      ],
      [
        492,
        238
      ],
      [
        493,
        173
      ],
      [
        577,
        176
      ],
      [
        591,
        235
      ],
      [
        556,
        190
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.05925
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">622</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">842</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">95</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">030424224.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="10"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaging in light effort activities such as miscellaneous sitting, talking in person, on the phone, or text messaging. This may include using a computer. 

The first person is centrally located within the image and appears to be interacting with an object or performing an action with their right arm. Their right leg is bent at the knee and hip, suggesting they might be seated on a chair or similar surface. Their left leg is also bent at the knee but less so than their right leg - it could be resting on a surface. The upper body leans slightly towards their right side while their head faces forward.

The second person is positioned towards the right of the image and appears to also be seated given that both legs are bent at knees and hips, possibly resting on a surface. They seem to have both arms raised; left arm more elevated than the right one which suggests they might be engaged in conversation or holding an object like a phone near their face for interaction.

In general, these poses suggest casual indoor activities where individuals may engage with objects around them or communicate with others through various means including direct conversation, phone calls or text messaging.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      338,
      258
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        477,
        423
      ],
      [
        300,
        416
      ],
      [
        321,
        400
      ],
      [
        519,
        408
      ],
      [
        -1,
        -1
      ],
      [
        311,
        408
      ],
      [
        309,
        208
      ],
      [
        314.9696,
        197.6361
      ],
      [
        375.0304,
        93.3639
      ],
      [
        461,
        395
      ],
      [
        334,
        380
      ],
      [
        309,
        225
      ],
      [
        309,
        191
      ],
      [
        299,
        58
      ],
      [
        260,
        156
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.609986
  },
  {
    "center": [
      546,
      249
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        575,
        416
      ],
      [
        498,
        377
      ],
      [
        577,
        365
      ],
      [
        693,
        405
      ],
      [
        -1,
        -1
      ],
      [
        538,
        371
      ],
      [
        472,
        219
      ],
      [
        472.0517,
        218.5069
      ],
      [
        482.9483,
        114.4931
      ],
      [
        444,
        185
      ],
      [
        456,
        296
      ],
      [
        419,
        231
      ],
      [
        524,
        207
      ],
      [
        577,
        132
      ],
      [
        477,
        138
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.137489
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">622</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">842</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">469</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">043194502.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="11"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads.

The centrally located person is standing facing slightly to the left with their right arm extended downwards and slightly bent at the elbow. Their left arm appears to be reaching across their body towards the right side. 

For their legs, it seems that they are standing with weight primarily on their left leg. The right leg appears to be slightly bent at the knee indicating possible movement or preparation for stepping.

As for their torso and head position; they are upright with a slight lean towards the left side likely due to weight distribution of what they might be carrying or preparing to lift. Their head is straight looking forward or possibly downwards considering occupational safety during lifting heavy objects.

In conclusion, this pose indicates an individual engaged in manual labor tasks such as lifting or moving items possibly related to truck loading/unloading activities.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      316,
      299
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        301,
        473
      ],
      [
        302,
        346
      ],
      [
        362,
        345
      ],
      [
        367,
        470
      ],
      [
        -1,
        -1
      ],
      [
        332,
        346
      ],
      [
        325,
        217
      ],
      [
        326.2681,
        196.1669
      ],
      [
        330.7319,
        122.8331
      ],
      [
        275,
        299
      ],
      [
        262,
        300
      ],
      [
        278,
        220
      ],
      [
        371,
        213
      ],
      [
        396,
        309
      ],
      [
        393,
        290
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.204083
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">029122914.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="12"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in the occupation of truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads.

The person centered at coordinates (435.0, 295.0) on a scale of 4.143112 is seen performing an activity related to their occupation. Their right arm appears to be extended towards the front with a bend at the elbow while their left arm seems to be raised slightly higher than their right shoulder.

Starting with the head region: The upper neck keypoint indicates that they are looking straight ahead or slightly upwards as it's positioned above thorax keypoint.

Moving onto torso: The thorax keypoint indicates that they are standing upright as it's vertically aligned with upper neck and pelvis keypoints which are not visible in this case.

Right arm: The right wrist is lower than the right elbow suggesting that their forearm might be elevated or bent upwards. The position of right shoulder suggests that this arm might be stretched out towards front or side.

Left Arm: There's no information available for left elbow and wrist but given the position of left shoulder being higher than right one, it can be inferred that this arm might also be raised or stretched outwards.

Legs: Unfortunately there're no visible keypoints for legs so we cannot infer anything about them.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      435,
      295
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        533,
        322
      ],
      [
        515.0945,
        277.1333
      ],
      [
        463.9055,
        148.8667
      ],
      [
        353,
        172
      ],
      [
        426,
        239
      ],
      [
        513,
        288
      ],
      [
        552,
        355
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ]
    ],
    "kpts_vis": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      0,
      0
    ],
    "scale": 4.143112
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">72</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">061185289.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="13"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is loading and unloading a truck. This activity involves standing, walking, carrying heavy loads, and tying down the load. 

The person centered around coordinates (183.0, 327.0) appears to be in an active state with their limbs engaged in some form of movement or action.

Their right leg seems invisible or obscured from view as both the right ankle and knee are not visible. The right hip is located at coordinate (110, 385), indicating that it may be bent or raised.

The left leg's hip is positioned at coordinate (208, 355), but both the knee and ankle are also not visible suggesting that this leg might also be bent or obscured from view.

The pelvis is situated higher than both hips at coordinate (159,370), implying an upright posture.

Their torso appears to be leaning forward slightly as indicated by the position of thorax at coordinate (189,228) which is lower than the pelvis but higher than upper neck located at coordinate (191,227).

The head seems to be tilted upwards since its topmost point located at coordinate (326,168) lies significantly above all other keypoints.

For their arms: 
- The right arm has its wrist positioned higher up at coordinate(367 ,363). The elbow joint sits lower down on coordinates(254 ,429). This suggests that this arm might be raised up.
- In contrast to this pattern seen on their right side; on their left side - wrist joint rests relatively low on coordinates(376 ,39), while elbow joint sits much higher up placed on coordinates(319 ,123). This implies a possible bending angle where forearm could potentially lie parallel with ground surface.
  
Despite some keypoints being invisible due to occlusion or other reasons; overall body pose suggests engagement in physical activity involving lifting/carrying loads given context of occupation provided for MPII dataset image analysis.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      183,
      327
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        110,
        385
      ],
      [
        208,
        355
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        159,
        370
      ],
      [
        189,
        228
      ],
      [
        191.1195,
        227.0916
      ],
      [
        326.8805,
        168.9084
      ],
      [
        367,
        363
      ],
      [
        254,
        429
      ],
      [
        166,
        303
      ],
      [
        212,
        153
      ],
      [
        319,
        123
      ],
      [
        376,
        39
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.431105
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">137</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">013949386.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="14"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy loads. This activity requires a lot of physical effort and coordination as it involves various movements such as standing, walking and lifting heavy items. 

The person located at the center of the image appears to be in a dynamic pose with their limbs oriented towards performing some task.

Starting with their right leg: The right hip is visible but the knee and ankle are not visible which suggests that this leg might be bent or obscured from view.

Moving on to their left leg: We can see that this limb is slightly bent at the hip joint but other keypoints like knee and ankle are not visible which indicates that this leg may also be bent or obscured.

Their torso seems to be leaning forward given that we can trace a line from pelvis through thorax to upper neck. This posture often signifies an action involving reaching out or bending over something.

For their right arm: It seems extended outwards with both wrist and elbow visible. The arm appears to be reaching upwards suggesting they might be lifting or holding something aloft.

Regarding their left arm: It's extended downwards with both elbow and wrist keypoints discernible. The orientation suggests they could have been using this hand for support while performing tasks.

Lastly for head position: From neck up through top of head there's a clear upward inclination indicating they're looking upwards possibly focusing on task at hand.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      244,
      190
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        208,
        331
      ],
      [
        159,
        313
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        184,
        322
      ],
      [
        198,
        105
      ],
      [
        216.6135,
        87.6702
      ],
      [
        295.3865,
        14.3298
      ],
      [
        322,
        385
      ],
      [
        254,
        278
      ],
      [
        222,
        118
      ],
      [
        174,
        92
      ],
      [
        181,
        226
      ],
      [
        197,
        364
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.22887
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">244</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">029214465.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="15"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is working, specifically involved in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy load.

The person at the center of the image appears to be in a state of motion or engaging in some physical activity. Their body orientation suggests they might be involved in lifting or carrying something heavy.

The left leg of this individual seems to be slightly bent at the knee and shifted backward whereas their right leg appears straighter and more forward. This might suggest that they are stepping forward with their right foot while supporting weight on their left.

Their right arm seems to be bent at an angle near the elbow with wrist higher than elbow level suggesting that they may be holding or lifting something. The left arm also shows a similar bend but it's positioned lower than the right one indicating it's possibly supporting weight from below.

The torso leans slightly towards their right side perhaps due to weight distribution. The head is tilted downward indicating focus on whatever task they are performing with their hands.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      472,
      245
    ],
    "id": 0,
    "kpts": [
      [
        525,
        478
      ],
      [
        529,
        369
      ],
      [
        517,
        220
      ],
      [
        570,
        204
      ],
      [
        574,
        371
      ],
      [
        581,
        480
      ],
      [
        544,
        212
      ],
      [
        488,
        76
      ],
      [
        479.0873,
        71.5436
      ],
      [
        392.9127,
        28.4564
      ],
      [
        416,
        251
      ],
      [
        469,
        201
      ],
      [
        459,
        104
      ],
      [
        516,
        48
      ],
      [
        588,
        132
      ],
      [
        587,
        242
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.890381
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">383</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">036636184.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="16"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. These activities typically involve a lot of movement and physical effort.

The centrally located person is actively engaged in their task with their limbs positioned for heavy lifting or carrying. 

Their right leg appears to be slightly bent at the knee and hip which may suggest some form of movement or preparation for lifting. The left leg seems to be straightened out more towards the back which could indicate that they're bracing themselves for physical exertion.

The right arm has a noticeable bend at the elbow with wrist directed towards the body's center. This could suggest that they are holding onto something or preparing to lift an object. The left arm also appears bent at the elbow but not as much as the right one, possibly because it's being used for balance or support.

Their torso seems slightly inclined forward indicating an active pose often associated with lifting or moving heavy objects. This forward inclination can also provide additional momentum needed when carrying heavy loads.

Finally, their head seems tilted slightly downwards perhaps focusing on an object they are about to lift or carry. Their neck appears aligned with their upper body further suggesting concentration on tasks performed by hands.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      573,
      288
    ],
    "id": 0,
    "kpts": [
      [
        555,
        370
      ],
      [
        568,
        298
      ],
      [
        559,
        255
      ],
      [
        645,
        140
      ],
      [
        600,
        343
      ],
      [
        610,
        480
      ],
      [
        602,
        198
      ],
      [
        515,
        179
      ],
      [
        508.3448,
        181.3768
      ],
      [
        395.6552,
        221.6232
      ],
      [
        495,
        361
      ],
      [
        470,
        285
      ],
      [
        464,
        170
      ],
      [
        566,
        187
      ],
      [
        671,
        230
      ],
      [
        591,
        316
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.589826
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">607</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">045606998.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="17"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. 

The person centered around coordinates (591.0, 378.0) appears to be performing a task with their right arm extended while their left arm is bent at the elbow.

Their right leg seems to be slightly bent at the knee and positioned behind them while the left leg appears to be straight and bearing most of their weight.

The right ankle keypoint isn't visible in this image but judging from the position of their right knee and hip keypoints, it's safe to say that they are possibly stepping backwards or maintaining balance.

Their torso leans slightly towards the left side indicating they are either turning or shifting weight towards that direction.

Their head is tilted downward suggesting concentration on a task at hand or looking at something below eye level. Their neck also seems to be slightly extended forward which further supports this observation.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      591,
      378
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        548,
        675
      ],
      [
        563,
        514
      ],
      [
        626,
        510
      ],
      [
        602,
        664
      ],
      [
        -1,
        -1
      ],
      [
        595,
        512
      ],
      [
        611,
        308
      ],
      [
        615.2092,
        299.334
      ],
      [
        657.7908,
        211.666
      ],
      [
        522,
        488
      ],
      [
        522,
        404
      ],
      [
        571,
        304
      ],
      [
        651,
        312
      ],
      [
        687,
        324
      ],
      [
        716,
        299
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.923866
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">75</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">059241457.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="18"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy load. This activity involves a lot of physical work and movement.

The centrally positioned person is standing with their limbs involved in some form of action.

The right leg appears to be straight with the ankle slightly behind the knee and hip. The left leg seems to be stepping forward or sideways as it's bent at the knee with the ankle ahead of both knee and hip.

Their right arm seems to be reaching out or pulling something as it's extended straight from wrist through elbow to shoulder. The left arm appears bent at elbow forming an angle between shoulder and wrist which suggests lifting or holding onto something.

The torso leans slightly towards left possibly due to weight distribution from whatever they are carrying or pulling. 

Finally, their head is tilted downwards indicating focus on their task at hand.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      662,
      359
    ],
    "id": 0,
    "kpts": [
      [
        679,
        637
      ],
      [
        663,
        528
      ],
      [
        639,
        374
      ],
      [
        748,
        369
      ],
      [
        727,
        532
      ],
      [
        727,
        666
      ],
      [
        694,
        372
      ],
      [
        595,
        219
      ],
      [
        592.5583,
        210.0951
      ],
      [
        563.4417,
        103.9049
      ],
      [
        495,
        354
      ],
      [
        526,
        310
      ],
      [
        553,
        217
      ],
      [
        636,
        220
      ],
      [
        616,
        329
      ],
      [
        529,
        353
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.303293
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">283</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">017052412.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="19"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. The individual appears to be standing with their upper body twisted slightly towards their right side.

The person located at the center of the image appears to be in an active state with their limbs positioned for manual labor. 

Their right leg seems to be slightly bent at the hip joint as indicated by keypoint 2 (right hip). However, we cannot infer more about this leg's pose due to invisible keypoints of right knee and ankle.

The left leg appears straightened out with no bend visible from hip to ankle (keypoints 3-5), suggesting that it might be bearing most of the person's weight.

Their torso is tilted towards their right side which can be interpreted from relative positions of pelvis (keypoint 6), thorax (7) and neck (8).

As for arms, they seem stretched out. The left arm seems extended outward from shoulder to wrist (keypoints 13-15), possibly reaching for something or performing an action. The right arm also looks extended but slightly bent at elbow joint as seen between keypoints 12-10.

Finally, head orientation can't be precisely determined due its close proximity between upper neck and head top keypoints but it seems aligned with torso direction indicating focus on current activity.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      542,
      483
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        531,
        597
      ],
      [
        629,
        588
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        580,
        593
      ],
      [
        571,
        388
      ],
      [
        572,
        384
      ],
      [
        612,
        279
      ],
      [
        496,
        638
      ],
      [
        490,
        531
      ],
      [
        516,
        403
      ],
      [
        626,
        372
      ],
      [
        653,
        403
      ],
      [
        697,
        364
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.38434
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">006505159.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="20"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in occupational activities related to truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. This involves a lot of physical activity which can be seen through the keypoints.

The centrally positioned person appears to be in motion with their limbs actively engaged.

Starting with their legs:
- The right leg seems slightly bent at the knee and hip as indicated by coordinates of right ankle (836, 666), right knee (841, 595) and right hip (830, 500). It may suggest that this foot is about to step forward.
- The left leg appears more straightened out but still slightly bent at the knee. Given coordinates for left ankle (912, 691), left knee (895, 593) and left hip (900,515), it might be bearing most of the weight currently.

Moving on to their arms:
- Their right arm seems bent at elbow with wrist lower than shoulder level. This could mean they are holding or lifting something.
- Similarly for the left arm where elbow is also bent but wrist is almost aligned with shoulder suggesting it's readying to lift or already holding onto something.

Their torso shows an upright position given by pelvis coordinate at center point between hips (865,508) and thorax coordinate above it at higher y-value(876 ,397).

Finally considering head position using upper neck keypoint(875 ,390) and head top keypoint(873 ,325), it can be inferred that they are looking straight ahead or slightly upwards which aligns with other observations suggesting active engagement in physical work.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      878,
      493
    ],
    "id": 0,
    "kpts": [
      [
        836,
        666
      ],
      [
        841,
        595
      ],
      [
        830,
        500
      ],
      [
        900,
        515
      ],
      [
        895,
        593
      ],
      [
        912,
        691
      ],
      [
        865,
        508
      ],
      [
        876,
        397
      ],
      [
        875.7539,
        390.6023
      ],
      [
        873.2461,
        325.3977
      ],
      [
        775,
        457
      ],
      [
        817,
        441
      ],
      [
        844,
        390
      ],
      [
        907,
        404
      ],
      [
        898,
        460
      ],
      [
        862,
        504
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.957582
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">459</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">094888554.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="21"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. The activity involves a lot of physical work and movement.

The person centered at coordinates (359.0, 460.0) is captured performing an action with their limbs positioned as follows:

The left leg's hip joint is visible at (227,655), but the knee and ankle joints are not visible in the image which might suggest that the leg could be bent or obscured from view.

The right leg's hip joint can be seen at (118,644), but like the left leg, its knee and ankle joints are not visible either implying similar possibilities.

Their pelvis can be identified at point (173,650) indicating an upright posture considering its relative position to other visible points.

For their upper body; starting with their right arm: The shoulder joint is located at point (228,275), elbow joint at point (180,540) while wrist joint is placed further down towards pelvis level at point (430,592). This suggests that they're possibly reaching out or holding onto something with their right hand.
 
Their left arm's shoulder can be seen higher up around thorax level on coordinates (401 ,355). The elbow appears to be slightly bent given its position on coordinates(336 ,506). Finally their left wrist seems to have moved closer towards center of body near pelvis area as it's located on coordinates(342 ,603).

Their torso has key points marked from thorax located around middle of frame(315 ,315), going upwards through neck region placed higher up(364 ,271) till top of head marked by highest point in frame(535 ,124).

This pose indicates that they may be involved in a task requiring them to reach out for objects while maintaining an upright stance.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      359,
      460
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        118,
        644
      ],
      [
        227,
        655
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        173,
        650
      ],
      [
        315,
        315
      ],
      [
        364.6897,
        271.9356
      ],
      [
        535.3103,
        124.0644
      ],
      [
        430,
        592
      ],
      [
        180,
        540
      ],
      [
        228,
        275
      ],
      [
        401,
        355
      ],
      [
        336,
        506
      ],
      [
        342,
        603
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 6.773445
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">577</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">096563203.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="22"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in an occupation-related activity, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. 

The centrally-located person is seen standing with their limbs in motion indicative of the described activities.

Starting with the legs:
- The right leg appears to be slightly bent at the knee and hip. The right ankle seems to be firmly planted on the ground indicating weight-bearing.
- The left leg also appears to be slightly bent at the knee but more so at the hip than its counterpart. Like its counterpart, it also seems to bear some weight.

Moving on to arms:
- The right arm appears extended outwards with a noticeable bend at elbow; possibly reaching for something or carrying a load.
- Similarly, left arm shows an extended pose but much more raised compared to right arm suggesting it could be lifting or supporting something heavy.

As for torso and head:
- The torso leans slightly towards their right side indicating possible effort or strain from lifting or carrying.
- Their head seems tilted upwards perhaps looking towards where they are reaching or lifting.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      454,
      336
    ],
    "id": 0,
    "kpts": [
      [
        409,
        642
      ],
      [
        425,
        535
      ],
      [
        410,
        402
      ],
      [
        498,
        398
      ],
      [
        519,
        505
      ],
      [
        517,
        619
      ],
      [
        454,
        400
      ],
      [
        508,
        242
      ],
      [
        514.0306,
        232.5234
      ],
      [
        564.9694,
        152.4766
      ],
      [
        346,
        378
      ],
      [
        370,
        296
      ],
      [
        452,
        228
      ],
      [
        563,
        255
      ],
      [
        632,
        318
      ],
      [
        728,
        304
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.846404
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">748</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">707</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">030461377.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="23"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in occupational activities, specifically truck driving, loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. The person's pose suggests that they are currently engaged in a task that involves lifting or carrying.

The centrally located person is relatively large scale with their limbs mostly visible except for the legs. 

Their right leg appears to be slightly bent at the hip and positioned towards the left side of their body. However, due to invisible knee and ankle keypoints it's not possible to provide more detailed information about the right leg.

Their left leg seems straight with hip joint being higher than right one indicating potential lifting of their left side. But again due to missing knee and ankle keypoints precise state cannot be predicted.

The torso appears upright with pelvis slightly tilted towards right indicating weight transfer or balance maintenance during lifting action.

The head seems tilted upward which might suggest looking at an object above or preparing for a lift motion.

Their right arm appears extended outwards with elbow joint showing high bend angle suggesting holding or grabbing something perhaps related to loading activity.

Their left arm also seems extended outwards but less than the right one with wrist being higher than elbow possibly supporting holding position of other arm or readying for another task.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      201,
      256
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        211,
        364
      ],
      [
        287,
        346
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        249,
        355
      ],
      [
        224,
        171
      ],
      [
        232.9115,
        147.0199
      ],
      [
        270.0885,
        46.9801
      ],
      [
        270,
        295
      ],
      [
        171,
        316
      ],
      [
        178,
        177
      ],
      [
        270,
        164
      ],
      [
        296,
        247
      ],
      [
        297,
        287
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.20173
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">30</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">009767211.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="24"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in an occupation, specifically truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. The activity involves a lot of physical work and movement.

The person located near the center of the image is captured in mid-action with their limbs positioned for carrying out heavy-duty tasks.

Starting with the legs, their right leg appears to be bent at the knee with the hip joint visible. The right ankle isn't visible in this pose. The left leg seems to be slightly bent at both hip and knee joints while left ankle isn't visible either indicating that they might be standing on uneven ground or stepping on something not captured within frame.

Moving onto their torso region - it's inclined towards right side suggesting they're leaning or reaching out for something. Their pelvis area shows a slight tilt towards right which aligns with overall posture.

Their arms seem to be actively engaged as well; right arm appears slightly bent at elbow joint while wrist joint is aligned straight suggesting holding or lifting action. Left arm seems more flexed than right one with elbow pointing downwards indicating a firm grip on object being handled.

Lastly, their head position suggests attention focused downwards possibly checking footing or inspecting object being handled.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      424,
      298
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        474,
        452
      ],
      [
        560,
        290
      ],
      [
        493,
        322
      ],
      [
        402,
        460
      ],
      [
        -1,
        -1
      ],
      [
        527,
        306
      ],
      [
        416,
        201
      ],
      [
        401.5918,
        197.7582
      ],
      [
        310.4082,
        177.2418
      ],
      [
        467,
        304
      ],
      [
        466,
        271
      ],
      [
        446,
        160
      ],
      [
        385,
        242
      ],
      [
        409,
        357
      ],
      [
        393,
        426
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.803894
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">91</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">068423303.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="25"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is performing occupational tasks related to truck driving, specifically loading and unloading a truck, tying down a load, standing, walking and carrying heavy loads. This activity involves significant physical movement and exertion.

The person centered at coordinates (285.0, 235.0) appears to be in the midst of moving or lifting an object with their left arm extended outward. Their right arm isn't visible within the frame of the image.

As for their legs and lower body, these parts are not visible within this frame either; therefore it's not possible to determine their stance or foot placement.

Their torso is slightly leaning towards the left side indicating some sort of action being performed using their left arm. The angle between their upper neck (keypoint 8) and thorax (keypoint 7), suggests that they are looking straight ahead or possibly downwards at what they're doing.

The head seems to be tilted downward slightly as indicated by the position of upper neck (keypoint 8) compared to head top (keypoint 9). This suggests that they might be focusing on something below their eye level - possibly on a task at hand like tying down load or picking up something heavy.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      285,
      235
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        166,
        305
      ],
      [
        180.5447,
        264.2038
      ],
      [
        233.4553,
        115.7962
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        116,
        321
      ],
      [
        215,
        288
      ],
      [
        295,
        300
      ],
      [
        386,
        302
      ]
    ],
    "kpts_vis": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1
    ],
    "scale": 4.726721
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">298</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">044015249.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="26"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in the activity of truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads. This activity involves a wide range of movements and positions that can be seen through the keypoints.

The person located towards the center-right part of the image is standing with their body slightly turned to their left. 

Their right leg appears to be straight with their right ankle positioned below their right knee which aligns vertically with the hip. The left leg seems to be bending at the knee as indicated by alignment of left hip, knee and ankle.

The person's torso leans slightly forward while maintaining an upright position from pelvis through thorax to upper neck.

Their head is tilted downward as seen from alignment between upper neck and top of head keypoints. 

The right arm appears bent at elbow forming an acute angle with wrist lower than shoulder level indicating possible carrying or lifting action. The left arm also shows similar bend but it's more extended outwards possibly for balance or grasping something.

Overall pose suggests that this individual might be involved in lifting or moving heavy objects typically found during loading/unloading activities in truck driving occupation.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      452,
      261
    ],
    "id": 0,
    "kpts": [
      [
        466,
        365
      ],
      [
        493,
        284
      ],
      [
        518,
        179
      ],
      [
        591,
        163
      ],
      [
        520,
        356
      ],
      [
        509,
        476
      ],
      [
        555,
        171
      ],
      [
        427,
        140
      ],
      [
        416.801,
        136.9332
      ],
      [
        294.199,
        100.0668
      ],
      [
        300,
        293
      ],
      [
        351,
        229
      ],
      [
        378,
        140
      ],
      [
        475,
        139
      ],
      [
        578,
        225
      ],
      [
        520,
        310
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.84075
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">600</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">012203823.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="27"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in occupational activities such as truck driving, loading and unloading a truck, tying down load, standing, walking and carrying heavy loads.

The person located at the center of the image appears to be standing upright with their body slightly turned towards their right. Their right leg seems to be bent at the knee and hip while their left leg seems straight but slightly bent at the hip. The left ankle is not visible which might suggest that it's behind or obscured by something.

Their torso is upright with their pelvis shifted slightly towards their left. The thorax appears to be leaning towards the right indicating a slight twist in the upper body.

The head of this individual is tilted upwards as indicated by relative positions of upper neck and head top keypoints.

As for arms, they are both raised. The right arm seems to be extended outward with a bend at elbow while holding onto something heavy as suggested by activity context. Meanwhile, left arm appears flexed at elbow forming an approximate 90-degree angle with shoulder joint.

Overall, this pose suggests that this person might be in process of lifting or moving heavy objects possibly during loading or unloading a truck.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      116,
      182
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        189,
        473
      ],
      [
        91,
        299
      ],
      [
        39,
        276
      ],
      [
        118,
        467
      ],
      [
        -1,
        -1
      ],
      [
        65,
        288
      ],
      [
        122,
        85
      ],
      [
        132.94,
        76.4196
      ],
      [
        213.06,
        13.5804
      ],
      [
        238,
        291
      ],
      [
        199,
        234
      ],
      [
        158,
        103
      ],
      [
        86,
        67
      ],
      [
        141,
        174
      ],
      [
        183,
        248
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.054701
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">889</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">714</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, truck driving, loading and unloading truck, tying down load, standing, walking and carrying heavy lo</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">049517691.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="28"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are seven people in the image who are participating in synchronized swimming. All of them seem to be executing a similar pose, which is likely part of their routine. Each person's limbs and torso appear to be positioned in a way that suggests they are either moving through water or preparing to dive.

The first person is located towards the left side of the image and appears to be leaning slightly forward with their right leg bent at the knee and extended backward. Their arms are raised above their head, with elbows bent at approximately 90 degrees.

The second individual is situated near the center-left of the image. They also have their right leg extended backward but it seems less bent than that of the first person. Their arms appear straighter as well, extending diagonally upward from their shoulders.

Person three, located at center-middle position, has both legs slightly spread apart with knees slightly bent. This individual's arms seem to be reaching out horizontally on either side, forming an almost straight line perpendicular to their body.

The fourth individual is positioned near center-right and seems to have a similar pose as person three but with legs more spread apart and knees more visibly bent. Their arms also extend outward from shoulders like third person's but appear less straightened.

Person five is found towards far-right center area and displays a unique posture among all individuals - while others' right legs were extended backwards or apart from left leg; this one has both legs close together giving impression they're standing upright underwater possibly supported by toes' contact with pool floor or due buoyancy effect. Arms' positioning resembles those seen in persons two &amp; four.

Moving further rightwards we see sixth swimmer who mirrors fifth one's stance except for slight differences - left arm isn't fully stretched out &amp; there appears some bend at elbow; moreover both feet aren't visible so can't confirm if they're standing like fifth swimmer or floating mid-water while maintaining vertical alignment of body parts.

Finally seventh participant situated extreme far-right does an almost perfect imitation of sixth one's pose barring minor variations - for instance: unlike sixth swimmer whose head was tilted upwards facing skyward direction indicating possible inhalation before submersion; this one looks directly ahead perhaps focusing on synchronizing movements with teammates.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      327,
      208
    ],
    "id": 0,
    "kpts": [
      [
        349,
        393
      ],
      [
        298,
        350
      ],
      [
        318,
        236
      ],
      [
        355,
        231
      ],
      [
        354,
        351
      ],
      [
        363,
        441
      ],
      [
        337,
        234
      ],
      [
        341,
        152
      ],
      [
        338.8426,
        128.0531
      ],
      [
        333.1574,
        64.9469
      ],
      [
        305,
        103
      ],
      [
        275,
        158
      ],
      [
        312,
        145
      ],
      [
        370,
        159
      ],
      [
        377,
        223
      ],
      [
        398,
        276
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.900855
  },
  {
    "center": [
      468,
      306
    ],
    "id": 1,
    "kpts": [
      [
        411,
        397
      ],
      [
        384,
        311
      ],
      [
        457,
        306
      ],
      [
        486,
        315
      ],
      [
        450,
        421
      ],
      [
        480,
        474
      ],
      [
        472,
        311
      ],
      [
        464,
        220
      ],
      [
        461.7728,
        205.2052
      ],
      [
        452.2272,
        141.7948
      ],
      [
        400,
        216
      ],
      [
        406,
        257
      ],
      [
        441,
        213
      ],
      [
        487,
        227
      ],
      [
        442,
        277
      ],
      [
        404,
        320
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.923746
  },
  {
    "center": [
      599,
      334
    ],
    "id": 2,
    "kpts": [
      [
        577,
        467
      ],
      [
        556,
        403
      ],
      [
        624,
        311
      ],
      [
        578,
        313
      ],
      [
        585,
        415
      ],
      [
        608,
        470
      ],
      [
        601,
        312
      ],
      [
        607,
        240
      ],
      [
        604.4911,
        216.9637
      ],
      [
        598.5089,
        162.0363
      ],
      [
        624,
        361
      ],
      [
        630,
        289
      ],
      [
        636,
        238
      ],
      [
        577,
        241
      ],
      [
        547,
        286
      ],
      [
        522,
        329
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.657564
  },
  {
    "center": [
      749,
      315
    ],
    "id": 3,
    "kpts": [
      [
        723,
        485
      ],
      [
        699,
        433
      ],
      [
        756,
        330
      ],
      [
        715,
        333
      ],
      [
        717,
        438
      ],
      [
        736,
        503
      ],
      [
        736,
        332
      ],
      [
        745,
        251
      ],
      [
        745.6255,
        227.4393
      ],
      [
        747.3745,
        161.5607
      ],
      [
        782,
        368
      ],
      [
        778,
        319
      ],
      [
        777,
        253
      ],
      [
        713,
        248
      ],
      [
        680,
        306
      ],
      [
        640,
        355
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.977052
  },
  {
    "center": [
      869,
      305
    ],
    "id": 4,
    "kpts": [
      [
        794,
        490
      ],
      [
        797,
        412
      ],
      [
        805,
        301
      ],
      [
        859,
        294
      ],
      [
        863,
        416
      ],
      [
        857,
        496
      ],
      [
        832,
        298
      ],
      [
        840,
        226
      ],
      [
        842.9392,
        220.4311
      ],
      [
        875.0608,
        159.5689
      ],
      [
        880,
        207
      ],
      [
        851,
        244
      ],
      [
        809,
        222
      ],
      [
        871,
        230
      ],
      [
        871,
        286
      ],
      [
        870,
        335
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.064558
  },
  {
    "center": [
      992,
      356
    ],
    "id": 5,
    "kpts": [
      [
        903,
        519
      ],
      [
        920,
        447
      ],
      [
        941,
        342
      ],
      [
        982,
        351
      ],
      [
        994,
        447
      ],
      [
        993,
        533
      ],
      [
        962,
        347
      ],
      [
        971,
        245
      ],
      [
        972.1366,
        241.7266
      ],
      [
        994.8634,
        176.2734
      ],
      [
        1005,
        221
      ],
      [
        991,
        269
      ],
      [
        946,
        243
      ],
      [
        995,
        246
      ],
      [
        999,
        311
      ],
      [
        1002,
        365
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.0786
  },
  {
    "center": [
      1076,
      317
    ],
    "id": 6,
    "kpts": [
      [
        1032,
        537
      ],
      [
        1043,
        462
      ],
      [
        1050,
        343
      ],
      [
        1098,
        351
      ],
      [
        1115,
        457
      ],
      [
        1116,
        542
      ],
      [
        1074,
        347
      ],
      [
        1076,
        254
      ],
      [
        1077.5291,
        251.6877
      ],
      [
        1115.4709,
        194.3123
      ],
      [
        1124,
        252
      ],
      [
        1104,
        292
      ],
      [
        1047,
        258
      ],
      [
        1104,
        249
      ],
      [
        1107,
        306
      ],
      [
        1109,
        356
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.063581
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">4</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,456</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">7</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">water activities, swimming, synchronized</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">003438852.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">7</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="29"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are three people in the image who are sitting quietly. Given the activity, it can be inferred that their body postures are relaxed, with most of them having their legs and arms bent.

The first person located towards the left side of the image is sitting with their right leg folded up towards their chest. Their right arm appears to be resting on this leg as both the elbow and wrist keypoints align closely with it. The left shoulder is raised slightly higher than the right, suggesting a slight tilt or turn in torso.

The second person situated around center of image has both legs bent at similar angles, possibly indicating they're seated on a flat surface like chair or floor. They have raised their right arm slightly higher than shoulder level while left arm seems to be resting more naturally.

Finally, the third person positioned towards the right side of image is also seated but with only visible data for one leg which appears to be stretched out or leaning against something given its alignment with hip joint. They have both arms bent at elbows where left arm seems to extend forward while right one rests lower down near waist level.

All three individuals' upper bodies appear upright based on thorax and neck keypoints positioning relative to pelvis points. Head position also remains fairly central over torso across all three persons which further suggests an overall relaxed posture during this quiet/light activity.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      191,
      283
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        135,
        404
      ],
      [
        253,
        411
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        194,
        408
      ],
      [
        238,
        210
      ],
      [
        232.8147,
        177.994
      ],
      [
        214.1853,
        63.006
      ],
      [
        136,
        407
      ],
      [
        119,
        331
      ],
      [
        150,
        211
      ],
      [
        326,
        208
      ],
      [
        315,
        364
      ],
      [
        187,
        394
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.494618
  },
  {
    "center": [
      453,
      373
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        308,
        464
      ],
      [
        386,
        395
      ],
      [
        516,
        415
      ],
      [
        344,
        465
      ],
      [
        -1,
        -1
      ],
      [
        451,
        405
      ],
      [
        466,
        231
      ],
      [
        464.3743,
        194.4217
      ],
      [
        459.6257,
        87.5783
      ],
      [
        370,
        399
      ],
      [
        384,
        362
      ],
      [
        394,
        228
      ],
      [
        537,
        234
      ],
      [
        547,
        391
      ],
      [
        412,
        412
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.208469
  },
  {
    "center": [
      733,
      341
    ],
    "id": 2,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        616,
        417
      ],
      [
        742,
        437
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        679,
        427
      ],
      [
        721,
        232
      ],
      [
        706.7914,
        182.4918
      ],
      [
        671.2086,
        58.5082
      ],
      [
        531,
        328
      ],
      [
        603,
        354
      ],
      [
        622,
        227
      ],
      [
        819,
        237
      ],
      [
        820,
        390
      ],
      [
        727,
        410
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.86966
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">877</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">187</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">134</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">inactivity quiet/light, sitting quietly</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">031171108.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="30"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are four people in the image who are participating in synchronized swimming. The activity involves maintaining a coordinated body pose while in water. It requires strength, flexibility, and precision.

The first person is located towards the left side of the image and appears to be moving upwards with their body slightly tilted to the right. Their right leg is bent at the knee and hip, while their left leg seems straighter with a slight bend at knee. Both arms are extended outwards, with elbows slightly bent forming an arc shape. The head is tilted backwards.

The second person is positioned near the center of the image and appears to be floating on water surface with their body oriented upwards. Their legs appear straighter than their arms which are fully extended above their head forming a 'V' shape. The head is also tilted backwards similar to first person.

The third individual can be seen towards right side of center position in an upright pose as if they're rising from water surface or hovering on it. Their legs seem straight whereas arms form an inverted 'V' shape above them similar to second individual's arm position but lower down closer to face level.

Lastly, fourth person can be seen on extreme right side appearing as if they're about to dive into water or just came out from it due its forward tilt orientation compared other individuals who have upward orientation instead. Legs seem semi-bent at knees while arms form a 'U' shape below them indicating possible diving motion or preparation for next move by pushing against water surface for propulsion force.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      159,
      294
    ],
    "id": 0,
    "kpts": [
      [
        110,
        330
      ],
      [
        134,
        338
      ],
      [
        118,
        298
      ],
      [
        144,
        311
      ],
      [
        153,
        338
      ],
      [
        125,
        336
      ],
      [
        131,
        305
      ],
      [
        173,
        296
      ],
      [
        171.63,
        297.2558
      ],
      [
        198.37,
        272.7442
      ],
      [
        107,
        286
      ],
      [
        137,
        272
      ],
      [
        162,
        289
      ],
      [
        184,
        302
      ],
      [
        200,
        321
      ],
      [
        223,
        330
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.088235
  },
  {
    "center": [
      338,
      251
    ],
    "id": 1,
    "kpts": [
      [
        306,
        358
      ],
      [
        331,
        320
      ],
      [
        324,
        260
      ],
      [
        341,
        268
      ],
      [
        351,
        320
      ],
      [
        326,
        355
      ],
      [
        333,
        264
      ],
      [
        363,
        206
      ],
      [
        362.5363,
        205.0436
      ],
      [
        347.4637,
        173.9564
      ],
      [
        352,
        155
      ],
      [
        347,
        180
      ],
      [
        365,
        206
      ],
      [
        361,
        206
      ],
      [
        389,
        176
      ],
      [
        385,
        162
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.036455
  },
  {
    "center": [
      514,
      224
    ],
    "id": 2,
    "kpts": [
      [
        510,
        366
      ],
      [
        499,
        317
      ],
      [
        507,
        267
      ],
      [
        533,
        266
      ],
      [
        525,
        318
      ],
      [
        537,
        365
      ],
      [
        520,
        267
      ],
      [
        509,
        207
      ],
      [
        511.3591,
        213.2908
      ],
      [
        497.6409,
        176.7092
      ],
      [
        466,
        166
      ],
      [
        476,
        188
      ],
      [
        493,
        207
      ],
      [
        524,
        206
      ],
      [
        530,
        175
      ],
      [
        524,
        159
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.172075
  },
  {
    "center": [
      681,
      315
    ],
    "id": 3,
    "kpts": [
      [
        712,
        360
      ],
      [
        682,
        330
      ],
      [
        705,
        312
      ],
      [
        728,
        309
      ],
      [
        702,
        327
      ],
      [
        726,
        356
      ],
      [
        717,
        311
      ],
      [
        680,
        286
      ],
      [
        681.7108,
        288.6613
      ],
      [
        660.2892,
        255.3387
      ],
      [
        643,
        323
      ],
      [
        659,
        309
      ],
      [
        663,
        286
      ],
      [
        696,
        286
      ],
      [
        724,
        296
      ],
      [
        749,
        306
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.188424
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">4</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">187</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">197</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">water activities, swimming, synchronized</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">052006802.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">4</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="31"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is participating in synchronized swimming. This activity typically involves precise and coordinated movements, often with a focus on arm positions and body twists.

The centrally positioned person seems to be floating on water with their body slightly twisted. 

Their right leg is invisible, suggesting it's either submerged or behind the body. The same goes for the left leg.

The torso appears to be twisted as the thorax and pelvis keypoints are not visible. This indicates a possible rotation of the upper body.

Their head is tilted upwards as indicated by the large vertical distance between upper neck and head top keypoints, possibly looking towards the sky or ceiling.

The right arm seems to be fully extended above their head, judging from wrist to elbow keypoint positions relative to shoulder keypoint.

Their left arm appears bent at a sharp angle judging from wrist position relative to elbow and shoulder keypoints, likely performing a specific pose or movement typical in synchronized swimming.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      362,
      181
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        417,
        243
      ],
      [
        417.9901,
        234.5243
      ],
      [
        441.0099,
        37.4757
      ],
      [
        433,
        291
      ],
      [
        233,
        302
      ],
      [
        308,
        234
      ],
      [
        525,
        252
      ],
      [
        733,
        282
      ],
      [
        541,
        301
      ]
    ],
    "kpts_vis": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.951661
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">4</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">187</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">288</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">water activities, swimming, synchronized</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">054671028.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="32"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in home activities, specifically scrubbing floors. This activity typically involves a bent posture, with the person's body close to the floor and their arms actively engaged.

The center-positioned person is likely kneeling or squatting down with their body close to the ground as they scrub the floor. 

Starting with their legs: 
The right leg appears to be folded at the knee and positioned under or behind them, as indicated by keypoint coordinates of right ankle (1087, 973), right knee (657, 915), and right hip (963, 802). The left leg seems to be extended forward or sideways from what can be seen from left hip (1241,812), left knee (1403,909) and left ankle coordinates(1041,910).

Moving on to their torso:
It seems slightly bent forward given that pelvis point (1102,807) is closer vertically to thorax point(1089 ,384) than it would typically be in an upright standing pose.

Their head:
Considering upper neck point(1089 ,301) and head top point(1091 ,26), it appears that they are looking downwards possibly focusing on where they're scrubbing.

Regarding arms:
The right arm appears extended towards ground which might indicate active engagement in scrubbing action. This can be inferred from wrist position at lower height than elbow for both arms - Right wrist(984 ,841), Right elbow(906 ,700), Left wrist(1316 ,555), Left elbow(1271 ,742). The exact direction of arm movement cannot be determined without temporal information but this static pose suggests an ongoing activity involving hands.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1101,
      700
    ],
    "id": 0,
    "kpts": [
      [
        1087,
        973
      ],
      [
        657,
        915
      ],
      [
        963,
        802
      ],
      [
        1241,
        812
      ],
      [
        1403,
        909
      ],
      [
        1041,
        910
      ],
      [
        1102,
        807
      ],
      [
        1089,
        384
      ],
      [
        1089.5645,
        301.2061
      ],
      [
        1091.4355,
        26.7939
      ],
      [
        984,
        841
      ],
      [
        906,
        700
      ],
      [
        908,
        397
      ],
      [
        1270,
        371
      ],
      [
        1271,
        742
      ],
      [
        1316,
        555
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 8.23256
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">868</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,575</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">12</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, scrubbing floors</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">018485446.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="33"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is performing light effort home activities, specifically mopping while standing. This activity involves using both arms, mainly the right arm for holding and maneuvering the mop, with a slight bending of the knees and a firm stance for balance.

The person located at center coordinates (452.0, 226.0) with a scale of 3.535176 is standing upright with their limbs in various positions.

Their left leg seems to be invisible or obscured from view as there are no visible keypoints for the left ankle and knee. The right leg appears to be slightly bent at the knee as suggested by relative positions of right hip (381,327) and right knee (379,472).

The torso appears straight given that thorax (439,142) lies relatively vertically above pelvis point (430,327). 

The head seems to be looking straight ahead or slightly upwards considering upper neck point at (439,134) lies just below head top point at (450,16).

For arms: The right arm appears bent significantly at elbow while holding something - possibly a mop; this can be inferred from relative positions of right wrist (346,323), elbow(343,242), shoulder(378,143). The left arm also seems bent but less than the other one; it may be supporting action of holding mop as suggested by points corresponding to left wrist(514288), elbow(579221), shoulder(500141).</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      452,
      226
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        379,
        472
      ],
      [
        381,
        327
      ],
      [
        479,
        326
      ],
      [
        447,
        470
      ],
      [
        -1,
        -1
      ],
      [
        430,
        327
      ],
      [
        439,
        142
      ],
      [
        439.7055,
        134.1812
      ],
      [
        450.2945,
        16.8188
      ],
      [
        346,
        323
      ],
      [
        343,
        242
      ],
      [
        378,
        143
      ],
      [
        500,
        141
      ],
      [
        579,
        221
      ],
      [
        514,
        288
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.535176
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">27</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">096958463.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="34"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is performing light effort mopping as a home activity. This activity generally involves standing and moving around with a mop, requiring the use of both arms and legs, with occasional bending at the waist.

The centrally positioned person is caught mid-motion while mopping. They are standing upright with their body slightly tilted towards right.

Their right leg seems to be bearing most of their weight, as it's straight and firmly planted on the ground from hip (406, 254) to knee (406, 397) and down to ankle (369, 474). The left leg appears slightly bent at the knee (461, 386), suggesting that they're in mid-step or shifting their balance from hip (471, 252) to ankle (448, 470).

The right arm appears extended but not fully straightened out towards lower-right direction from shoulder (404,97) through elbow (432,193) to wrist(489 ,139). This could be indicative of them holding onto a mop handle. Their left arm is bent at an angle approximately around ninety degrees between shoulder(477 ,100), elbow(496 ,186), and wrist(533 ,246). It might be supporting or balancing out the movement of their right arm.

Their torso is upright but slightly leaning towards right side indicated by alignment from pelvis point(439 ,253 ) up through thorax point(441 ,99 )to upper neck point(446 ,89 ).

Lastly for head positioning; it seems like they are looking downwards given by coordinates between upper neck point(446 ,89 )and top head point position which lies far above on y-axis coordinate at position (492 ,2 ).</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      469,
      204
    ],
    "id": 0,
    "kpts": [
      [
        369,
        474
      ],
      [
        406,
        397
      ],
      [
        406,
        254
      ],
      [
        471,
        252
      ],
      [
        461,
        386
      ],
      [
        448,
        470
      ],
      [
        439,
        253
      ],
      [
        441,
        99
      ],
      [
        446.2789,
        89.1831
      ],
      [
        492.7211,
        2.8169
      ],
      [
        489,
        139
      ],
      [
        432,
        193
      ],
      [
        404,
        97
      ],
      [
        477,
        100
      ],
      [
        496,
        186
      ],
      [
        533,
        246
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.941836
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">91</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">077513282.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="35"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is doing light effort home activities, specifically mopping while standing. The activity involves movement of arms and torso, with legs providing support.

The person located at the center of the image has their body facing slightly to the right. Their left leg appears to be supporting most of their weight, while their right leg is partially obscured or not visible.

Starting from the lower body, their right hip joint is visible but both knee and ankle are not detectable. The left hip joint seems slightly raised compared to the right one, possibly due to a slight bend in that leg but it's hard to confirm as neither knee nor ankle on this side are detectable either.

Moving up towards the torso, it's tilted forward indicating a leaning posture which is common during mopping. This can also be inferred from pelvis and thorax keypoints being closer vertically than horizontally.

The upper body shows more activity - both shoulders are clearly seen with left shoulder being higher than its counterpart indicating an upward arm movement on that side. This can also be confirmed by comparing elbow and wrist positions - left elbow seems bent with wrist positioned near waist level suggesting a grip on mop handle.

On contrary, right arm appears extended downwards with elbow lower than shoulder level and wrist near waist level - possibly holding bottom part of mop stick for support during cleaning motion.

Unfortunately head top isn't visible but considering neck position relative to shoulders we can assume head faced downwards focusing on cleaning task at hand.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      320,
      237
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        282,
        331
      ],
      [
        412,
        360
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        347,
        346
      ],
      [
        369,
        91
      ],
      [
        371,
        104
      ],
      [
        -1,
        -1
      ],
      [
        221,
        126
      ],
      [
        269,
        214
      ],
      [
        293,
        84
      ],
      [
        445,
        98
      ],
      [
        441,
        307
      ],
      [
        266,
        266
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.493876
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">162</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">093949894.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="36"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in home activities, specifically mopping with light effort. The activity involves standing and using upper body strength to move the mop.

The person located near the center of the image appears to be in a slightly leaned forward position, as if they're pushing a mop forward. Their right leg seems to be behind them while their left leg is more forward, suggesting that they are placing most of their weight on their left foot. However, due to missing key points for both knees and ankles, it's difficult to confirm this.

Their right arm looks extended outwards with a slight bend at the elbow which could indicate holding onto a mop handle. The wrist appears lower than the elbow suggesting that they're applying downward pressure on an object like a mop. Meanwhile, their left arm seems raised with more bend at the elbow compared to right arm which indicates that it's supporting top part of mop handle.

Their torso leans forward slightly indicating engagement in an activity such as mopping or sweeping. The head tilts upward slightly from neck possibly focusing on area being cleaned.

Unfortunately without visibility of knees and ankles we can't accurately describe leg positions but based on hip positions we can infer about possible stance during this cleaning activity.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      297,
      216
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        254,
        318
      ],
      [
        357,
        381
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        306,
        350
      ],
      [
        309,
        95
      ],
      [
        310.7676,
        110.3785
      ],
      [
        297.2324,
        -7.3785
      ],
      [
        206,
        226
      ],
      [
        192,
        189
      ],
      [
        231,
        107
      ],
      [
        386,
        83
      ],
      [
        336,
        161
      ],
      [
        188,
        132
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.555971
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">225</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">089482735.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="37"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is mopping. This activity involves standing and performing a light effort task, typically involving the use of one's arms to move the mop and legs to provide stability.

The person centered around coordinates (366.0, 242.0) with a scale of 3.370014 is standing upright with their limbs engaged in cleaning activity.

Their right leg appears straight with the ankle, knee, and hip aligned vertically which provides balance for their stance while mopping. The left leg is slightly bent at the knee suggesting that it bears less weight than the right.

The right arm has a slight bend at elbow while holding onto what could be assumed as mop handle; wrist positioned lower than elbow indicating grip on an object below shoulder level. The left arm appears extended outwards from body possibly maintaining balance or holding another part of mop handle; there's a noticeable bend at elbow with wrist higher than it indicating grip on an object above waist level.

Torso maintains an upright position indicative of stance during light effort tasks like mopping; pelvis slightly tilted towards right side suggesting majority weight bearing on right leg.

Finally, head seems to be facing forward or slightly downwards perhaps focusing on area being cleaned. This can be inferred from positions of upper neck and top of head keypoints which are almost vertically aligned.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      366,
      242
    ],
    "id": 0,
    "kpts": [
      [
        305,
        403
      ],
      [
        313,
        294
      ],
      [
        301,
        202
      ],
      [
        404,
        222
      ],
      [
        386,
        320
      ],
      [
        400,
        412
      ],
      [
        353,
        212
      ],
      [
        356,
        144
      ],
      [
        350.0271,
        116.6241
      ],
      [
        373.9729,
        226.3759
      ],
      [
        265,
        166
      ],
      [
        273,
        107
      ],
      [
        294,
        136
      ],
      [
        418,
        152
      ],
      [
        420,
        282
      ],
      [
        396,
        371
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.370014
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">318</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">059789998.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="38"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is performing home activities, specifically mopping with light effort while standing. This activity typically involves a slightly bent pose with one arm extended holding the mop and legs spaced apart for balance.

The centrally located person is presumably cleaning their surroundings with their mop. Their body appears to be leaning slightly forward, suggesting that they are applying force onto the mop.

The right leg of this individual seems to be straight and firmly planted on the ground from ankle to hip, providing stability. The left leg, however, seems slightly bent at the knee which might be due to shifting weight or movement.

Their right arm appears extended towards the ground indicating that it's holding onto a tool like a mop. There's a slight bend in elbow suggesting an active movement rather than static hold. The left arm also seems engaged but less extended than right one, possibly maintaining balance or aiding in mopping motion.

The torso of this individual leans forward slightly indicating engagement in task at hand. The head position suggests focus on immediate vicinity as if looking at something close by on floor - likely where they're mopping next.

Overall posture suggests an active stance involved in household chores requiring moderate physical effort like mopping.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      382,
      201
    ],
    "id": 0,
    "kpts": [
      [
        447,
        396
      ],
      [
        454,
        275
      ],
      [
        505,
        154
      ],
      [
        615,
        66
      ],
      [
        543,
        347
      ],
      [
        552,
        455
      ],
      [
        560,
        110
      ],
      [
        338,
        155
      ],
      [
        334.4195,
        154.4292
      ],
      [
        203.5805,
        133.5708
      ],
      [
        295,
        243
      ],
      [
        334,
        200
      ],
      [
        317,
        141
      ],
      [
        358,
        169
      ],
      [
        518,
        183
      ],
      [
        518,
        282
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.974736
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">341</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,716</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">382</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, mopping, standing, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">092187424.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="39"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is working as a chambermaid or hotel housekeeper, possibly making a bed, cleaning a bathroom, or pushing a cart. This activity involves various movements such as bending, reaching out and possibly lifting items.

The central person is relatively large scale with their body parts spread across the frame. They seem to be in an active state with multiple limbs engaged in different actions.

Their right leg appears bent at the knee and slightly raised from their hip, indicating that they might be stepping forward or supporting their weight while performing an action. The left leg seems to be straight and stable on the ground providing balance.

The right arm looks extended towards something perhaps holding or reaching out for an object. The left arm appears to be bent at the elbow suggesting it could also be engaged in holding something or performing another task.

Their torso seems inclined forward slightly indicating that they might be leaning into their work. This posture suggests engagement and focus on the task at hand.

Lastly, considering head's position relative to other body parts it appears that they are looking downwards likely focused on what they are doing with their hands.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      273,
      249
    ],
    "id": 0,
    "kpts": [
      [
        240,
        417
      ],
      [
        353,
        356
      ],
      [
        189,
        339
      ],
      [
        249,
        289
      ],
      [
        341,
        268
      ],
      [
        233,
        393
      ],
      [
        219,
        314
      ],
      [
        272,
        187
      ],
      [
        284.4743,
        176.2583
      ],
      [
        367.5257,
        104.7417
      ],
      [
        407,
        345
      ],
      [
        331,
        332
      ],
      [
        270,
        210
      ],
      [
        274,
        163
      ],
      [
        324,
        232
      ],
      [
        380,
        261
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.288
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">148</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">787</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, chambermaid, hotel housekeeper, making bed, cleaning bathroom, pushing cart</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">008849250.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="40"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in home activities, specifically cleaning. This activity involves movements such as bending, reaching out, and possibly squatting or kneeling.

The person located at the center of the image is actively cleaning with their limbs positioned to perform this task. 

Their right leg appears slightly bent at the knee, indicating that they may be shifting their weight or preparing to move. The right ankle is further forward than the hip and knee, suggesting a step forward or a slight lean.

The left leg seems straighter compared to the right leg with both hip and knee aligned vertically. The ankle position suggests that it's bearing most of the body's weight.

For their arms, we see that their right arm appears extended outward with a slight bend at elbow while wrist positioned lower than elbow indicating a reaching out gesture possibly towards an object of interest for cleaning.

Their left arm seems more relaxed compared to their right arm with elbow bent more prominently than on other side and wrist positioned higher than elbow suggesting it might be holding something closer to body or being used for support.

Looking at torso keypoints - pelvis and thorax - we can infer that they are leaning slightly towards right side which aligns well with positioning of rest of body parts in performing cleaning action.

Finally head keypoints - upper neck and head top - are tilted downwards suggesting focus on task being performed by hands.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      348,
      132
    ],
    "id": 0,
    "kpts": [
      [
        413,
        316
      ],
      [
        420,
        268
      ],
      [
        431,
        175
      ],
      [
        432,
        176
      ],
      [
        318,
        197
      ],
      [
        325,
        232
      ],
      [
        432,
        176
      ],
      [
        240,
        42
      ],
      [
        171,
        30
      ],
      [
        63,
        13
      ],
      [
        204,
        109
      ],
      [
        214,
        74
      ],
      [
        231,
        3
      ],
      [
        248,
        80
      ],
      [
        404,
        193
      ],
      [
        282,
        188
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.271139
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">620</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">787</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">82</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">home activities, cleaning, general</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">019598286.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="41"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is working as a chambermaid, possibly tidying up a hotel room or pushing a cart. The activity involves various movements and poses, often requiring bending or kneeling.

The person centered around the coordinates (200.0, 301.0) and scaled at 4.751879 appears to be in action with their limbs engaged in different activities.

Starting with the legs: Their right leg seems to be slightly bent at the knee with their ankle positioned lower than it; suggesting that they might be stepping forward or standing on uneven ground. Their left leg appears to be more bent at the knee compared to their right leg, indicating that they might have weight shifted onto this side.

Moving onto arms: The right arm is stretched out towards something probably indicating that they are reaching for an object or stabilizing themselves against something. The elbow of this arm is higher than wrist and shoulder suggesting an elevated reach while left arm seems folded at elbow which could suggest holding of some object close to body.

Their torso leans slightly towards right side which aligns with position of arms and legs suggesting dynamic movement such as reaching out for something while maintaining balance on uneven surface.

Finally, head appears tilted downwards pointing towards what could potentially be area of focus - perhaps an item being picked up or place where cleaning process is focused.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      200,
      301
    ],
    "id": 0,
    "kpts": [
      [
        175,
        412
      ],
      [
        204,
        247
      ],
      [
        104,
        413
      ],
      [
        18,
        348
      ],
      [
        126,
        240
      ],
      [
        124,
        382
      ],
      [
        61,
        381
      ],
      [
        74,
        261
      ],
      [
        62.9805,
        278.3163
      ],
      [
        148.0195,
        144.6837
      ],
      [
        370,
        284
      ],
      [
        261,
        346
      ],
      [
        119,
        327
      ],
      [
        28,
        194
      ],
      [
        159,
        145
      ],
      [
        268,
        121
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.751879
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">148</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">787</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">144</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, chambermaid, hotel housekeeper, making bed, cleaning bathroom, pushing cart</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">004522729.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="42"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in light yard work, specifically picking flowers or vegetables. This activity involves a good deal of bending over and reaching down, as well as occasional walking or standing.

The centrally-located person is in a slightly bent over position with their limbs oriented towards the ground. 

Starting with the legs, both are slightly bent at the knees indicating that this person is not standing upright but rather leaning forward. The right ankle and knee appear to be directly aligned with each other, suggesting that most weight may be on this leg. The left leg seems to be positioned slightly behind the right one.

Moving onto arms, both arms are extended downwards towards the ground which aligns with picking up objects from ground level. The right arm appears to be more stretched out than left one which could suggest that it's actively engaged in picking something up.

The torso of this individual leans forward from pelvis to thorax creating an angle with vertical axis which further confirms that they're bending over for their task.

Lastly, considering head position relative to upper neck and shoulders suggests they're looking downwards likely focusing on what they're picking up from ground level.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      719,
      298
    ],
    "id": 0,
    "kpts": [
      [
        720,
        638
      ],
      [
        707,
        524
      ],
      [
        684,
        365
      ],
      [
        784,
        366
      ],
      [
        792,
        520
      ],
      [
        797,
        649
      ],
      [
        734,
        366
      ],
      [
        739,
        175
      ],
      [
        737.8234,
        153.0862
      ],
      [
        732.1766,
        47.9138
      ],
      [
        694,
        378
      ],
      [
        659,
        288
      ],
      [
        683,
        176
      ],
      [
        795,
        174
      ],
      [
        803,
        294
      ],
      [
        771,
        377
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.159716
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">513</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">082873751.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="43"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is tending to a garden, implied to be walking or standing while picking up yard items, lightly picking flowers or vegetables. The activity involves bending, reaching and possibly squatting.

The person centered around coordinates (885.0, 379.0) and scaled at 6.245398 is engaging in this activity with their limbs positioned as follows:

Their right leg's hip joint is visible but knee and ankle joints are not visible which could mean that they're obscured by an object or bent towards the camera.
Their left leg seems to be slightly bent at the hip as it's higher than the right hip indicating a lifting or stepping motion.
The pelvis area suggests they might be turned slightly towards their left.

The torso seems upright given the positions of thorax and pelvis keypoints. The upper neck keypoint being close to thorax indicates that their head might be tilted downwards – likely focused on what they are picking up.

Their right arm appears extended with both elbow and wrist lower than shoulder hinting they may be reaching out for something or have just picked something up.
Their left arm appears bent at elbow with wrist higher than elbow suggesting it could be holding onto something like a basket for collecting items.

In terms of head position, considering only neck and top of head keypoints due to lack of facial feature data - it seems like they're looking downwards possibly focusing on what they're doing with their hands.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      885,
      379
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        788,
        577
      ],
      [
        944,
        621
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        866,
        599
      ],
      [
        872,
        293
      ],
      [
        865.7188,
        278.0061
      ],
      [
        785.2812,
        85.9939
      ],
      [
        702,
        533
      ],
      [
        754,
        444
      ],
      [
        768,
        282
      ],
      [
        975,
        303
      ],
      [
        989,
        552
      ],
      [
        980,
        710
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 6.245398
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">513</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">93</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">035675333.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="44"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in gardening, specifically implied walking or standing while picking up yard items, possibly light objects like flowers or vegetables. The activity involves bending down and reaching out with their arms.

The person centered towards the right-middle of the image appears to be reaching downwards with their left arm, possibly to pick something up from the ground. Their right leg seems to be slightly bent at the knee, supporting their weight as they lean over.

The right leg of this person is slightly bent at the knee with foot not visible in this frame. The left leg appears straight and firmly planted on ground providing balance.

Their left arm is extended downwards and slightly forward - indicating they might be reaching for something on ground level. The right arm seems to be hanging relaxed by their side.

Their torso leans forward suggesting a bending motion at waistline. This posture supports idea that they are picking something up from the ground level.

The head position suggests that they are looking down towards what they are reaching for with their left hand.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      611,
      374
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        544,
        624
      ],
      [
        509,
        409
      ],
      [
        624,
        413
      ],
      [
        621,
        628
      ],
      [
        -1,
        -1
      ],
      [
        567,
        411
      ],
      [
        584,
        185
      ],
      [
        581.6629,
        154.7729
      ],
      [
        571.3371,
        21.2271
      ],
      [
        399,
        313
      ],
      [
        490,
        323
      ],
      [
        506,
        190
      ],
      [
        661,
        179
      ],
      [
        647,
        322
      ],
      [
        512,
        294
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.018334
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">513</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">215</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">028093451.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="45"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaging in lawn and garden activities, implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending over to pick items from the ground and some level of arm movement.

The person located towards the left of the image is bending over with their right leg slightly bent. The right knee is positioned lower than the hip indicating a bend. The right arm is extended downwards with a slight bend at the elbow suggesting that they might be reaching for something on the ground. Their head is tilted downwards pointing towards what they are reaching for.

The second person, located more towards the center of image, appears to be standing upright with their right hip visible but knee and ankle not visible which suggests that they may have one foot slightly behind them or out of frame. Their arms are also extended with a noticeable bend at both elbows suggesting an active engagement in an activity such as holding or manipulating something. Their head seems to be tilted downward slightly indicating focus on whatever task they're performing.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      269,
      237
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        233,
        449
      ],
      [
        217,
        316
      ],
      [
        277,
        311
      ],
      [
        279,
        455
      ],
      [
        -1,
        -1
      ],
      [
        247,
        314
      ],
      [
        232,
        198
      ],
      [
        231.0347,
        196.0005
      ],
      [
        190.9653,
        112.9995
      ],
      [
        217,
        138
      ],
      [
        172,
        189
      ],
      [
        198,
        206
      ],
      [
        265,
        190
      ],
      [
        308,
        261
      ],
      [
        287,
        194
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.765004
  },
  {
    "center": [
      386,
      341
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        388,
        450
      ],
      [
        451,
        437
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        420,
        444
      ],
      [
        389,
        295
      ],
      [
        388.2573,
        293.2791
      ],
      [
        348.7427,
        201.7209
      ],
      [
        420,
        290
      ],
      [
        399,
        367
      ],
      [
        348,
        307
      ],
      [
        429,
        282
      ],
      [
        493,
        375
      ],
      [
        509,
        292
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.991636
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,164</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">101</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">098688694.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="46"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are four people in the image who are engaging in lawn and garden activities, implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending over to pick items from the ground and standing upright.

The first person is located at coordinates (319.0, 228.0) with a scale of 2.618971. This person is bending over with their torso leaning forward towards the ground. The right leg is straight while the left leg appears to be slightly bent at the knee. Both arms are extended downwards towards the ground with elbows slightly bent.

The second person is located at coordinates (369.0, 149.0) with a scale of 2.290586.This individual appears to be standing upright with both legs straight and parallel to each other.The arms appear to be held close to their body with elbows slightly bent.

The third person can be found at coordinates (553.0, 192.) with a scale of 2.157465.This individual's pose suggests they may be reaching for something as one arm extends outwards while other keypoints such as ankles and knees remain invisible.

The fourth person can be found at coordinates (452.,175.) on a scale of 1 .978072.They seem to stand erectly.Their right arm seems extended outwards whereas left arm remains close to body.Right knee appears slightly bent whereas left one seems straight.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      319,
      228
    ],
    "id": 0,
    "kpts": [
      [
        248,
        405
      ],
      [
        237,
        322
      ],
      [
        246,
        239
      ],
      [
        322,
        232
      ],
      [
        307,
        340
      ],
      [
        310,
        408
      ],
      [
        284,
        236
      ],
      [
        291,
        103
      ],
      [
        288.3711,
        85.182
      ],
      [
        275.6289,
        -1.182
      ],
      [
        233,
        254
      ],
      [
        235,
        187
      ],
      [
        242,
        109
      ],
      [
        340,
        97
      ],
      [
        359,
        165
      ],
      [
        338,
        223
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.618971
  },
  {
    "center": [
      369,
      149
    ],
    "id": 1,
    "kpts": [
      [
        343,
        322
      ],
      [
        342,
        260
      ],
      [
        341,
        184
      ],
      [
        385,
        184
      ],
      [
        383,
        261
      ],
      [
        381,
        328
      ],
      [
        363,
        184
      ],
      [
        366,
        107
      ],
      [
        364.9148,
        100.6336
      ],
      [
        352.0852,
        25.3664
      ],
      [
        385,
        161
      ],
      [
        333,
        167
      ],
      [
        335,
        109
      ],
      [
        397,
        105
      ],
      [
        408,
        164
      ],
      [
        346,
        157
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.290586
  },
  {
    "center": [
      553,
      192
    ],
    "id": 2,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        487,
        254
      ],
      [
        603,
        256
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        545,
        255
      ],
      [
        560,
        58
      ],
      [
        557.8465,
        53.2497
      ],
      [
        528.1535,
        -12.2497
      ],
      [
        407,
        276
      ],
      [
        462,
        183
      ],
      [
        487,
        67
      ],
      [
        632,
        48
      ],
      [
        639,
        182
      ],
      [
        639,
        302
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.157465
  },
  {
    "center": [
      452,
      175
    ],
    "id": 3,
    "kpts": [
      [
        433,
        370
      ],
      [
        438,
        306
      ],
      [
        448,
        200
      ],
      [
        499,
        200
      ],
      [
        488,
        295
      ],
      [
        485,
        365
      ],
      [
        474,
        200
      ],
      [
        483,
        55
      ],
      [
        482.663,
        54.2261
      ],
      [
        456.337,
        -6.2261
      ],
      [
        434,
        183
      ],
      [
        450,
        131
      ],
      [
        448,
        58
      ],
      [
        518,
        52
      ],
      [
        525,
        129
      ],
      [
        511,
        196
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.978072
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,164</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">277</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">077224477.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">4</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="47"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in lawn and garden activities, specifically implied walking or standing - picking up yard, light, picking flowers or vegetables. The activity involves bending down and reaching out to pick things from the ground, which might involve a slight bend at the hips and knees.

The centered person is at a large scale with their body parts positioned as follows:

Their right leg isn't visible in this dataset. The left leg appears to be slightly bent at the hip, indicating a possible crouch or bend down motion.

The right arm seems to be extended outwards with a noticeable bend at the elbow. This could imply that they're reaching out for something. Their left arm also appears extended but it's unclear if there's any significant bend at the elbow due to lack of data for left wrist.

Their torso leans forward slightly, possibly due to bending down motion involved in their activity. 

The head position suggests they are looking downwards - perhaps towards what they're picking up from the ground.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      454,
      261
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        379,
        327
      ],
      [
        506,
        371
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        443,
        349
      ],
      [
        446,
        135
      ],
      [
        450.0434,
        152.8844
      ],
      [
        415.9566,
        2.1156
      ],
      [
        201,
        280
      ],
      [
        266,
        209
      ],
      [
        367,
        128
      ],
      [
        524,
        141
      ],
      [
        483,
        321
      ],
      [
        339,
        320
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.63722
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,164</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">442</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">019871568.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="48"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are five people in image who are engaging in gardening activities, specifically picking up yard items and possibly picking flowers or vegetables.

The first person is located at the far left of the image and appears to be bending down slightly with their right leg bent and left leg straight. Their right arm is raised at approximately a 45-degree angle, indicating that they might be reaching for something.

The second person, located towards the center-left of the image, is standing upright with both legs slightly bent. They appear to be reaching forward with their right arm while their left arm hangs by their side.

The third person, positioned roughly in the middle of the frame, seems to have most of their body turned away from view. Their visible limbs suggest a slight bend as if leaning or stepping forward.

The fourth individual is found near center-right of the image. They appear to be leaning forward with both arms extended downwards and knees slightly bent - possibly indicating an action such as lifting or digging.

Lastly, an individual on far right has been captured mid-motion which makes it difficult to discern specific limb positions due to several keypoints being invisible. However, judging from available data it can be inferred that they have one arm raised - potentially performing similar tasks as others.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      92,
      258
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        82,
        375
      ],
      [
        74,
        290
      ],
      [
        33,
        277
      ],
      [
        81,
        380
      ],
      [
        -1,
        -1
      ],
      [
        54,
        284
      ],
      [
        66,
        186
      ],
      [
        72,
        173
      ],
      [
        108,
        109
      ],
      [
        105,
        231
      ],
      [
        112,
        263
      ],
      [
        77,
        195
      ],
      [
        54,
        176
      ],
      [
        95,
        226
      ],
      [
        93,
        253
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.215552
  },
  {
    "center": [
      226,
      257
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        215,
        452
      ],
      [
        207,
        352
      ],
      [
        273,
        343
      ],
      [
        287,
        445
      ],
      [
        -1,
        -1
      ],
      [
        240,
        348
      ],
      [
        220,
        173
      ],
      [
        222,
        154
      ],
      [
        233,
        63
      ],
      [
        218,
        312
      ],
      [
        146,
        273
      ],
      [
        162,
        178
      ],
      [
        278,
        168
      ],
      [
        320,
        260
      ],
      [
        305,
        311
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.769063
  },
  {
    "center": [
      325,
      237
    ],
    "id": 2,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        282,
        268
      ],
      [
        327,
        262
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        305,
        265
      ],
      [
        304,
        176
      ],
      [
        304,
        165
      ],
      [
        306,
        95
      ],
      [
        287,
        278
      ],
      [
        276,
        234
      ],
      [
        281,
        178
      ],
      [
        327,
        173
      ],
      [
        331,
        241
      ],
      [
        338,
        276
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.124237
  },
  {
    "center": [
      571,
      363
    ],
    "id": 3,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        496,
        459
      ],
      [
        509,
        378
      ],
      [
        573,
        387
      ],
      [
        551,
        469
      ],
      [
        -1,
        -1
      ],
      [
        541,
        383
      ],
      [
        557,
        252
      ],
      [
        550,
        230
      ],
      [
        522,
        138
      ],
      [
        476,
        344
      ],
      [
        511,
        318
      ],
      [
        522,
        246
      ],
      [
        592,
        257
      ],
      [
        602,
        350
      ],
      [
        549,
        381
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.856101
  },
  {
    "center": [
      500,
      386
    ],
    "id": 4,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        459,
        466
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        512,
        366
      ],
      [
        512,
        348
      ],
      [
        512,
        254
      ],
      [
        462,
        446
      ],
      [
        468,
        416
      ],
      [
        485,
        354
      ],
      [
        539,
        377
      ],
      [
        542,
        449
      ],
      [
        -1,
        -1
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      0
    ],
    "scale": 2.820383
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">11</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,164</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">517</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">lawn and garden, implied walkingstanding - picking up yard, light, picking flowers or vegetables</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">000552212.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">5</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="49"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in image who are engaged in various activities such as sitting, talking in person, on the phone, computer, or text messaging with light effort. The interactions seem casual and relaxed.

The first person is located towards the right side of the image. They appear to be sitting with their body slightly tilted towards their right. Their right leg is bent at the knee and extended forward while their left leg is also bent at the knee but positioned backward. The pelvis and thorax indicate a slight twist in torso suggesting they might be turning to their left side.

Their right arm seems to be resting on a surface or holding an object as it's bent at elbow with wrist positioned lower than elbow. Their left arm appears to be lifted higher than shoulder level possibly holding something up near head level.

The second person is located towards the left side of the image. This individual seems to be seated as well but appears more upright compared to first individual based on position of hips and thorax keypoints. However, visibility of this person's right leg joints are not clear which makes precise pose description difficult for that limb.

Their arms suggest they might also be interacting with an object or a device - perhaps texting or typing - given both wrists being elevated above elbows' height and closer proximity between wrist-elbow-shoulder keypoints indicating bend in arms.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      878,
      464
    ],
    "id": 0,
    "kpts": [
      [
        878,
        680
      ],
      [
        751,
        548
      ],
      [
        932,
        530
      ],
      [
        992,
        550
      ],
      [
        715,
        557
      ],
      [
        752,
        629
      ],
      [
        962,
        540
      ],
      [
        932,
        329
      ],
      [
        918.6941,
        300.9672
      ],
      [
        842.3059,
        140.0328
      ],
      [
        831,
        431
      ],
      [
        894,
        423
      ],
      [
        896,
        321
      ],
      [
        967,
        337
      ],
      [
        1011,
        507
      ],
      [
        860,
        487
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.344299
  },
  {
    "center": [
      345,
      459
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        530,
        582
      ],
      [
        261,
        598
      ],
      [
        349,
        499
      ],
      [
        518,
        530
      ],
      [
        458,
        603
      ],
      [
        305,
        549
      ],
      [
        316,
        314
      ],
      [
        323.844,
        279.5133
      ],
      [
        366.156,
        93.4867
      ],
      [
        432,
        533
      ],
      [
        331,
        511
      ],
      [
        267,
        334
      ],
      [
        364,
        293
      ],
      [
        398,
        436
      ],
      [
        509,
        498
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.723333
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">622</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">315</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">36</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">035846573.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="50"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are partaking in miscellaneous activities such as sitting, talking in person, on the phone, computer use, or text messaging with light effort. The poses suggest a casual and relaxed setting with both individuals engaged in some form of communication.

The first person located towards the right side of the image is seated with their body slightly turned to their left. Their right leg appears to be folded at the knee and drawn up towards their torso while their left leg is bent at the knee pointing outwardly. Unfortunately, both ankles and feet are not visible for further details. Their torso is upright with a slight lean to the left indicating engagement in conversation or activity. The head is tilted downward suggesting focus on something possibly held by their hands.

Their right arm seems to be resting on an elevated surface like a table or desk as indicated by its stretched state from shoulder to wrist. The hand might be interacting with an object like a phone or mouse due to its position relative to other keypoints but it's speculative without clear visibility of fingers' orientation. On contrast, their left arm exhibits more flexibility; it's bent at elbow making an angle slightly less than 90 degrees which suggests that this hand might also be involved in handling some object.

The second person positioned towards center-left of the image appears seated too but facing more directly forward compared to first one. Similar to first person, this individual's legs seem folded at knees but exact pose isn't clear due lack of visible ankles and feet data points.

Their torso leans forward suggesting engagement while head tilts downward indicating concentration on something within hand reach distance which could either be a mobile device or keyboard based on activity context provided.

This individual's arms show interesting dynamics; while right arm extends fully indicating resting flat perhaps over lap or low table surface, left arm bends sharply almost making 90 degree angle at elbow hinting that they're holding something close - maybe a mobile device given nature of activities described earlier.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      761,
      369
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        630,
        632
      ],
      [
        803,
        510
      ],
      [
        938,
        536
      ],
      [
        712,
        625
      ],
      [
        -1,
        -1
      ],
      [
        871,
        523
      ],
      [
        865,
        293
      ],
      [
        863,
        277
      ],
      [
        841,
        99
      ],
      [
        731,
        540
      ],
      [
        749,
        430
      ],
      [
        784,
        281
      ],
      [
        946,
        305
      ],
      [
        989,
        501
      ],
      [
        988,
        649
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.362376
  },
  {
    "center": [
      447,
      481
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        609,
        639
      ],
      [
        303,
        668
      ],
      [
        379,
        603
      ],
      [
        590,
        641
      ],
      [
        -1,
        -1
      ],
      [
        341,
        636
      ],
      [
        308,
        368
      ],
      [
        337,
        292
      ],
      [
        420,
        81
      ],
      [
        376,
        712
      ],
      [
        169,
        636
      ],
      [
        264,
        394
      ],
      [
        351,
        341
      ],
      [
        401,
        499
      ],
      [
        487,
        617
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 6.785
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">622</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">315</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">97</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, sitting, talking in person, on the phone, computer, or text messaging, light effort</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">011586906.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="51"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in miscellaneous activities, standing and talking in person. This activity involves the individual being upright with their torso relatively straight and their arms actively involved in gestures or movements that could be associated with conversation.

The center-positioned person is within a medium close-up range with their body oriented slightly towards the right. Their right leg appears to be supporting most of their weight as indicated by the position of the right hip keypoint, although both legs are not fully visible.

Their torso is straight, as inferred from the alignment of pelvis, thorax, upper neck and head top keypoints. This suggests they are standing upright.

The head seems to be tilted slightly downwards based on relative positions of upper neck and head top keypoints which might indicate that they are looking at something or someone closer to them.

Their right arm appears bent at an angle close to 90 degrees judging from wrist, elbow and shoulder keypoints' coordinates. The hand might be raised for gesturing while talking or holding an object considering its relative position above waist level but below chest level.

The left arm also seems bent but at a larger angle than the right arm - possibly around 120 degrees based on wrist, elbow and shoulder keypoints' arrangement. The left hand's location near waist level suggests it may be resting against their body or holding onto something near waist height.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      355,
      342
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        254,
        459
      ],
      [
        369,
        460
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        312,
        460
      ],
      [
        327,
        241
      ],
      [
        324.6475,
        220.3504
      ],
      [
        311.3525,
        103.6496
      ],
      [
        192,
        331
      ],
      [
        222,
        373
      ],
      [
        249,
        244
      ],
      [
        404,
        237
      ],
      [
        453,
        371
      ],
      [
        412,
        351
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.523671
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">982</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,896</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">8</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, standing, talking in person</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">006355835.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="52"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in miscellaneous activities, standing, and talking in person. This activity involves upright posture with potential arm movements for gesturing during conversation.

The centrally located person is captured at a medium distance with their body oriented slightly towards the right side of the frame. 

Starting from their lower body:
- The right leg of this individual appears to be bent at the knee and hip, as indicated by keypoints 1 and 2. However, the ankle isn't visible.
- The left leg seems to be straight with a slight bend at the knee (keypoint 4), extending from hip (keypoint 3) down to ankle which isn't visible.
 
Moving up to their torso:
- The pelvis (keypoint 6) seems evenly positioned between both hips suggesting an upright stance.
- The thorax (keypoint 7) aligns directly above pelvis indicating a straight back.

Regarding their arms:
- Their right arm appears raised with elbow bend (keypoint 11). Wrist position suggests that hand might be near chest or shoulder level.
- Left arm seems extended outwards from shoulder (keypoint 13), likely bent at elbow joint (keypoint 14). Wrist position suggests that hand might be gesturing while speaking.

Finally, regarding head position:
- Neck appears erect as upper neck point aligns directly above thorax.
- Head top's placement indicates head facing forward or slightly tilted down.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      309,
      222
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        293,
        412
      ],
      [
        278,
        294
      ],
      [
        354,
        306
      ],
      [
        357,
        415
      ],
      [
        -1,
        -1
      ],
      [
        316,
        300
      ],
      [
        316,
        162
      ],
      [
        315.5619,
        160.2475
      ],
      [
        297.4381,
        87.7525
      ],
      [
        246,
        229
      ],
      [
        247,
        255
      ],
      [
        269,
        165
      ],
      [
        362,
        159
      ],
      [
        394,
        241
      ],
      [
        361,
        231
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.241785
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">982</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,896</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">103</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, standing, talking in person</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">031098232.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="53"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaged in miscellaneous activities, standing and talking in person. The general pose suggests a conversation between the two individuals, with both of them standing upright and their arms positioned as if gesturing or expressing themselves.

The first person is located towards the right side of the image. They are standing upright with their body facing slightly to the left. Their right arm is bent at the elbow and raised to shoulder level, suggesting they may be making a gesture or pointing at something. Their left arm appears to be hanging naturally by their side.

Their right leg is visible from hip to ankle while their left leg appears obscured or not visible in this image. The torso is straight and aligned with their head which is tilted slightly downwards as if looking at something below eye level.

The second person is located towards the left side of the image. This individual also appears to be standing upright but facing more directly forward compared to the first person.

Their left arm seems raised and bent at an angle similar to that of first person's right arm - possibly indicating a reciprocal gesture in conversation. The right arm, however, seems more relaxed by their side but slightly away from body perhaps holding an object or making another gesture.

Like first individual, only one leg (in this case it's left) can be seen from hip down while other isn't visible due likely being obscured by angle or clothing. Torso alignment suggests an attentive posture directed towards center-right area where other individual stands; head positioning indicates attention focused roughly same direction - possibly on aforementioned conversational partner.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      444,
      320
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        429,
        413
      ],
      [
        513,
        422
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        471,
        418
      ],
      [
        480,
        275
      ],
      [
        478.8023,
        260.0288
      ],
      [
        471.1977,
        164.9712
      ],
      [
        415,
        418
      ],
      [
        425,
        346
      ],
      [
        435,
        267
      ],
      [
        524,
        283
      ],
      [
        530,
        383
      ],
      [
        505,
        452
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.860836
  },
  {
    "center": [
      195,
      312
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        162,
        438
      ],
      [
        183,
        423
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        173,
        431
      ],
      [
        154,
        228
      ],
      [
        160.6644,
        210.4896
      ],
      [
        198.3356,
        111.5104
      ],
      [
        266,
        276
      ],
      [
        206,
        342
      ],
      [
        128,
        229
      ],
      [
        180,
        227
      ],
      [
        211,
        308
      ],
      [
        260,
        271
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.177169
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">982</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,896</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">190</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, standing, talking in person</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">032518332.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="54"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are engaging in miscellaneous activities, standing, and talking in person. The individuals seem to be engaged in a conversation while maintaining a standing position. 

The first person located around the center of the image is turned slightly to their left side with their right side more visible to us. Their right arm is bent at the elbow and raised towards chest level with their wrist slightly lower than the elbow, possibly gesturing while speaking. The left arm seems to be relaxed by their side but not fully visible due to angle of body orientation. As for legs, they are standing straight but only right hip is visible and other leg joints aren't seen due to occlusion or body orientation.

The second person located towards the left of the image has a more frontal pose compared to first one. This individual's head is titled slightly downward with top part clearly seen from this perspective. Their torso appears straight, indicating an upright posture while standing. Both arms are bent at elbows: right arm raised higher than left one where wrist ends up being approximately at waist level; on contrary, left arm's wrist reaches almost down till hip level which could suggest it being rested or placed on some surface unseen in data representation here.

For lower body part: both knees are bent suggesting that feet might be apart providing balance during interaction; however only left ankle joint isn't visible so actual foot position remains uncertain.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      400,
      283
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        344,
        382
      ],
      [
        447,
        392
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        396,
        387
      ],
      [
        403,
        197
      ],
      [
        401.1966,
        180.3537
      ],
      [
        391.8034,
        93.6463
      ],
      [
        293,
        379
      ],
      [
        320,
        299
      ],
      [
        345,
        202
      ],
      [
        461,
        191
      ],
      [
        506,
        299
      ],
      [
        443,
        290
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.61644
  },
  {
    "center": [
      122,
      279
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        128,
        453
      ],
      [
        99,
        338
      ],
      [
        160,
        333
      ],
      [
        179,
        452
      ],
      [
        -1,
        -1
      ],
      [
        130,
        336
      ],
      [
        119,
        225
      ],
      [
        117.7788,
        219.6008
      ],
      [
        101.2212,
        146.3992
      ],
      [
        75,
        263
      ],
      [
        54,
        292
      ],
      [
        81,
        226
      ],
      [
        157,
        224
      ],
      [
        186,
        289
      ],
      [
        192,
        347
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.251527
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">982</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,896</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">449</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">miscellaneous, standing, talking in person</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">063755747.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="55"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are seven people in the image who are playing lawn bowling, bocce ball, or some other outdoor sport. They all appear to be in various stages of play, with some preparing to throw their balls and others observing.

The first person is located towards the left-middle of the image. They seem to be in a throwing position with their right arm extended forward and slightly bent at the elbow. Their left arm is also bent at the elbow but is positioned more towards their body. Both legs appear straight with their right leg slightly behind them and left leg forward.

The second person is on the far-left side of the image. They seem to be standing upright watching others play, as both arms are hanging down by their sides and both legs are straight.

The third person can be found slightly right from center of the image. This individual appears to have just thrown a ball as they're leaning forward with both arms pointing towards where they were aiming, while keeping legs straight for balance.

The fourth person is located near middle-right side of picture. Their posture suggests that they might have just finished a throw; one arm seems extended outwards while other one hangs by side, and legs look fairly relaxed but still apart for stability.

In top-right part we find fifth player who appears ready for action: right arm seems drawn back possibly holding a ball while left hand points ahead likely targeting spot; knees look slightly bent indicating preparation for movement.

Moving further right we see sixth participant who's probably observing game: hands rest casually near waistline while feet stand firmly apart providing solid base; head tilts downwards as if focusing on something below them - perhaps watching trajectory of thrown ball?

Finally seventh player - furthest on right - stands tall like an observer too: arms relaxed by sides suggest passive stance currently not involved in active play; body leans little backwards implying comfortability on field rather than readiness for quick movements.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      205,
      237
    ],
    "id": 0,
    "kpts": [
      [
        218,
        383
      ],
      [
        204,
        314
      ],
      [
        191,
        241
      ],
      [
        236,
        238
      ],
      [
        239,
        313
      ],
      [
        257,
        380
      ],
      [
        214,
        240
      ],
      [
        198,
        146
      ],
      [
        194.1776,
        131.5792
      ],
      [
        179.8224,
        77.4208
      ],
      [
        209,
        216
      ],
      [
        175,
        203
      ],
      [
        166,
        153
      ],
      [
        229,
        138
      ],
      [
        249,
        190
      ],
      [
        234,
        218
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.680857
  },
  {
    "center": [
      29,
      306
    ],
    "id": 1,
    "kpts": [
      [
        33,
        380
      ],
      [
        41,
        402
      ],
      [
        34,
        341
      ],
      [
        72,
        329
      ],
      [
        61,
        349
      ],
      [
        68,
        398
      ],
      [
        53,
        335
      ],
      [
        45,
        278
      ],
      [
        43.7956,
        269.569
      ],
      [
        37.2044,
        223.431
      ],
      [
        23,
        324
      ],
      [
        21,
        306
      ],
      [
        22,
        281
      ],
      [
        68,
        275
      ],
      [
        80,
        313
      ],
      [
        85,
        347
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.398193
  },
  {
    "center": [
      282,
      237
    ],
    "id": 2,
    "kpts": [
      [
        293,
        375
      ],
      [
        295,
        322
      ],
      [
        293,
        269
      ],
      [
        345,
        255
      ],
      [
        320,
        317
      ],
      [
        321,
        390
      ],
      [
        319,
        262
      ],
      [
        305,
        206
      ],
      [
        311.5009,
        215.9062
      ],
      [
        277.4991,
        164.0938
      ],
      [
        271,
        256
      ],
      [
        268,
        230
      ],
      [
        270,
        208
      ],
      [
        340,
        204
      ],
      [
        354,
        241
      ],
      [
        333,
        286
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.859187
  },
  {
    "center": [
      441,
      278
    ],
    "id": 3,
    "kpts": [
      [
        409,
        380
      ],
      [
        418,
        321
      ],
      [
        417,
        262
      ],
      [
        463,
        252
      ],
      [
        455,
        317
      ],
      [
        452,
        399
      ],
      [
        440,
        257
      ],
      [
        405,
        203
      ],
      [
        412.1101,
        212.9542
      ],
      [
        377.8899,
        165.0458
      ],
      [
        381,
        314
      ],
      [
        385,
        259
      ],
      [
        372,
        216
      ],
      [
        438,
        189
      ],
      [
        472,
        238
      ],
      [
        451,
        287
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.766243
  },
  {
    "center": [
      556,
      221
    ],
    "id": 4,
    "kpts": [
      [
        532,
        390
      ],
      [
        533,
        323
      ],
      [
        532,
        257
      ],
      [
        586,
        250
      ],
      [
        592,
        321
      ],
      [
        597,
        388
      ],
      [
        559,
        254
      ],
      [
        551,
        155
      ],
      [
        551.0621,
        157.8582
      ],
      [
        549.9379,
        106.1418
      ],
      [
        517,
        255
      ],
      [
        502,
        209
      ],
      [
        514,
        159
      ],
      [
        588,
        150
      ],
      [
        614,
        209
      ],
      [
        593,
        252
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.551856
  },
  {
    "center": [
      695,
      217
    ],
    "id": 5,
    "kpts": [
      [
        642,
        383
      ],
      [
        656,
        312
      ],
      [
        667,
        225
      ],
      [
        731,
        224
      ],
      [
        731,
        314
      ],
      [
        723,
        384
      ],
      [
        699,
        225
      ],
      [
        699,
        138
      ],
      [
        699.2891,
        140.65
      ],
      [
        692.7109,
        80.35
      ],
      [
        645,
        223
      ],
      [
        636,
        179
      ],
      [
        662,
        139
      ],
      [
        736,
        136
      ],
      [
        761,
        174
      ],
      [
        750,
        213
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.819732
  },
  {
    "center": [
      791,
      216
    ],
    "id": 6,
    "kpts": [
      [
        798,
        387
      ],
      [
        788,
        314
      ],
      [
        779,
        225
      ],
      [
        832,
        226
      ],
      [
        833,
        310
      ],
      [
        837,
        385
      ],
      [
        806,
        226
      ],
      [
        810,
        138
      ],
      [
        809.6645,
        128.6056
      ],
      [
        807.3355,
        63.3944
      ],
      [
        771,
        232
      ],
      [
        771,
        183
      ],
      [
        777,
        138
      ],
      [
        843,
        138
      ],
      [
        849,
        189
      ],
      [
        847,
        238
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.957582
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">12</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">100</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">38</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, lawn bowling, bocce ball, outdoor</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">088721274.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">7</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="56"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are three people in the image who are participating in outdoor sports, specifically lawn bowling or bocce ball. Their poses suggest that they're in various stages of the game. 

The person at the left side of the image is preparing to throw a ball with their right hand. Their right shoulder and elbow are bent, indicating a pre-throw stance. The right hip is slightly raised compared to left one, suggesting a shift of weight on left leg for balance.

The person at the center of the image appears to be observing or waiting for their turn. They're standing upright with both arms slightly bent at elbows and relaxed by their sides.

The person on the right side of the image seems to be in mid-action, possibly having just thrown a ball or about to do so. Their right knee is bent while left leg seems straight supporting body weight, suggesting dynamic movement happening. The arms seem outstretched towards front with palms facing downward as if they've just released something from their hands.

In general, all three individuals have their heads turned towards what could likely be where action is happening – possibly watching trajectory of balls being thrown.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      237,
      217
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        173,
        424
      ],
      [
        287,
        396
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        230,
        410
      ],
      [
        175,
        163
      ],
      [
        180.8747,
        151.8237
      ],
      [
        251.1253,
        18.1763
      ],
      [
        258,
        344
      ],
      [
        101,
        330
      ],
      [
        108,
        171
      ],
      [
        241,
        155
      ],
      [
        279,
        269
      ],
      [
        299,
        321
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.529583
  },
  {
    "center": [
      441,
      284
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        433,
        390
      ],
      [
        552,
        372
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        493,
        381
      ],
      [
        480,
        195
      ],
      [
        480.9821,
        186.1607
      ],
      [
        493.0179,
        77.8393
      ],
      [
        432,
        348
      ],
      [
        387,
        299
      ],
      [
        410,
        199
      ],
      [
        550,
        190
      ],
      [
        576,
        290
      ],
      [
        511,
        310
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.269642
  },
  {
    "center": [
      727,
      359
    ],
    "id": 2,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        743,
        461
      ],
      [
        739,
        388
      ],
      [
        810,
        397
      ],
      [
        795,
        463
      ],
      [
        -1,
        -1
      ],
      [
        775,
        393
      ],
      [
        763,
        291
      ],
      [
        765.7537,
        297.5734
      ],
      [
        729.2463,
        210.4266
      ],
      [
        720,
        361
      ],
      [
        719,
        334
      ],
      [
        722,
        292
      ],
      [
        803,
        290
      ],
      [
        830,
        346
      ],
      [
        832,
        398
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.834541
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">12</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">100</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">202</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, lawn bowling, bocce ball, outdoor</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">011959425.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="57"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are participating in religious activities, serving food in church. The activities involve a lot of movement and interaction, with both individuals engaging in different tasks.

The person on the right is standing with their body slightly turned to their left. Their left leg is visible with the hip, knee and ankle aligned vertically. The right leg isn't visible which suggests that it might be behind the left leg or obscured from view. Their torso is upright but not visible above waist level which implies they may be behind a counter or table. The right arm is extended forward at shoulder height, possibly reaching for something or someone while their left arm appears to be bent at the elbow and raised slightly above waist level.

The person on the left appears to be bending over slightly as indicated by their hip keypoints being higher than those of their shoulders. Both legs aren't fully visible suggesting they might be kneeling or bending one knee significantly more than other people around them would typically do while standing up straight. They seem to have both arms extended towards each other at chest level possibly holding onto something between them like a tray of food items for distribution during this religious activity event.

In general, these poses suggest active involvement and engagement in serving food during religious activities within a church setting.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1343,
      576
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        1822,
        1071
      ],
      [
        1648,
        547
      ],
      [
        1641,
        461
      ],
      [
        1634,
        98
      ],
      [
        1632,
        1072
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        1898,
        556
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        1390,
        509
      ],
      [
        1027,
        563
      ],
      [
        827,
        460
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      0,
      0,
      0,
      1,
      0,
      0,
      1,
      1,
      1
    ],
    "scale": 11.813901
  },
  {
    "center": [
      292,
      339
    ],
    "id": 1,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        132,
        883
      ],
      [
        172,
        849
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        152,
        866
      ],
      [
        64,
        410
      ],
      [
        71,
        364
      ],
      [
        121,
        39
      ],
      [
        454,
        364
      ],
      [
        320,
        603
      ],
      [
        32,
        443
      ],
      [
        95,
        376
      ],
      [
        250,
        365
      ],
      [
        415,
        204
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 9.885233
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">13</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,793</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">154</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">religious activities, serving food in church</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">056127720.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="58"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is serving food in a church. This religious activity typically involves standing, bending, and reaching as individuals serve food to others.

The centrally located person appears to be in the middle of serving with their right arm extended. 

Their left leg and right leg are not visible in this image, which could suggest that they are standing behind a counter or table.

Their torso seems to be slightly leaning forward, as indicated by the position of thorax keypoint relative to pelvis keypoint which is not visible but can be inferred from other keypoints. This posture might indicate that they are reaching out or bending over slightly to serve food.

Their right arm appears to be extended outwards with some bend at the elbow. The wrist is lower than the shoulder suggesting an angle of less than 90 degrees at the elbow joint indicating a reach-out action possibly towards someone or something like a dish or tray.

The left arm also seems bent at the elbow with wrist higher than shoulder indicating an angle more than 90 degrees at elbow joint suggesting that it may be holding something closer towards their body.

The head position suggests that they are looking down which aligns with their current activity of serving food where one would typically look downwards towards plates and dishes.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1257,
      297
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        1232,
        288
      ],
      [
        1236.1271,
        311.7755
      ],
      [
        1181.8729,
        -0.77553
      ],
      [
        692,
        464
      ],
      [
        902,
        417
      ],
      [
        1059,
        247
      ],
      [
        1405,
        329
      ],
      [
        1498,
        613
      ],
      [
        1303,
        562
      ]
    ],
    "kpts_vis": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 9.516749
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">13</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,793</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">224</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">religious activities, serving food in church</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">077096718.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="59"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in the image who are participating in winter activities, specifically downhill skiing. The pose of these individuals suggests dynamic movement as seen in skiing, with bent knees and leaning torsos. 

The person located towards the left side of the image is in a typical downhill skiing position with their limbs oriented for balance and control. Their right leg is slightly bent at the knee and extended behind them while their left leg is also bent but more forward pointing than the right one, suggesting a turning motion. Their torso leans forward from pelvis to thorax, indicating momentum. The head is held straight above the upper neck, looking ahead.

Their right arm extends out to their side with a slight bend at elbow while their left arm appears to be more inwardly positioned with a noticeable bend at elbow - possibly due to holding ski poles not visible in this 2D perspective.

The second person towards the right side of image also exhibits a similar pose that's characteristic for downhill skiers. Both legs are noticeably bent at knees but unlike first individual, they appear symmetrically positioned relative to each other which might suggest that this person is moving straight down hill rather than making a turn.

Their torso leans forward significantly from pelvis through thorax up till upper neck creating an almost linear alignment suggesting speed or aggressive stance on skis. Unlike first individual though, this person's head appears slightly tilted downward rather than looking straight ahead.

Both arms extend outwards away from body maintaining almost equal distance throughout - from shoulders through elbows till wrists which could be indicative of maintaining balance during fast paced movement.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      633,
      371
    ],
    "id": 0,
    "kpts": [
      [
        674,
        492
      ],
      [
        671,
        427
      ],
      [
        673,
        370
      ],
      [
        628,
        362
      ],
      [
        617,
        422
      ],
      [
        603,
        480
      ],
      [
        651,
        366
      ],
      [
        663,
        277
      ],
      [
        663.2685,
        266.6642
      ],
      [
        664.7315,
        210.3358
      ],
      [
        697,
        367
      ],
      [
        696,
        329
      ],
      [
        693,
        281
      ],
      [
        633,
        273
      ],
      [
        619,
        322
      ],
      [
        606,
        357
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.690425
  },
  {
    "center": [
      775,
      350
    ],
    "id": 1,
    "kpts": [
      [
        769,
        461
      ],
      [
        779,
        416
      ],
      [
        804,
        361
      ],
      [
        770,
        358
      ],
      [
        754,
        408
      ],
      [
        737,
        456
      ],
      [
        787,
        360
      ],
      [
        798,
        296
      ],
      [
        796.8957,
        287.4414
      ],
      [
        791.1043,
        242.5586
      ],
      [
        772,
        276
      ],
      [
        801,
        282
      ],
      [
        818,
        292
      ],
      [
        778,
        300
      ],
      [
        741,
        296
      ],
      [
        707,
        291
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.357645
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,331</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">042754102.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="60"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is skiing downhill. This activity typically involves a forward lean of the body, knees bent and arms out to maintain balance.

The centered person is relatively large in scale with their limbs positioned for downhill skiing. 

Starting with the legs, their right leg appears slightly bent at the knee and hip, indicating a semi-crouched position typical for downhill skiing. The left leg mirrors this position, maintaining balance and control during descent.

Moving onto their arms, the right arm seems to be extended outward slightly behind them likely holding a ski pole. Similarly, the left arm also appears to be extended outward but more towards their front which could suggest they are mid-motion or adjusting direction.

Their torso leans forward suggesting momentum and speed as they descend down the slope. 

Lastly, their head appears upright with relation to upper neck suggesting that they are looking ahead possibly scanning terrain or deciding on direction of travel.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      291,
      326
    ],
    "id": 0,
    "kpts": [
      [
        366,
        358
      ],
      [
        363,
        241
      ],
      [
        335,
        358
      ],
      [
        245,
        359
      ],
      [
        291,
        335
      ],
      [
        354,
        271
      ],
      [
        290,
        359
      ],
      [
        282,
        231
      ],
      [
        285.6428,
        211.9453
      ],
      [
        304.3572,
        114.0547
      ],
      [
        441,
        376
      ],
      [
        384,
        329
      ],
      [
        337,
        246
      ],
      [
        226,
        215
      ],
      [
        196,
        291
      ],
      [
        215,
        359
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.989903
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,331</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">63</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">002541913.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="61"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is skiing downhill. The activity involves a lot of lower body movement, with the knees and ankles bending to absorb shocks and navigate turns.

The center person is in an active state with their limbs positioned for downhill skiing.

Starting with the legs, their right leg appears to be bent at the knee and hip, suggesting a forward leaning posture typical of downhill skiing. The right ankle seems to be slightly flexed as well. Similarly, their left leg also appears bent at the knee and hip but to a lesser extent than the right. 

Moving onto arms, their right arm seems extended outwards with a slight bend at the elbow which could be holding ski poles for balance and navigation during skiing. Their left arm also appears extended outwards but more so than the right arm - perhaps they are mid-motion or preparing for a turn.

Their torso leans forward slightly aligning itself with gravity's pull down slope - this helps skiers maintain control while speeding down hills.

Lastly, their head faces straight ahead indicating focus on path ahead - an essential aspect of safe downhill skiing.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      313,
      240
    ],
    "id": 0,
    "kpts": [
      [
        382,
        521
      ],
      [
        365,
        400
      ],
      [
        318,
        304
      ],
      [
        251,
        308
      ],
      [
        311,
        383
      ],
      [
        322,
        467
      ],
      [
        285,
        306
      ],
      [
        303,
        163
      ],
      [
        303.3578,
        161.5348
      ],
      [
        323.6422,
        78.4652
      ],
      [
        432,
        280
      ],
      [
        382,
        238
      ],
      [
        339,
        164
      ],
      [
        267,
        162
      ],
      [
        262,
        239
      ],
      [
        303,
        274
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.565307
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,331</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">132</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">010789143.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="62"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically downhill skiing. The skier's pose suggests a dynamic movement typically seen during a downhill ski run.

The center of the image features this person, appearing quite large due to their close proximity to the camera. They are leaning forward with their body tilted towards the right side of frame.

Starting with their legs:
- The right leg is bent at an angle, with the knee positioned ahead of the hip and ankle. The knee seems to be bearing most of body weight.
- Similar to the right leg, left leg is also bent but it's slightly behind compared to right leg indicating a push-off position common in skiing.

Moving on to arms:
- Their right arm is extended forward and slightly towards left from viewer’s perspective, suggesting that they might be holding onto ski poles.
- Similarly, left arm appears extended but it's angled more downwards than right arm.

As for torso and head:
- The torso leans forward significantly as if preparing for or currently executing a swift move down hill.
- Head faces straight ahead which suggests that skier has their eyes on path ahead.

Overall, this pose captures an intense moment mid-action during downhill skiing.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      257,
      306
    ],
    "id": 0,
    "kpts": [
      [
        288,
        688
      ],
      [
        274,
        555
      ],
      [
        181,
        430
      ],
      [
        129,
        429
      ],
      [
        205,
        547
      ],
      [
        213,
        652
      ],
      [
        155,
        430
      ],
      [
        180,
        153
      ],
      [
        196.509,
        129.1181
      ],
      [
        266.491,
        27.8819
      ],
      [
        262,
        350
      ],
      [
        226,
        323
      ],
      [
        214,
        171
      ],
      [
        146,
        134
      ],
      [
        201,
        267
      ],
      [
        250,
        335
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.692102
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,331</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">196</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">003142919.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="63"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are two people in image who are engaging in winter activities, specifically downhill skiing. The keypoint data indicates that both individuals are likely in the midst of active movement, possibly mid-stride or during a turn based on the positions of their limbs and body.

The person at the center-right of the image is actively skiing with their limbs positioned for balance and control. Their right leg is slightly bent at the knee and hip, suggesting forward momentum. The left leg mirrors this position, indicating that they might be mid-stride or initiating a turn. Both arms appear to be held out to either side for balance, with slight bends at each elbow.

The person located towards the center-left of the image appears to also be actively skiing but might be leaning into a sharper turn based on their pose. Their right leg is significantly bent at both hip and knee while their left leg maintains a straighter alignment. This could suggest an aggressive carving motion or tight turn being executed by this skier. Both arms are held out from their body similarly to the first individual, likely for stability during this maneuver.

In both cases, it's worth noting that due to active movement in downhill skiing which typically involves rapid shifts in weight distribution and balance adjustment, these poses may not represent static states but rather snapshots within dynamic actions.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      651,
      242
    ],
    "id": 0,
    "kpts": [
      [
        630,
        287
      ],
      [
        639,
        265
      ],
      [
        645,
        238
      ],
      [
        664,
        239
      ],
      [
        658,
        266
      ],
      [
        649,
        291
      ],
      [
        655,
        239
      ],
      [
        662,
        202
      ],
      [
        662.1424,
        199.793
      ],
      [
        663.8576,
        173.207
      ],
      [
        636,
        236
      ],
      [
        640,
        219
      ],
      [
        647,
        200
      ],
      [
        677,
        203
      ],
      [
        677,
        216
      ],
      [
        675,
        227
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 0.79924
  },
  {
    "center": [
      241,
      252
    ],
    "id": 1,
    "kpts": [
      [
        239,
        351
      ],
      [
        242,
        296
      ],
      [
        216,
        246
      ],
      [
        180,
        244
      ],
      [
        212,
        294
      ],
      [
        221,
        347
      ],
      [
        198,
        245
      ],
      [
        222,
        200
      ],
      [
        222.6442,
        199.1337
      ],
      [
        250.3558,
        161.8663
      ],
      [
        234,
        265
      ],
      [
        241,
        249
      ],
      [
        240,
        201
      ],
      [
        203,
        198
      ],
      [
        211,
        230
      ],
      [
        221,
        253
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.393241
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,331</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">266</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">063641041.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="64"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically cross-country skiing. The keypoint data suggests that the person is captured mid-action, with their body leaning forward and limbs positioned for propelling themselves forward.

The centrally-located person is standing upright with their body slightly tilted forward. This posture indicates a dynamic movement often observed in cross-country skiing.

Starting from the lower body, both legs are bent at the knees suggesting a semi-crouched position typical of this activity. The right leg appears to be slightly behind relative to the left leg, possibly indicating a stride or push-off motion.

Moving on to the upper body, both arms are extended outwards but not fully straightened. The right arm seems to be positioned slightly ahead compared to the left arm, which could indicate an alternating arm swing action common in cross-country skiing.

The torso appears inclined forward from pelvis towards thorax and neck areas suggesting a hunched over pose that skiers adopt for better balance and propulsion. 

Lastly, observing head keypoints - upper neck and head top - it can be inferred that they are keeping their head down as part of maintaining this overall posture for efficient movement during skiing.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      862,
      426
    ],
    "id": 0,
    "kpts": [
      [
        873,
        526
      ],
      [
        873,
        485
      ],
      [
        874,
        427
      ],
      [
        844,
        426
      ],
      [
        845,
        482
      ],
      [
        844,
        526
      ],
      [
        859,
        427
      ],
      [
        858,
        376
      ],
      [
        857.328,
        367.7677
      ],
      [
        854.672,
        335.2323
      ],
      [
        891,
        440
      ],
      [
        895,
        416
      ],
      [
        881,
        374
      ],
      [
        834,
        377
      ],
      [
        824,
        413
      ],
      [
        823,
        443
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 0.979306
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">14</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">706</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">10</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, cross-country</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">031435598.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="65"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is participating in winter activities, specifically cross-country skiing. This activity typically involves a forward-leaning posture with arms and legs moving alternately.

The central person is large-scale and centered towards the right side of the image. They are captured mid-action, seemingly pushing off with their poles to gain momentum.

Starting from their lower body, the right leg appears extended backwards with a slight bend at the knee, indicating a push-off motion typical in skiing. The right ankle is not visible suggesting that it might be obscured by snow or ski equipment. The left leg seems to be bent at the knee and hip, positioned slightly forward as if preparing for the next stride.

Moving on to their upper body, both arms appear extended outwards as if gripping ski poles for balance and propulsion. The right arm is slightly bent at elbow whereas left arm appears straighter pointing downwards; this asymmetry suggests an alternate poling action common in cross-country skiing.

As for their torso and head region: they are leaning forward from pelvis up through thorax to upper neck - a typical pose when trying to maintain balance during such winter activities. Their head top seems lowered possibly focusing on terrain ahead or maintaining stability during movement.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      770,
      714
    ],
    "id": 0,
    "kpts": [
      [
        933,
        1074
      ],
      [
        897,
        968
      ],
      [
        863,
        773
      ],
      [
        746,
        794
      ],
      [
        762,
        1015
      ],
      [
        -1,
        -1
      ],
      [
        805,
        784
      ],
      [
        774,
        609
      ],
      [
        772.0811,
        595.1415
      ],
      [
        757.9189,
        492.8585
      ],
      [
        781,
        670
      ],
      [
        827,
        644
      ],
      [
        837,
        603
      ],
      [
        711,
        614
      ],
      [
        670,
        682
      ],
      [
        707,
        629
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.097767
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">14</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">706</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">78</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, cross-country</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">050857069.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="66"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is skiing downhill. The sport of downhill skiing involves a dynamic body pose, typically with the skier leaning forward, knees bent, and arms outstretched for balance.

The person in the center of the image is engaged in this activity. Their body orientation suggests they are moving swiftly down a slope.

Starting with their legs:
- The right leg appears to be slightly bent at the knee and hip, suggesting a semi-flexed position common in downhill skiing.
- The left leg mirrors this posture but seems to be more extended at the knee and hip joints.
- Both ankles seem to be flexed as well, indicating that they are applying pressure on their ski boots for control.

Moving onto their torso:
- The pelvis and thorax appear to be leaning forward - a typical posture for gaining speed while skiing.
- Their upper neck shows an upright position aligning with their torso's inclination; it suggests they're looking ahead on their path.

Lastly, considering their arms:
- Their right arm appears extended towards front-right direction from shoulder joint while elbow seems slightly bent
- Similarly, left arm also shows an extended position towards front-left direction from shoulder joint but elbow here looks more flexed than its counterpart.
 
This overall body posture indicates that they are actively engaged in downhill skiing.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1382,
      434
    ],
    "id": 0,
    "kpts": [
      [
        1437,
        624
      ],
      [
        1381,
        547
      ],
      [
        1319,
        455
      ],
      [
        1395,
        428
      ],
      [
        1452,
        533
      ],
      [
        1499,
        620
      ],
      [
        1357,
        442
      ],
      [
        1331,
        311
      ],
      [
        1331.574,
        321.475
      ],
      [
        1326.426,
        227.525
      ],
      [
        1225,
        402
      ],
      [
        1232,
        374
      ],
      [
        1268,
        318
      ],
      [
        1393,
        304
      ],
      [
        1442,
        332
      ],
      [
        1496,
        358
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.822731
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">661</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">090756647.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="67"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is participating in winter activities, specifically downhill skiing. The person appears to be captured mid-motion, possibly during a high-speed descent or a turn maneuver.

The center of the frame person is engaged in an intense activity with their limbs positioned for balance and control. 

Their right leg seems to be slightly bent at the knee and hip, while their left leg appears more flexed at both joints. This could suggest that they are leaning into a turn or adjusting their weight distribution for stability.

The right arm is bent at the elbow and extended outwards from the body, likely helping maintain balance during movement. The left arm also appears to be bent at the elbow but drawn closer towards the body compared to the right arm.

Their torso leans forward slightly indicating speed and control while skiing downhill. This posture aids in reducing air resistance and maintaining balance over skis.

Lastly, their head seems to be facing straight ahead suggesting focus on their path down slope.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      588,
      633
    ],
    "id": 0,
    "kpts": [
      [
        230,
        930
      ],
      [
        354,
        784
      ],
      [
        500,
        630
      ],
      [
        642,
        681
      ],
      [
        474,
        802
      ],
      [
        373,
        936
      ],
      [
        571,
        656
      ],
      [
        663,
        410
      ],
      [
        668.3875,
        427.5093
      ],
      [
        625.6125,
        288.4907
      ],
      [
        314,
        443
      ],
      [
        429,
        415
      ],
      [
        563,
        370
      ],
      [
        762,
        450
      ],
      [
        824,
        603
      ],
      [
        805,
        689
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.363514
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">661</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">62</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">024929223.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="68"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically downhill skiing. The activity typically involves a forward-leaning posture with bent knees, arms positioned to balance and guide movements, and feet secured on skis.

The person located centrally in the image appears to be mid-action while skiing downhill. Their body orientation suggests swift movement.

Starting with their right leg, the ankle is slightly ahead of the knee indicating a bent position while their hip leans towards the back. This indicates that they are pushing off from this leg for momentum.

The left leg mirrors this position but seems more straightened out suggesting it's bearing most of their weight at this moment. 

Their torso leans forward significantly from the pelvis up to thorax and neck indicating an aggressive skiing posture meant for speed or control during descent.

The head appears tilted upwards slightly which could suggest looking ahead down the slope or responding to wind resistance due to high speed.

For arms, both are extended wide outwards but bent at elbows forming almost right angles. The right arm extends backwards suggesting recent use of ski pole for thrust while left arm extends forward possibly preparing for next pole plant for maintaining rhythm or direction change.

Overall, this pose captures an intense moment during downhill skiing where quick decisions and precise movements can greatly affect performance.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      718,
      351
    ],
    "id": 0,
    "kpts": [
      [
        736,
        646
      ],
      [
        752,
        484
      ],
      [
        681,
        370
      ],
      [
        783,
        368
      ],
      [
        856,
        485
      ],
      [
        853,
        650
      ],
      [
        732,
        369
      ],
      [
        752,
        205
      ],
      [
        745.007,
        214.9901
      ],
      [
        814.993,
        115.0099
      ],
      [
        601,
        306
      ],
      [
        600,
        265
      ],
      [
        673,
        195
      ],
      [
        831,
        215
      ],
      [
        889,
        294
      ],
      [
        966,
        353
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.661239
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">661</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">209</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">075555114.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="69"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in winter activities, specifically skiing and climbing up. This activity involves a lot of lower body movement, especially the legs and hips, which are crucial for maintaining balance and navigating through the snow.

The central person is captured in a dynamic pose with their limbs positioned as if they are pushing off the ground with ski poles to climb uphill.

Their right leg appears to be slightly bent at the knee and hip, suggesting that they're putting weight on it. The right ankle seems to be flexed as well.

The left leg appears straighter than the right one, with both knee and hip extended. The left ankle seems to be angled forward, likely indicating that this foot is leading at this moment of motion.

Their torso leans forward slightly from their pelvis towards their head top. It suggests an active engagement of core muscles necessary for skiing uphill.

The arms are both bent at elbows but differ in positions: The right arm extends forward from shoulder while left arm pulls back behind them - mimicking a typical pole-pushing motion during skiing.
 
Lastly, their head aligns straight above upper neck suggesting that they're looking ahead possibly focusing on their path or destination.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      738,
      437
    ],
    "id": 0,
    "kpts": [
      [
        923,
        630
      ],
      [
        901,
        532
      ],
      [
        836,
        449
      ],
      [
        882,
        415
      ],
      [
        862,
        515
      ],
      [
        797,
        605
      ],
      [
        859,
        432
      ],
      [
        745,
        274
      ],
      [
        711.9408,
        271.1096
      ],
      [
        595.0592,
        260.8904
      ],
      [
        524,
        298
      ],
      [
        626,
        288
      ],
      [
        712,
        215
      ],
      [
        778,
        332
      ],
      [
        649,
        418
      ],
      [
        513,
        407
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.519827
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">127</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">6</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">022879817.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="70"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in winter activities, specifically skiing and climbing up. The individual appears to be performing a strenuous activity, as indicated by the positioning of their limbs.

The person centered towards the right side of the image is actively moving with their limbs extended.

Starting with their left leg, it seems to be stretched out behind them with a slight bend at the knee, suggesting that they are pushing off from this leg for forward movement. The right knee on the other hand is bent and raised slightly higher than hip level indicating an upward climb or stride.

Moving onto arms, both arms are bent at sharp angles at elbow joints. The right arm appears to be reaching forward while left arm seems to be pulling back as if they are using ski poles for propulsion.

As for torso and head - Torso leans forward suggesting an aggressive posture needed for uphill skiing. Head position suggests looking straight ahead focusing on path ahead.

Please note that not all keypoints were visible in this dataset; specifically, we could not determine locations of ankles which could have provided further insights into pose analysis.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      739,
      310
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        455,
        648
      ],
      [
        664,
        619
      ],
      [
        854,
        630
      ],
      [
        931,
        715
      ],
      [
        -1,
        -1
      ],
      [
        759,
        625
      ],
      [
        798,
        314
      ],
      [
        791.7744,
        341.6355
      ],
      [
        845.2256,
        104.3645
      ],
      [
        473,
        381
      ],
      [
        545,
        299
      ],
      [
        704,
        307
      ],
      [
        892,
        321
      ],
      [
        1051,
        205
      ],
      [
        1038,
        9
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 7.296513
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">127</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">66</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">007697991.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="71"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. The pose suggests a strenuous activity with significant body tension and balance required.

The central person is positioned slightly to the right with their body almost facing directly towards us. 

Their right leg appears to be bent at the knee, suggesting a stepping motion. The ankle, knee, and hip form an acute angle indicative of this movement.

Similarly, their left leg also appears to be bent at the knee but less so than the right one. This could suggest that they are using it for support as they lift themselves up.

The torso of this individual seems to be leaning forward slightly as if straining against an incline or exerting effort in climbing.

Their right arm is bent at the elbow with their wrist higher than it indicating that they might be pushing against something like ski poles for support or leverage during their climb.

On the other hand, their left arm seems slightly extended but still maintaining a bend at elbow holding another pole perhaps for balance during this uphill climb. 

Lastly, from what can be seen of their head position relative to neck and shoulders suggests they are looking upwards or ahead possibly gauging distance or direction.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      220,
      238
    ],
    "id": 0,
    "kpts": [
      [
        253,
        336
      ],
      [
        234,
        286
      ],
      [
        245,
        236
      ],
      [
        265,
        235
      ],
      [
        250,
        291
      ],
      [
        269,
        348
      ],
      [
        255,
        236
      ],
      [
        230,
        177
      ],
      [
        224.9983,
        172.1265
      ],
      [
        196.0017,
        143.8735
      ],
      [
        209,
        222
      ],
      [
        218,
        212
      ],
      [
        221,
        177
      ],
      [
        238,
        177
      ],
      [
        244,
        215
      ],
      [
        216,
        221
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.214552
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">86</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">016122129.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="72"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. The person appears to be mid-motion, possibly exerting effort to ascend a slope.

The center person is located at coordinates (408.0, 209.0) with a scale of 1.530741 and they are actively engaged in their activity with their limbs positioned for balance and movement.

Starting with the legs:
- The right leg seems to be bent at the knee with the ankle situated behind it, indicating an active push-off motion common in skiing.
- The left leg appears similarly bent but slightly more extended than the right one, perhaps preparing for or recovering from a stride.

Moving on to the arms:
- Their right arm is extended forward and slightly upwards as if reaching out for balance or pulling on ski poles.
- Their left arm is also extended but directed downwards and backwards, suggesting that it was recently used for propulsion or balance.

As for their torso:
- It leans forward suggesting active engagement and momentum towards an uphill direction which aligns well with climbing up during skiing activities.

Lastly regarding their head:
- It's held high above shoulders level but tilts forward slightly hinting towards concentration on upcoming terrain or path ahead while skiing uphill.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      408,
      209
    ],
    "id": 0,
    "kpts": [
      [
        408,
        398
      ],
      [
        442,
        337
      ],
      [
        446,
        187
      ],
      [
        362,
        181
      ],
      [
        394,
        321
      ],
      [
        341,
        384
      ],
      [
        404,
        184
      ],
      [
        441,
        118
      ],
      [
        470.8992,
        123.4362
      ],
      [
        521.1008,
        132.5638
      ],
      [
        539,
        96
      ],
      [
        503,
        64
      ],
      [
        490,
        95
      ],
      [
        392,
        140
      ],
      [
        351,
        142
      ],
      [
        342,
        199
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.530741
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">147</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">092969765.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="73"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is skiing downhill. The activity involves a forward-leaning position, with arms extended for balance and knees slightly bent. 

The center person appears to be in mid-movement, likely navigating a downhill slope while skiing. Their body orientation suggests active engagement with their environment.

Their right arm is extended forward, with the wrist positioned higher than the elbow, indicating an active movement or gesture. This could be for balance or steering purposes during skiing. The left arm mirrors this position but slightly lower.

Both legs are not visible in this dataset; hence we cannot provide information about them.

The torso leans forward from the pelvis to thorax and up to the neck, suggesting an aggressive or proactive stance common in downhill skiing activities.

Despite missing data points for head keypoints (upper neck and head top), based on available information from thorax and shoulder positions, it can be inferred that they are looking straight ahead which aligns with typical pose during downhill skiing where focus on path ahead is crucial.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      218,
      372
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        216,
        372
      ],
      [
        219.5859,
        351.381
      ],
      [
        228.4141,
        300.619
      ],
      [
        295,
        419
      ],
      [
        276,
        414
      ],
      [
        255,
        370
      ],
      [
        176,
        374
      ],
      [
        161,
        400
      ],
      [
        183,
        397
      ]
    ],
    "kpts_vis": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.545719
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">281</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">063340376.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="74"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are three people in the image who are engaging in winter activities, such as skiing and climbing up. All individuals appear to be in active poses associated with these activities, with their limbs positioned for movement or balance.

The person located at the center of the image is actively climbing up with their right leg visible. The right knee is bent and higher than the ankle, suggesting a stepping-up motion. The right arm is also bent at the elbow and lifted above waist level, which could indicate pushing off with a ski pole or maintaining balance during ascent. The left arm appears to be extended forward slightly. 

The person on the right side of this individual seems to be skiing downhill or balancing themselves on an incline. Both legs are slightly bent at knees indicating a crouching pose common in skiing for stability and control over speed. Their arms seem to be held out wide possibly holding ski poles for balance.

Lastly, there's another individual towards left side of image who seems to maintain a steady upright position despite being engaged in winter activity like skiing or climbing up slope which might indicate they're either standing still or moving very slowly uphill/downhill.
Their legs seem slightly apart while both arms are close to torso perhaps holding onto something like ski poles for support.

In all cases heads appear upright facing forwards indicating alertness towards path ahead fitting well into context of winter sports where focus on path ahead is crucial.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      318,
      375
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        265,
        472
      ],
      [
        290,
        394
      ],
      [
        345,
        401
      ],
      [
        335,
        472
      ],
      [
        -1,
        -1
      ],
      [
        318,
        398
      ],
      [
        301,
        291
      ],
      [
        294.0641,
        271.9758
      ],
      [
        272.9359,
        214.0242
      ],
      [
        240,
        382
      ],
      [
        255,
        339
      ],
      [
        261,
        302
      ],
      [
        340,
        280
      ],
      [
        360,
        354
      ],
      [
        328,
        336
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.850492
  },
  {
    "center": [
      501,
      390
    ],
    "id": 1,
    "kpts": [
      [
        496,
        471
      ],
      [
        486,
        440
      ],
      [
        474,
        388
      ],
      [
        496,
        382
      ],
      [
        486,
        434
      ],
      [
        486,
        476
      ],
      [
        485,
        385
      ],
      [
        484,
        334
      ],
      [
        484.5062,
        340.0746
      ],
      [
        481.4938,
        303.9254
      ],
      [
        439,
        375
      ],
      [
        449,
        357
      ],
      [
        464,
        332
      ],
      [
        503,
        336
      ],
      [
        522,
        364
      ],
      [
        529,
        392
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.088235
  },
  {
    "center": [
      574,
      352
    ],
    "id": 2,
    "kpts": [
      [
        566,
        423
      ],
      [
        567,
        391
      ],
      [
        570,
        362
      ],
      [
        589,
        369
      ],
      [
        592,
        394
      ],
      [
        592,
        418
      ],
      [
        580,
        366
      ],
      [
        575,
        329
      ],
      [
        574.9218,
        328.3481
      ],
      [
        572.0782,
        304.6519
      ],
      [
        565,
        361
      ],
      [
        563,
        351
      ],
      [
        564,
        329
      ],
      [
        586,
        329
      ],
      [
        596,
        355
      ],
      [
        582,
        367
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 0.715989
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">087146059.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="75"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. This activity involves a lot of leg work, often with the knees bent and arms positioned for balance or to use ski poles.

The centrally located person is captured mid-action with their limbs positioned as if they are climbing uphill. 

Their right leg appears to be bent at the knee, suggesting that it might be lifting off the ground or pushing against it for upward movement. The left leg seems to be straightened and firmly planted on the ground, providing support.

The right arm's position cannot be determined due to invisibility of some keypoints but we can observe that their left arm appears extended outwards from the shoulder towards their front-left side, possibly reaching out for support or balance.

Their torso seems slightly leaned forward indicating effort being put into climbing up. 

Lastly, their head is upright facing forward which indicates focus on path ahead during this strenuous activity.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      417,
      281
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        357,
        438
      ],
      [
        353,
        356
      ],
      [
        433,
        356
      ],
      [
        415,
        455
      ],
      [
        -1,
        -1
      ],
      [
        393,
        356
      ],
      [
        407,
        202
      ],
      [
        417.1508,
        169.6141
      ],
      [
        438.8492,
        100.3859
      ],
      [
        545,
        225
      ],
      [
        -1,
        -1
      ],
      [
        467,
        198
      ],
      [
        346,
        205
      ],
      [
        311,
        244
      ],
      [
        309,
        293
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1
    ],
    "scale": 2.176471
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">446</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">080367208.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="76"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in winter activities, specifically skiing and climbing up. This activity generally involves bending at the hips and knees, extending the arms for balance and propulsion, and leaning forward slightly from the waist.

The center person is positioned with their body facing towards the right side of the image. Their legs are apart with right hip visible at coordinates (422, 423) but both knees and ankles are not visible indicating they might be bent or obscured due to clothing or equipment.

Their torso appears to be leaning forward given that their pelvis point at (461,426) is closer to their thorax point at (474,307). Their head seems to be looking upwards as indicated by upper neck position (468,322) being lower than head top position (499,235).

The right arm appears extended diagonally downwards with wrist coordinate at (345,316), elbow coordinate at (362,331), indicating a slight bend in elbow joint. The left arm also seems extended diagonally upwards with wrist coordinate located higher than elbow coordinate which itself is higher than shoulder coordinate - suggesting an upward reach or push.

In conclusion this pose suggests a person engaged in uphill skiing motion where they are pushing themselves upward using ski poles while keeping their legs bent for stability.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      467,
      376
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        422,
        423
      ],
      [
        499,
        429
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        461,
        426
      ],
      [
        474,
        307
      ],
      [
        468.3917,
        322.7033
      ],
      [
        499.6083,
        235.2967
      ],
      [
        345,
        316
      ],
      [
        362,
        331
      ],
      [
        423,
        305
      ],
      [
        524,
        309
      ],
      [
        586,
        351
      ],
      [
        612,
        345
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.784414
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">978</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,376</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">634</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, climbing up</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">018657006.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="77"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in winter activities, specifically downhill skiing. The pose suggests a dynamic action, likely captured mid-movement. 

The person located towards the center of the image is actively skiing with their limbs distributed for balance and motion.

The right leg appears to be slightly bent at the knee and hip, with the ankle positioned behind. This suggests that weight might be shifted onto this leg for balance or control during a turn or maneuver.

The left leg seems to be more straightened compared to the right one, possibly taking less weight but providing stability nonetheless.

The right arm appears flexed at both elbow and wrist while being held up front, suggesting it might be holding a ski pole for guidance or support.

In contrast, their left arm seems extended outwards and slightly backwards with a slight bend at elbow which could imply additional balancing act or just part of their movement dynamics.

Their torso leans forward from pelvis area indicating an aggressive stance often seen in downhill skiing where maintaining low center of gravity helps improve control over speed and direction changes on slopes. 

Finally, their head faces forward suggesting they are looking ahead on their path down slope which is consistent with safety practices followed in such winter sports activities.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      284,
      222
    ],
    "id": 0,
    "kpts": [
      [
        247,
        328
      ],
      [
        255,
        282
      ],
      [
        280,
        220
      ],
      [
        316,
        232
      ],
      [
        293,
        275
      ],
      [
        287,
        336
      ],
      [
        298,
        226
      ],
      [
        314,
        166
      ],
      [
        317.5527,
        158.6104
      ],
      [
        335.4473,
        121.3896
      ],
      [
        255,
        230
      ],
      [
        252,
        185
      ],
      [
        284,
        156
      ],
      [
        344,
        176
      ],
      [
        353,
        215
      ],
      [
        346,
        246
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.238967
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">960</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,158</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">168</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">winter activities, skiing, downhill</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">089255900.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="78"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is grooming, feeding, cleaning, harnessing and unharnessing a horse. This activity typically involves interaction with an animal and may require bending or reaching movements.

The centrally located person is engaged with their surroundings. The right ankle keypoint isn't visible which might suggest that it's obscured or behind the horse.

Starting from the lower body:

- The right leg seems to be bent at the knee and hip as we can see from keypoints 1 (right knee) and 2 (right hip). This suggests that this individual might be kneeling or crouching.
- The left leg appears to be straightened out with both knee and hip keypoints 4 (left knee) and 3 (left hip) aligned vertically. It's possible that this person is supporting their weight on this leg.
- Unfortunately, left ankle keypoint isn't visible which restricts further analysis of left foot position.

Moving up to upper body:

- The torso appears upright given relatively straight alignment between pelvis keypoint 6, thorax keypoint 7 and upper neck keypoint 8.
  
For arms:

- Right arm seems to be lifted upwards near shoulder level as suggested by keypoints for right wrist at location [994,537] being above elbow [1023,460] which itself is above shoulder [1096,353].
- Left arm also appears raised but more forward directed since wrist point at [1132,678] lies horizontally closer to torso than its corresponding elbow point at [1285,588].

Finally for head:

- Head orientation can't be precisely determined but it seems slightly tilted downwards considering alignment of upper neck point at [1185,324] with head top point at [1181,184]. 

Overall pose suggests an active engagement probably involving some task related to horse care.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1091,
      546
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        1113,
        899
      ],
      [
        1077,
        656
      ],
      [
        1222,
        671
      ],
      [
        1210,
        923
      ],
      [
        -1,
        -1
      ],
      [
        1150,
        664
      ],
      [
        1186,
        370
      ],
      [
        1185.0154,
        324.5122
      ],
      [
        1181.9846,
        184.4878
      ],
      [
        994,
        537
      ],
      [
        1023,
        460
      ],
      [
        1096,
        353
      ],
      [
        1276,
        387
      ],
      [
        1285,
        588
      ],
      [
        1132,
        678
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 4.201714
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,431</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">5</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">053934224.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="79"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves several movements and postures that indicate interaction with an animal - likely a horse given the context.

The person located approximately at the center of the image is captured mid-action with their limbs positioned to suggest they are interacting with something or someone at their right side.

Their right leg appears to be bent at the hip, suggesting they might be kneeling or crouching. However, due to lack of visibility of knee and ankle joints for both legs, it's difficult to confirm this posture precisely.

Their torso leans slightly towards their right side indicating a possible bend from waist or hip. The thorax appears higher than hips suggesting an upright upper body position.

The head seems tilted upwards which could mean that they are looking up or ahead. As for arms, both are extended in different directions - right arm downwards and left arm upwards - possibly interacting with something on either sides of them.

The right arm shows a noticeable bend at elbow while wrist joint indicates hand might be facing downwards. This could suggest holding onto something below waist level like a brush or reins if we consider horse grooming context. 

On contrary left arm seems fully extended upwards with slight bend at elbow while wrist indicates hand facing outwards possibly reaching out for something above shoulder level like hanging feed bags or harness hooks etc.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      891,
      556
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        820,
        835
      ],
      [
        1127,
        842
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        974,
        839
      ],
      [
        980,
        436
      ],
      [
        990.1692,
        341.1663
      ],
      [
        1012.8308,
        129.8337
      ],
      [
        736,
        869
      ],
      [
        733,
        708
      ],
      [
        795,
        423
      ],
      [
        1164,
        448
      ],
      [
        1170,
        711
      ],
      [
        1211,
        959
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 6.376326
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,431</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">65</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">080744016.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="80"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is participating in sports, specifically horse cart driving, either standing or sitting. The activity involves a mix of upper body movement for controlling the horse and maintaining balance.

The person located near the center of the image appears to be sitting with their limbs arranged accordingly. 

Their right leg is bent at the knee, with their ankle positioned below and slightly to the left of it. The right hip is higher than both knee and ankle suggesting a folded posture.

The left leg mirrors this position almost identically, suggesting both legs are symmetrically positioned on either side of a possible cart or saddle. 

Their torso seems upright as indicated by close proximity between pelvis and thorax keypoints, with slight tilt towards right possibly due to reins control or balance maintenance.

The arms appear to be actively engaged in holding reins or balancing. The right arm has elbow slightly above wrist level while left arm has wrist higher than elbow indicating different actions being performed by each hand.

The head appears to be tilted down slightly as if looking at something below eye level, perhaps focusing on controlling reins or observing path ahead.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      397,
      254
    ],
    "id": 0,
    "kpts": [
      [
        356,
        312
      ],
      [
        355,
        278
      ],
      [
        380,
        272
      ],
      [
        441,
        272
      ],
      [
        426,
        283
      ],
      [
        429,
        341
      ],
      [
        411,
        272
      ],
      [
        422,
        209
      ],
      [
        418.9951,
        197.8391
      ],
      [
        411.0049,
        168.1609
      ],
      [
        362,
        243
      ],
      [
        382,
        239
      ],
      [
        393,
        205
      ],
      [
        450,
        212
      ],
      [
        455,
        252
      ],
      [
        428,
        244
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 0.92205
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">262</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">781</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">39</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">sports, horse cart, driving, standing or sitting</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">089609130.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="81"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of bending and reaching out with arms and legs. 

The person located at the center of the image is standing with their body slightly bent forward. Their right leg appears to be extended behind them while their left leg supports their weight.

Their right leg from ankle to hip (keypoints 0-2) seems to be extended backward indicating a step or a stance while performing an action. The knee appears slightly bent indicating some tension in maintaining this position.

The left leg from ankle to hip (keypoints 5-3) seems more stable or grounded as it supports the body's weight. The knee joint shows no significant bending implying that it's straightened for support.

The torso (keypoints 2-7) leans forward suggesting an active engagement with something on ground level or below their waist height.

Their head (keypoints 8-9) is tilted downward indicating focus on something below them which could be part of their task at hand.

As for the arms, they are both lifted away from the body suggesting active use. The right arm from wrist to shoulder (keypoints 10-12) seems raised and possibly reaching out towards something or someone as if performing an action such as grooming or harnessing.

Similarly, the left arm from wrist to shoulder (keypoints 15-13), though not as high as the other arm, also suggests active movement probably holding onto something like a tool used for cleaning.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      146,
      278
    ],
    "id": 0,
    "kpts": [
      [
        143,
        475
      ],
      [
        175,
        406
      ],
      [
        114,
        291
      ],
      [
        197,
        267
      ],
      [
        219,
        348
      ],
      [
        204,
        446
      ],
      [
        156,
        279
      ],
      [
        143,
        135
      ],
      [
        161.1306,
        112.0346
      ],
      [
        214.8694,
        43.9654
      ],
      [
        94,
        244
      ],
      [
        44,
        213
      ],
      [
        89,
        135
      ],
      [
        197,
        134
      ],
      [
        207,
        216
      ],
      [
        247,
        246
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.601759
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,357</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">106</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">011005192.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="82"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is occupied with horse grooming, feeding, cleaning, harnessing and unharnessing. The pose suggests an action of reaching out or interacting with something at a lower level.

The centrally located person is positioned mid-frame with their limbs spread out. Their body seems to be leaning forward slightly suggesting an engagement in some activity.

Starting from the legs:
- The right leg is partially visible with only the knee and hip visible. Their right knee appears to be slightly bent indicating a semi-flexed position.
- The left leg's hip, knee and ankle are all visible. It appears to be more straightened than the right leg but still maintaining slight bend at the knee which suggests a stance that supports bending over or reaching out.

Moving onto the torso:
- The torso seems to be leaning forward as indicated by relative positions of pelvis and thorax keypoints.
 
For arms:
- The right arm's wrist, elbow and shoulder are all visible. This arm seems extended forward possibly reaching for something as suggested by low position of wrist keypoint compared to shoulder keypoint.
- Similarly, left arm also seems extended but towards side rather than front. All keypoints (wrist, elbow &amp; shoulder) are clearly seen in this case too.

Finally for head,
- Neck and head top keypoints suggest that head is turned slightly towards left side while it maintains its overall downward orientation likely focusing on task being performed by hands/arms.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      436,
      252
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        458,
        424
      ],
      [
        427,
        288
      ],
      [
        483,
        294
      ],
      [
        522,
        400
      ],
      [
        -1,
        -1
      ],
      [
        455,
        291
      ],
      [
        430,
        172
      ],
      [
        435.4046,
        161.6065
      ],
      [
        463.5954,
        107.3935
      ],
      [
        421,
        57
      ],
      [
        375,
        112
      ],
      [
        397,
        156
      ],
      [
        462,
        187
      ],
      [
        489,
        231
      ],
      [
        497,
        293
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.833135
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1,357</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">171</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">022793516.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="83"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity generally involves a lot of bending and reaching with the arms, as well as squatting or kneeling to reach lower parts of the horse.

The center person is positioned slightly to the right with their body facing forward. 

Starting with their legs:
- The right leg appears to be bent at the knee and slightly extended backward.
- The left leg seems to be straight and supporting most of their weight.

Moving on to their arms:
- The right arm appears extended forward with a slight bend at elbow.
- Unfortunately, we cannot see any information about the left wrist due to it being invisible in this dataset.

As for their torso:
- It's leaning slightly towards left indicating some sort of engagement or interaction.

Lastly for their head:
- It's tilted downwards possibly focusing on something below them.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      321,
      323
    ],
    "id": 0,
    "kpts": [
      [
        363,
        455
      ],
      [
        299,
        404
      ],
      [
        300,
        306
      ],
      [
        345,
        300
      ],
      [
        291,
        414
      ],
      [
        301,
        472
      ],
      [
        323,
        303
      ],
      [
        328,
        211
      ],
      [
        324.2447,
        198.5326
      ],
      [
        306.7553,
        140.4674
      ],
      [
        300,
        274
      ],
      [
        350,
        269
      ],
      [
        347,
        205
      ],
      [
        308,
        216
      ],
      [
        302,
        270
      ],
      [
        -1,
        -1
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      0
    ],
    "scale": 1.819257
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">336</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">086073058.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="84"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of movement and interaction with the horse.

The centrally located person appears to be interacting with something or someone out of frame, likely a horse given the context. Their body orientation suggests they are facing towards their right side.

Starting with their legs, it appears that only the hip joints are visible while both knees and ankles are not detected. This limits precise description of leg pose but based on available data we can say that their hips are slightly apart indicating a stance wider than shoulder width.

Moving up to their torso, it seems to be leaning forward slightly as indicated by position of pelvis and thorax keypoints. The head is tilted downwards suggesting focus on an object or task at hand.

Their right arm appears extended downwards with elbow joint visible but wrist joint not detected. The left arm seems to be bent at the elbow and raised upwards as if reaching for something or performing an action.

In summary, this individual's pose suggests they may be conducting tasks related to horse care such as grooming or harnessing.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      350,
      288
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        338,
        385
      ],
      [
        456,
        388
      ],
      [
        -1,
        -1
      ],
      [
        -1,
        -1
      ],
      [
        397,
        387
      ],
      [
        400,
        202
      ],
      [
        396.1337,
        141.4287
      ],
      [
        388.8663,
        27.5713
      ],
      [
        277,
        429
      ],
      [
        307,
        347
      ],
      [
        315,
        211
      ],
      [
        484,
        193
      ],
      [
        502,
        368
      ],
      [
        466,
        314
      ]
    ],
    "kpts_vis": [
      0,
      0,
      1,
      1,
      0,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.422673
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">336</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">69</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">000695213.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="85"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is grooming, feeding, cleaning, harnessing and unharnessing a horse. This activity involves a lot of movements and interactions with the horse.

The center person is in the middle of an action with their limbs positioned to perform various tasks related to horse care.

The right leg seems to be slightly bent at the knee and hip, possibly providing balance while performing tasks. The left leg appears straighter and grounded firmly on the surface.

The right arm appears bent at both elbow and shoulder joints indicating that it might be holding or manipulating some tool for grooming or feeding. The left arm also seems slightly bent at elbow joint but less so than right arm which suggests it might be used for stabilizing or supporting something.

Their torso leans forward slightly suggesting engagement in an activity that requires close attention. 

Lastly, their head seems to be tilted downwards likely focusing on the task they are performing with their hands.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      307,
      179
    ],
    "id": 0,
    "kpts": [
      [
        329,
        345
      ],
      [
        349,
        256
      ],
      [
        362,
        159
      ],
      [
        295,
        161
      ],
      [
        281,
        270
      ],
      [
        289,
        354
      ],
      [
        329,
        160
      ],
      [
        289,
        82
      ],
      [
        281.6384,
        78.4507
      ],
      [
        240.3616,
        58.5493
      ],
      [
        325,
        180
      ],
      [
        350,
        119
      ],
      [
        328,
        76
      ],
      [
        249,
        87
      ],
      [
        263,
        151
      ],
      [
        266,
        194
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.37472
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,076</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">10</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">041741100.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="86"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaged in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity generally involves bending over or stooping down to reach the horse's level and using hands and arms for tasks such as brushing or feeding.

The person centered at coordinates (115.0, 242.0) appears to be slightly bent forward with their limbs actively engaged in a task.

Starting with the legs, their right leg seems to be slightly bent at the knee while standing firm on ground as indicated by keypoints of right hip (62, 250), right knee (100, 265), and right ankle (76, 322). The left leg appears more straightened but also firmly planted on ground as per keypoints of left hip (131, 260), left knee (166,282) and left ankle (115,307).

Moving onto their torso region which includes pelvis-thorax-upper neck-head top sequence of keypoints [(97,255)-(121-189)-(121-177)-(124-125)], it suggests a slight forward bend indicative of an engaging task.

Looking at arms now; their right arm seems extended downwards perhaps holding something or performing a task given by keypoints from shoulder-elbow-wrist [(91-190)-(89-223)-(131-246)]. Their left arm also appears extended but angled upwards possibly reaching out for something as suggested by shoulder-elbow-wrist keypoints [(151-187),(156-239),(150 -261)].

Lastly considering head position relative to upper neck keypoint indicates that they are looking downwards likely focused on the task being performed.</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      115,
      242
    ],
    "id": 0,
    "kpts": [
      [
        76,
        322
      ],
      [
        100,
        265
      ],
      [
        62,
        250
      ],
      [
        131,
        260
      ],
      [
        166,
        282
      ],
      [
        115,
        307
      ],
      [
        97,
        255
      ],
      [
        121,
        189
      ],
      [
        121.5925,
        177.8898
      ],
      [
        124.4075,
        125.1102
      ],
      [
        131,
        246
      ],
      [
        89,
        223
      ],
      [
        91,
        190
      ],
      [
        151,
        187
      ],
      [
        156,
        239
      ],
      [
        150,
        261
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.585636
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,076</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">133</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">022210781.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="87"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There is one person in the image who is engaging in horse grooming, feeding, cleaning, harnessing and unharnessing. This activity involves a lot of bending and reaching as well as interaction with an animal.

The center-right person is standing upright with their limbs arranged in a manner indicative of an action related to horse care.

Starting with the left leg, the knee and hip are visible while the ankle isn't. The knee seems to be slightly bent indicating that this leg might be bearing most of the body's weight or preparing for motion. 

The right leg appears to be stretched out towards the back suggesting that it's providing balance while performing an action. Both right ankle and knee are not visible which might indicate they are behind something or obscured from view.

Moving onto arms, both hands appear to be lifted up near their respective shoulders indicating possible interaction or handling of objects at chest level or higher. The left arm seems more extended than right arm suggesting it could be reaching out for something.

Regarding torso and head; they seem straight aligned with each other indicating upright posture. The upper neck appears higher than thorax implying that head is raised probably looking forward or upwards.

In conclusion, based on keypoints data this individual seems engaged in some sort of care-taking activity involving bending, reaching out and possibly interacting with objects at different levels around them.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      261,
      136
    ],
    "id": 0,
    "kpts": [
      [
        -1,
        -1
      ],
      [
        273,
        234
      ],
      [
        276,
        164
      ],
      [
        213,
        158
      ],
      [
        209,
        245
      ],
      [
        -1,
        -1
      ],
      [
        245,
        161
      ],
      [
        257,
        53
      ],
      [
        267.4526,
        37.3211
      ],
      [
        294.5474,
        -3.3211
      ],
      [
        355,
        137
      ],
      [
        315,
        113
      ],
      [
        302,
        54
      ],
      [
        211,
        51
      ],
      [
        194,
        98
      ],
      [
        190,
        157
      ]
    ],
    "kpts_vis": [
      0,
      1,
      1,
      1,
      1,
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.465376
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">15</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">2,076</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">286</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">occupation, horse grooming, feeding, cleaning, harnessing and unharnessing</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">011986537.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">1</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="88"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are six people in the image who are performing conditioning exercises, video exercise workouts, or TV conditioning programs. The individuals appear to be in various stages of workout routines, involving a range of movements from stretching to aerobic exercises.

The first person is located towards the left side of the image and appears to be mid-way through an exercise routine. Their right leg is significantly bent at the knee with the ankle raised high and behind them. The left leg is slightly bent at the knee, indicating a possible balancing pose. Their right arm is bent at a sharp angle near their waist while their left arm extends outward with a slight bend at elbow.

The second person is positioned slightly towards center-left and seems to be engaged in an aerobic activity. Both legs are moderately bent suggesting they might be squatting or jumping. Their arms seem extended outwards with elbows slightly bent which could indicate that they are maintaining balance during their activity.

The third individual situated around center-right area seems to be doing a stretching or balancing exercise as well. Their right leg appears straight while their left leg shows moderate bending at knee suggesting an asymmetrical pose. Both arms show some degree of bending but not too drastically - this could suggest either reaching for something or maintaining balance.

Moving further towards right we have fourth person who also looks like they're involved in some form of stretching routine as both legs appear fairly straight compared to others'. Arms seem relaxed and mildly bent which could possibly indicate rest between sets.

Fifth person on far-right seems engaged in another form of physical activity where both legs appear moderately flexed suggesting either squatting position or mid-motion action like running/jumping etc.. Arms display moderate bending indicating active movement rather than resting state.

Finally sixth individual located on extreme far-right shows similar characteristics as fifth one - moderate flexing in knees hinting active engagement &amp; mild bending in arms suggesting ongoing motion rather than static pose.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      333,
      475
    ],
    "id": 0,
    "kpts": [
      [
        216,
        696
      ],
      [
        254,
        600
      ],
      [
        314,
        514
      ],
      [
        383,
        510
      ],
      [
        429,
        602
      ],
      [
        477,
        690
      ],
      [
        349,
        512
      ],
      [
        328,
        420
      ],
      [
        325.5228,
        411.7426
      ],
      [
        303.4772,
        338.2574
      ],
      [
        266,
        493
      ],
      [
        245,
        468
      ],
      [
        279,
        416
      ],
      [
        377,
        423
      ],
      [
        370,
        475
      ],
      [
        324,
        498
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.301624
  },
  {
    "center": [
      455,
      638
    ],
    "id": 1,
    "kpts": [
      [
        256,
        790
      ],
      [
        347,
        703
      ],
      [
        422,
        634
      ],
      [
        530,
        619
      ],
      [
        561,
        687
      ],
      [
        545,
        771
      ],
      [
        476,
        627
      ],
      [
        425,
        507
      ],
      [
        427.1445,
        520.2242
      ],
      [
        410.8555,
        419.7758
      ],
      [
        268,
        557
      ],
      [
        256,
        535
      ],
      [
        350,
        513
      ],
      [
        499,
        501
      ],
      [
        460,
        554
      ],
      [
        345,
        564
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.052815
  },
  {
    "center": [
      689,
      733
    ],
    "id": 2,
    "kpts": [
      [
        313,
        951
      ],
      [
        501,
        848
      ],
      [
        614,
        742
      ],
      [
        737,
        754
      ],
      [
        799,
        824
      ],
      [
        773,
        941
      ],
      [
        676,
        748
      ],
      [
        696,
        626
      ],
      [
        689.2714,
        570.7294
      ],
      [
        674.7286,
        451.2706
      ],
      [
        669,
        723
      ],
      [
        580,
        776
      ],
      [
        592,
        629
      ],
      [
        799,
        622
      ],
      [
        828,
        742
      ],
      [
        734,
        715
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.610225
  },
  {
    "center": [
      1230,
      672
    ],
    "id": 3,
    "kpts": [
      [
        1036,
        917
      ],
      [
        1065,
        747
      ],
      [
        1188,
        660
      ],
      [
        1306,
        658
      ],
      [
        1438,
        795
      ],
      [
        1551,
        925
      ],
      [
        1247,
        659
      ],
      [
        1245,
        481
      ],
      [
        1244.1275,
        486.4647
      ],
      [
        1264.8725,
        356.5353
      ],
      [
        1183,
        672
      ],
      [
        1145,
        583
      ],
      [
        1157,
        484
      ],
      [
        1332,
        477
      ],
      [
        1347,
        581
      ],
      [
        1289,
        672
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.947252
  },
  {
    "center": [
      1472,
      527
    ],
    "id": 4,
    "kpts": [
      [
        1377,
        706
      ],
      [
        1383,
        597
      ],
      [
        1418,
        556
      ],
      [
        1477,
        560
      ],
      [
        1537,
        605
      ],
      [
        1611,
        667
      ],
      [
        1448,
        558
      ],
      [
        1455,
        477
      ],
      [
        1456.7167,
        471.3036
      ],
      [
        1475.2833,
        409.6964
      ],
      [
        1443,
        536
      ],
      [
        1402,
        552
      ],
      [
        1404,
        470
      ],
      [
        1506,
        483
      ],
      [
        1508,
        562
      ],
      [
        1482,
        536
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 1.930322
  },
  {
    "center": [
      1626,
      628
    ],
    "id": 5,
    "kpts": [
      [
        1427,
        819
      ],
      [
        1466,
        687
      ],
      [
        1528,
        598
      ],
      [
        1610,
        614
      ],
      [
        1685,
        720
      ],
      [
        1795,
        821
      ],
      [
        1569,
        606
      ],
      [
        1596,
        499
      ],
      [
        1597.5457,
        490.1325
      ],
      [
        1613.4543,
        398.8675
      ],
      [
        1593,
        571
      ],
      [
        1528,
        593
      ],
      [
        1536,
        489
      ],
      [
        1656,
        509
      ],
      [
        1637,
        619
      ],
      [
        1629,
        585
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.779237
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">849</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">288</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">75</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">conditioning exercise, video exercise workouts, TV conditioning programs</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">094290970.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">6</div></div>
							</td>
					</tr><tr class="group cursor-pointer space-x-4 divide-x border-b outline-offset-[-2px] odd:bg-gray-50 hover:bg-gray-100 dark:odd:bg-gray-925 dark:hover:bg-gray-850  last:border-none" tabindex="0" data-row-idx="89"><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">There are three people in the image who are performing conditioning exercises, specifically video exercise workouts or TV conditioning programs. These exercises generally involve a range of movements and positions, often targeting multiple body areas for strength and flexibility.

The first person is located centrally and is quite large in scale, indicating they may be closer to the viewer. They seem to be in a standing position with their weight evenly distributed between their legs. Their right leg appears slightly bent at the knee while their left leg seems straight. The right arm is bent at the elbow with the wrist level with their waist, while the left arm is extended outwards at shoulder height. Their torso maintains an upright position and their head appears to be tilted upwards.

The second person is positioned towards the left of this scene and has a smaller scale compared to the first person suggesting they are further away from us. This individual also seems to be in an upright stance but with more noticeable bend at both knees suggesting they might be mid-motion during an exercise routine. Both arms appear curved at elbows but held differently - right arm close to body while left extends outwardly around shoulder level. The head of this person seems slightly inclined downwards.

The third individual situated towards center-right of this scene has smallest scale among all indicating farthest distance from viewer's perspective. They seem engaged in similar activity as others but possibly different movement as both knees appear significantly bent indicating squat-like posture or mid-jump action perhaps due to dynamic nature of conditioning exercises being performed by them all together here on screen.
Their arms display contrast - right one hangs down whereas left one extends outwards around chest level which could indicate asymmetrical movement pattern or simply different point within same exercise sequence as others.
Their head orientation suggests focus downwards likely on own body during these movements.

Overall, each individual presents unique pose within same activity context showing diversity typical for group workout scenarios where everyone follows general instructions but adapts according personal comfort and fitness levels.
</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-left" dir="auto">[
  {
    "center": [
      1320,
      517
    ],
    "id": 0,
    "kpts": [
      [
        1200,
        913
      ],
      [
        1196,
        734
      ],
      [
        1191,
        507
      ],
      [
        1301,
        508
      ],
      [
        1307,
        744
      ],
      [
        1294,
        874
      ],
      [
        1246,
        508
      ],
      [
        1264,
        262
      ],
      [
        1258.7121,
        240.1227
      ],
      [
        1218.2879,
        72.8773
      ],
      [
        1147,
        516
      ],
      [
        1124,
        391
      ],
      [
        1157,
        266
      ],
      [
        1371,
        257
      ],
      [
        1408,
        408
      ],
      [
        1330,
        518
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 5.161842
  },
  {
    "center": [
      684,
      471
    ],
    "id": 1,
    "kpts": [
      [
        691,
        885
      ],
      [
        660,
        709
      ],
      [
        622,
        502
      ],
      [
        723,
        500
      ],
      [
        723,
        702
      ],
      [
        739,
        897
      ],
      [
        673,
        501
      ],
      [
        649,
        279
      ],
      [
        645.5769,
        253.0418
      ],
      [
        628.4231,
        122.9582
      ],
      [
        562,
        510
      ],
      [
        563,
        411
      ],
      [
        563,
        282
      ],
      [
        734,
        276
      ],
      [
        810,
        382
      ],
      [
        746,
        476
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 3.936293
  },
  {
    "center": [
      821,
      366
    ],
    "id": 2,
    "kpts": [
      [
        751,
        624
      ],
      [
        756,
        514
      ],
      [
        751,
        366
      ],
      [
        827,
        358
      ],
      [
        833,
        502
      ],
      [
        827,
        621
      ],
      [
        789,
        362
      ],
      [
        773,
        188
      ],
      [
        776.5965,
        154.9973
      ],
      [
        786.4035,
        65.0027
      ],
      [
        715,
        346
      ],
      [
        689,
        293
      ],
      [
        704,
        191
      ],
      [
        842,
        184
      ],
      [
        883,
        263
      ],
      [
        861,
        339
      ]
    ],
    "kpts_vis": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "scale": 2.71582
  }
]</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">849</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">288</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">417</div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">conditioning exercise, video exercise workouts, TV conditioning programs</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="" dir="auto"><span class="">032320293.jpg</span></div></div>
							</td><td class="min-w-fit max-w-sm break-words p-2 "><div class="line-clamp-2 "><div class="text-right" dir="auto">3</div></div>
							</td>
					</tr></tbody></table>
		<div class="bg-linear-to-b sticky left-0 border-t border-dashed border-gray-300 from-gray-100 to-white py-3 text-center font-mono text-xs dark:border-gray-700 dark:from-gray-950 dark:to-gray-900">End of preview. <a href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train" class="group"><span class="underline decoration-gray-300 group-hover:decoration-gray-400 dark:decoration-gray-500 dark:group-hover:decoration-gray-300">Expand</span>
						in <svg class="text-lg mr-0.5 inline -translate-y-px text-red-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 12 12"><path fill="currentColor" d="M2.5 2h7a1 1 0 0 1 1 1v6a1 1 0 0 1-1 1h-7a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1Zm0 2v2h3V4h-3Zm4 0v2h3V4h-3Zm-4 3v2h3V7h-3Zm4 0v2h3V7h-3Z"></path></svg>Data Studio
					</a></div></div>




			<div class="bg-linear-to-b from-gray-100 to-white dark:from-gray-950 dark:to-gray-900 "><hr class="flex-none -translate-y-px border-t border-dashed border-gray-300 bg-white dark:border-gray-700 dark:bg-gray-950">
					<nav><ul class="flex select-none items-center justify-between space-x-2 text-gray-700 sm:justify-center py-1 text-center font-mono text-xs rounded-b-lg"><li><a class="flex items-center rounded-lg px-2.5 py-1 hover:bg-gray-50 dark:hover:bg-gray-800 pointer-events-none cursor-default text-gray-400 hover:text-gray-700" href=""><svg class="mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M10 16L20 6l1.4 1.4l-8.6 8.6l8.6 8.6L20 26z" fill="currentColor"></path></svg>
		Previous</a></li>
			<li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1 bg-gray-50 font-semibold ring-1 ring-inset ring-gray-200 dark:bg-gray-900 dark:text-yellow-500 dark:ring-gray-900 hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train?p=0">1</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train?p=1">2</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train?p=2">3</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  pointer-events-none cursor-default" href="#">...</a>
				</li><li class="hidden sm:block"><a class="rounded-lg px-2.5 py-1  hover:bg-gray-50 dark:hover:bg-gray-800" href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train?p=146">147</a>
				</li>
			<li><a class="flex items-center rounded-lg px-2.5 py-1 hover:bg-gray-50 dark:hover:bg-gray-800 " href="/datasets/saifkhichi96/mpii-human-pose-captions/viewer/gpt-4/train?p=1">Next
		<svg class="ml-1.5 transform rotate-180" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M10 16L20 6l1.4 1.4l-8.6 8.6l8.6 8.6L20 26z" fill="currentColor"></path></svg></a></li></ul></nav></div></div>






</div></div></div></div></div></div></div>

				
					<div class="SVELTE_HYDRATER contents" data-target="RepoCodeCopy" data-props="{}"><div></div></div>
					

					<div class="SVELTE_HYDRATER contents" data-target="SideNavigation" data-props="{&quot;titleTree&quot;:[{&quot;id&quot;:&quot;dataset-structure&quot;,&quot;label&quot;:&quot;Dataset Structure&quot;,&quot;children&quot;:[{&quot;id&quot;:&quot;data-instances&quot;,&quot;label&quot;:&quot;Data Instances&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Data Instances&quot;},{&quot;id&quot;:&quot;data-fields&quot;,&quot;label&quot;:&quot;Data Fields&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Data Fields&quot;},{&quot;id&quot;:&quot;data-splits&quot;,&quot;label&quot;:&quot;Data Splits&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Data Splits&quot;}],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Dataset Structure&quot;},{&quot;id&quot;:&quot;dataset-creation&quot;,&quot;label&quot;:&quot;Dataset Creation&quot;,&quot;children&quot;:[{&quot;id&quot;:&quot;curation-rationale&quot;,&quot;label&quot;:&quot;Curation Rationale&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Curation Rationale&quot;},{&quot;id&quot;:&quot;source-data&quot;,&quot;label&quot;:&quot;Source Data&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Source Data&quot;},{&quot;id&quot;:&quot;annotations&quot;,&quot;label&quot;:&quot;Annotations&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Annotations&quot;},{&quot;id&quot;:&quot;personal-and-sensitive-information&quot;,&quot;label&quot;:&quot;Personal and Sensitive Information&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Personal and Sensitive Information&quot;}],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Dataset Creation&quot;},{&quot;id&quot;:&quot;considerations-for-using-the-data&quot;,&quot;label&quot;:&quot;Considerations for Using the Data&quot;,&quot;children&quot;:[{&quot;id&quot;:&quot;social-impact-of-dataset&quot;,&quot;label&quot;:&quot;Social Impact of Dataset&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Social Impact of Dataset&quot;},{&quot;id&quot;:&quot;discussion-of-biases&quot;,&quot;label&quot;:&quot;Discussion of Biases&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Discussion of Biases&quot;},{&quot;id&quot;:&quot;other-known-limitations&quot;,&quot;label&quot;:&quot;Other Known Limitations&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Other Known Limitations&quot;}],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Considerations for Using the Data&quot;},{&quot;id&quot;:&quot;additional-information&quot;,&quot;label&quot;:&quot;Additional Information&quot;,&quot;children&quot;:[{&quot;id&quot;:&quot;dataset-curators&quot;,&quot;label&quot;:&quot;Dataset Curators&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Dataset Curators&quot;},{&quot;id&quot;:&quot;licensing-information&quot;,&quot;label&quot;:&quot;Licensing Information&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Licensing Information&quot;},{&quot;id&quot;:&quot;citation-information&quot;,&quot;label&quot;:&quot;Citation Information&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Citation Information&quot;},{&quot;id&quot;:&quot;contributions&quot;,&quot;label&quot;:&quot;Contributions&quot;,&quot;children&quot;:[],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Contributions&quot;}],&quot;isValid&quot;:true,&quot;title&quot;:&quot;Additional Information&quot;}],&quot;classNames&quot;:&quot;top-6&quot;}">

<div class="absolute -left-12 bottom-0 top-0 z-10 top-6"><div class="sticky top-4 flex"><div class="h-7 pt-[0.175rem]">
				<span class="peer" tabindex="0"><button class="select-none hover:cursor-pointer"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-lg opacity-80 hover:opacity-100" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg></button></span>
				<div class="invisible w-0 -translate-x-24 -translate-y-6 overflow-hidden rounded-xl border bg-white transition-transform hover:visible hover:w-52 hover:translate-x-0 peer-focus-within:visible peer-focus-within:w-52 peer-focus-within:translate-x-0"><nav aria-label="Secondary" class="max-h-[550px] overflow-y-auto p-3"><ul><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#dataset-structure" title="Dataset Structure"><!-- HTML_TAG_START -->Dataset Structure<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#data-instances" title="Data Instances"><!-- HTML_TAG_START -->Data Instances<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#data-fields" title="Data Fields"><!-- HTML_TAG_START -->Data Fields<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#data-splits" title="Data Splits"><!-- HTML_TAG_START -->Data Splits<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#dataset-creation" title="Dataset Creation"><!-- HTML_TAG_START -->Dataset Creation<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#curation-rationale" title="Curation Rationale"><!-- HTML_TAG_START -->Curation Rationale<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#source-data" title="Source Data"><!-- HTML_TAG_START -->Source Data<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#annotations" title="Annotations"><!-- HTML_TAG_START -->Annotations<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#personal-and-sensitive-information" title="Personal and Sensitive Information"><!-- HTML_TAG_START -->Personal and Sensitive Information<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#considerations-for-using-the-data" title="Considerations for Using the Data"><!-- HTML_TAG_START -->Considerations for Using the Data<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#social-impact-of-dataset" title="Social Impact of Dataset"><!-- HTML_TAG_START -->Social Impact of Dataset<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#discussion-of-biases" title="Discussion of Biases"><!-- HTML_TAG_START -->Discussion of Biases<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#other-known-limitations" title="Other Known Limitations"><!-- HTML_TAG_START -->Other Known Limitations<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li><li class="mb-3 text-sm last:mb-0"><a class="mb-1 block break-words font-semibold text-gray-700 *:break-words hover:underline active:text-gray-900 dark:active:text-gray-200" href="#additional-information" title="Additional Information"><!-- HTML_TAG_START -->Additional Information<!-- HTML_TAG_END --></a>
									<ul class="pl-1"><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#dataset-curators" title="Dataset Curators"><!-- HTML_TAG_START -->Dataset Curators<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#licensing-information" title="Licensing Information"><!-- HTML_TAG_START -->Licensing Information<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#citation-information" title="Citation Information"><!-- HTML_TAG_START -->Citation Information<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li><li><a class="mb-0.5 block break-words hover:underline active:text-gray-700 dark:active:text-gray-300 text-gray-500" href="#contributions" title="Contributions"><!-- HTML_TAG_START -->Contributions<!-- HTML_TAG_END --></a>
												<ul class="pl-2"></ul>
											</li></ul>
								</li></ul></nav></div></div></div></div></div>
					<div class="2xl:pr-6"><div class="prose pl-6 -ml-6 hf-sanitized hf-sanitized-kWTAFwBydYIktjxBt9dzl">
	<!-- HTML_TAG_START --><h1 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-card-for-mpii-human-pose-descriptions" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-card-for-mpii-human-pose-descriptions">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Card for MPII Human Pose Descriptions
	</span>
</h1>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-summary" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-summary">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Summary
	</span>
</h3>
<p>The MPII Human Pose Descriptions dataset extends the widely-used MPII Human Pose Dataset with rich textual annotations. These annotations are generated by various state-of-the-art language models (LLMs) and include detailed descriptions of the activities being performed, the count of people present, and their specific poses.</p>
<p>The dataset consists of the same image splits as provided in MMPose, with 14644 training samples and 2723 validation samples. Each image is accompanied by one or more pose descriptions generated by different LLMs. The descriptions are also accompanied by additional annotation information, including the activity type, people count, and pose keypoints, which are derived from the original MPII Human Pose Dataset annotations.</p>
<p>By adding textual annotations to the existing human pose dataset, this extended version supports novel research in multi-modal learning, where both visual and textual cues can be explored.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#supported-tasks" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="supported-tasks">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Supported Tasks
	</span>
</h3>


<p>The MPII Human Pose Descriptions dataset is designed to support a variety of tasks in multi-modal learning. It is particularly valuable for research in combining visual and textual data, and it has been utilized in the development of the CLIP-3 model.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#multi-modal-learning" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="multi-modal-learning">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Multi-Modal Learning
	</span>
</h4>
<p>This dataset enables the exploration of models that can learn to correlate images with text descriptions. The detailed textual descriptions, describing the activity, people count, and their poses, make it suitable for multi-modal representation learning. The applications can range from visual question answering to image retrieval using natural language queries.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#fine-grained-activity-recognition" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="fine-grained-activity-recognition">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Fine-Grained Activity Recognition
	</span>
</h4>
<p>The dataset can also be employed for recognizing specific human activities and poses. The textual annotations provide a rich source of information about the activity being performed and the number of individuals involved, allowing for fine-grained classification tasks.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#text-enhanced-visual-models" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="text-enhanced-visual-models">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Text-Enhanced Visual Models
	</span>
</h4>
<p>Researchers may use this dataset to train models like CLIP-3 that leverage textual descriptions along with visual features. The detailed annotations provide insights into human figures and activities, supporting tasks such as person detection, person counting, and pose estimation.</p>


<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#languages" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="languages">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Languages
	</span>
</h3>
<p>The pose descriptions in the MPII Human Pose Descriptions dataset are written exclusively in English. They are generated by various language models and provide detailed descriptions of human figures, poses, and activities in the corresponding images from the MPII Human Pose Dataset.</p>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-structure" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-structure">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Structure
	</span>
</h2>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#data-instances" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="data-instances">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Data Instances
	</span>
</h3>
<p>The dataset contains textual descriptions for the images in the MPII Human Pose dataset, along with additional annotation information. Each data instance includes the following fields:</p>
<ul>
<li><code>image</code>: The image filename (e.g., "005808361.jpg").</li>
<li><code>video_id</code>: The unique identifier for the corresponding video.</li>
<li><code>video_frame</code>: The specific frame number within the video.</li>
<li><code>activity_id</code>: The identifier for the activity being performed.</li>
<li><code>activity</code>: The description of the activity (e.g., "sports, curling").</li>
<li><code>count</code>: The number of people in the image.</li>
<li><code>people</code>: A list of dictionaries containing information about each individual person in the image, including <code>id</code>, <code>center</code>, <code>scale</code>, <code>kpts</code>, and <code>kpts_vis</code>.</li>
<li><code>description</code>: A generated text description that captures the human pose, activity, and people count in the image.</li>
</ul>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#data-fields" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="data-fields">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Data Fields
	</span>
</h3>
<p>The dataset contains the following fields:</p>
<ul>
<li><code>image</code>: String</li>
<li><code>video_id</code>: Integer</li>
<li><code>video_frame</code>: Integer</li>
<li><code>activity_id</code>: Integer</li>
<li><code>activity</code>: String</li>
<li><code>count</code>: Integer</li>
<li><code>people</code>: List of dictionaries</li>
<li><code>description</code>: String</li>
</ul>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#data-splits" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="data-splits">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Data Splits
	</span>
</h3>
<p>We provide the same data splits as the annotations provided in MMPose for the MPII Human Pose Dataset. The training split contains 14644 samples, while the validation split contains 2723 samples.</p>
<p>The dataset has been curated into multiple versions, each corresponding to different Large Language Models (LLMs) used for generating the pose descriptions. In each specific version, the captions are uniquely generated by that corresponding model. This following table summarizes the captioned samples for each version:</p>
<div class="max-w-full overflow-auto">
	<table>
		<thead><tr>
<th>Config Name</th>
<th>Model</th>
<th>Creator</th>
<th>Training Images</th>
<th>Validation Images</th>
</tr>

		</thead><tbody><tr>
<td><code>gpt-3.5-turbo-legacy</code></td>
<td><code>gpt-3.5-turbo-0301</code></td>
<td>OpenAI</td>
<td>14644</td>
<td>2723</td>
</tr>
<tr>
<td><code>gpt-3.5-turbo</code></td>
<td><code>gpt-3.5-turbo-0613</code></td>
<td>OpenAI</td>
<td>14644</td>
<td>2723</td>
</tr>
<tr>
<td><code>gpt-4</code></td>
<td><code>gpt-4-0613</code></td>
<td>OpenAI</td>
<td>7000</td>
<td>0</td>
</tr>
<tr>
<td><code>llama-2</code></td>
<td><code>meta-llama/Llama-2-70b-chat-hf</code></td>
<td>Meta</td>
<td>14644</td>
<td>2723</td>
</tr>
</tbody>
	</table>
</div>
<p>To load a specific version of the dataset, the <code>config_name</code> parameter can be used, as demonstrated in the following code snippet:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

train_data = load_dataset(<span class="hljs-string">"saifkhichi96/mpii-human-pose-captions"</span>, config_name=<span class="hljs-string">"gpt-4"</span>, split=<span class="hljs-string">"train"</span>)
</code></pre>
<p>This will load the training split of the dataset with pose descriptions generated by the <code>gpt-4-0613</code> model. Note that the <code>config_name</code> parameter is optional, and if not specified, the default version generated by <code>gpt-3.5-turbo-0301</code> will be loaded. Training captions for each config are unique. However, for the validation split, default captions are returned if the specified configuration does not have validation captions written by that model.</p>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-creation" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-creation">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Creation
	</span>
</h2>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#curation-rationale" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="curation-rationale">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Curation Rationale
	</span>
</h3>
<p>The dataset was curated to provide detailed captions for the images in the MPII Human Pose dataset, with text generated by different LLMs, each offering varying degrees of accuracy. These captions enable fine-grained understanding and analysis of human poses, activities, and object interactions within the images. Different versions of the dataset are available, tailored to different LLMs, to suit various research needs and use-cases.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#source-data" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="source-data">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Source Data
	</span>
</h3>
<p>Images for this dataset are sourced from the MPII Human Pose Dataset, available for <a rel="nofollow" href="https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz">download</a>. Raw annotations, transformed into JSON format by MMPose, are also used and can be accessed <a rel="nofollow" href="https://download.openmmlab.com/mmpose/datasets/mpii_annotations.tar">here</a>. While the images are not directly used for captioning, the annotations, containing human pose keypoints and activity labels, are vital in creating prompts for Large Language Models (LLMs). These prompts guide the LLMs in generating detailed captions. The final dataset is a fusion of these captions with the original MPII Human Pose Dataset annotations.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#annotations" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="annotations">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Annotations
	</span>
</h3>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#annotation-process" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="annotation-process">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Annotation process
	</span>
</h4>
<p>The pose descriptions were automatically generated by the LLMs based on the images from the MPII Human Pose Dataset. The annotations include not only textual descriptions but also specific details such as activity type, people count, and pose keypoints.</p>
<p>Human evaluation was also conducted on a subset of the dataset (100 samples), where human evaluators ranked the sentences in the textual descriptions on a scale from 1 (wrong) to 5 (perfect). This evaluation helped in understanding the relative accuracy and quality of the generated captions.</p>
<h4 class="relative group flex items-center">
	<a rel="nofollow" href="#who-are-the-annotators" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="who-are-the-annotators">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Who are the annotators?
	</span>
</h4>
<p>The pose descriptions were produced by different Large Language Models, each providing text with unique characteristics and levels of accuracy. This includes OpenAI's <code>gpt-3.5-turbo-0301</code>, <code>gpt-3.5-turbo-0613</code>, and <code>gpt-4-0613</code>, as well as Meta's <code>Llama-2-70b-chat-hf</code> accessed through HuggingFace. All other fields in the annotations come from the MMPose version of the original MPII Human Pose Dataset.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#personal-and-sensitive-information" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="personal-and-sensitive-information">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Personal and Sensitive Information
	</span>
</h3>
<p>The dataset does not contain personal or sensitive information. It is derived from public images of human poses and activities, and the descriptions were generated by language models without inclusion of any identifiable or private details.</p>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#considerations-for-using-the-data" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="considerations-for-using-the-data">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Considerations for Using the Data
	</span>
</h2>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#social-impact-of-dataset" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="social-impact-of-dataset">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Social Impact of Dataset
	</span>
</h3>
<p>The dataset has the potential to advance research and applications in various fields such as human pose estimation, activity recognition, human-computer interaction, sports analytics, healthcare, and more. By providing rich, descriptive captions generated by multiple LLMs, it enables diverse analyses and comparisons of models' understanding and interpretations of visual human activities.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#discussion-of-biases" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="discussion-of-biases">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Discussion of Biases
	</span>
</h3>
<p>As the pose descriptions are generated by various LLMs, biases inherent in these models could be reflected in the descriptions. These biases might include model-specific understanding or interpretations of activities, poses, or contexts within the images. Furthermore, the varying degrees of accuracy across different LLMs could introduce inconsistencies. Users should be aware of these aspects when utilizing the dataset and consider conducting a detailed analysis of potential biases for their specific use-cases.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#other-known-limitations" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="other-known-limitations">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Other Known Limitations
	</span>
</h3>
<p>Some limitations of the dataset include potential inaccuracies in textual descriptions due to the automated nature of the generation process by LLMs. There may also be disparities in the quality of captions across different models or for different types of activities or poses. Users should take these factors into account when using the dataset for training or evaluation purposes.</p>
<h2 class="relative group flex items-center">
	<a rel="nofollow" href="#additional-information" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="additional-information">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Additional Information
	</span>
</h2>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#dataset-curators" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="dataset-curators">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Dataset Curators
	</span>
</h3>
<p>The dataset was curated by researchers at the MindGarage Lab at the University of Kaiserslautern, Germany, which is a part of the Augmented Vision group at the German Research Center for Artificial Intelligence (DFKI).</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#licensing-information" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="licensing-information">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Licensing Information
	</span>
</h3>
<p>The dataset is licensed under the Simplified BSD License, which allows for free use, modification, and distribution of the dataset with proper attribution and compliance with the license terms.</p>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#citation-information" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="citation-information">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Citation Information
	</span>
</h3>
<pre><code class="language-bibtex">@misc{khan2024focusclipmultimodalsubjectlevelguidance,
      title={FocusCLIP: Multimodal Subject-Level Guidance for Zero-Shot Transfer in Human-Centric Tasks}, 
      author={Muhammad Saif Ullah Khan and Muhammad Ferjad Naeem and Federico Tombari and Luc Van Gool and Didier Stricker and Muhammad Zeshan Afzal},
      year={2024},
      eprint={2403.06904},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.06904}, 
}
</code></pre>
<h3 class="relative group flex items-center">
	<a rel="nofollow" href="#contributions" class="block pr-1.5 text-lg md:absolute md:p-1.5 md:opacity-0 md:group-hover:opacity-100 md:right-full" id="contributions">
		<span class="header-link"><svg viewBox="0 0 256 256" preserveAspectRatio="xMidYMid meet" height="1em" width="1em" role="img" aria-hidden="true" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" class="text-gray-500 hover:text-black dark:hover:text-gray-200 w-4"><path fill="currentColor" d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"></path></svg></span>
	</a>
	<span>
		Contributions
	</span>
</h3>
<p>To contribute to the dataset, please contact the dataset curator. We are particularly interested in more human evaluation of the dataset, and provide an online interface for this purpose. Please contact us if you are interested in contributing to this effort.</p>
<!-- HTML_TAG_END --></div>
</div></section>
			
			<section class="pt-6 border-gray-100 md:pb-24 md:pl-6 md:w-64 lg:w-80 xl:w-96 flex-none order-first md:order-none md:border-l pt-3! md:pt-6!"><dl class="flex items-baseline justify-between"><dt class="text-sm text-gray-500">Downloads last month</dt><div class="mx-4 flex-1 border-b border-dotted"></div><dd class="font-semibold">144</dd></dl>
				
				<div class="divider-column-vertical"></div>
				<div class="grid grid-cols-2 gap-x-2 md:flex md:flex-row md:flex-wrap"><div class="SVELTE_HYDRATER contents" data-target="DatasetAndModelActionsDropdown" data-props="{&quot;classNames&quot;:&quot;order-last&quot;,&quot;discussionsDisabled&quot;:false,&quot;repo&quot;:{&quot;type&quot;:&quot;dataset&quot;,&quot;name&quot;:&quot;saifkhichi96/mpii-human-pose-captions&quot;},&quot;doi&quot;:{&quot;id&quot;:&quot;10.57967/hf/1876&quot;,&quot;commit&quot;:&quot;1b7e8cee5fed55545e6dccaa3c03cdea5f1cb6e1&quot;},&quot;canWrite&quot;:false,&quot;canDisable&quot;:false,&quot;repoIsPrivate&quot;:false,&quot;repoIsGated&quot;:false,&quot;repoIsDisabled&quot;:false,&quot;repoIsAdminFlaggedNFAA&quot;:false,&quot;repoHasBlockedOids&quot;:false}"><div class="order-last"><div class="relative ">
	<button class="btn px-1.5 py-1.5 " type="button">
		
			<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="p-0.5" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><circle cx="16" cy="7" r="3" fill="currentColor"></circle><circle cx="16" cy="16" r="3" fill="currentColor"></circle><circle cx="16" cy="25" r="3" fill="currentColor"></circle></svg>
		
		</button>
	
	
	</div></div>















</div>
					<div class="SVELTE_HYDRATER contents" data-target="DatasetLibrary" data-props="{&quot;classNames&quot;:&quot;md:w-full xl:w-auto xl:flex-none&quot;,&quot;libraries&quot;:[{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;datasets&quot;,&quot;function&quot;:&quot;load_dataset&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;gpt-4&quot;,&quot;arguments&quot;:{&quot;config_name&quot;:&quot;gpt-4&quot;},&quot;code&quot;:&quot;from datasets import load_dataset\n\nds = load_dataset(\&quot;saifkhichi96/mpii-human-pose-captions\&quot;, \&quot;gpt-4\&quot;)&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;arguments&quot;:{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;},&quot;code&quot;:&quot;from datasets import load_dataset\n\nds = load_dataset(\&quot;saifkhichi96/mpii-human-pose-captions\&quot;, \&quot;gpt-3.5-turbo\&quot;)&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;arguments&quot;:{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;},&quot;code&quot;:&quot;from datasets import load_dataset\n\nds = load_dataset(\&quot;saifkhichi96/mpii-human-pose-captions\&quot;, \&quot;gpt-3.5-turbo-legacy\&quot;)&quot;},{&quot;config_name&quot;:&quot;llama-2&quot;,&quot;arguments&quot;:{&quot;config_name&quot;:&quot;llama-2&quot;},&quot;code&quot;:&quot;from datasets import load_dataset\n\nds = load_dataset(\&quot;saifkhichi96/mpii-human-pose-captions\&quot;, \&quot;llama-2\&quot;)&quot;}]},{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;pandas&quot;,&quot;function&quot;:&quot;pd.read_json&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;gpt-4&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-4-0613/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}},&quot;code&quot;:&quot;import pandas as pd\n\nsplits = {'train': 'gpt-4-0613/train.json', 'validation': 'gpt-3.5-turbo-0613/val.json'}\ndf = pd.read_json(\&quot;hf://datasets/saifkhichi96/mpii-human-pose-captions/\&quot; + splits[\&quot;train\&quot;])&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-3.5-turbo-0301/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0301/val.json&quot;}},&quot;code&quot;:&quot;import pandas as pd\n\nsplits = {'train': 'gpt-3.5-turbo-0301/train.json', 'validation': 'gpt-3.5-turbo-0301/val.json'}\ndf = pd.read_json(\&quot;hf://datasets/saifkhichi96/mpii-human-pose-captions/\&quot; + splits[\&quot;train\&quot;])&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-3.5-turbo-0613/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}},&quot;code&quot;:&quot;import pandas as pd\n\nsplits = {'train': 'gpt-3.5-turbo-0613/train.json', 'validation': 'gpt-3.5-turbo-0613/val.json'}\ndf = pd.read_json(\&quot;hf://datasets/saifkhichi96/mpii-human-pose-captions/\&quot; + splits[\&quot;train\&quot;])&quot;},{&quot;config_name&quot;:&quot;llama-2&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;llama-2-70b-chat-hf/train.json&quot;,&quot;validation&quot;:&quot;llama-2-70b-chat-hf/val.json&quot;}},&quot;code&quot;:&quot;import pandas as pd\n\nsplits = {'train': 'llama-2-70b-chat-hf/train.json', 'validation': 'llama-2-70b-chat-hf/val.json'}\ndf = pd.read_json(\&quot;hf://datasets/saifkhichi96/mpii-human-pose-captions/\&quot; + splits[\&quot;train\&quot;])&quot;}]},{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;mlcroissant&quot;,&quot;function&quot;:&quot;Dataset&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;gpt-4&quot;,&quot;arguments&quot;:{&quot;record_set&quot;:&quot;gpt-4&quot;,&quot;partial&quot;:false},&quot;code&quot;:&quot;from mlcroissant import Dataset\n\nds = Dataset(jsonld=\&quot;https://huggingface.co/api/datasets/saifkhichi96/mpii-human-pose-captions/croissant\&quot;)\nrecords = ds.records(\&quot;gpt-4\&quot;)&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;arguments&quot;:{&quot;record_set&quot;:&quot;gpt-3.5-turbo&quot;,&quot;partial&quot;:false},&quot;code&quot;:&quot;from mlcroissant import Dataset\n\nds = Dataset(jsonld=\&quot;https://huggingface.co/api/datasets/saifkhichi96/mpii-human-pose-captions/croissant\&quot;)\nrecords = ds.records(\&quot;gpt-3.5-turbo\&quot;)&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;arguments&quot;:{&quot;record_set&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;partial&quot;:false},&quot;code&quot;:&quot;from mlcroissant import Dataset\n\nds = Dataset(jsonld=\&quot;https://huggingface.co/api/datasets/saifkhichi96/mpii-human-pose-captions/croissant\&quot;)\nrecords = ds.records(\&quot;gpt-3.5-turbo-legacy\&quot;)&quot;},{&quot;config_name&quot;:&quot;llama-2&quot;,&quot;arguments&quot;:{&quot;record_set&quot;:&quot;llama-2&quot;,&quot;partial&quot;:false},&quot;code&quot;:&quot;from mlcroissant import Dataset\n\nds = Dataset(jsonld=\&quot;https://huggingface.co/api/datasets/saifkhichi96/mpii-human-pose-captions/croissant\&quot;)\nrecords = ds.records(\&quot;llama-2\&quot;)&quot;}]},{&quot;language&quot;:&quot;python&quot;,&quot;library&quot;:&quot;polars&quot;,&quot;function&quot;:&quot;pl.read_json&quot;,&quot;loading_codes&quot;:[{&quot;config_name&quot;:&quot;gpt-4&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-4-0613/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}},&quot;code&quot;:&quot;import polars as pl\n\nsplits = {'train': 'gpt-4-0613/train.json', 'validation': 'gpt-3.5-turbo-0613/val.json'}\ndf = pl.read_json('hf://datasets/saifkhichi96/mpii-human-pose-captions/' + splits['train'])\n&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo-legacy&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-3.5-turbo-0301/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0301/val.json&quot;}},&quot;code&quot;:&quot;import polars as pl\n\nsplits = {'train': 'gpt-3.5-turbo-0301/train.json', 'validation': 'gpt-3.5-turbo-0301/val.json'}\ndf = pl.read_json('hf://datasets/saifkhichi96/mpii-human-pose-captions/' + splits['train'])\n&quot;},{&quot;config_name&quot;:&quot;gpt-3.5-turbo&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;gpt-3.5-turbo-0613/train.json&quot;,&quot;validation&quot;:&quot;gpt-3.5-turbo-0613/val.json&quot;}},&quot;code&quot;:&quot;import polars as pl\n\nsplits = {'train': 'gpt-3.5-turbo-0613/train.json', 'validation': 'gpt-3.5-turbo-0613/val.json'}\ndf = pl.read_json('hf://datasets/saifkhichi96/mpii-human-pose-captions/' + splits['train'])\n&quot;},{&quot;config_name&quot;:&quot;llama-2&quot;,&quot;arguments&quot;:{&quot;splits&quot;:{&quot;train&quot;:&quot;llama-2-70b-chat-hf/train.json&quot;,&quot;validation&quot;:&quot;llama-2-70b-chat-hf/val.json&quot;}},&quot;code&quot;:&quot;import polars as pl\n\nsplits = {'train': 'llama-2-70b-chat-hf/train.json', 'validation': 'llama-2-70b-chat-hf/val.json'}\ndf = pl.read_json('hf://datasets/saifkhichi96/mpii-human-pose-captions/' + splits['train'])\n&quot;}]}]}"><div class="relative md:w-full xl:w-auto xl:flex-none">
	<button class="from-gray-800! to-black! max-xl:mb-2 text-white! gap-1! border-gray-800! dark:border-gray-900!  btn w-full cursor-pointer text-sm" type="button">
		<svg class="mr-1.5 mr-0.5! " xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32" style="transform: rotate(360deg);"><path d="M31 16l-7 7l-1.41-1.41L28.17 16l-5.58-5.59L24 9l7 7z" fill="currentColor"></path><path d="M1 16l7-7l1.41 1.41L3.83 16l5.58 5.59L8 23l-7-7z" fill="currentColor"></path><path d="M12.419 25.484L17.639 6l1.932.518L14.35 26z" fill="currentColor"></path></svg>
			Use this dataset
		<svg class="-mr-1 text-gray-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg></button>
	
	
	</div>

</div>
					
					</div>
				<div class="divider-column-vertical"></div>
					<div class="flex flex-col flex-wrap xl:flex-row"><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="https://www.saifkhichi.com/research/focusclip/" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Homepage:</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->saifkhichi.com<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="https://huggingface.co/datasets/saifkhichi96/mpii-human-pose-captions" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Repository:</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->huggingface.co<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="https://arxiv.org/abs/2403.06904" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Paper:</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->FocusCLIP: Multimodal Subject-Level Guidance for Zero-Shot Transfer in Human-Centric Tasks<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="mailto:muhammad_saif_ullah.khan@dfki.de" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Point of Contact:</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->Saif Khan<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 pointer-events-none" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Size of downloaded dataset files:</div>
		<div class="truncate text-sm ">
			<!-- HTML_TAG_START -->136 MB<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 " href="/datasets/saifkhichi96/mpii-human-pose-captions/tree/refs%2Fconvert%2Fparquet/" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Size of the auto-converted Parquet files:</div>
		<div class="truncate text-sm group-hover:underline">
			<!-- HTML_TAG_START -->38.3 MB<!-- HTML_TAG_END --></div></a><a class="bg-linear-to-r dark:via-none group mb-1.5 flex max-w-full flex-col overflow-hidden rounded-lg border border-gray-100 from-white via-white to-white px-2 py-1 hover:from-gray-50 dark:from-gray-900 dark:to-gray-925 dark:hover:to-gray-900 md:mr-1.5 pointer-events-none" rel="nofollow" target="_blank"><div class="truncate text-xs text-gray-400">Number of rows:</div>
		<div class="truncate text-sm ">
			<!-- HTML_TAG_START -->69,468<!-- HTML_TAG_END --></div></a></div>
				
				
				
				

				
				<div class="divider-column-vertical md:hidden"></div></section></div></main>

	<footer class="b-12 mb-2 flex border-t border-gray-100 md:h-14"><nav class="container relative flex flex-col justify-between space-y-2 py-6 text-gray-500 max-md:*:self-start md:flex-row md:items-center md:space-y-0 md:py-0 md:text-sm"><div class="SVELTE_HYDRATER contents" data-target="ThemeSwitcher" data-props="{&quot;theme&quot;:&quot;system&quot;,&quot;isLoggedIn&quot;:false,&quot;menuClassNames&quot;:&quot;md:-top-24&quot;,&quot;classNames&quot;:&quot;max-md:mb-5 max-md:*:self-start&quot;}">
<div class="relative inline-block max-md:mb-5 max-md:*:self-start">
	<button class="rounded-full border border-gray-100 pl-2 py-1 pr-2.5  flex items-center text-sm text-gray-500 bg-white hover:bg-purple-50 hover:border-purple-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 dark:border-gray-800 " type="button">
		<svg class="mr-1.5 text-gray-500" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6 22.5h20a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2H6a2 2 0 0 0-2 2v13.5a2 2 0 0 0 2 2ZM7 7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h18a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1H7Z" fill="currentColor"></path><path d="M6 8a1 1 0 0 1 1-1h18a1 1 0 0 1 1 1v11a1 1 0 0 1-1 1H7a1 1 0 0 1-1-1V8Z" fill="currentColor" fill-opacity=".4"></path><path d="M29 25H3a1 1 0 1 0 0 2h26a1 1 0 1 0 0-2Z" fill="currentColor"></path></svg>
			System theme
		</button>
	
	
	</div></div>
		<div class="font-semibold text-black md:hidden">Company</div>
		<a class="hover:underline" href="/terms-of-service">TOS</a>
		<a class="hover:underline" href="/privacy">Privacy</a>
		<a class="hover:underline" href="/huggingface">About</a>
		<a class="hover:underline" href="https://apply.workable.com/huggingface/">Jobs</a>
		<a href="/" class="max-md:mb-4! max-md:mt-8! group flex-none max-md:order-last"><svg class="h-7 w-7 transition-transform group-hover:-translate-y-px" viewBox="0 0 95 88" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5Z" fill="#FFD21E"></path><path d="M81.9619 41.75C81.9619 22.5581 66.4037 7 47.2119 7C28.02 7 12.4619 22.5581 12.4619 41.75C12.4619 60.9419 28.02 76.5 47.2119 76.5C66.4037 76.5 81.9619 60.9419 81.9619 41.75ZM8.46185 41.75C8.46185 20.349 25.8108 3 47.2119 3C68.6129 3 85.9619 20.349 85.9619 41.75C85.9619 63.151 68.6129 80.5 47.2119 80.5C25.8108 80.5 8.46185 63.151 8.46185 41.75Z" fill="#FF9D0B"></path><path d="M58.5024 32.2915C59.7768 32.7415 60.2839 35.3615 61.5713 34.6769C64.0095 33.3805 64.9351 30.353 63.6387 27.9148C62.3423 25.4767 59.3148 24.5511 56.8766 25.8475C54.4384 27.1439 53.5128 30.1714 54.8092 32.6096C55.4211 33.7604 57.3632 31.8892 58.5024 32.2915Z" fill="#3A3B45"></path><path d="M34.9454 32.2915C33.671 32.7415 33.164 35.3615 31.8766 34.6769C29.4384 33.3805 28.5128 30.353 29.8092 27.9148C31.1056 25.4767 34.1331 24.5511 36.5713 25.8475C39.0095 27.1439 39.9351 30.1714 38.6387 32.6096C38.0268 33.7604 36.0846 31.8892 34.9454 32.2915Z" fill="#3A3B45"></path><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="#3A3B45"></path><mask id="mask0" style="mask-type:alpha" maskUnits="userSpaceOnUse" x="33" y="41" width="27" height="16"><path d="M46.9619 56.289C56.7903 56.289 59.9619 47.5261 59.9619 43.0262C59.9619 40.6875 58.3898 41.4236 55.8718 42.6702C53.5449 43.8222 50.4102 45.4101 46.9619 45.4101C39.7822 45.4101 33.9619 38.5263 33.9619 43.0262C33.9619 47.5261 37.1334 56.289 46.9619 56.289Z" fill="white"></path></mask><g mask="url(#mask0)"><path d="M47.2119 66.5C52.0018 66.5 55.8848 62.617 55.8848 57.8271C55.8848 54.0962 53.5291 50.9156 50.224 49.6915C50.1023 49.6464 49.9794 49.604 49.8553 49.5643C49.0219 49.2979 48.1337 52.1623 47.2119 52.1623C46.3506 52.1623 45.5186 49.2797 44.7332 49.5135C41.151 50.5799 38.5389 53.8984 38.5389 57.8271C38.5389 62.617 42.4219 66.5 47.2119 66.5Z" fill="#F94040"></path></g><path d="M70.7119 37C72.5068 37 73.9619 35.5449 73.9619 33.75C73.9619 31.9551 72.5068 30.5 70.7119 30.5C68.9169 30.5 67.4619 31.9551 67.4619 33.75C67.4619 35.5449 68.9169 37 70.7119 37Z" fill="#FF9D0B"></path><path d="M24.2119 37C26.0068 37 27.4619 35.5449 27.4619 33.75C27.4619 31.9551 26.0068 30.5 24.2119 30.5C22.4169 30.5 20.9619 31.9551 20.9619 33.75C20.9619 35.5449 22.4169 37 24.2119 37Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M17.5238 48C15.9048 48 14.4578 48.665 13.4488 49.871C12.8248 50.618 12.1728 51.822 12.1198 53.625C11.4408 53.43 10.7878 53.321 10.1778 53.321C8.6278 53.321 7.2278 53.915 6.2378 54.994C4.9658 56.379 4.4008 58.081 4.6468 59.784C4.7638 60.595 5.0348 61.322 5.4398 61.995C4.5858 62.686 3.9568 63.648 3.6528 64.805C3.4148 65.712 3.1708 67.601 4.4448 69.547C4.3638 69.674 4.2878 69.806 4.2168 69.941C3.4508 71.395 3.4018 73.038 4.0778 74.568C5.1028 76.887 7.6498 78.714 12.5958 80.675C15.6728 81.895 18.4878 82.675 18.5128 82.682C22.5808 83.737 26.2598 84.273 29.4448 84.273C35.2988 84.273 39.4898 82.48 41.9018 78.944C45.7838 73.25 45.2288 68.042 40.2058 63.022C37.4258 60.244 35.5778 56.148 35.1928 55.249C34.4168 52.587 32.3648 49.628 28.9538 49.628H28.9528C28.6658 49.628 28.3758 49.651 28.0898 49.696C26.5958 49.931 25.2898 50.791 24.3568 52.085C23.3498 50.833 22.3718 49.837 21.4868 49.275C20.1528 48.429 18.8198 48 17.5238 48ZM17.5238 52C18.0338 52 18.6568 52.217 19.3438 52.653C21.4768 54.006 25.5928 61.081 27.0998 63.833C27.6048 64.755 28.4678 65.145 29.2448 65.145C30.7868 65.145 31.9908 63.612 29.3858 61.664C25.4688 58.733 26.8428 53.942 28.7128 53.647C28.7948 53.634 28.8758 53.628 28.9538 53.628C30.6538 53.628 31.4038 56.558 31.4038 56.558C31.4038 56.558 33.6018 62.078 37.3778 65.851C41.1538 69.625 41.3488 72.654 38.5968 76.69C36.7198 79.442 33.1268 80.273 29.4448 80.273C25.6258 80.273 21.7108 79.379 19.5168 78.81C19.4088 78.782 6.0658 75.013 7.7558 71.805C8.0398 71.266 8.5078 71.05 9.0968 71.05C11.4768 71.05 15.8058 74.592 17.6668 74.592C18.0828 74.592 18.3758 74.415 18.4958 73.983C19.2888 71.138 6.4388 69.942 7.5218 65.821C7.7128 65.092 8.2308 64.796 8.9588 64.797C12.1038 64.797 19.1598 70.328 20.6388 70.328C20.7518 70.328 20.8328 70.295 20.8768 70.225C21.6178 69.029 21.2118 68.194 15.9888 65.033C10.7658 61.871 7.0998 59.969 9.1848 57.699C9.4248 57.437 9.7648 57.321 10.1778 57.321C13.3488 57.322 20.8408 64.14 20.8408 64.14C20.8408 64.14 22.8628 66.243 24.0858 66.243C24.3668 66.243 24.6058 66.132 24.7678 65.858C25.6348 64.396 16.7148 57.636 16.2118 54.847C15.8708 52.957 16.4508 52 17.5238 52Z" fill="#FF9D0B"></path><path class="origin-bottom-right transition-transform group-hover:-rotate-6" d="M38.5967 76.6898C41.3487 72.6538 41.1537 69.6248 37.3777 65.8508C33.6017 62.0778 31.4037 56.5578 31.4037 56.5578C31.4037 56.5578 30.5827 53.3518 28.7127 53.6468C26.8427 53.9418 25.4697 58.7328 29.3867 61.6638C33.3037 64.5938 28.6067 66.5848 27.0997 63.8328C25.5927 61.0808 21.4777 54.0058 19.3437 52.6528C17.2107 51.2998 15.7087 52.0578 16.2117 54.8468C16.7147 57.6358 25.6357 64.3958 24.7677 65.8588C23.8997 67.3208 20.8407 64.1398 20.8407 64.1398C20.8407 64.1398 11.2687 55.4288 9.18465 57.6988C7.10065 59.9688 10.7657 61.8708 15.9887 65.0328C21.2127 68.1938 21.6177 69.0288 20.8767 70.2248C20.1347 71.4208 8.60465 61.6998 7.52165 65.8208C6.43965 69.9418 19.2887 71.1378 18.4957 73.9828C17.7027 76.8288 9.44465 68.5978 7.75565 71.8048C6.06565 75.0128 19.4087 78.7818 19.5167 78.8098C23.8267 79.9278 34.7727 82.2968 38.5967 76.6898Z" fill="#FFD21E"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M77.3999 48C79.0189 48 80.4659 48.665 81.4749 49.871C82.0989 50.618 82.7509 51.822 82.8039 53.625C83.4829 53.43 84.1359 53.321 84.7459 53.321C86.2959 53.321 87.6959 53.915 88.6859 54.994C89.9579 56.379 90.5229 58.081 90.2769 59.784C90.1599 60.595 89.8889 61.322 89.4839 61.995C90.3379 62.686 90.9669 63.648 91.2709 64.805C91.5089 65.712 91.7529 67.601 90.4789 69.547C90.5599 69.674 90.6359 69.806 90.7069 69.941C91.4729 71.395 91.5219 73.038 90.8459 74.568C89.8209 76.887 87.2739 78.714 82.3279 80.675C79.2509 81.895 76.4359 82.675 76.4109 82.682C72.3429 83.737 68.6639 84.273 65.4789 84.273C59.6249 84.273 55.4339 82.48 53.0219 78.944C49.1399 73.25 49.6949 68.042 54.7179 63.022C57.4979 60.244 59.3459 56.148 59.7309 55.249C60.5069 52.587 62.5589 49.628 65.9699 49.628H65.9709C66.2579 49.628 66.5479 49.651 66.8339 49.696C68.3279 49.931 69.6339 50.791 70.5669 52.085C71.5739 50.833 72.5519 49.837 73.4369 49.275C74.7709 48.429 76.1039 48 77.3999 48ZM77.3999 52C76.8899 52 76.2669 52.217 75.5799 52.653C73.4469 54.006 69.3309 61.081 67.8239 63.833C67.3189 64.755 66.4559 65.145 65.6789 65.145C64.1369 65.145 62.9329 63.612 65.5379 61.664C69.4549 58.733 68.0809 53.942 66.2109 53.647C66.1289 53.634 66.0479 53.628 65.9699 53.628C64.2699 53.628 63.5199 56.558 63.5199 56.558C63.5199 56.558 61.3219 62.078 57.5459 65.851C53.7699 69.625 53.5749 72.654 56.3269 76.69C58.2039 79.442 61.7969 80.273 65.4789 80.273C69.2979 80.273 73.2129 79.379 75.4069 78.81C75.5149 78.782 88.8579 75.013 87.1679 71.805C86.8839 71.266 86.4159 71.05 85.8269 71.05C83.4469 71.05 79.1179 74.592 77.2569 74.592C76.8409 74.592 76.5479 74.415 76.4279 73.983C75.6349 71.138 88.4849 69.942 87.4019 65.821C87.2109 65.092 86.6929 64.796 85.9649 64.797C82.8199 64.797 75.7639 70.328 74.2849 70.328C74.1719 70.328 74.0909 70.295 74.0469 70.225C73.3059 69.029 73.7119 68.194 78.9349 65.033C84.1579 61.871 87.8239 59.969 85.7389 57.699C85.4989 57.437 85.1589 57.321 84.7459 57.321C81.5749 57.322 74.0829 64.14 74.0829 64.14C74.0829 64.14 72.0609 66.243 70.8379 66.243C70.5569 66.243 70.3179 66.132 70.1559 65.858C69.2889 64.396 78.2089 57.636 78.7119 54.847C79.0529 52.957 78.4729 52 77.3999 52Z" fill="#FF9D0B"></path><path class="origin-bottom-left transition-transform group-hover:rotate-6" d="M56.3271 76.6898C53.5751 72.6538 53.7701 69.6248 57.5461 65.8508C61.3221 62.0778 63.5201 56.5578 63.5201 56.5578C63.5201 56.5578 64.3411 53.3518 66.2111 53.6468C68.0811 53.9418 69.4541 58.7328 65.5371 61.6638C61.6201 64.5938 66.3171 66.5848 67.8241 63.8328C69.3311 61.0808 73.4461 54.0058 75.5801 52.6528C77.7131 51.2998 79.2151 52.0578 78.7121 54.8468C78.2091 57.6358 69.2881 64.3958 70.1561 65.8588C71.0241 67.3208 74.0831 64.1398 74.0831 64.1398C74.0831 64.1398 83.6551 55.4288 85.7391 57.6988C87.8231 59.9688 84.1581 61.8708 78.9351 65.0328C73.7111 68.1938 73.3061 69.0288 74.0471 70.2248C74.7891 71.4208 86.3191 61.6998 87.4021 65.8208C88.4841 69.9418 75.6351 71.1378 76.4281 73.9828C77.2211 76.8288 85.4791 68.5978 87.1681 71.8048C88.8581 75.0128 75.5151 78.7818 75.4071 78.8098C71.0971 79.9278 60.1511 82.2968 56.3271 76.6898Z" fill="#FFD21E"></path></svg></a>
		<div class="max-md:mt-8! font-semibold text-black md:hidden">Website</div>

		<a class="hover:underline" href="/models">Models</a>
		<a class="hover:underline" href="/datasets">Datasets</a>
		<a class="hover:underline" href="/spaces">Spaces</a>
		<a class="hover:underline" href="/pricing">Pricing</a>
		<a class="hover:underline" href="/docs">Docs</a></nav></footer></div>

		<script>
			import("\/front\/build\/kube-68d7aa0\/index.js");
			window.moonSha = "kube-68d7aa0\/";
			window.__hf_deferred = {};
		</script>

		<!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>
	</body>
</html>
