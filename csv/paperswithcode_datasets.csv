dataset_id,dataset_name,description,source_url,license,modalities,languages,year_published,paper_title,paper_url,dataset_size,dataset_splits,num_classes,associated_tasks,benchmark_urls,pwc_url
10000-people-human-pose-recognition-data,"10,000 People - Human Pose Recognition Data Dataset","Description:
10,000 People - Human Pose Recognition Data. This dataset includes indoor and outdoor scenes.This dataset covers males and females. Age distribution ranges from teenager to the elderly, the middle-aged and young people are the majorities. The data diversity includes different shooting heights, different ages, different light conditions, different collecting environment, clothes in different seasons, multiple human poses. For each subject, the labels of gender, race, age, collecting environment and clothes were annotated. The data can be used for human pose recognition and other tasks.

Data size:
10,000 people

Race distribution:
Asian (Chinese)",https://production-media.paperswithcode.com/datasets/da76c793-ff57-4d89-90bf-ec04e02fe149.png,EditCommercial license,"3D, Image, Video",,,,,,,,"Pose Tracking, Object Detection, Contrastive Learning, Pose Estimation","object-detection-on-10000-people-human-pose, contrastive-learning-on-10000-people-human",
300w,300W Dataset,"The 300-W is a face dataset that consists of 300 Indoor and 300 Outdoor in-the-wild images. It covers a large variation of identity, expression, illumination conditions, pose, occlusion and face size. The images were downloaded from google.com by making queries such as “party”, “conference”, “protests”, “football” and “celebrities”. Compared to the rest of in-the-wild datasets, the 300-W database contains a larger percentage of partially-occluded images and covers more expressions than the common “neutral” or “smile”, such as “surprise” or “scream”.
Images were annotated with the 68-point mark-up using a semi-automatic methodology. The images of the database were carefully selected so that they represent a characteristic sample of challenging but natural face instances under totally unconstrained conditions. Thus, methods that achieve accurate performance on the 300-W database can demonstrate the same accuracy in most realistic cases.
Many images of the database contain more than one annotated faces (293 images with 1 face, 53 images with 2 faces and 53 images with [3, 7] faces). Consequently, the database consists of 600 annotated face instances, but 399 unique images. Finally, there is a large variety of face sizes. Specifically, 49.3% of the faces have size in the range [48.6k, 2.0M] and the overall mean size is 85k (about 292 × 292) pixels.",https://ibug.doc.ic.ac.uk/media/uploads/documents/sagonas_2016_imavis.pdf,"EditCustom (research-only, non-commercial)","3D, Image",,,,,293 images,"tests”, “football” and “celebrities”. Compared to the rest of in-the-wild datasets, the 300-W database contains a larger percentage of partially-occluded images",,"Face Alignment, Unsupervised Facial Landmark Detection, Facial Landmark Detection, 2D Pose Estimation, 3D Reconstruction, Pose Estimation","facial-landmark-detection-on-300w, unsupervised-facial-landmark-detection-on, pose-estimation-on-300w-full, face-alignment-on-300w-split-2-300w-lp, 2d-pose-estimation-on-300w, 3d-reconstruction-on-300w, face-alignment-on-300w, facial-landmark-detection-on-300w-full, face-alignment-on-300w-split-2",
3dpw,3DPW Dataset,"The 3D Poses in the Wild dataset is the first dataset in the wild with accurate 3D poses for evaluation. While other datasets outdoors exist, they are all restricted to a small recording volume. 3DPW is the first one that includes video footage taken from a moving phone camera.

The dataset includes:


60 video sequences.
2D pose annotations.
3D poses obtained with the method introduced in the paper.
Camera poses for every frame in the sequences.
3D body scans and 3D people models (re-poseable and re-shapeable). Each sequence contains its corresponding models.
18 3D models in different clothing variations.",http://virtualhumans.mpi-inf.mpg.de/3DPW,"EditCustom (research-only, non-commercial)","3D, Image, Time Series",,,,,,,,"Human Pose Forecasting, 3D Human Pose Estimation, Hand Pose Estimation, Pose Estimation, Cross-domain 3D Human Pose Estimation","3d-human-pose-estimation-on-3dpw, pose-estimation-on-3dpw, human-pose-forecasting-on-3dpw, cross-domain-3d-human-pose-estimation-on-3dpw, hand-pose-estimation-on-3dpw",
amass,AMASS Dataset,"AMASS is a large database of human motion unifying different optical marker-based motion capture datasets by representing them within a common framework and parameterization. AMASS is readily useful for animation, visualization, and generating training data for deep learning.",https://production-media.paperswithcode.com/datasets/Screenshot_2021-01-28_at_14.25.22.png,"EditCustom (research-only, non-commercial)","3D, Image, Time Series",,,,,,,,"Human Pose Forecasting, 3D Human Pose Estimation, Pose Estimation",human-pose-forecasting-on-amass,
bdd100k,BDD100K Dataset,"Datasets drive vision progress, yet existing driving datasets are impoverished in terms of visual content and supported tasks to study multitask learning for autonomous driving. Researchers are usually constrained to study a small set of problems on one dataset, while real-world computer vision applications require performing tasks of various complexities. We construct BDD100K, the largest driving video dataset with 100K videos and 10 tasks to evaluate the exciting progress of image recognition algorithms on autonomous driving. The dataset possesses geographic, environmental, and weather diversity, which is useful for training models that are less likely to be surprised by new conditions. Based on this diverse dataset, we build a benchmark for heterogeneous multitask learning and study how to solve the tasks together. Our experiments show that special training strategies are needed for existing models to perform such heterogeneous tasks. BDD100K opens the door for future studies in this important venue. More detail is at the dataset home page.",https://production-media.paperswithcode.com/datasets/bdd.gif,EditMixed License,"Image, Video",,,,,,,,"Image Classification, 2D Object Detection, Multiple Object Track and Segmentation, Amodal Panoptic Segmentation, Multi-Object Tracking and Segmentation, Traffic Object Detection, Multiple Object Tracking, Drivable Area Detection, Panoptic Segmentation, Instance Segmentation, Video Instance Segmentation, Multi-Object Tracking, Lane Detection, Domain Adaptation, Steering Control, Semantic Segmentation, Object Detection, Video Segmentation, Semi-Supervised Instance Segmentation","2d-object-detection-on-bdd100k-val, instance-segmentation-on-bdd100k-val, object-detection-on-bdd100k, steering-control-on-bdd100k-val, multi-object-tracking-on-bdd100k, multiple-object-tracking-on-bdd100k-val, semantic-segmentation-on-bdd100k-val, amodal-panoptic-segmentation-on-bdd100k-val, traffic-object-detection-on-bdd100k-val, lane-detection-on-bdd100k-val, multiple-object-tracking-on-bdd100k-test-1, drivable-area-detection-on-bdd100k-val, object-detection-on-bdd100k-val, multiple-object-track-and-segmentation-on-2, multi-object-tracking-and-segmentation-on-3, video-instance-segmentation-on-bdd100k-val",
coco,MS COCO Dataset,"The MS COCO (Microsoft Common Objects in Context) dataset is a large-scale object detection, segmentation, key-point detection, and captioning dataset. The dataset consists of 328K images.

Splits:
The first version of MS COCO dataset was released in 2014. It contains 164K images split into training (83K), validation (41K) and test (41K) sets. In 2015 additional test set of 81K images was released, including all the previous test images and 40K new images.

Based on community feedback, in 2017 the training/validation split was changed from 83K/41K to 118K/5K. The new split uses the same images and annotations. The 2017 test set is a subset of 41K images of the 2015 test set. Additionally, the 2017 release contains a new unannotated dataset of 123K images.

Annotations:
The dataset has annotations for


object detection: bounding boxes and per-instance segmentation masks with 80 object categories,
captioning: natural language descriptions of the images (see MS COCO Captions),
keypoints detection: containing more than 200,000 images and 250,000 person instances labeled with keypoints (17 possible keypoints, such as left eye, nose, right hip, right ankle),
stuff image segmentation – per-pixel segmentation masks with 91 stuff categories, such as grass, wall, sky (see MS COCO Stuff),
panoptic: full scene segmentation, with 80 thing categories (such as person, bicycle, elephant) and a subset of 91 stuff categories (grass, sky, road),
dense pose: more than 39,000 images and 56,000 person instances labeled with DensePose annotations – each labeled person is annotated with an instance id and a mapping between image pixels that belong to that person body and a template 3D model.
The annotations are publicly available only for training and validation images.",https://cocodataset.org/,EditCustom,"3D, Graph, Image, Text",English,2014,,,328K images,"split into training (83K), validation (41K) and test (41K) sets. In 2015 additional test set of 81K images",,"Homography Estimation, Generalized Zero-Shot Object Detection, Scene Graph Generation, Image Captioning, Few-Shot Object Detection, Unsupervised Object Localization, Few Shot Open Set Object Detection, Visual Question Answering, Object Localization, Unsupervised Semantic Segmentation, Quantization, Object Proposal Generation, One-Shot Instance Segmentation, Paraphrase Generation, Real-Time Object Detection, Open World Object Detection, Zero-shot Text-to-Image Retrieval, One-Shot Object Detection, Semi Supervised Learning for Image Captioning, Interactive Segmentation, Visual Question Answering (VQA), Multi-Label Image Classification, Conditional Image Generation, Point-Supervised Instance Segmentation, mage-to-Text Retrieval, Multi-Label Learning, Question Answering, Active Object Detection, Image Outpainting, Layout-to-Image Generation, Open Vocabulary Object Detection, Image-to-Text Retrieval, Panoptic Segmentation, Weakly Supervised Object Detection, Activeness Detection, Robust Object Detection, Single-object discovery, Region Proposal, Instance Segmentation, Keypoint Detection, Text-to-Image Generation, Question Generation, Zero-Shot Object Detection, Zero-Shot Cross-Modal Retrieval, Knowledge Distillation, Unsupervised Semantic Segmentation with Language-image Pre-training, Multi-Label Classification, Semantic Segmentation, Image Retrieval, Multi-Person Pose Estimation, Real-time Instance Segmentation, Weakly-supervised instance segmentation, Multi-object discovery, Cross-Modal Retrieval, Object Detection, Box-supervised Instance Segmentation, Pose Estimation, Object Counting, Zero-Shot Composed Image Retrieval (ZS-CIR), Image-level Supervised Instance Segmentation","instance-segmentation-on-coco-minval, question-answering-on-coco-visual-question, pose-estimation-on-ms-coco, mage-to-text-retrieval-on-mscoco, open-vocabulary-object-detection-on-mscoco, cross-modal-retrieval-on-coco-2014, layout-to-image-generation-on-coco-stuff-4, object-detection-on-coco-1, visual-question-answering-on-coco, keypoint-detection-on-coco, object-detection-on-coco-5, visual-question-answering-on-coco-visual-4, pose-estimation-on-coco, image-outpainting-on-mscoco, object-proposal-generation-on-coco, image-retrieval-on-coco, image-retrieval-on-mscoco, region-proposal-on-coco-test-dev, zero-shot-composed-image-retrieval-zs-cir-on-4, weakly-supervised-object-detection-on-mscoco, pose-estimation-on-coco-minival, image-level-supervised-instance-segmentation-1, zero-shot-text-to-image-retrieval-on-ms-coco, panoptic-segmentation-on-coco-panoptic, pose-estimation-on-coco-test-dev, semantic-segmentation-on-coco-1, point-supervised-instance-segmentation-on-1, few-shot-object-detection-on-ms-coco-10-shot, real-time-instance-segmentation-on-mscoco, text-to-image-generation-on-ms-coco, cross-modal-retrieval-on-mscoco, pose-estimation-on-densepose-coco, image-to-text-retrieval-on-coco, one-shot-instance-segmentation-on-coco, single-object-discovery-on-coco-20k, box-supervised-instance-segmentation-on-coco, visual-question-answering-on-coco-visual-5, scene-graph-generation-on-ms-coco, text-to-image-generation-on-coco, active-object-detection-on-coco, interactive-segmentation-on-coco, open-world-object-detection-on-coco-2017-2, image-captioning-on-mscoco-1, weakly-supervised-object-detection-on-coco-2, image-captioning-on-coco, question-generation-on-coco-visual-question, object-detection-on-mscoco-6, zero-shot-object-detection-on-ms-coco, unsupervised-semantic-segmentation-with-5, instance-segmentation-on-coco, knowledge-distillation-on-coco, zero-shot-object-detection-on-mscoco, generalized-zero-shot-object-detection-on-ms, keypoint-detection-on-coco-test-dev, paraphrase-generation-on-mscoco, multi-person-pose-estimation-on-coco-test-dev, object-counting-on-coco-count-test, zero-shot-cross-modal-retrieval-on-coco-2014, panoptic-segmentation-on-coco-minival, interactive-segmentation-on-coco-minival, few-shot-object-detection-on-coco-2017, object-detection-on-coco, multi-label-classification-on-ms-coco, one-shot-object-detection-on-coco, unsupervised-semantic-segmentation-on-coco-1, object-detection-on-coco-2017, multi-person-pose-estimation-on-coco, open-world-object-detection-on-coco-2017, image-captioning-on-ms-coco, homography-estimation-on-coco-2014, multi-person-pose-estimation-on-coco-minival, panoptic-segmentation-on-coco-test-dev, visual-question-answering-on-coco-visual, multi-object-discovery-on-coco-20k, robust-object-detection-on-coco, real-time-instance-segmentation-on-mscoco-1k, instance-segmentation-on-coco-minival, object-detection-on-coco-minival, few-shot-open-set-object-detection-on-mscoco, conditional-image-generation-on-coco-animals, weakly-supervised-object-detection-on-coco, quantization-on-coco, unsupervised-object-localization-on-coco-20k, keypoint-detection-on-coco-test-challenge, cross-modal-retrieval-on-mscoco-1k, multi-label-learning-on-coco-2014, visual-question-answering-on-coco-visual-1, visual-question-answering-on-coco-visual-2, object-detection-on-mscoco-7, visual-question-answering-on-coco-visual-3, open-world-object-detection-on-coco-2017-1, multi-label-image-classification-on-mscoco, semi-supervised-learning-for-image-captioning, weakly-supervised-instance-segmentation-on-2, activeness-detection-on-coco-test-dev, real-time-object-detection-on-coco",
densepose,DensePose Dataset,"DensePose-COCO is a large-scale ground-truth dataset with image-to-surface correspondences manually annotated
on 50K COCO images and train DensePose-RCNN, to densely regress part-specific UV coordinates within every human
region at multiple frames per second.",https://arxiv.org/pdf/1802.00434v1.pdf,EditCC BY-NC 2.0,"3D, Image, Text",English,,,,,,,"3D Human Pose Estimation, Pose Estimation, Image Generation",,
gqa,GQA Dataset,"The GQA dataset is a large-scale visual question answering dataset with real images from the Visual Genome dataset and balanced question-answer pairs. Each training and validation image is also associated with scene graph annotations describing the classes and attributes of those objects in the scene, and their pairwise relations. Along with the images and question-answer pairs, the GQA dataset provides two types of pre-extracted visual features for each image – convolutional grid features of size 7×7×2048 extracted from a ResNet-101 network trained on ImageNet, and object detection features of size Ndet×2048 (where Ndet is the number of detected objects in each image with a maximum of 100 per image) from a Faster R-CNN detector.",https://arxiv.org/abs/1905.04405,EditCC BY 4.0,"Graph, Image, Text",English,2048,,,,"training and validation image is also associated with scene graph annotations describing the classes and attributes of those objects in the scene, and their pairwise relations. Along with the images",,"Scene Graph Generation, Visual Question Answering (VQA), Visual Question Answering, Object Detection, Graph Question Answering","visual-question-answering-on-gqa, visual-question-answering-on-gqa-1, scene-graph-generation-on-gqa, visual-question-answering-on-gqa-test-dev, object-detection-on-gqa, graph-question-answering-on-gqa, visual-question-answering-on-gqa-test-std, visual-question-answering-on-gqa-test2019",
jhmdb,JHMDB Dataset,"JHMDB is an action recognition dataset that consists of 960 video sequences belonging to 21 actions. It is a subset of the larger HMDB51 dataset collected from digitized movies and YouTube videos. The dataset contains video and annotation for puppet flow per frame (approximated optimal flow on the person), puppet mask per frame, joint positions per frame, action label per clip and meta label per clip (camera motion, visible body parts, camera viewpoint, number of people, video quality).",https://arxiv.org/abs/2008.09880,EditUnknown,"3D, Image, Video",,,,,,,,"Skeleton Based Action Recognition, 2D Human Pose Estimation, Referring Expression Segmentation, Action Detection, Pose Estimation","2d-human-pose-estimation-on-jhmdb-2d-poses, skeleton-based-action-recognition-on-jhmdb-2d, skeleton-based-action-recognition-on-jhmdb, skeleton-based-action-recognition-on-j-hmbd, action-detection-on-j-hmdb, referring-expression-segmentation-on-j-hmdb, pose-estimation-on-j-hmdb, skeleton-based-action-recognition-on-j-hmdb",
kitti,KITTI Dataset,"KITTI (Karlsruhe Institute of Technology and Toyota Technological Institute) is one of the most popular datasets for use in mobile robotics and autonomous driving. It consists of hours of traffic scenarios recorded with a variety of sensor modalities, including high-resolution RGB, grayscale stereo cameras, and a 3D laser scanner. Despite its popularity, the dataset itself does not contain ground truth for semantic segmentation. However, various researchers have manually annotated parts of the dataset to fit their necessities. Álvarez et al. generated ground truth for 323 images from the road detection challenge with three classes: road, vertical, and sky. Zhang et al. annotated 252 (140 for training and 112 for testing) acquisitions – RGB and Velodyne scans – from the tracking challenge for ten object categories: building, sky, road, vegetation, sidewalk, car, pedestrian, cyclist, sign/pole, and fence. Ros et al. labeled 170 training images and 46 testing images (from the visual odometry challenge) with 11 classes: building, tree, sky, car, sign, road, pedestrian, fence, pole, sidewalk, and bicyclist.",https://arxiv.org/abs/1704.06857,EditCC BY-NC-SA 3.0,"3D, Image, Text, Time Series, Video",English,,,,323 images,"training and 112 for testing) acquisitions – RGB and Velodyne scans – from the tracking challenge for ten object categories: building, sky, road, vegetation, sidewalk, car, pedestrian, cyclist, sign/pole, and fence. Ros et al. labeled 170 training images",11,"Monocular Cross-View Road Scene Parsing(Road), Visual Place Recognition, Dense Pixel Correspondence Estimation, Stereo Disparity Estimation, Scene Flow Estimation, Text-To-SQL, Unsupervised Monocular Depth Estimation, Horizon Line Estimation, Object Localization, 3D Object Tracking, Image Super-Resolution, Monocular Depth Estimation, Object Tracking, Stereo Depth Estimation, Vehicle Pose Estimation, Monocular Cross-View Road Scene Parsing(Vehicle), Optical Flow Estimation, Depth Completion, Image to Point Cloud Registration, 3D Object Detection From Stereo Images, Multiple Object Tracking, Visual Odometry, Video Prediction, Depth Prediction, Point Cloud Registration, Image Clustering, Image Dehazing, Panoptic Segmentation, 3D Single Object Tracking, Monocular 3D Object Detection, Stereo Image Super-Resolution, Scene Generation, Image-to-Image Translation, Knowledge Distillation, Unsupervised Object Detection, Semantic Segmentation, Transfer Learning, Real-time Instance Segmentation, Egocentric Pose Estimation, Prediction Of Occupancy Grid Maps, Object Detection, 3D Object Detection, Novel View Synthesis, Pose Estimation, Depth Estimation, Birds Eye View Object Detection","monocular-3d-object-detection-on-kitti-7, stereo-image-super-resolution-on-kitti2015-4x, monocular-3d-object-detection-on-kitti-5, 3d-object-detection-on-kitti-cars-easy, 3d-object-detection-on-kitti-cyclists-easy, 3d-object-detection-on-kitti-pedestrians-1, pose-estimation-on-kitti-2015, object-localization-on-kitti-pedestrian-easy, image-super-resolution-on-kitti-2012-4x, stereo-depth-estimation-on-kitti2012, visual-place-recognition-on-kitti, depth-estimation-on-kitti-2015, stereo-image-super-resolution-on-kitti2015-2x, depth-estimation-on-kitti-eigen-split-3, object-localization-on-kitti-cyclists-easy, 3d-object-detection-on-kitti-cyclists-1, object-detection-on-kitti-cars-moderate, image-super-resolution-on-kitti-2015-2x, stereo-image-super-resolution-on-kitti2012-2x-1, monocular-depth-estimation-on-kitti-object, birds-eye-view-object-detection-on-kitti-16, object-localization-on-kitti-cars-moderate, image-dehazing-on-kitti, birds-eye-view-object-detection-on-kitti-4, real-time-instance-segmentation-on-kitti, novel-view-synthesis-on-kitti, birds-eye-view-object-detection-on-kitti-17, vehicle-pose-estimation-on-kitti, birds-eye-view-object-detection-on-kitti-cars-5, 3d-object-detection-on-kitti-cyclist-easy-val, birds-eye-view-object-detection-on-kitti-13, stereo-disparity-estimation-on-kitti-2015, point-cloud-registration-on-kitti, novel-view-synthesis-on-kitti-novel-view, optical-flow-estimation-on-kitti-2015-train, 3d-object-detection-on-kitti-cyclist-moderate, vehicle-pose-estimation-on-kitti-cars-hard, semantic-segmentation-on-kitti-semantic, monocular-3d-object-detection-on-kitti-4, birds-eye-view-object-detection-on-kitti-cars, birds-eye-view-object-detection-on-kitti-7, monocular-cross-view-road-scene-parsing-road-1, object-tracking-on-kitti, object-detection-on-kitti-cyclists-hard, 3d-object-detection-from-stereo-images-on-3, egocentric-pose-estimation-on-kitti-odometry, 3d-object-detection-on-kitti-pedestrian-2, scene-flow-estimation-on-kitti-2015-scene-1, object-detection-on-kitti-pedestrians, birds-eye-view-object-detection-on-kitti-cars-3, 3d-object-detection-on-kitti-pedestrians, object-localization-on-kitti-pedestrians, monocular-cross-view-road-scene-parsing-road, 3d-object-detection-on-kitti-pedestrians-easy, test-results-on-kitti, stereo-depth-estimation-on-kitti2015, object-detection-on-kitti-cars-easy, birds-eye-view-object-detection-on-kitti-11, object-detection-on-kitti-pedestrians-hard, optical-flow-estimation-on-kitti-2015-2, unsupervised-object-detection-on-kitti, monocular-3d-object-detection-on-kitti, birds-eye-view-object-detection-on-kitti-2, video-prediction-on-kitti, object-localization-on-kitti-cyclists, transfer-learning-on-kitti-object-tracking, 3d-object-detection-on-kitti-pedestrian-easy-1, monocular-3d-object-detection-on-kitti-cars-2, stereo-image-super-resolution-on-kitti2012-4x, scene-flow-estimation-on-kitti-2015-scene, stereo-image-super-resolution-on-kitti2012-2x-2, 3d-object-detection-from-stereo-images-on-1, 3d-object-detection-on-kitti-pedestrians-hard, birds-eye-view-object-detection-on-kitti-cars-4, object-localization-on-kitti-cars-hard, text-to-sql-on-2d-kitti-cars-easy, birds-eye-view-object-detection-on-kitti-12, image-to-image-translation-on-kitti-object, monocular-3d-object-detection-on-kitti-1, optical-flow-estimation-on-kitti-2012, object-detection-on-kitti-cyclists-moderate, image-super-resolution-on-kitti-2015-4x, knowledge-distillation-on-kitti, object-localization-on-kitti-pedestrians-hard, 3d-object-detection-on-kitti-pedestrian-hard-1, monocular-3d-object-detection-on-kitti-6, point-cloud-registration-on-kitti-fcgf, birds-eye-view-object-detection-on-kitti-9, unsupervised-monocular-depth-estimation-on-4, depth-completion-on-kitti, image-clustering-on-kitti, panoptic-segmentation-on-kitti-panoptic-1, horizon-line-estimation-on-kitti-horizon, stereo-depth-estimation-on-kitti-2015, 3d-object-detection-on-kitti-cyclists-hard, birds-eye-view-object-detection-on-kitti-cars-2, dense-pixel-correspondence-estimation-on-1, image-to-point-cloud-registration-on-kitti, monocular-depth-estimation-on-kitti-eigen, 3d-object-detection-on-kitti-cars-hard-val, birds-eye-view-object-detection-on-kitti-3, 3d-object-detection-on-kitti-cars-easy-val, 3d-object-detection-from-stereo-images-on-2, monocular-depth-estimation-on-kitti-2, object-localization-on-kitti-pedestrians-easy, birds-eye-view-object-detection-on-kitti-8, object-localization-on-kitti-cyclists-hard, optical-flow-estimation-on-kitti-2012-2, object-detection-on-kitti-pedestrians-easy, optical-flow-estimation-on-kitti-2015, birds-eye-view-object-detection-on-kitti-1, stereo-image-super-resolution-on-kitti2012-2x-3, dense-pixel-correspondence-estimation-on-2, multiple-object-tracking-on-kitti-test-online, image-super-resolution-on-kitti-2012-2x, point-cloud-registration-on-kitti-trained-on, 3d-object-detection-on-kitti-cyclists, 3d-object-detection-on-kitti-pedestrian-hard, scene-generation-on-kitti, birds-eye-view-object-detection-on-kitti-6, monocular-depth-estimation-on-kitti-eigen-1, object-localization-on-kitti-cars-easy, 3d-object-detection-on-kitti-cyclist-hard-val, monocular-3d-object-detection-on-kitti-cars, monocular-3d-object-detection-on-kitti-cars-1, depth-prediction-on-kitti-2015, birds-eye-view-object-detection-on-kitti-cars-1, birds-eye-view-object-detection-on-kitti-10, 3d-object-detection-on-kitti-pedestrian-easy, 3d-object-detection-on-kitti-pedestrian-1, unsupervised-monocular-depth-estimation-on-5, unsupervised-monocular-depth-estimation-on-1, 3d-object-detection-on-kitti-pedestrian, multiple-object-tracking-on-kitti-test, birds-eye-view-object-detection-on-kitti, object-detection-on-kitti-cars-hard, monocular-cross-view-road-scene-parsing, object-detection-on-kitti-cyclists-easy, 3d-object-detection-on-kitti-cars-hard, 3d-object-detection-on-kitti-cars-moderate-1, birds-eye-view-object-detection-on-kitti-5, monocular-3d-object-detection-on-kitti-3",
lvis,LVIS Dataset,LVIS is a dataset for long tail instance segmentation. It has annotations for over 1000 object categories in 164k images.,https://arxiv.org/pdf/1908.03195.pdf,EditCustom (CC BY 4.0 + COCO license),Image,English,,,,164k images,,,"Novel Object Detection, Instance Segmentation, Few-Shot Object Detection, Zero-Shot Instance Segmentation, Zero-Shot Object Detection, Long-tailed Object Detection, Object Detection, Open Vocabulary Object Detection, Unsupervised Object Detection","few-shot-object-detection-on-lvis-v1-0-val, instance-segmentation-on-lvis-v1-0-test-dev, zero-shot-object-detection-on-lvis-v1-0-val, instance-segmentation-on-lvis-v1-0-val, few-shot-object-detection-on-lvis-v1-0-test, object-detection-on-lvis-v1-0-minival, zero-shot-instance-segmentation-on-lvis-v1-0, object-detection-on-lvis-v1-0-1, unsupervised-object-detection-on-lvis-v1-0, object-detection-on-lvis-v1-0-val, long-tailed-object-detection-on-lvis-v1-0-val, novel-object-detection-on-lvis-v1-0-val, open-vocabulary-object-detection-on-lvis-v1-0, zero-shot-object-detection-on-lvis-v1-0",
manga109,Manga109 Dataset,"Manga109 has been compiled by the Aizawa Yamasaki Matsui Laboratory, Department of Information and Communication Engineering, the Graduate School of Information Science and Technology, the University of Tokyo. The compilation is intended for use in academic research on the media processing of Japanese manga. Manga109 is composed of 109 manga volumes drawn by professional manga artists in Japan. These manga were commercially made available to the public between the 1970s and 2010s, and encompass a wide range of target readerships and genres (see the table in Explore for further details.) Most of the manga in the compilation are available at the manga library “Manga Library Z” (formerly the “Zeppan Manga Toshokan” library of out-of-print manga).",http://www.manga109.org/en/,"EditCustom (Manga109: research-only, non-commercial. Manga109-s: available for commercial use under appropriate conditions.)",Image,Japanese,,,,,,,"Blind Super-Resolution, Object Detection, Image Super-Resolution, Face Detection, Body Detection","blind-super-resolution-on-manga109-2x, blind-super-resolution-on-manga109-4x, image-super-resolution-on-manga109-16x, object-detection-on-manga109-s-15test, image-super-resolution-on-manga109-2x, body-detection-on-manga109, blind-super-resolution-on-manga109-3x, image-super-resolution-on-manga109-3x, image-super-resolution-on-manga109-8x, face-detection-on-manga109, image-super-resolution-on-manga109-4x, object-detection-on-manga109",
mpii,MPII Dataset,"The MPII Human Pose Dataset for single person pose estimation is composed of about 25K images of which 15K are training samples, 3K are validation samples and 7K are testing samples (which labels are withheld by the authors). The images are taken from YouTube videos covering 410 different human activities and the poses are manually annotated with up to 16 body joints.",https://arxiv.org/abs/1802.09232,EditSimplified BSD,"3D, Image, Time Series, Video",English,,,,25K images,"training samples, 3K are validation samples",,"Keypoint Detection, Temporal Action Localization, Multi-Person Pose Estimation, Pose Estimation","keypoint-detection-on-mpii-multi-person, pose-estimation-on-mpii, multi-person-pose-estimation-on-mpii-multi, pose-estimation-on-mpii-single-person",
nuscenes,nuScenes Dataset,"The nuScenes dataset is a large-scale autonomous driving dataset. The dataset has 3D bounding boxes for 1000 scenes collected in Boston and Singapore. Each scene is 20 seconds long and annotated at 2Hz. This results in a total of 28130 samples for training, 6019 samples for validation and 6008 samples for testing. The dataset has the full autonomous vehicle data suite: 32-beam LiDAR, 6 cameras and radars with complete 360° coverage. The 3D object detection challenge evaluates the performance on 10 classes: cars, trucks, buses, trailers, construction vehicles, pedestrians, motorcycles, bicycles, traffic cones and barriers.",https://arxiv.org/abs/1911.10150,EditCustom (CC BY-NC-SA 4.0 with exceptions for startups and research; separate commercial licenses),"3D, Image, Time Series, Video",English,,,,28130 samples,"training, 6019 samples",10,"Motion Detection, Trajectory Planning, Bird's-Eye View Semantic Segmentation, Semi-Supervised Semantic Segmentation, Weather Forecasting, Trajectory Prediction, Instance Segmentation, Monocular 3D Object Detection, Online Vectorized HD Map Construction, LIDAR Semantic Segmentation, 3D Multi-Object Tracking, HD semantic map learning, Lane Detection, 3D Semantic Segmentation, Weakly supervised Semantic Segmentation, Prediction Of Occupancy Grid Maps, Object Detection, 3D Object Detection, Motion Planning","trajectory-planning-on-nuscenes, weakly-supervised-semantic-segmentation-on-9, 3d-object-detection-on-nuscenes-camera-only, object-detection-on-nuscenes, trajectory-prediction-on-nuscenes, lidar-semantic-segmentation-on-nuscenes, bird-s-eye-view-semantic-segmentation-on, 3d-object-detection-on-nuscenes, 3d-object-detection-on-nuscenes-camera-radar, prediction-of-occupancy-grid-maps-on-nuscenes, online-vectorized-hd-map-construction-on, 3d-multi-object-tracking-on-nuscenes, motion-planning-on-nuscenes, hd-semantic-map-learning-on-nuscenes, semi-supervised-semantic-segmentation-on-25, instance-segmentation-on-nuscenes, 3d-multi-object-tracking-on-nuscenes-camera-2, 3d-multi-object-tracking-on-nuscenes-camera-1, lane-detection-on-nuscenes, 3d-semantic-segmentation-on-nuscenes, motion-detection-on-nuscenes, monocular-3d-object-detection-on-nuscenes",
object-detection,Object Detection,Object detection is the task of identifying an object in an image.,https://github.com/PaddlePaddle/PaddleDetection,,"3D, Graph, Image, Text, Video",English,,,,,,,"Object Detection In Aerial Images, Camouflaged Object Segmentation, Few-Shot Object Detection, License Plate Detection, Dense Object Detection, Malaria Vivax Detection, Fracture detection, Object Proposal Generation, Body Detection, Object Detection In Indoor Scenes, Zero-Shot Scene Graph Generation, Real-Time Object Detection, Open World Object Detection, One-Shot Object Detection, Fish Detection, Semantic Part Detection, Medical Object Detection, Moving Object Detection, Surgical tool detection, Small Object Detection, Weakly Supervised 3D Detection, Open Vocabulary Object Detection, Weakly Supervised Object Detection, Described Object Detection, Head Detection, Robust Object Detection, Co-Salient Object Detection, 3D Object Detection From Monocular Images, Malaria Ovale Detection, Multiview Detection, RGB Salient Object Detection, Zero-Shot Object Detection, Video Object Detection, Multiple Affordance Detection, Malaria Malariae Detection, Class-agnostic Object Detection, Pupil Detection, Object Skeleton Detection, Malaria Falciparum Detection, 3D Object Detection, RGB-D Salient Object Detection, Video Salient Object Detection","object-detection-on-nao, object-detection-on-eventped, object-detection-on-sixray, object-detection-on-nuscenes, object-detection-on-sfchd, object-detection-on-flir, object-detection-on-cisol-track-a-td-tsr, object-detection-on-coco-1, object-detection-on-bigdetection-val, object-detection-on-pascal-voc-to-clipart1k, object-detection-on-texbig-2023-test, object-detection-on-songdo-vision, object-detection-on-tbbr, object-detection-on-a2d, object-detection-on-oodis, object-detection-on-coco-5, object-detection-on-aodraw, object-detection-on-pascal-voc-2007-15-5, object-detection-on-sar-aircraft-1-0, object-detection-on-inoutdoor, object-detection-on-evd4uav, object-detection-on-kitti-cars-moderate, object-detection-on-manga109-s-15test, object-detection-on-ai-tod, object-detection-on-vedai, object-detection-on-bdd100k-val, object-detection-on-cppe-5, object-detection-on-pascal-voc-to, object-detection-on-pascal-voc-10, object-detection-on-sa-det-100k, object-detection-on-mju-waste, object-detection-on-coco-val2017, object-detection-on-spacenet-2, object-detection-on-cityscapes-to-foggy, object-detection-on-kitti-cyclists-hard, object-detection-on-crowdhuman, object-detection-on-clipart1k, object-detection-on-kitti-pedestrians, object-detection-on-odinw-full-shot-13-tasks, object-detection-on-pascal-voc, object-detection-on-kitti-cars-easy, object-detection-on-multispectral-dataset, object-detection-on-kitti-pedestrians-hard, object-detection-on-peopleart, object-detection-on-visdrone-10-labeled-data, object-detection-on-4, object-detection-on-sun-rgbd-val, object-detection-on-a-dataset-of, object-detection-on-pascal-voc-2007, object-detection-on-coco-2017-val, object-detection-on-openimages-v6, object-detection-on-extended-taco-1, object-detection-on-grazpedwri-dx, object-detection-on-manga109, object-detection-on-pku-ddd17-car, object-detection-on-ldd, object-detection-on-comic2k, object-detection-on-ua-detrac, object-detection-on-llvip, object-detection-on-drinking-waste, object-detection-on-crowdhuman-full-body, object-detection-on-pku-ddd17-car-1, object-detection-on-gqa, object-detection-on-elevater, object-detection-on-pascal-voc-2012-test, object-detection-on-kitti-cyclists-moderate, object-detection-on-aquatrash, object-detection-on-muses-multi-sensor, object-detection-on-mscoco-6, object-detection-on-dsec, object-detection-on-lvis-v1-0-minival, object-detection-on-shel5k-1, object-detection-on-waymo-2d-detection-all-ns-1, object-detection-on-isaid, object-detection-on-plad, object-detection-on-odinw-full-shot-35-tasks, object-detection-on-uavdt, object-detection-on-coco-11, object-detection-on-widerperson, object-detection-on-citypersons, object-detection-on-coco, object-detection-on-visual-genome, object-detection-on-pascal-voc-to-comic2k, object-detection-on-deeptrash, object-detection-on-coco-o, object-detection-on-visdrone-1-labeled-data, object-detection-on-coco-2017, object-detection-on-industreal, object-detection-on-pascal-part-2010-animals, object-detection-on-10000-people-human-pose, object-detection-on-spacenet-1, object-detection-on-stcrowd, object-detection-on-visdrone-5-labeled-data, object-detection-on-uavvaste, object-detection-on-waymo-2d-detection-all-ns, object-detection-on-objects365, object-detection-on-coco-minival, object-detection-on-kitti-pedestrians-easy, object-detection-on-pascal-voc-2012, object-detection-on-waterscenes, object-detection-on-extragalactic-planetary, object-detection-on-watercolor2k, object-detection-on-gmot-40, object-detection-on-waymo-open-dataset, object-detection-on-nii-cu-mapd, object-detection-on-c2a-human-detection-in, object-detection-on-flickrlogos-32, object-detection-on-bdd100k, object-detection-on-seadronessee, object-detection-on-lvis-v1-0-val, object-detection-on-cisol-track-b-tsr-only, object-detection-on-leukemiaattri, object-detection-on-mscoco-7, object-detection-on-drone-vs-bird, object-detection-on-gen1-detection, object-detection-on-extended-taco-7, object-detection-on-kitti-cars-hard, object-detection-on-kitti-cyclists-easy, object-detection-on-texbig-2022-test, object-detection-on-visdrone-det2019-1, object-detection-on-lvis-v1-0-1, object-detection-on-india-driving-dataset, object-detection-on-usb-standard-usb-1-0",
pascal3d-2,PASCAL3D+ Dataset,"The Pascal3D+ multi-view dataset consists of images in the wild, i.e., images of object categories exhibiting high variability, captured under uncontrolled settings, in cluttered scenes and under many different poses. Pascal3D+ contains 12 categories of rigid objects selected from the PASCAL VOC 2012 dataset. These objects are annotated with pose information (azimuth, elevation and distance to camera). Pascal3D+ also adds pose annotated images of these 12 categories from the ImageNet dataset.",https://arxiv.org/abs/1511.05175,EditUnknown,"3D, Image",,2012,,,,,12,"Keypoint Detection, Object Detection, Viewpoint Estimation, Pose Estimation",keypoint-detection-on-pascal3d,
pose-estimation,Pose Estimation,"**Pose Estimation** is a computer vision task where the goal is to detect the position and orientation of a person or an object. Usually, this is done by predicting the location of specific keypoints like hands, head, elbows, etc. in case of Human Pose Estimation.



A common benchmark for this task is [MPII Human Pose](https://paperswithcode.com/sota/pose-estimation-on-mpii-human-pose)



<span style=""color:grey; opacity: 0.6"">( Image credit: [Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose](https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch) )</span>",https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch,,"3D, Image, Time Series",,,,,,,,"Activeness Detection, 6D Pose Estimation using RGBD, RF-based Pose Estimation, Multi-Person Pose Estimation, 3D Pose Estimation, Human Pose Forecasting, Keypoint Detection, 6D Pose Estimation using RGB, 6D Pose Estimation, Hand Joint Reconstruction, 3D Human Pose Estimation, Head Pose Estimation, Animal Pose Estimation, Vehicle Pose Estimation, Semi-supervised 2D and 3D landmark labeling, Hand Pose Estimation, Car Pose Estimation","pose-estimation-on-300w-full, pose-estimation-on-coco-test-dev, pose-estimation-on-ms-coco, pose-estimation-on-uav-human, pose-estimation-on-inloc, pose-estimation-on-coco-2017-val, pose-estimation-on-densepose-coco, pose-estimation-on-3dpw, pose-estimation-on-j-hmdb, pose-estimation-on-kitti-2015, pose-estimation-on-crowdpose, pose-estimation-on-itop-top-view, pose-estimation-on-upenn-action, pose-estimation-on-mpii-human-pose, pose-estimation-on-coco-val2017, pose-estimation-on-flic-wrists, pose-estimation-on-mpii-single-person, pose-estimation-on-2, pose-estimation-on-mpii, pose-estimation-on-salsa, pose-estimation-on-coco, pose-estimation-on-brace, pose-estimation-on-merl-rav, pose-estimation-on-pix3d, pose-estimation-on-ochuman, pose-estimation-on-aic, pose-estimation-on-itop-front-view, pose-estimation-on-apollocar3d, pose-estimation-on-leeds-sports-poses, pose-estimation-on-coco-minival, pose-estimation-on-flic-elbows",
sun-rgb-d,SUN RGB-D Dataset,"The SUN RGBD dataset contains 10335 real RGB-D images of room scenes. Each RGB image has a corresponding depth and segmentation map. As many as 700 object categories are labeled. The training and testing sets contain 5285 and 5050 images, respectively.",https://arxiv.org/abs/1903.04294,EditUnknown,"3D, Image",,,,,5050 images,training and testing sets contain 5285 and 5050 images,,"Object Detection In Indoor Scenes, Panoptic Segmentation, Scene Recognition, Semantic Segmentation, Room Layout Estimation, Monocular 3D Object Detection, Robust Semi-Supervised RGBD Semantic Segmentation, Scene Classification (unified classes), Object Detection, 3D Object Detection, Monocular Depth Estimation, Panoptic Segmentation (PanopticNDT instances), Scene Segmentation","monocular-depth-estimation-on-sun-rgbd, monocular-3d-object-detection-on-sun-rgb-d, 3d-object-detection-on-sun-rgbd, panoptic-segmentation-panopticndt-instances, robust-semi-supervised-rgbd-semantic-1, room-layout-estimation-on-sun-rgb-d, scene-recognition-on-sun-rgbd, object-detection-in-indoor-scenes-on-sun-rgb, object-detection-on-sun-rgbd-val, scene-segmentation-on-sun-rgbd, panoptic-segmentation-on-sun-rgbd, 3d-object-detection-on-sun-rgbd-val, scene-classification-unified-classes-on-sun, semantic-segmentation-on-sun-rgbd",
visual-genome,Visual Genome Dataset,"Visual Genome contains Visual Question Answering data in a multi-choice setting. It consists of 101,174 images from MSCOCO with 1.7 million QA pairs, 17 questions per image on average. Compared to the Visual Question Answering dataset, Visual Genome represents a more balanced distribution over 6 question types: What, Where, When, Who, Why and How. The Visual Genome dataset also presents 108K images with densely annotated objects, attributes and relationships.",https://arxiv.org/abs/1903.12314,EditCC BY 4.0,"Graph, Image, Text",English,,,,174 images,,,"Visual Relationship Detection, Unsupervised KG-to-Text Generation, Scene Graph Generation, Bidirectional Relationship Classification, Visual Question Answering (VQA), Phrase Grounding, Unsupervised semantic parsing, Dense Captioning, Object Detection, Image Generation from Scene Graphs, Multi-label Image Recognition with Partial Labels, Layout-to-Image Generation, Scene Graph Classification, Unbiased Scene Graph Generation, Scene Graph Detection, Predicate Classification","phrase-grounding-on-visual-genome, unbiased-scene-graph-generation-on-visual, multi-label-image-recognition-with-partial-2, image-generation-from-scene-graphs-on-visual, visual-question-answering-on-visual-genome-1, object-detection-on-visual-genome, layout-to-image-generation-on-visual-genome-3, layout-to-image-generation-on-visual-genome-2, unsupervised-semantic-parsing-on-vg-graph, dense-captioning-on-visual-genome, predicate-classification-on-visual-genome, scene-graph-classification-on-visual-genome, unsupervised-kg-to-text-generation-on-vg, scene-graph-generation-on-visual-genome, layout-to-image-generation-on-visual-genome-4, bidirectional-relationship-classification-on, scene-graph-detection-on-visual-genome, visual-relationship-detection-on-visual, visual-question-answering-on-visual-genome",
waymo-open-dataset,Waymo Open Dataset Dataset,"The Waymo Open Dataset is comprised of high resolution sensor data collected by autonomous vehicles operated by the Waymo Driver in a wide variety of conditions. 

The Waymo Open Dataset currently contains 1,950 segments. The authors plan to grow this dataset in the future. Currently the datasets includes:


1,950 segments of 20s each, collected at 10Hz (390,000 frames) in diverse geographies and conditions
Sensor data
1 mid-range lidar
4 short-range lidars
5 cameras (front and sides)
Synchronized lidar and camera data
Lidar to camera projections
Sensor calibrations and vehicle poses


Labeled data
Labels for 4 object classes - Vehicles, Pedestrians, Cyclists, Signs
High-quality labels for lidar data in 1,200 segments
12.6M 3D bounding box labels with tracking IDs on lidar data
High-quality labels for camera data in 1,000 segments
11.8M 2D bounding box labels with tracking IDs on camera data",https://production-media.paperswithcode.com/datasets/waymo.jpg,EditCustom (non-commercial),"3D, Image, Video",,,,,,,,"3D Object Detection From Monocular Images, 3D Semantic Segmentation, Multiple Object Tracking, Autonomous Driving, Video Object Detection, 3D Multi-Object Tracking, 3D Human Pose Estimation, Object Detection, 3D Object Detection","3d-object-detection-on-waymo-cyclist, 3d-object-detection-on-waymo-open-dataset, 3d-object-detection-on-waymo-vehicle, 3d-object-detection-on-waymo-all-ns, 3d-object-detection-on-waymo-pedestrian, object-detection-on-waymo-2d-detection-all-ns, object-detection-on-waymo-open-dataset, 3d-object-detection-from-monocular-images-on-6, object-detection-on-waymo-2d-detection-all-ns-1, 3d-multi-object-tracking-on-waymo-open-1, 3d-semantic-segmentation-on-waymo-open, 3d-multi-object-tracking-on-waymo-open, video-object-detection-on-waymo-open-dataset, multiple-object-tracking-on-waymo-open, 3d-human-pose-estimation-on-waymo-open",
